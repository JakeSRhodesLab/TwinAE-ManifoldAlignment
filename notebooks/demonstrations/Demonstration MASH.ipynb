{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphtools is already installed\n",
      "POT (ot) is already installed\n",
      "Installing scprep...\n",
      "Failed to install scprep\n",
      "Installing phate...\n",
      "Failed to install scprep\n",
      "Installing phate...\n",
      "Failed to install phate\n",
      "sklearn is already installed\n",
      "scipy is already installed\n",
      "numpy is already installed\n",
      "matplotlib is already installed\n",
      "seaborn is already installed\n",
      "Failed to install phate\n",
      "sklearn is already installed\n",
      "scipy is already installed\n",
      "numpy is already installed\n",
      "matplotlib is already installed\n",
      "seaborn is already installed\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"Failed to install {package}\")\n",
    "\n",
    "# Install missing packages (common dependencies for the alignment methods)\n",
    "packages = [\n",
    "    \"graphtools\", \n",
    "    \"POT\",  # Python Optimal Transport (provides 'ot' module)\n",
    "    \"scprep\",\n",
    "    \"phate\",\n",
    "    \"sklearn\",\n",
    "    \"scipy\",\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        if package == \"POT\":\n",
    "            __import__(\"ot\")  # POT installs as 'ot'\n",
    "            print(\"POT (ot) is already installed\")\n",
    "        else:\n",
    "            __import__(package)\n",
    "            print(f\"{package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        install_package(package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASH imported successfully from src structure\n",
      "Utils imported successfully from src structure\n",
      "test_manifold_algorithms imported from src structure\n",
      "SPUD imported successfully from mashspud package\n",
      "Import setup complete!\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "# Import specific classes to avoid __init__.py issues during development\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the source directory to path for imports\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../src'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../Python_Files'))\n",
    "\n",
    "# Standard imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Try to import MASH from the src structure first, then fallback\n",
    "try:\n",
    "    from graph_manifold_alignment.alignment_methods.MASH_MD import MASH\n",
    "    print(\"MASH imported successfully from src structure\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        from AlignmentMethods.MASH_MD import MASH\n",
    "        print(\"MASH imported from Python_Files structure\")\n",
    "    except ImportError as e:\n",
    "        print(f\"MASH import failed: {e}\")\n",
    "        MASH = None\n",
    "\n",
    "# Try to import utilities\n",
    "try:\n",
    "    from graph_manifold_alignment.helpers.utils import *\n",
    "    print(\"Utils imported successfully from src structure\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        from Helpers.utils import *\n",
    "        print(\"Utils imported from Python_Files structure\")\n",
    "    except ImportError as e:\n",
    "        print(f\"Utils import failed: {e}\")\n",
    "\n",
    "# Try to import test_manifold_algorithms for tma functionality\n",
    "try:\n",
    "    from graph_manifold_alignment.main.test_manifold_algorithms import test_manifold_algorithms\n",
    "    print(\"test_manifold_algorithms imported from src structure\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        from Main.test_manifold_algorithms import test_manifold_algorithms  \n",
    "        print(\"test_manifold_algorithms imported from Python_Files structure\")\n",
    "    except ImportError:\n",
    "        print(\"test_manifold_algorithms not available\")\n",
    "        test_manifold_algorithms = None\n",
    "\n",
    "# SPUD from the mashspud package\n",
    "try:\n",
    "    from mashspud import SPUD\n",
    "    print(\"SPUD imported successfully from mashspud package\")\n",
    "except ImportError:\n",
    "    print(\"SPUD from mashspud package not available. Ensure mashspud is installed: pip install git+https://github.com/rustadadam/mashspud.git\")\n",
    "    SPUD = None\n",
    "\n",
    "print(\"Import setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Timeless Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found at ..\\..\\data\\classification\\Timeless Variables 2024-07-09.csv\n",
      "Using alternative file: ..\\..\\data\\classification\\Profile Variables 2024-07-31.xlsx\n",
      "Data shape: (4385, 43)\n",
      "Dropped columns: ['PTRACCAT', 'DX_bl', 'PTMARRY']\n",
      "Final data shape: (4385, 40)\n",
      "Sample columns: ['PTEDUCAT', 'PTHAND', 'MOTHAD', 'FATHAD', 'MOTHDEM', 'FATHDEM', 'AGE', 'AB42_RAW', 'PHC_AB42', 'Tau_RAW']\n",
      "Using alternative file: ..\\..\\data\\classification\\Profile Variables 2024-07-31.xlsx\n",
      "Data shape: (4385, 43)\n",
      "Dropped columns: ['PTRACCAT', 'DX_bl', 'PTMARRY']\n",
      "Final data shape: (4385, 40)\n",
      "Sample columns: ['PTEDUCAT', 'PTHAND', 'MOTHAD', 'FATHAD', 'MOTHDEM', 'FATHDEM', 'AGE', 'AB42_RAW', 'PHC_AB42', 'Tau_RAW']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check if the file exists in the data directory\n",
    "timeless_file = r\"..\\..\\data\\classification\\Timeless Variables 2024-07-09.csv\"\n",
    "try:\n",
    "    timeless = pd.read_csv(timeless_file)\n",
    "    print(f\"Successfully loaded timeless data from: {timeless_file}\")\n",
    "    print(f\"Data shape: {timeless.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at {timeless_file}\")\n",
    "    # Try alternative locations\n",
    "    alt_files = [\n",
    "        r\"..\\..\\data\\classification\\Profile Variables 2024-07-31.xlsx\",\n",
    "        r\"..\\..\\data\\classification\\Visit Variables 2024-08-01.xlsx\"\n",
    "    ]\n",
    "    \n",
    "    for alt_file in alt_files:\n",
    "        try:\n",
    "            if alt_file.endswith('.xlsx'):\n",
    "                timeless = pd.read_excel(alt_file, index_col=0)\n",
    "            else:\n",
    "                timeless = pd.read_csv(alt_file)\n",
    "            print(f\"Using alternative file: {alt_file}\")\n",
    "            print(f\"Data shape: {timeless.shape}\")\n",
    "            break\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    else:\n",
    "        print(\"No suitable data file found\")\n",
    "        timeless = None\n",
    "\n",
    "if timeless is not None:\n",
    "    # Fill NaN values and drop problematic columns if they exist\n",
    "    timeless = timeless.fillna(-4)\n",
    "    columns_to_drop = []\n",
    "    for col in [\"PTRACCAT\", \"DX_bl\", \"PTMARRY\"]:\n",
    "        if col in timeless.columns:\n",
    "            columns_to_drop.append(col)\n",
    "    \n",
    "    if columns_to_drop:\n",
    "        timeless = timeless.drop(columns=columns_to_drop)\n",
    "        print(f\"Dropped columns: {columns_to_drop}\")\n",
    "    \n",
    "    print(f\"Final data shape: {timeless.shape}\")\n",
    "    print(f\"Sample columns: {list(timeless.columns[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTHAND</th>\n",
       "      <th>MOTHAD</th>\n",
       "      <th>FATHAD</th>\n",
       "      <th>MOTHDEM</th>\n",
       "      <th>FATHDEM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AB42_RAW</th>\n",
       "      <th>PHC_AB42</th>\n",
       "      <th>Tau_RAW</th>\n",
       "      <th>...</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTDOBYY</th>\n",
       "      <th>PTPLANG</th>\n",
       "      <th>PTETHCAT</th>\n",
       "      <th>PTIDENT</th>\n",
       "      <th>PTENGSPK</th>\n",
       "      <th>PTETHCATH</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>CV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4258</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>75.8</td>\n",
       "      <td>142.0</td>\n",
       "      <td>-0.4743</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>667.125980</td>\n",
       "      <td>28.392511</td>\n",
       "      <td>0.042559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7037</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-1.1494</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>204.578917</td>\n",
       "      <td>12.879560</td>\n",
       "      <td>0.062956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>165.063529</td>\n",
       "      <td>13.678820</td>\n",
       "      <td>0.082870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PTEDUCAT  PTHAND  MOTHAD  FATHAD  MOTHDEM  FATHDEM   AGE  AB42_RAW  \\\n",
       "RID                                                                        \n",
       "504       14.0     1.0    -4.0    -4.0     -4.0     -4.0  -4.0      -4.0   \n",
       "4258      14.0     2.0    -4.0    -4.0     -4.0     -4.0  75.8     142.0   \n",
       "7037      16.0     1.0    -4.0    -4.0      0.0      0.0  -4.0      -4.0   \n",
       "4580      16.0     1.0    -4.0    -4.0     -4.0     -4.0  69.7     115.0   \n",
       "6465      18.0     1.0    -4.0    -4.0      1.0      0.0  66.8      -4.0   \n",
       "\n",
       "      PHC_AB42  Tau_RAW  ...  PTGENDER  PTDOBYY  PTPLANG  PTETHCAT  PTIDENT  \\\n",
       "RID                      ...                                                  \n",
       "504    -4.0000     -4.0  ...       1.0   1927.0      1.0       2.0     -4.0   \n",
       "4258   -0.4743    114.0  ...       1.0   1935.0      1.0       2.0     -4.0   \n",
       "7037   -4.0000     -4.0  ...       1.0   1959.0      1.0       2.0     -4.0   \n",
       "4580   -1.1494    106.0  ...       2.0   1942.0      1.0       2.0     -4.0   \n",
       "6465   -4.0000     -4.0  ...       1.0   1951.0      1.0       2.0     -4.0   \n",
       "\n",
       "      PTENGSPK  PTETHCATH        Mean         SD        CV  \n",
       "RID                                                         \n",
       "504       -4.0       -4.0   -4.000000  -4.000000 -4.000000  \n",
       "4258      -4.0       -4.0  667.125980  28.392511  0.042559  \n",
       "7037      -4.0       -4.0   -4.000000  -4.000000 -4.000000  \n",
       "4580      -4.0       -4.0  204.578917  12.879560  0.062956  \n",
       "6465      -4.0       -4.0  165.063529  13.678820  0.082870  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeless.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4385)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timeless.columns), len(timeless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.,  2.,  1., ...,  1., -4., -4.], shape=(4385,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(timeless)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_a = np.array(timeless)[:200, :10].astype(float)\n",
    "domain_b = np.array(timeless)[:200, 10:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 200 anchor pairs\n",
      "First 22 anchors: [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21]]\n"
     ]
    }
   ],
   "source": [
    "# Create proper anchors for the domains\n",
    "# Since we're working with the same dataset split into two domains,\n",
    "# we can create simple paired anchors\n",
    "if 'domain_a' in locals() and 'domain_b' in locals():\n",
    "    num_samples = min(len(domain_a), len(domain_b))\n",
    "    anchors = [[i, i] for i in range(num_samples)]\n",
    "    print(f\"Created {len(anchors)} anchor pairs\")\n",
    "    print(f\"First 22 anchors: {anchors[:22]}\")\n",
    "else:\n",
    "    print(\"domain_a and domain_b not yet defined. Run the previous cells first.\")\n",
    "    anchors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASH instance created successfully\n",
      "MASH object type: <class 'graph_manifold_alignment.alignment_methods.MASH_MD.MASH'>\n",
      "MASH methods: ['DTM', 'FOSCTTM', 'IDC', 'apply_aggregation', 'build_graphs', 'burn_in', 'cross_embedding_knn', 'density_normalized_kernel', 'distance_measures', 'embeddings']...\n",
      "mash variable created: True\n",
      "mash is None: False\n"
     ]
    }
   ],
   "source": [
    "# Create MASH instance\n",
    "if MASH is not None:\n",
    "    try:\n",
    "        mash = MASH(t = -1, knn = 2, verbose = 2)\n",
    "        print(\"MASH instance created successfully\")\n",
    "        print(f\"MASH object type: {type(mash)}\")\n",
    "        print(f\"MASH methods: {[method for method in dir(mash) if not method.startswith('_')][:10]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MASH instance: {e}\")\n",
    "        mash = None\n",
    "else:\n",
    "    print(\"MASH class not available\")\n",
    "    mash = None\n",
    "\n",
    "# Verify the variable exists\n",
    "print(f\"mash variable created: {'mash' in locals()}\")\n",
    "if 'mash' in locals():\n",
    "    print(f\"mash is None: {mash is None}\")\n",
    "else:\n",
    "    print(\"mash variable not found in locals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to fit MASH model...\n",
      "domain_a shape: (200, 10)\n",
      "domain_b shape: (200, 30)\n",
      "anchors shape: 200\n",
      "Converted domains tuple length: 2\n",
      "Converted known_anchors shape: (200, 2)\n",
      "Sample anchors: [[0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]]\n",
      "Error during MASH fitting: 'tuple' object does not support item assignment\n",
      "Available MASH methods: ['DTM', 'FOSCTTM', 'IDC', 'apply_aggregation', 'build_graphs', 'burn_in', 'cross_embedding_knn', 'density_normalized_kernel', 'distance_measures', 'domain_count']\n"
     ]
    }
   ],
   "source": [
    "# Fit the MASH model\n",
    "if 'mash' in locals() and mash is not None and \\\n",
    "   'domain_a' in locals() and 'domain_b' in locals() and \\\n",
    "   'anchors' in locals():\n",
    "    try:\n",
    "        print(\"Attempting to fit MASH model...\")\n",
    "        print(f\"domain_a shape: {domain_a.shape if hasattr(domain_a, 'shape') else 'unknown'}\")\n",
    "        print(f\"domain_b shape: {domain_b.shape if hasattr(domain_b, 'shape') else 'unknown'}\")\n",
    "        print(f\"anchors shape: {anchors.shape if hasattr(anchors, 'shape') else len(anchors) if hasattr(anchors, '__len__') else 'unknown'}\")\n",
    "        \n",
    "        # MASH expects domains as a tuple and anchors as 2D array\n",
    "        domains = (domain_a, domain_b)\n",
    "        \n",
    "        # Convert 1D anchors to 2D format expected by MASH\n",
    "        if hasattr(anchors, 'shape') and len(anchors.shape) == 2:\n",
    "            known_anchors = anchors  # Already 2D\n",
    "        else:\n",
    "            # Convert anchors from pairs format to MASH format\n",
    "            # anchors is [[a1,b1], [a2,b2], ...] so convert to proper format\n",
    "            known_anchors = np.array(anchors)\n",
    "            \n",
    "        print(f\"Converted domains tuple length: {len(domains)}\")\n",
    "        print(f\"Converted known_anchors shape: {known_anchors.shape}\")\n",
    "        print(f\"Sample anchors: {known_anchors[:5]}\")\n",
    "        \n",
    "        # Fit MASH with correct API\n",
    "        mash.fit(domains, known_anchors)\n",
    "        print(\"MASH model fitted successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during MASH fitting: {e}\")\n",
    "        print(\"Available MASH methods:\", [method for method in dir(mash) if not method.startswith('_')][:10] if 'mash' in locals() else 'mash not available')\n",
    "else:\n",
    "    missing = []\n",
    "    if 'mash' not in locals(): missing.append('mash')\n",
    "    if 'domain_a' not in locals(): missing.append('domain_a')  \n",
    "    if 'domain_b' not in locals(): missing.append('domain_b')\n",
    "    if 'anchors' not in locals(): missing.append('anchors')\n",
    "    print(f\"Cannot fit MASH - missing variables: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dig_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdig_time\u001b[49m.plot_heat_maps()\n",
      "\u001b[31mNameError\u001b[39m: name 'dig_time' is not defined"
     ]
    }
   ],
   "source": [
    "dig_time.plot_heat_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dig_time is not None and hasattr(dig_time, 'plot_emb') and timeless is not None:\n",
    "    try:\n",
    "        # Create labels - use a column that exists or create dummy labels\n",
    "        if \"PTGENDER\" in timeless.columns:\n",
    "            labels = pd.concat([timeless[\"PTGENDER\"][:200], timeless[\"PTGENDER\"][:200]])\n",
    "            print(\"Using PTGENDER for labels\")\n",
    "        else:\n",
    "            # Create dummy labels based on row index\n",
    "            dummy_labels = np.random.randint(0, 3, 200)  # 3 categories\n",
    "            labels = pd.concat([pd.Series(dummy_labels), pd.Series(dummy_labels)])\n",
    "            print(\"Using dummy labels\")\n",
    "        \n",
    "        dig_time.plot_emb(labels = labels)\n",
    "        print(\"Embedding plot created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating embedding plot: {e}\")\n",
    "else:\n",
    "    print(\"Cannot create plot: missing dig_time object, plot_emb method, or timeless data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Timeless and Timefull variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataclasses. Note, we want to distort to leave domain unchanged\n",
    "if test_manifold_algorithms is not None:\n",
    "    try:\n",
    "        # Check if the CSV files exist first\n",
    "        timeless_file = \"../../data/classification/Timeless Variables 2024-07-09.csv\"\n",
    "        visits_file = \"../../data/classification/Visit Variables 2024-08-01.xlsx\"\n",
    "        \n",
    "        # For now, create dummy data classes since the exact files may not exist\n",
    "        print(\"Creating test manifold algorithms instances...\")\n",
    "        \n",
    "        # Create instances (these may fail if the files don't exist)\n",
    "        try:\n",
    "            timeless_data = test_manifold_algorithms(\"Timeless Variables 2024-07-09.csv\", split = \"distort\", verbose = 3, random_state=2816)\n",
    "            print(\"Timeless data loaded successfully\")\n",
    "        except:\n",
    "            print(\"Failed to load timeless data - using dummy data\")\n",
    "            # Create a dummy data class\n",
    "            class DummyData:\n",
    "                def __init__(self):\n",
    "                    self.split_A = np.random.rand(100, 20)\n",
    "                    self.labels = np.random.randint(0, 3, 100)\n",
    "            timeless_data = DummyData()\n",
    "        \n",
    "        try:\n",
    "            visits_data = test_manifold_algorithms(\"Visit Variables 2024-07-09.csv\", split = \"distort\", verbose = 3, random_state=2816)  \n",
    "            print(\"Visits data loaded successfully\")\n",
    "        except:\n",
    "            print(\"Failed to load visits data - using dummy data\")\n",
    "            class DummyData:\n",
    "                def __init__(self):\n",
    "                    self.split_A = np.random.rand(150, 25)\n",
    "                    self.labels = np.random.randint(0, 3, 150)\n",
    "            visits_data = DummyData()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating test_manifold_algorithms instances: {e}\")\n",
    "        timeless_data = None\n",
    "        visits_data = None\n",
    "else:\n",
    "    print(\"test_manifold_algorithms not available. Cannot create data instances.\")\n",
    "    timeless_data = None\n",
    "    visits_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MASH alignment for the test data\n",
    "if 'timeless_data' in locals() and 'visits_data' in locals() and \\\n",
    "   timeless_data is not None and visits_data is not None:\n",
    "    try:\n",
    "        print(\"Creating MASH model for timeless vs visits alignment...\")\n",
    "        tv = MASH(n_pca = 10)\n",
    "        \n",
    "        # MASH expects domains as tuple and known_anchors as 2D array\n",
    "        domains = (timeless_data.split_A, visits_data.split_A)\n",
    "        \n",
    "        # Create simple identity anchors for demonstration\n",
    "        min_samples = min(len(timeless_data.split_A), len(visits_data.split_A))\n",
    "        n_anchors = min(50, min_samples)  # Use up to 50 anchors\n",
    "        known_anchors = np.array([[i, i] for i in range(n_anchors)])\n",
    "        \n",
    "        print(f\"Domains: {len(domains)} domains with shapes {[d.shape for d in domains]}\")\n",
    "        print(f\"Anchors: {known_anchors.shape} anchors\")\n",
    "        \n",
    "        # Fit the MASH model\n",
    "        tv.fit(domains, known_anchors)\n",
    "        print(\"MASH model fitted successfully\")\n",
    "        \n",
    "        # Try to get alignment score if method exists\n",
    "        try:\n",
    "            alignment_score = tv.FOSCTTM()\n",
    "            print(f\"Alignment score: {alignment_score}\")\n",
    "        except:\n",
    "            print(\"Could not compute alignment score\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating MASH alignment: {e}\")\n",
    "        tv = None\n",
    "else:\n",
    "    print(\"Cannot create MASH alignment - missing data objects\")\n",
    "    tv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load visits labels data\n",
    "try:\n",
    "    # Try multiple possible file paths\n",
    "    possible_files = [\n",
    "        \"../../data/classification/Visit Variables 2024-08-01.xlsx\",\n",
    "        \"../../data/classification/Visit Variables 2024-07-09.csv\",\n",
    "        \"../../data/classification/Progression Variables 2024-08-17.xlsx\"\n",
    "    ]\n",
    "    \n",
    "    visits_labels = None\n",
    "    for file_path in possible_files:\n",
    "        try:\n",
    "            if file_path.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path)\n",
    "            else:\n",
    "                df = pd.read_excel(file_path)\n",
    "            \n",
    "            # Look for ID column (could be RID, ID, PatientID, etc.)\n",
    "            id_columns = ['RID', 'ID', 'PatientID', 'Subject_ID', 'SubjectID']\n",
    "            id_col = None\n",
    "            for col in id_columns:\n",
    "                if col in df.columns:\n",
    "                    id_col = col\n",
    "                    break\n",
    "            \n",
    "            if id_col:\n",
    "                visits_labels = df[id_col].values\n",
    "                print(f\"Successfully loaded visits labels from {file_path}\")\n",
    "                print(f\"Found {len(visits_labels)} labels using column '{id_col}'\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"No suitable ID column found in {file_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Could not load {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if visits_labels is None:\n",
    "        print(\"Could not load visits labels from any source - creating dummy labels\")\n",
    "        if 'visits_data' in locals() and visits_data is not None:\n",
    "            visits_labels = np.arange(len(visits_data.split_A))\n",
    "        else:\n",
    "            visits_labels = np.arange(100)  # Default dummy labels\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error loading visits labels: {e}\")\n",
    "    visits_labels = np.arange(100)  # Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset NaN values to be -4 :)\n",
    "timeless_data.split_A[np.isnan(timeless_data.split_A)] = -4\n",
    "visits_data.split_A[np.isnan(visits_data.split_A)] = -4\n",
    "\n",
    "#Lets subset the data\n",
    "timeless_data.split_A = timeless_data.split_A[:SUBSET_VAL]\n",
    "visits_data.split_A = visits_data.split_A[:max(TV_anchors[:, 1])+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TV_anchors), len(visits_data.split_A), max(TV_anchors[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TV_anchors[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the merged values --> This will take up the rest of your day\n",
    "tv = MASH(n_pca = 10)\n",
    "tv.fit(timeless_data.split_A, visits_data.split_A, known_anchors = TV_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv.plot_heat_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv.plot_emb(show_anchors = False, show_lines = False, n_comp = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(graphtools.Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots with the MASH-aligned data\n",
    "if 'mash' in locals() and 'timeless_data' in locals() and 'visits_data' in locals() and \\\n",
    "   timeless_data is not None and visits_data is not None:\n",
    "    try:\n",
    "        # Get the transformed data from MASH\n",
    "        transformed_timeless = mash.get_aligned_data(timeless_data.split_A)\n",
    "        transformed_visits = mash.get_aligned_data(visits_data.split_A)\n",
    "        \n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Original timeless data\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.scatter(timeless_data.split_A[:, 0], timeless_data.split_A[:, 1], \n",
    "                   c=timeless_data.labels, alpha=0.7)\n",
    "        plt.title('Original Timeless Data')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        \n",
    "        # Original visits data  \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.scatter(visits_data.split_A[:, 0], visits_data.split_A[:, 1], \n",
    "                   c=visits_data.labels, alpha=0.7)\n",
    "        plt.title('Original Visits Data')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        \n",
    "        # MASH aligned data\n",
    "        plt.subplot(1, 3, 3)\n",
    "        if len(transformed_timeless) > 0:\n",
    "            plt.scatter(transformed_timeless[:, 0], transformed_timeless[:, 1], \n",
    "                       c=timeless_data.labels, alpha=0.7, label='Timeless')\n",
    "        if len(transformed_visits) > 0:\n",
    "            plt.scatter(transformed_visits[:, 0], transformed_visits[:, 1], \n",
    "                       c=visits_data.labels, alpha=0.7, label='Visits')\n",
    "        plt.title('MASH Aligned Data')\n",
    "        plt.xlabel('Aligned Feature 1')\n",
    "        plt.ylabel('Aligned Feature 2')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating plots: {e}\")\n",
    "        print(\"Creating simple visualization with available data...\")\n",
    "        \n",
    "        # Fallback plotting\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        if hasattr(timeless_data, 'split_A') and timeless_data.split_A is not None:\n",
    "            plt.scatter(timeless_data.split_A[:, 0], timeless_data.split_A[:, 1], alpha=0.7)\n",
    "            plt.title('Timeless Data')\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'No timeless data available', ha='center', va='center')\n",
    "            plt.title('Timeless Data (Not Available)')\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        if hasattr(visits_data, 'split_A') and visits_data.split_A is not None:\n",
    "            plt.scatter(visits_data.split_A[:, 0], visits_data.split_A[:, 1], alpha=0.7)\n",
    "            plt.title('Visits Data')\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'No visits data available', ha='center', va='center')\n",
    "            plt.title('Visits Data (Not Available)')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "else:\n",
    "    print(\"Cannot create plots - missing MASH model or data objects\")\n",
    "    print(\"Available variables:\", [var for var in locals().keys() if not var.startswith('_')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deleteme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
