{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization Tests\n",
    "\n",
    "This file is to help plot the data, and discover trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 17:58:09.261031: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAGAN is running on TensorFlow 2.16.1\n"
     ]
    }
   ],
   "source": [
    "#Import everything\n",
    "import test_manifold_algorithms as tma\n",
    "import MAGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Clear Directory\"\"\"\n",
    "#Careful. This will reset all of the resutls that we have collected\n",
    "#tma.clear_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "---------------------------       Initalizing class with winequality-red.csv data       ---------------------------\n",
      "\n",
      "Splitting the data randomly\n",
      "Split A features shape: (1599, 6)\n",
      "Split B Features shape (1599, 5)\n",
      "MDS initialized with 5 components\n",
      "The knn values are: (2, 34, 66, 98, 130, 162, 194, 226, 258, 290)\n",
      "\n",
      "-------------------------------------    SPUD Tests winequality-red   -------------------------------------\n",
      "\n",
      "Operation average\n",
      "    Kind distance\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.35937173053358473\n",
      "                Unable to calculate Cross Embedding\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Practice Tests to Run\"\"\"\n",
    "test = tma.test_manifold_algorithms(\"winequality-red.csv\", split = \"random\", percent_of_anchors = [0.1], random_state=186, verbose = 2)\n",
    "#print(f\"Anchors : {test.anchors}\")\n",
    "#print(f\"KNN range {test.knn_range}\")\n",
    "test.run_SPUD_tests(kind = [\"distance\"])\n",
    "#test.run_DIG_tests(predict = True)\n",
    "#test.run_NAMA_tests()\n",
    "#test.run_DTA_tests()\n",
    "#test.run_SSMA_tests()\n",
    "#MAGAN.run_MAGAN(test.split_A, test.split_B, labels1 = test.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "---------------------------       Initalizing class with iris.csv data       ---------------------------\n",
      "\n",
      "Splitting the data randomly\n",
      "Split A features shape: (150, 1)\n",
      "Split B Features shape (150, 3)\n",
      "MDS initialized with 2 components\n",
      "The knn values are: (2, 6, 10, 14, 18, 22, 26, 30, 34, 38)\n",
      "\n",
      " \n",
      " \n",
      "---------------------------       Initalizing class with iris.csv data       ---------------------------\n",
      "\n",
      "Splitting the data randomly\n",
      "Split A features shape: (150, 2)\n",
      "Split B Features shape (150, 2)\n",
      "MDS initialized with 2 components\n",
      "The knn values are: (2, 6, 10, 14, 18, 22, 26, 30, 34, 38)\n",
      "\n",
      " \n",
      " \n",
      "---------------------------       Initalizing class with iris.csv data       ---------------------------\n",
      "\n",
      "Splitting the data randomly\n",
      "Split A features shape: (150, 2)\n",
      "Split B Features shape (150, 2)\n",
      "MDS initialized with 2 components\n",
      "The knn values are: (2, 6, 10, 14, 18, 22, 26, 30, 34, 38)\n",
      "\n",
      "-------------------------------------    SPUD Tests iris   -------------------------------------\n",
      "\n",
      "Operation average\n",
      "    Kind distance\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4451555555555556\n",
      "                CE Score: 0.6666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.36\n",
      "                CE Score: 0.6733333333333333\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3714666666666667\n",
      "                CE Score: 0.6866666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.27097777777777776\n",
      "                CE Score: 0.8466666666666667\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.32204444444444447\n",
      "                CE Score: 0.6666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.17111111111111113\n",
      "                CE Score: 0.82\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3214222222222223\n",
      "                CE Score: 0.6666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.1676\n",
      "                CE Score: 0.8466666666666667\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.28217777777777775\n",
      "                CE Score: 0.6666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.1688\n",
      "                CE Score: 0.84\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2842222222222222\n",
      "                CE Score: 0.6466666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.17155555555555557\n",
      "                CE Score: 0.8866666666666667\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2876444444444445\n",
      "                CE Score: 0.6466666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.1696888888888889\n",
      "                CE Score: 0.8866666666666667\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2797333333333334\n",
      "                CE Score: 0.68\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.17004444444444444\n",
      "                CE Score: 0.84\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.27622222222222226\n",
      "                CE Score: 0.66\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.16933333333333336\n",
      "                CE Score: 0.8466666666666667\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2790222222222222\n",
      "                CE Score: 0.6733333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.17200000000000004\n",
      "                CE Score: 0.8466666666666667\n",
      "Operation abs\n",
      "    Kind distance\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.5411999999999999\n",
      "                CE Score: 0.05333333333333334\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.5141777777777777\n",
      "                CE Score: 0.06\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.44382222222222223\n",
      "                CE Score: 0.2\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3917777777777778\n",
      "                CE Score: 0.2\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3630666666666667\n",
      "                CE Score: 0.66\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19973333333333335\n",
      "                CE Score: 0.8733333333333333\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.34693333333333337\n",
      "                CE Score: 0.6933333333333334\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18808888888888886\n",
      "                CE Score: 0.8333333333333334\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2303111111111111\n",
      "                CE Score: 0.82\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.1923111111111111\n",
      "                CE Score: 0.9333333333333333\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23222222222222225\n",
      "                CE Score: 0.76\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18635555555555558\n",
      "                CE Score: 0.92\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2396444444444445\n",
      "                CE Score: 0.7733333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19413333333333335\n",
      "                CE Score: 0.9466666666666667\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.22831111111111113\n",
      "                CE Score: 0.8666666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19008888888888886\n",
      "                CE Score: 0.9266666666666666\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.21688888888888888\n",
      "                CE Score: 0.8\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19026666666666667\n",
      "                CE Score: 0.9333333333333333\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.22386666666666666\n",
      "                CE Score: 0.8066666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18755555555555556\n",
      "                CE Score: 0.9066666666666666\n",
      "\n",
      "-------------------------------------    SPUD Tests iris   -------------------------------------\n",
      "\n",
      "Operation average\n",
      "    Kind distance\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4243111111111112\n",
      "                CE Score: 0.41333333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.38395555555555555\n",
      "                CE Score: 0.9066666666666666\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.22293333333333337\n",
      "                CE Score: 0.94\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.21320000000000003\n",
      "                CE Score: 0.9\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.24297777777777782\n",
      "                CE Score: 0.8933333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.22217777777777778\n",
      "                CE Score: 0.9\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2273333333333334\n",
      "                CE Score: 0.9066666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.2164888888888889\n",
      "                CE Score: 0.9\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.22555555555555554\n",
      "                CE Score: 0.8733333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.21319999999999997\n",
      "                CE Score: 0.9\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2270666666666667\n",
      "                CE Score: 0.96\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.21946666666666667\n",
      "                CE Score: 0.9\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23497777777777779\n",
      "                CE Score: 0.9466666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.22364444444444445\n",
      "                CE Score: 0.8666666666666667\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23777777777777775\n",
      "                CE Score: 0.9466666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.22422222222222227\n",
      "                CE Score: 0.9\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23177777777777778\n",
      "                CE Score: 0.94\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.224\n",
      "                CE Score: 0.92\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.22657777777777777\n",
      "                CE Score: 0.9333333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.22026666666666667\n",
      "                CE Score: 0.8866666666666667\n",
      "Operation abs\n",
      "    Kind distance\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.5753777777777778\n",
      "                CE Score: 0.03333333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.6079555555555556\n",
      "                CE Score: 0.013333333333333334\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.18657777777777776\n",
      "                CE Score: 0.92\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.16426666666666664\n",
      "                CE Score: 0.9333333333333333\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.19315555555555555\n",
      "                CE Score: 0.8133333333333334\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19315555555555552\n",
      "                CE Score: 0.9466666666666667\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.20066666666666663\n",
      "                CE Score: 0.8266666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18973333333333334\n",
      "                CE Score: 0.94\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.20955555555555555\n",
      "                CE Score: 0.8333333333333334\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19897777777777775\n",
      "                CE Score: 0.9533333333333334\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.20360000000000003\n",
      "                CE Score: 0.8266666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19435555555555556\n",
      "                CE Score: 0.9333333333333333\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.21680000000000002\n",
      "                CE Score: 0.88\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.21395555555555557\n",
      "                CE Score: 0.8733333333333333\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.21662222222222222\n",
      "                CE Score: 0.8066666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.20973333333333333\n",
      "                CE Score: 0.8466666666666667\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.21586666666666662\n",
      "                CE Score: 0.9266666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.21502222222222225\n",
      "                CE Score: 0.9066666666666666\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.20999999999999996\n",
      "                CE Score: 0.9\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.20906666666666665\n",
      "                CE Score: 0.9266666666666666\n",
      "\n",
      "-------------------------------------    SPUD Tests iris   -------------------------------------\n",
      "\n",
      "Operation average\n",
      "    Kind distance\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4596\n",
      "                CE Score: 0.3333333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3967111111111112\n",
      "                CE Score: 0.6333333333333333\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.22284444444444446\n",
      "                CE Score: 0.92\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18048888888888887\n",
      "                CE Score: 0.9333333333333333\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2361777777777778\n",
      "                CE Score: 0.9266666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18595555555555557\n",
      "                CE Score: 0.8666666666666667\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2321777777777778\n",
      "                CE Score: 0.94\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18404444444444443\n",
      "                CE Score: 0.9333333333333333\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23062222222222223\n",
      "                CE Score: 0.92\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18195555555555554\n",
      "                CE Score: 0.9\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23133333333333336\n",
      "                CE Score: 0.9333333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.17426666666666668\n",
      "                CE Score: 0.9\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23191111111111107\n",
      "                CE Score: 0.9266666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.1814666666666667\n",
      "                CE Score: 0.94\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2335555555555556\n",
      "                CE Score: 0.9266666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18533333333333335\n",
      "                CE Score: 0.8066666666666666\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23542222222222223\n",
      "                CE Score: 0.92\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18400000000000002\n",
      "                CE Score: 0.8866666666666667\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.23622222222222225\n",
      "                CE Score: 0.9333333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.1832444444444445\n",
      "                CE Score: 0.78\n",
      "Operation abs\n",
      "    Kind distance\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3872\n",
      "                CE Score: 0.32666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.5069777777777776\n",
      "                CE Score: 0.38\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.18484444444444448\n",
      "                CE Score: 0.82\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18942222222222221\n",
      "                CE Score: 0.9266666666666666\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.1933333333333333\n",
      "                CE Score: 0.86\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18382222222222222\n",
      "                CE Score: 0.8933333333333333\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.18702222222222223\n",
      "                CE Score: 0.8266666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.18942222222222221\n",
      "                CE Score: 0.8933333333333333\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.1948\n",
      "                CE Score: 0.88\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19746666666666665\n",
      "                CE Score: 0.9\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.20208888888888893\n",
      "                CE Score: 0.86\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19640000000000002\n",
      "                CE Score: 0.8266666666666667\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.2024\n",
      "                CE Score: 0.8666666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.20311111111111113\n",
      "                CE Score: 0.9066666666666666\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.19355555555555556\n",
      "                CE Score: 0.9\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19888888888888887\n",
      "                CE Score: 0.8466666666666667\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.19773333333333334\n",
      "                CE Score: 0.9133333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19822222222222222\n",
      "                CE Score: 0.8733333333333333\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.1924888888888889\n",
      "                CE Score: 0.8266666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.19897777777777775\n",
      "                CE Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing All functions\"\"\"\n",
    "class_instances = tma.run_all_tests(csv_files = [\"iris.csv\"], test_random = 3, #General function arguments\n",
    "                                split = \"random\", verbose = 2, percent_of_anchors = [0.05, 0.1], #Init Key arguments\n",
    "                                run_DIG = False, page_ranks = (\"None\", \"off-diagonal\", \"full\"), predict = True, #DIG key arguments\n",
    "                                run_DTA = False,\n",
    "                                run_NAMA = False,\n",
    "                                run_SSMA = False,\n",
    "                                run_SPUD = True, operations = (\"average\", \"abs\"), kind = [\"distance\"]) #SPUD key arguments | SPUDS_Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We do not have available the needed predict values\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Visualization\"\"\"\n",
    "#Veiwing with MatplotLib\n",
    "tma.visualize_results(file_names = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['csv_file', 'method', 'seed', 'split', 'KNN', 'Percent_of_Anchors',\n",
       "       'FOSCTTM', 'Cross_Embedding_KNN', 'Page_Rank', 'Predicted_Feature_MAE',\n",
       "       'Operation', 'SPUDS_Algorithm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veiwing with DataFrame\n",
    "df = tma.upload_to_DataFrame()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FOSCTTM</th>\n",
       "      <th>Cross_Embedding_KNN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csv_file</th>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iris</th>\n",
       "      <th>SPUD</th>\n",
       "      <td>0.309136</td>\n",
       "      <td>0.657333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FOSCTTM  Cross_Embedding_KNN\n",
       "csv_file method                               \n",
       "iris     SPUD    0.309136             0.657333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['csv_file', 'method'])[['FOSCTTM', \"Cross_Embedding_KNN\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FOSCTTM</th>\n",
       "      <th>Cross_Embedding_KNN</th>\n",
       "      <th>Predicted_Feature_MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csv_file</th>\n",
       "      <th>Page_Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FOSCTTM, Cross_Embedding_KNN, Predicted_Feature_MAE]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are all DIG Methods\n",
    "df.groupby(['csv_file', \"Page_Rank\"])[['FOSCTTM', \"Cross_Embedding_KNN\", \"Predicted_Feature_MAE\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FOSCTTM</th>\n",
       "      <th>Cross_Embedding_KNN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csv_file</th>\n",
       "      <th>Operation</th>\n",
       "      <th>Percent_of_Anchors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">iris</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">abs</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.254332</td>\n",
       "      <td>0.742667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.236447</td>\n",
       "      <td>0.805111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">average</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.273342</td>\n",
       "      <td>0.803111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.212973</td>\n",
       "      <td>0.863111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        FOSCTTM  Cross_Embedding_KNN\n",
       "csv_file Operation Percent_of_Anchors                               \n",
       "iris     abs       0.05                0.254332             0.742667\n",
       "                   0.1                 0.236447             0.805111\n",
       "         average   0.05                0.273342             0.803111\n",
       "                   0.1                 0.212973             0.863111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are all SPUD Methods // With Pure\n",
    "df.groupby(['csv_file', \"Operation\", \"SPUDS_Algorithm\"])[['FOSCTTM', \"Cross_Embedding_KNN\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Tests Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "---------------------------       Initalizing class with iris.csv data       ---------------------------\n",
      "\n",
      "Spliting the data evenly\n",
      "Split A features shape: (150, 2)\n",
      "Split B Features shape (150, 2)\n",
      "MDS initialized with 2 components\n",
      "The knn values are: (2, 6, 10, 14, 18, 22, 26, 30, 34, 38)\n"
     ]
    }
   ],
   "source": [
    "iris_tma = tma.test_manifold_algorithms(\"iris.csv\", split = \"even\", percent_of_anchors= [0.1], verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/user/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/util/decorator_utils.py:153: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
      "Help on package tensorflow.compat.v1 in tensorflow.compat:\n",
      "\n",
      "NAME\n",
      "    tensorflow.compat.v1 - Bring in all of the public TensorFlow interface into this module.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __internal__ (package)\n",
      "    app (package)\n",
      "    audio (package)\n",
      "    autograph (package)\n",
      "    bitwise (package)\n",
      "    compat (package)\n",
      "    config (package)\n",
      "    data (package)\n",
      "    debugging (package)\n",
      "    distribute (package)\n",
      "    distributions (package)\n",
      "    dtypes (package)\n",
      "    errors (package)\n",
      "    experimental (package)\n",
      "    feature_column (package)\n",
      "    gfile (package)\n",
      "    graph_util (package)\n",
      "    image (package)\n",
      "    initializers (package)\n",
      "    io (package)\n",
      "    layers (package)\n",
      "    linalg (package)\n",
      "    lite (package)\n",
      "    logging (package)\n",
      "    lookup (package)\n",
      "    losses (package)\n",
      "    manip (package)\n",
      "    math (package)\n",
      "    metrics (package)\n",
      "    mixed_precision (package)\n",
      "    mlir (package)\n",
      "    nest (package)\n",
      "    nn (package)\n",
      "    profiler (package)\n",
      "    python_io (package)\n",
      "    quantization (package)\n",
      "    queue (package)\n",
      "    ragged (package)\n",
      "    random (package)\n",
      "    raw_ops (package)\n",
      "    resource_loader (package)\n",
      "    saved_model (package)\n",
      "    sets (package)\n",
      "    signal (package)\n",
      "    sparse (package)\n",
      "    spectral (package)\n",
      "    strings (package)\n",
      "    summary (package)\n",
      "    sysconfig (package)\n",
      "    test (package)\n",
      "    tpu (package)\n",
      "    train (package)\n",
      "    types (package)\n",
      "    user_ops (package)\n",
      "    version (package)\n",
      "    xla (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        tensorflow.python.framework.errors_impl.OpError\n",
      "    builtins.object\n",
      "        tensorflow.python.eager.backprop.GradientTape\n",
      "        tensorflow.python.framework.ops.GraphKeys\n",
      "        tensorflow.python.framework.ops.RegisterGradient\n",
      "        tensorflow.python.framework.tensor_shape.Dimension\n",
      "        tensorflow.python.ops.critical_section_ops.CriticalSection\n",
      "        tensorflow.python.ops.data_flow_ops.ConditionalAccumulatorBase\n",
      "            tensorflow.python.ops.data_flow_ops.ConditionalAccumulator\n",
      "            tensorflow.python.ops.data_flow_ops.SparseConditionalAccumulator\n",
      "        tensorflow.python.ops.data_flow_ops.QueueBase\n",
      "            tensorflow.python.ops.data_flow_ops.FIFOQueue\n",
      "            tensorflow.python.ops.data_flow_ops.PaddingFIFOQueue\n",
      "            tensorflow.python.ops.data_flow_ops.PriorityQueue\n",
      "            tensorflow.python.ops.data_flow_ops.RandomShuffleQueue\n",
      "        tensorflow.python.ops.gradients_util.AggregationMethod\n",
      "        tensorflow.python.ops.io_ops.ReaderBase\n",
      "            tensorflow.python.ops.io_ops.FixedLengthRecordReader\n",
      "            tensorflow.python.ops.io_ops.IdentityReader\n",
      "            tensorflow.python.ops.io_ops.LMDBReader\n",
      "            tensorflow.python.ops.io_ops.TFRecordReader\n",
      "            tensorflow.python.ops.io_ops.TextLineReader\n",
      "            tensorflow.python.ops.io_ops.WholeFileReader\n",
      "        tensorflow.python.ops.tensor_array_ops.TensorArray\n",
      "        tensorflow.python.ops.variable_scope.VariableScope\n",
      "        tensorflow.python.ops.variable_scope.variable_scope\n",
      "    builtins.tuple(builtins.object)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensorValue\n",
      "    contextlib.AbstractContextManager(abc.ABC)\n",
      "        tensorflow.python.framework.ops.name_scope_v1\n",
      "    enum.Enum(builtins.object)\n",
      "        tensorflow.python.ops.unconnected_gradients.UnconnectedGradients\n",
      "        tensorflow.python.ops.variables.VariableAggregation\n",
      "        tensorflow.python.ops.variables.VariableSynchronization\n",
      "    google._upb._message.Message(builtins.object)\n",
      "        tensorflow.core.framework.attr_value_pb2.AttrValue(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.attr_value_pb2.NameAttrList(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.graph_pb2.GraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.node_def_pb2.NodeDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.SummaryMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.ConfigProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GPUOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GraphOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.OptimizerOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.MetaGraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.TensorInfo(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.LogMessage(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tsl.protobuf.histogram_pb2.HistogramProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "    google.protobuf.message.Message(builtins.object)\n",
      "        tensorflow.core.framework.attr_value_pb2.AttrValue(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.attr_value_pb2.NameAttrList(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.graph_pb2.GraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.node_def_pb2.NodeDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.SummaryMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.ConfigProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GPUOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GraphOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.OptimizerOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.MetaGraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.TensorInfo(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.LogMessage(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tsl.protobuf.histogram_pb2.HistogramProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "    tensorflow.core.function.trace_type.serialization.Serializable(builtins.object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "        tensorflow.python.framework.tensor_shape.TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    tensorflow.python.client._pywrap_tf_session.PyGraph(builtins.object)\n",
      "        tensorflow.python.framework.ops.Graph\n",
      "    tensorflow.python.client._pywrap_tf_session.PyOperation(builtins.object)\n",
      "        tensorflow.python.framework.ops.Operation\n",
      "    tensorflow.python.client.session.BaseSession(tensorflow.python.client.session.SessionInterface)\n",
      "        tensorflow.python.client.session.InteractiveSession\n",
      "        tensorflow.python.client.session.Session\n",
      "    tensorflow.python.framework._dtypes.DType(pybind11_builtins.pybind11_object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "    tensorflow.python.framework.composite_tensor.CompositeTensor(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.internal.RaggedTensor)\n",
      "    tensorflow.python.framework.device_spec.DeviceSpecV2(builtins.object)\n",
      "        tensorflow.python.framework.device_spec.DeviceSpecV1\n",
      "    tensorflow.python.framework.tensor.DenseSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "    tensorflow.python.framework.type_spec.BatchableTypeSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensorSpec\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.python.types.internal.RaggedTensorSpec)\n",
      "    tensorflow.python.ops.init_ops.Initializer(builtins.object)\n",
      "        tensorflow.python.ops.init_ops.Constant\n",
      "        tensorflow.python.ops.init_ops.Ones\n",
      "        tensorflow.python.ops.init_ops.Orthogonal\n",
      "        tensorflow.python.ops.init_ops.RandomNormal\n",
      "        tensorflow.python.ops.init_ops.RandomUniform\n",
      "        tensorflow.python.ops.init_ops.TruncatedNormal\n",
      "        tensorflow.python.ops.init_ops.UniformUnitScaling\n",
      "        tensorflow.python.ops.init_ops.VarianceScaling\n",
      "            tensorflow.python.ops.init_ops.GlorotNormal\n",
      "            tensorflow.python.ops.init_ops.GlorotUniform\n",
      "        tensorflow.python.ops.init_ops.Zeros\n",
      "    tensorflow.python.ops.parsing_config.FixedLenFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_config.FixedLenFeature\n",
      "    tensorflow.python.ops.parsing_config.FixedLenSequenceFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_config.FixedLenSequenceFeature\n",
      "    tensorflow.python.ops.parsing_config.SparseFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_config.SparseFeature\n",
      "    tensorflow.python.ops.parsing_config.VarLenFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_config.VarLenFeature\n",
      "    tensorflow.python.ops.variables.Variable(tensorflow.python.trackable.base.Trackable)\n",
      "        tensorflow.python.ops.variable_v1.VariableV1\n",
      "    tensorflow.python.trackable.autotrackable.AutoTrackable(tensorflow.python.trackable.base.Trackable)\n",
      "        tensorflow.python.module.module.Module\n",
      "    tensorflow.python.types.core.Symbol(tensorflow.python.types.core.Tensor)\n",
      "        tensorflow.python.framework.tensor.Tensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "    tensorflow.python.types.internal.IndexedSlices(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "    tensorflow.python.types.internal.NativeObject(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.tensor.Tensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.internal.RaggedTensor)\n",
      "    tensorflow.python.types.internal.RaggedTensor(builtins.object)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.internal.RaggedTensor)\n",
      "    tensorflow.python.types.internal.RaggedTensorSpec(builtins.object)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.python.types.internal.RaggedTensorSpec)\n",
      "    tensorflow.python.types.internal.TensorSpec(builtins.object)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "    tensorflow.python.types.internal.TypeSpec(builtins.object)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    tensorflow.python.types.trace.TraceType(builtins.object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.tensor_shape.TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    \n",
      "    class AggregationMethod(builtins.object)\n",
      "     |  A class listing aggregation methods used to combine gradients.\n",
      "     |  \n",
      "     |  Computing partial derivatives can require aggregating gradient\n",
      "     |  contributions. This class lists the various methods that can\n",
      "     |  be used to combine gradients in the graph.\n",
      "     |  \n",
      "     |  The following aggregation methods are part of the stable API for\n",
      "     |  aggregating gradients:\n",
      "     |  \n",
      "     |  *  `ADD_N`: All of the gradient terms are summed as part of one\n",
      "     |     operation using the \"AddN\" op (see `tf.add_n`). This\n",
      "     |     method has the property that all gradients must be ready and\n",
      "     |     buffered separately in memory before any aggregation is performed.\n",
      "     |  *  `DEFAULT`: The system-chosen default aggregation method.\n",
      "     |  \n",
      "     |  The following aggregation methods are experimental and may not\n",
      "     |  be supported in future releases:\n",
      "     |  \n",
      "     |  * `EXPERIMENTAL_TREE`: Gradient terms are summed in pairs using\n",
      "     |    the \"AddN\" op. This method of summing gradients may reduce\n",
      "     |    performance, but it can improve memory utilization because the\n",
      "     |    gradients can be released earlier.\n",
      "     |  * `EXPERIMENTAL_ACCUMULATE_N`: Same as `EXPERIMENTAL_TREE`.\n",
      "     |  \n",
      "     |  Example usage when computing gradient:\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def example():\n",
      "     |  ...   x = tf.constant(1.0)\n",
      "     |  ...   y = x * 2.0\n",
      "     |  ...   z = y + y + y + y\n",
      "     |  ...   return tf.gradients(z, [x, y],\n",
      "     |  ...     aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)\n",
      "     |  >>> example()\n",
      "     |  [<tf.Tensor: shape=(), dtype=float32, numpy=8.0>,\n",
      "     |   <tf.Tensor: shape=(), dtype=float32, numpy=4.0>]\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ADD_N = 0\n",
      "     |  \n",
      "     |  DEFAULT = 0\n",
      "     |  \n",
      "     |  EXPERIMENTAL_ACCUMULATE_N = 2\n",
      "     |  \n",
      "     |  EXPERIMENTAL_TREE = 1\n",
      "    \n",
      "    class AttrValue(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      AttrValue\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ListValue = <class 'tensorflow.core.framework.attr_value_pb2.ListValue...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class ConditionalAccumulator(ConditionalAccumulatorBase)\n",
      "     |  ConditionalAccumulator(dtype, shape=None, shared_name=None, name='conditional_accumulator', reduction_type='MEAN')\n",
      "     |  \n",
      "     |  A conditional accumulator for aggregating gradients.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConditionalAccumulator\n",
      "     |      ConditionalAccumulatorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape=None, shared_name=None, name='conditional_accumulator', reduction_type='MEAN')\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        shared_name: Optional. If non-empty, this accumulator will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the accumulator.\n",
      "     |        reduction_type: Reduction type to use when taking the gradient.\n",
      "     |  \n",
      "     |  apply_grad(self, grad, local_step=0, name=None)\n",
      "     |      Attempts to apply a gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., local_step\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad: The gradient tensor to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  take_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      \n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tensor holding the value of the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If num_required < 1\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class ConditionalAccumulatorBase(builtins.object)\n",
      "     |  ConditionalAccumulatorBase(dtype, shape, accumulator_ref)\n",
      "     |  \n",
      "     |  A conditional accumulator for aggregating gradients.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape, accumulator_ref)\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        accumulator_ref: A handle to the conditional accumulator, created by sub-\n",
      "     |          classes\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class ConfigProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      ConfigProto\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  DeviceCountEntry = <class 'tensorflow.core.protobuf.config_pb2.DeviceC...\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class CriticalSection(builtins.object)\n",
      "     |  CriticalSection(name=None, shared_name=None, critical_section_def=None, import_scope=None)\n",
      "     |  \n",
      "     |  Critical section.\n",
      "     |  \n",
      "     |  A `CriticalSection` object is a resource in the graph which executes subgraphs\n",
      "     |  in **serial** order.  A common example of a subgraph one may wish to run\n",
      "     |  exclusively is the one given by the following function:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  v = resource_variable_ops.ResourceVariable(0.0, name=\"v\")\n",
      "     |  \n",
      "     |  def count():\n",
      "     |    value = v.read_value()\n",
      "     |    with tf.control_dependencies([value]):\n",
      "     |      with tf.control_dependencies([v.assign_add(1)]):\n",
      "     |        return tf.identity(value)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Here, a snapshot of `v` is captured in `value`; and then `v` is updated.\n",
      "     |  The snapshot value is returned.\n",
      "     |  \n",
      "     |  If multiple workers or threads all execute `count` in parallel, there is no\n",
      "     |  guarantee that access to the variable `v` is atomic at any point within\n",
      "     |  any thread's calculation of `count`.  In fact, even implementing an atomic\n",
      "     |  counter that guarantees that the user will see each value `0, 1, ...,` is\n",
      "     |  currently impossible.\n",
      "     |  \n",
      "     |  The solution is to ensure any access to the underlying resource `v` is\n",
      "     |  only processed through a critical section:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  cs = CriticalSection()\n",
      "     |  f1 = cs.execute(count)\n",
      "     |  f2 = cs.execute(count)\n",
      "     |  output = f1 + f2\n",
      "     |  session.run(output)\n",
      "     |  ```\n",
      "     |  The functions `f1` and `f2` will be executed serially, and updates to `v`\n",
      "     |  will be atomic.\n",
      "     |  \n",
      "     |  **NOTES**\n",
      "     |  \n",
      "     |  All resource objects, including the critical section and any captured\n",
      "     |  variables of functions executed on that critical section, will be\n",
      "     |  colocated to the same device (host and cpu/gpu).\n",
      "     |  \n",
      "     |  When using multiple critical sections on the same resources, there is no\n",
      "     |  guarantee of exclusive access to those resources.  This behavior is disallowed\n",
      "     |  by default (but see the kwarg `exclusive_resource_access`).\n",
      "     |  \n",
      "     |  For example, running the same function in two separate critical sections\n",
      "     |  will not ensure serial execution:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  v = tf.compat.v1.get_variable(\"v\", initializer=0.0, use_resource=True)\n",
      "     |  def accumulate(up):\n",
      "     |    x = v.read_value()\n",
      "     |    with tf.control_dependencies([x]):\n",
      "     |      with tf.control_dependencies([v.assign_add(up)]):\n",
      "     |        return tf.identity(x)\n",
      "     |  ex1 = CriticalSection().execute(\n",
      "     |    accumulate, 1.0, exclusive_resource_access=False)\n",
      "     |  ex2 = CriticalSection().execute(\n",
      "     |    accumulate, 1.0, exclusive_resource_access=False)\n",
      "     |  bad_sum = ex1 + ex2\n",
      "     |  sess.run(v.initializer)\n",
      "     |  sess.run(bad_sum)  # May return 0.0\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, shared_name=None, critical_section_def=None, import_scope=None)\n",
      "     |      Creates a critical section.\n",
      "     |  \n",
      "     |  execute(self, fn, exclusive_resource_access=True, name=None)\n",
      "     |      Execute function `fn()` inside the critical section.\n",
      "     |      \n",
      "     |      `fn` should not accept any arguments.  To add extra arguments to when\n",
      "     |      calling `fn` in the critical section, create a lambda:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      critical_section.execute(lambda: fn(*my_args, **my_kwargs))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fn: The function to execute.  Must return at least one tensor.\n",
      "     |        exclusive_resource_access: Whether the resources required by\n",
      "     |          `fn` should be exclusive to this `CriticalSection`.  Default: `True`.\n",
      "     |          You may want to set this to `False` if you will be accessing a\n",
      "     |          resource in read-only mode in two different CriticalSections.\n",
      "     |        name: The name to use when creating the execute operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensors returned from `fn()`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `fn` attempts to lock this `CriticalSection` in any nested\n",
      "     |          or lazy way that may cause a deadlock.\n",
      "     |        ValueError: If `exclusive_resource_access == True` and\n",
      "     |          another `CriticalSection` has an execution requesting the same\n",
      "     |          resources as `fn``.  Note, even if `exclusive_resource_access` is\n",
      "     |          `True`, if another execution in another `CriticalSection` was created\n",
      "     |          without `exclusive_resource_access=True`, a `ValueError` will be raised.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  DType(type_enum, handle_data=None)\n",
      "     |  \n",
      "     |  Represents the type of the elements in a `Tensor`.\n",
      "     |  \n",
      "     |  `DType`'s are used to specify the output data type for operations which\n",
      "     |  require it, or to inspect the data type of existing `Tensor`'s.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |  >>> tf.constant(1, dtype=tf.int64)\n",
      "     |  <tf.Tensor: shape=(), dtype=int64, numpy=1>\n",
      "     |  >>> tf.constant(1.0).dtype\n",
      "     |  tf.float32\n",
      "     |  \n",
      "     |  See `tf.dtypes` for a complete list of `DType`'s defined.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DType\n",
      "     |      tensorflow.python.framework._dtypes.DType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns True iff this DType refers to the same type as `other`.\n",
      "     |  \n",
      "     |  __hash__(...)\n",
      "     |      __hash__(self: tensorflow.python.framework._dtypes.DType) -> int\n",
      "     |  \n",
      "     |  __init__(self, type_enum, handle_data=None)\n",
      "     |      __init__(self: tensorflow.python.framework._dtypes.DType, arg0: object) -> None\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns True iff self != other.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  cast(self, value, cast_context)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.framework.types_pb2.SerializedDType\n",
      "     |      Returns a proto representation of the Dtype instance.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns True if the `other` DType will be converted to this DType (TF1).\n",
      "     |      \n",
      "     |      Programs written for TensorFlow 2.x do not need this function.\n",
      "     |      Instead, they can do equality comparison on `DType` objects directly:\n",
      "     |      `tf.as_dtype(this) == tf.as_dtype(other)`.\n",
      "     |      \n",
      "     |      This function exists only for compatibility with TensorFlow 1.x, where it\n",
      "     |      additionally allows conversion from a reference type (used by\n",
      "     |      `tf.compat.v1.Variable`) to its base type.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `DType` (or object that may be converted to a `DType`).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if a Tensor of the `other` `DType` will be implicitly converted to\n",
      "     |        this `DType`.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, types: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('DType')]\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.framework.types_pb2.SerializedDType) -> 'DType' from tensorflow.python.framework.dtypes.DTypeMeta\n",
      "     |      Returns a Dtype instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.framework.types_pb2.SerializedDType] from tensorflow.python.framework.dtypes.DTypeMeta\n",
      "     |      Returns the type of proto associated with DType serialization.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  as_numpy_dtype\n",
      "     |      Returns a Python `type` object based on this `DType`.\n",
      "     |  \n",
      "     |  base_dtype\n",
      "     |      Returns a non-reference `DType` based on this `DType` (for TF1).\n",
      "     |      \n",
      "     |      Programs written for TensorFlow 2.x do not need this attribute.\n",
      "     |      It exists only for compatibility with TensorFlow 1.x, which used\n",
      "     |      reference `DType`s in the implementation of `tf.compat.v1.Variable`.\n",
      "     |      In TensorFlow 2.x, `tf.Variable` is implemented without reference types.\n",
      "     |  \n",
      "     |  limits\n",
      "     |      Return intensity limits, i.e.\n",
      "     |      \n",
      "     |      (min, max) tuple, of the dtype.\n",
      "     |      Args:\n",
      "     |        clip_negative : bool, optional If True, clip the negative range (i.e.\n",
      "     |          return 0 for min intensity) even if the image dtype allows negative\n",
      "     |          values. Returns\n",
      "     |        min, max : tuple Lower and upper intensity limits.\n",
      "     |  \n",
      "     |  max\n",
      "     |      Returns the maximum representable value in this data type.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if this is a non-numeric, unordered, or quantized type.\n",
      "     |  \n",
      "     |  min\n",
      "     |      Returns the minimum representable value in this data type.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if this is a non-numeric, unordered, or quantized type.\n",
      "     |  \n",
      "     |  real_dtype\n",
      "     |      Returns the `DType` corresponding to this `DType`'s real part.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework._dtypes.DType:\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |      __int__(self: tensorflow.python.framework._dtypes.DType) -> int\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: tensorflow.python.framework._dtypes.DType) -> str\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: tensorflow.python.framework._dtypes.DType) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.framework._dtypes.DType:\n",
      "     |  \n",
      "     |  as_datatype_enum\n",
      "     |      Returns a `types_pb2.DataType` enum value based on this data type.\n",
      "     |  \n",
      "     |  is_bool\n",
      "     |      Returns whether this is a boolean data type.\n",
      "     |  \n",
      "     |  is_complex\n",
      "     |      Returns whether this is a complex floating point type.\n",
      "     |  \n",
      "     |  is_floating\n",
      "     |      Returns whether this is a (non-quantized, real) floating point type.\n",
      "     |  \n",
      "     |  is_integer\n",
      "     |      Returns whether this is a (non-quantized) integer type.\n",
      "     |  \n",
      "     |  is_numeric\n",
      "     |      Returns whether this is a numeric data type.\n",
      "     |  \n",
      "     |  is_numpy_compatible\n",
      "     |      Returns whether this data type has a compatible NumPy data type.\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Returns whether this is a quantized data type.\n",
      "     |  \n",
      "     |  is_unsigned\n",
      "     |      Returns whether this type is unsigned.\n",
      "     |      \n",
      "     |      Non-numeric, unordered, and quantized types are not considered unsigned, and\n",
      "     |      this function returns `False`.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.trace.TraceType:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    DeviceSpec = class DeviceSpecV1(DeviceSpecV2)\n",
      "     |  DeviceSpec(job=None, replica=None, task=None, device_type=None, device_index=None)\n",
      "     |  \n",
      "     |  Represents a (possibly partial) specification for a TensorFlow device.\n",
      "     |  \n",
      "     |  `DeviceSpec`s are used throughout TensorFlow to describe where state is stored\n",
      "     |  and computations occur. Using `DeviceSpec` allows you to parse device spec\n",
      "     |  strings to verify their validity, merge them or compose them programmatically.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Place the operations on device \"GPU:0\" in the \"ps\" job.\n",
      "     |  device_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  with tf.device(device_spec.to_string()):\n",
      "     |    # Both my_var and squared_var will be placed on /job:ps/device:GPU:0.\n",
      "     |    my_var = tf.Variable(..., name=\"my_variable\")\n",
      "     |    squared_var = tf.square(my_var)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  With eager execution disabled (by default in TensorFlow 1.x and by calling\n",
      "     |  disable_eager_execution() in TensorFlow 2.x), the following syntax\n",
      "     |  can be used:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.compat.v1.disable_eager_execution()\n",
      "     |  \n",
      "     |  # Same as previous\n",
      "     |  device_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  # No need of .to_string() method.\n",
      "     |  with tf.device(device_spec):\n",
      "     |    my_var = tf.Variable(..., name=\"my_variable\")\n",
      "     |    squared_var = tf.square(my_var)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If a `DeviceSpec` is partially specified, it will be merged with other\n",
      "     |  `DeviceSpec`s according to the scope in which it is defined. `DeviceSpec`\n",
      "     |  components defined in inner scopes take precedence over those defined in\n",
      "     |  outer scopes.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  gpu0_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  with tf.device(DeviceSpec(job=\"train\").to_string()):\n",
      "     |    with tf.device(gpu0_spec.to_string()):\n",
      "     |      # Nodes created here will be assigned to /job:ps/device:GPU:0.\n",
      "     |    with tf.device(DeviceSpec(device_type=\"GPU\", device_index=1).to_string()):\n",
      "     |      # Nodes created here will be assigned to /job:train/device:GPU:1.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  A `DeviceSpec` consists of 5 components -- each of\n",
      "     |  which is optionally specified:\n",
      "     |  \n",
      "     |  * Job: The job name.\n",
      "     |  * Replica: The replica index.\n",
      "     |  * Task: The task index.\n",
      "     |  * Device type: The device type string (e.g. \"CPU\" or \"GPU\").\n",
      "     |  * Device index: The device index.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DeviceSpecV1\n",
      "     |      DeviceSpecV2\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  merge_from(self, dev)\n",
      "     |      Merge the properties of \"dev\" into this `DeviceSpec`.\n",
      "     |      \n",
      "     |      Note: Will be removed in TensorFlow 2.x since DeviceSpecs will become\n",
      "     |            immutable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dev: a `DeviceSpec`.\n",
      "     |  \n",
      "     |  parse_from_string(self, spec)\n",
      "     |      Parse a `DeviceSpec` name into its components.\n",
      "     |      \n",
      "     |      **2.x behavior change**:\n",
      "     |      \n",
      "     |      In TensorFlow 1.x, this function mutates its own state and returns itself.\n",
      "     |      In 2.x, DeviceSpecs are immutable, and this function will return a\n",
      "     |        DeviceSpec which contains the spec.\n",
      "     |      \n",
      "     |      * Recommended:\n",
      "     |      \n",
      "     |        ```\n",
      "     |        # my_spec and my_updated_spec are unrelated.\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_updated_spec = tf.DeviceSpec.from_string(\"/GPU:0\")\n",
      "     |        with tf.device(my_updated_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      * Will work in 1.x and 2.x (though deprecated in 2.x):\n",
      "     |      \n",
      "     |        ```\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_updated_spec = my_spec.parse_from_string(\"/GPU:0\")\n",
      "     |        with tf.device(my_updated_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      * Will NOT work in 2.x:\n",
      "     |      \n",
      "     |        ```\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_spec.parse_from_string(\"/GPU:0\")  # <== Will not update my_spec\n",
      "     |        with tf.device(my_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      In general, `DeviceSpec.from_string` should completely replace\n",
      "     |      `DeviceSpec.parse_from_string`, and `DeviceSpec.replace` should\n",
      "     |      completely replace setting attributes directly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: an optional string of the form\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:CPU:<id> or\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:GPU:<id> as cpu and gpu are\n",
      "     |           mutually exclusive. All entries are optional.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `DeviceSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the spec was not valid.\n",
      "     |  \n",
      "     |  to_string(self)\n",
      "     |      Return a string representation of this `DeviceSpec`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        a string of the form\n",
      "     |        /job:<name>/replica:<id>/task:<id>/device:<device_type>:<id>.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  device_index\n",
      "     |  \n",
      "     |  device_type\n",
      "     |  \n",
      "     |  job\n",
      "     |  \n",
      "     |  replica\n",
      "     |  \n",
      "     |  task\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DeviceSpecV2:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Checks if the `other` DeviceSpec is same as the current instance, eg have\n",
      "     |      \n",
      "     |         same value for all the internal fields.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another DeviceSpec\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Return `True` if `other` is also a DeviceSpec instance and has same value\n",
      "     |        as the current instance.\n",
      "     |        Return `False` otherwise.\n",
      "     |  \n",
      "     |  __init__(self, job=None, replica=None, task=None, device_type=None, device_index=None)\n",
      "     |      Create a new `DeviceSpec` object.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        job: string.  Optional job name.\n",
      "     |        replica: int.  Optional replica index.\n",
      "     |        task: int.  Optional task index.\n",
      "     |        device_type: Optional device type string (e.g. \"CPU\" or \"GPU\")\n",
      "     |        device_index: int.  Optional device index.  If left unspecified, device\n",
      "     |          represents 'any' device_index.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  make_merged_spec(self, dev)\n",
      "     |      Returns a new DeviceSpec which incorporates `dev`.\n",
      "     |      \n",
      "     |      When combining specs, `dev` will take precedence over the current spec.\n",
      "     |      So for instance:\n",
      "     |      ```\n",
      "     |      first_spec = tf.DeviceSpec(job=0, device_type=\"CPU\")\n",
      "     |      second_spec = tf.DeviceSpec(device_type=\"GPU\")\n",
      "     |      combined_spec = first_spec.make_merged_spec(second_spec)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      is equivalent to:\n",
      "     |      ```\n",
      "     |      combined_spec = tf.DeviceSpec(job=0, device_type=\"GPU\")\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dev: a `DeviceSpec`\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new `DeviceSpec` which combines `self` and `dev`\n",
      "     |  \n",
      "     |  replace(self, **kwargs)\n",
      "     |      Convenience method for making a new DeviceSpec by overriding fields.\n",
      "     |      \n",
      "     |      For instance:\n",
      "     |      ```\n",
      "     |      my_spec = DeviceSpec=(job=\"my_job\", device=\"CPU\")\n",
      "     |      my_updated_spec = my_spec.replace(device=\"GPU\")\n",
      "     |      my_other_spec = my_spec.replace(device=None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        **kwargs: This method takes the same args as the DeviceSpec constructor\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A DeviceSpec with the fields specified in kwargs overridden.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from DeviceSpecV2:\n",
      "     |  \n",
      "     |  from_string(spec) from builtins.type\n",
      "     |      Construct a `DeviceSpec` from a string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: a string of the form\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:CPU:<id> or\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:GPU:<id> as cpu and gpu are\n",
      "     |           mutually exclusive. All entries are optional.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A DeviceSpec.\n",
      "    \n",
      "    class Dimension(builtins.object)\n",
      "     |  Dimension(value)\n",
      "     |  \n",
      "     |  Represents the value of one dimension in a TensorShape.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  In TF2, members of a `TensorShape` object are integers. The `Dimension` class\n",
      "     |  is not part of TF2's data model.\n",
      "     |  \n",
      "     |  Please refer to the [TensorShape section of the migration guide]\n",
      "     |  (https://www.tensorflow.org/guide/migrate/index#tensorshape) on common code\n",
      "     |  patterns adapting Dimension objects to a TF2 syntax.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |      Returns the sum of `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are summed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    + tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m + n)\n",
      "     |      tf.compat.v1.Dimension(m)    + tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) + tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) + tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the sum of `self` and `other`.\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Equivalent to `bool(self.value)`.\n",
      "     |  \n",
      "     |  __div__(self, other)\n",
      "     |      DEPRECATED: Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only for backwards compatibility purposes; new code\n",
      "     |      should use `__floordiv__` via the syntax `x // y`.  Using `x // y`\n",
      "     |      communicates clearly that the result rounds down, and is forward compatible\n",
      "     |      to Python 3.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns true if `other` has the same known value as this Dimension.\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |      Returns the quotient of `self` and `other` rounded down.\n",
      "     |      \n",
      "     |      Dimensions are divided as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    // tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m // n)\n",
      "     |      tf.compat.v1.Dimension(m)    // tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) // tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) // tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Returns True if `self` is known to be greater than or equal to `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    >= tf.compat.v1.Dimension(n))    == (m >= n)\n",
      "     |      (tf.compat.v1.Dimension(m)    >= tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) >= tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) >= tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value >= other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Returns True if `self` is known to be greater than `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    > tf.compat.v1.Dimension(n))    == (m > n)\n",
      "     |      (tf.compat.v1.Dimension(m)    > tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) > tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) > tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value > other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __index__(self)\n",
      "     |  \n",
      "     |  __init__(self, value)\n",
      "     |      Creates a new Dimension with the given value.\n",
      "     |  \n",
      "     |  __int__(self)\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Returns True if `self` is known to be less than or equal to `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    <= tf.compat.v1.Dimension(n))    == (m <= n)\n",
      "     |      (tf.compat.v1.Dimension(m)    <= tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) <= tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) <= tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value <= other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __long__(self)\n",
      "     |      # This is needed for Windows.\n",
      "     |      # See https://github.com/tensorflow/tensorflow/pull/9780\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Returns True if `self` is known to be less than `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    < tf.compat.v1.Dimension(n))    == (m < n)\n",
      "     |      (tf.compat.v1.Dimension(m)    < tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) < tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) < tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value < other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __mod__(self, other)\n",
      "     |      Returns `self` modulo `other`.\n",
      "     |      \n",
      "     |      Dimension modulo are computed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    % tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m % n)\n",
      "     |      tf.compat.v1.Dimension(m)    % tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) % tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) % tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is `self` modulo `other`.\n",
      "     |  \n",
      "     |  __mul__(self, other)\n",
      "     |      Returns the product of `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are summed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    * tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m * n)\n",
      "     |      tf.compat.v1.Dimension(m)    * tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) * tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) * tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the product of `self` and `other`.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns true if `other` has a different known value from `self`.\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |      Returns the sum of `other` and `self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the sum of `self` and `other`.\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |      Returns the quotient of `other` and `self` rounded down.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __rmod__(self, other)\n",
      "     |      Returns `other` modulo `self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is `other` modulo `self`.\n",
      "     |  \n",
      "     |  __rmul__(self, other)\n",
      "     |      Returns the product of `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the product of `self` and `other`.\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |      Returns the subtraction of `self` from `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the subtraction of `self` from `other`.\n",
      "     |  \n",
      "     |  __rtruediv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__(self, other)\n",
      "     |      Returns the subtraction of `other` from `self`.\n",
      "     |      \n",
      "     |      Dimensions are subtracted as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    - tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m - n)\n",
      "     |      tf.compat.v1.Dimension(m)    - tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) - tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) - tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the subtraction of `other` from `self`.\n",
      "     |  \n",
      "     |  __truediv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'Dimension' and 'int'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  assert_is_compatible_with(self, other)\n",
      "     |      Raises an exception if `other` is not compatible with this Dimension.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible (see\n",
      "     |          is_compatible_with).\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns true if `other` is compatible with this Dimension.\n",
      "     |      \n",
      "     |      Two known Dimensions are compatible if they have the same value.\n",
      "     |      An unknown Dimension is compatible with all other Dimensions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if this Dimension and `other` are compatible.\n",
      "     |  \n",
      "     |  merge_with(self, other)\n",
      "     |      Returns a Dimension that combines the information in `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are combined as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(n))     ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(None))  ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      tf.compat.v1.Dimension(None).merge_with(tf.compat.v1.Dimension(n))     ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      # equivalent to tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None).merge_with(tf.compat.v1.Dimension(None))\n",
      "     |      \n",
      "     |      # raises ValueError for n != m\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(m))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension containing the combined information of `self` and\n",
      "     |        `other`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible (see\n",
      "     |          is_compatible_with).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of this dimension, or None if it is unknown.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      Event\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class FIFOQueue(QueueBase)\n",
      "     |  FIFOQueue(capacity, dtypes, shapes=None, names=None, shared_name=None, name='fifo_queue')\n",
      "     |  \n",
      "     |  A queue implementation that dequeues elements in first-in first-out order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FIFOQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, dtypes, shapes=None, names=None, shared_name=None, name='fifo_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `FIFOQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `FIFOQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `dtypes`, and whose shapes are optionally described\n",
      "     |      by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects\n",
      "     |          with the same length as `dtypes`, or `None`.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from QueueBase:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class FixedLenFeature(FixedLenFeature)\n",
      "     |  FixedLenFeature(shape, dtype, default_value=None)\n",
      "     |  \n",
      "     |  Configuration for parsing a fixed-length input feature.\n",
      "     |  \n",
      "     |  To treat sparse input as dense, provide a `default_value`; otherwise,\n",
      "     |  the parse functions will fail on any examples missing this feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    shape: Shape of input data.\n",
      "     |    dtype: Data type of input.\n",
      "     |    default_value: Value to be used if an example is missing this feature. It\n",
      "     |        must be compatible with `dtype` and of the specified `shape`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLenFeature\n",
      "     |      FixedLenFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, shape, dtype, default_value=None)\n",
      "     |      Create new instance of FixedLenFeature(shape, dtype, default_value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.FixedLenFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.FixedLenFeature', 'FixedLenFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new FixedLenFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new FixedLenFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  default_value\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  __match_args__ = ('shape', 'dtype', 'default_value')\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('shape', 'dtype', 'default_value')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    class FixedLenSequenceFeature(FixedLenSequenceFeature)\n",
      "     |  FixedLenSequenceFeature(shape, dtype, allow_missing=False, default_value=None)\n",
      "     |  \n",
      "     |  Configuration for parsing a variable-length input feature into a `Tensor`.\n",
      "     |  \n",
      "     |  The resulting `Tensor` of parsing a single `SequenceExample` or `Example` has\n",
      "     |  a static `shape` of `[None] + shape` and the specified `dtype`.\n",
      "     |  The resulting `Tensor` of parsing a `batch_size` many `Example`s has\n",
      "     |  a static `shape` of `[batch_size, None] + shape` and the specified `dtype`.\n",
      "     |  The entries in the `batch` from different `Examples` will be padded with\n",
      "     |  `default_value` to the maximum length present in the `batch`.\n",
      "     |  \n",
      "     |  To treat a sparse input as dense, provide `allow_missing=True`; otherwise,\n",
      "     |  the parse functions will fail on any examples missing this feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    shape: Shape of input data for dimension 2 and higher. First dimension is\n",
      "     |      of variable length `None`.\n",
      "     |    dtype: Data type of input.\n",
      "     |    allow_missing: Whether to allow this feature to be missing from a feature\n",
      "     |      list item. Is available only for parsing `SequenceExample` not for\n",
      "     |      parsing `Examples`.\n",
      "     |    default_value: Scalar value to be used to pad multiple `Example`s to their\n",
      "     |      maximum length. Irrelevant for parsing a single `Example` or\n",
      "     |      `SequenceExample`. Defaults to \"\" for dtype string and 0 otherwise\n",
      "     |      (optional).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLenSequenceFeature\n",
      "     |      FixedLenSequenceFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, shape, dtype, allow_missing=False, default_value=None)\n",
      "     |      Create new instance of FixedLenSequenceFeature(shape, dtype, allow_missing, default_value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.FixedLenSequenceFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.FixedLenSequenceFeature', 'FixedLenSequenceFea...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new FixedLenSequenceFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new FixedLenSequenceFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  allow_missing\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  default_value\n",
      "     |      Alias for field number 3\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  __match_args__ = ('shape', 'dtype', 'allow_missing', 'default_value')\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('shape', 'dtype', 'allow_missing', 'default_value')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    class FixedLengthRecordReader(ReaderBase)\n",
      "     |  FixedLengthRecordReader(record_bytes, header_bytes=None, footer_bytes=None, hop_bytes=None, name=None, encoding=None)\n",
      "     |  \n",
      "     |  A Reader that outputs fixed-length records from a file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLengthRecordReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, record_bytes, header_bytes=None, footer_bytes=None, hop_bytes=None, name=None, encoding=None)\n",
      "     |      Create a FixedLengthRecordReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        record_bytes: An int.\n",
      "     |        header_bytes: An optional int. Defaults to 0.\n",
      "     |        footer_bytes: An optional int. Defaults to 0.\n",
      "     |        hop_bytes: An optional int. Defaults to 0.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        encoding: The type of encoding for the file. Defaults to none.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class GPUOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      GPUOptions\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class GradientTape(builtins.object)\n",
      "     |  GradientTape(persistent=False, watch_accessed_variables=True)\n",
      "     |  \n",
      "     |  Record operations for automatic differentiation.\n",
      "     |  \n",
      "     |  Operations are recorded if they are executed within this context manager and\n",
      "     |  at least one of their inputs is being \"watched\".\n",
      "     |  \n",
      "     |  Trainable variables (created by `tf.Variable` or `tf.compat.v1.get_variable`,\n",
      "     |  where `trainable=True` is default in both cases) are automatically watched.\n",
      "     |  Tensors can be manually watched by invoking the `watch` method on this context\n",
      "     |  manager.\n",
      "     |  \n",
      "     |  For example, consider the function `y = x * x`. The gradient at `x = 3.0` can\n",
      "     |  be computed as:\n",
      "     |  \n",
      "     |  >>> x = tf.constant(3.0)\n",
      "     |  >>> with tf.GradientTape() as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   y = x * x\n",
      "     |  >>> dy_dx = g.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  GradientTapes can be nested to compute higher-order derivatives. For example,\n",
      "     |  \n",
      "     |  >>> x = tf.constant(5.0)\n",
      "     |  >>> with tf.GradientTape() as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   with tf.GradientTape() as gg:\n",
      "     |  ...     gg.watch(x)\n",
      "     |  ...     y = x * x\n",
      "     |  ...   dy_dx = gg.gradient(y, x)  # dy_dx = 2 * x\n",
      "     |  >>> d2y_dx2 = g.gradient(dy_dx, x)  # d2y_dx2 = 2\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "     |  >>> print(d2y_dx2)\n",
      "     |  tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  By default, the resources held by a GradientTape are released as soon as\n",
      "     |  GradientTape.gradient() method is called. To compute multiple gradients over\n",
      "     |  the same computation, create a persistent gradient tape. This allows multiple\n",
      "     |  calls to the gradient() method as resources are released when the tape object\n",
      "     |  is garbage collected. For example:\n",
      "     |  \n",
      "     |  >>> x = tf.constant(3.0)\n",
      "     |  >>> with tf.GradientTape(persistent=True) as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   y = x * x\n",
      "     |  ...   z = y * y\n",
      "     |  >>> dz_dx = g.gradient(z, x)  # (4*x^3 at x = 3)\n",
      "     |  >>> print(dz_dx)\n",
      "     |  tf.Tensor(108.0, shape=(), dtype=float32)\n",
      "     |  >>> dy_dx = g.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  By default GradientTape will automatically watch any trainable variables that\n",
      "     |  are accessed inside the context. If you want fine grained control over which\n",
      "     |  variables are watched you can disable automatic tracking by passing\n",
      "     |  `watch_accessed_variables=False` to the tape constructor:\n",
      "     |  \n",
      "     |  >>> x = tf.Variable(2.0)\n",
      "     |  >>> w = tf.Variable(5.0)\n",
      "     |  >>> with tf.GradientTape(\n",
      "     |  ...     watch_accessed_variables=False, persistent=True) as tape:\n",
      "     |  ...   tape.watch(x)\n",
      "     |  ...   y = x ** 2  # Gradients will be available for `x`.\n",
      "     |  ...   z = w ** 3  # No gradients will be available as `w` isn't being watched.\n",
      "     |  >>> dy_dx = tape.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "     |  >>> # No gradients will be available as `w` isn't being watched.\n",
      "     |  >>> dz_dw = tape.gradient(z, w)\n",
      "     |  >>> print(dz_dw)\n",
      "     |  None\n",
      "     |  \n",
      "     |  Note that when using models you should ensure that your variables exist when\n",
      "     |  using `watch_accessed_variables=False`. Otherwise it's quite easy to make your\n",
      "     |  first iteration not have any gradients:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = tf.keras.layers.Dense(32)\n",
      "     |  b = tf.keras.layers.Dense(32)\n",
      "     |  \n",
      "     |  with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
      "     |    tape.watch(a.variables)  # Since `a.build` has not been called at this point\n",
      "     |                             # `a.variables` will return an empty list and the\n",
      "     |                             # tape will not be watching anything.\n",
      "     |    result = b(a(inputs))\n",
      "     |    tape.gradient(result, a.variables)  # The result of this computation will be\n",
      "     |                                        # a list of `None`s since a's variables\n",
      "     |                                        # are not being watched.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that only tensors with real or complex dtypes are differentiable.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      Enters a context inside which operations are recorded on this tape.\n",
      "     |  \n",
      "     |  __exit__(self, typ, value, traceback)\n",
      "     |      Exits the recording context, no further operations are traced.\n",
      "     |  \n",
      "     |  __init__(self, persistent=False, watch_accessed_variables=True)\n",
      "     |      Creates a new GradientTape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        persistent: Boolean controlling whether a persistent gradient tape\n",
      "     |          is created. False by default, which means at most one call can\n",
      "     |          be made to the gradient() method on this object.\n",
      "     |        watch_accessed_variables: Boolean controlling whether the tape will\n",
      "     |          automatically `watch` any (trainable) variables accessed while the tape\n",
      "     |          is active. Defaults to True meaning gradients can be requested from any\n",
      "     |          result computed in the tape derived from reading a trainable `Variable`.\n",
      "     |          If False users must explicitly `watch` any `Variable`s they want to\n",
      "     |          request gradients from.\n",
      "     |  \n",
      "     |  batch_jacobian(self, target, source, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      "     |      Computes and stacks per-example jacobians.\n",
      "     |      \n",
      "     |      See [wikipedia article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant)\n",
      "     |      for the definition of a Jacobian. This function is essentially an efficient\n",
      "     |      implementation of the following:\n",
      "     |      \n",
      "     |      `tf.stack([self.jacobian(y[i], x[i]) for i in range(x.shape[0])])`.\n",
      "     |      \n",
      "     |      Note that compared to `GradientTape.jacobian` which computes gradient of\n",
      "     |      each output value w.r.t each input value, this function is useful when\n",
      "     |      `target[i,...]` is independent of `source[j,...]` for `j != i`. This\n",
      "     |      assumption allows more efficient computation as compared to\n",
      "     |      `GradientTape.jacobian`. The output, as well as intermediate activations,\n",
      "     |      are lower dimensional and avoid a bunch of redundant zeros which would\n",
      "     |      result in the jacobian computation given the independence assumption.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      Note: By default the batch_jacobian implementation uses parallel for (pfor),\n",
      "     |      which creates a tf.function under the hood for each batch_jacobian call.\n",
      "     |      For better performance, and to avoid recompilation and vectorization\n",
      "     |      rewrites on each call, enclose GradientTape code in @tf.function.\n",
      "     |      \n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.GradientTape() as g:\n",
      "     |        x = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float32)\n",
      "     |        g.watch(x)\n",
      "     |        y = x * x\n",
      "     |      batch_jacobian = g.batch_jacobian(y, x)\n",
      "     |      # batch_jacobian is [[[2,  0], [0,  4]], [[6,  0], [0,  8]]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: A tensor with rank 2 or higher and with shape [b, y1, ..., y_n].\n",
      "     |          `target[i,...]` should only depend on `source[i,...]`.\n",
      "     |        source: A tensor with rank 2 or higher and with shape [b, x1, ..., x_m].\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      "     |          in parallel. This knob can be used to control the total memory usage.\n",
      "     |        experimental_use_pfor: If true, uses pfor for computing the Jacobian. Else\n",
      "     |          uses a tf.while_loop.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tensor `t` with shape [b, y_1, ..., y_n, x1, ..., x_m] where `t[i, ...]`\n",
      "     |        is the jacobian of `target[i, ...]` w.r.t. `source[i, ...]`, i.e. stacked\n",
      "     |        per-example jacobians.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      "     |          enabled and without enabling experimental_use_pfor.\n",
      "     |        ValueError: If vectorization of jacobian computation fails or if first\n",
      "     |          dimension of `target` and `source` do not match.\n",
      "     |  \n",
      "     |  gradient(self, target, sources, output_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      "     |      Computes the gradient using operations recorded in context of this tape.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      In addition to Tensors, gradient also supports RaggedTensors. For example,\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1.0, 2.0], [3.0]])\n",
      "     |      >>> with tf.GradientTape() as g:\n",
      "     |      ...   g.watch(x)\n",
      "     |      ...   y = x * x\n",
      "     |      >>> g.gradient(y, x)\n",
      "     |      <tf.RaggedTensor [[2.0, 4.0], [6.0]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: a list or nested structure of Tensors or Variables or\n",
      "     |          CompositeTensors to be differentiated.\n",
      "     |        sources: a list or nested structure of Tensors or Variables or\n",
      "     |          CompositeTensors. `target` will be differentiated against elements in\n",
      "     |          `sources`.\n",
      "     |        output_gradients: a list of gradients, one for each differentiable\n",
      "     |          element of target. Defaults to None.\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        a list or nested structure of Tensors (or IndexedSlices, or None, or\n",
      "     |        CompositeTensor), one for each element in `sources`. Returned structure\n",
      "     |        is the same as the structure of `sources`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called inside the context of the tape.\n",
      "     |        TypeError: If the target is a None object.\n",
      "     |        ValueError: If the target is a variable or if unconnected gradients is\n",
      "     |         called with an unknown value.\n",
      "     |  \n",
      "     |  jacobian(self, target, sources, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      "     |      Computes the jacobian using operations recorded in context of this tape.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      Note: By default the jacobian implementation uses parallel for (pfor), which\n",
      "     |      creates a tf.function under the hood for each jacobian call. For better\n",
      "     |      performance, and to avoid recompilation and vectorization rewrites on each\n",
      "     |      call, enclose GradientTape code in @tf.function.\n",
      "     |      \n",
      "     |      See[wikipedia\n",
      "     |      article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant)\n",
      "     |      for the definition of a Jacobian.\n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.GradientTape() as g:\n",
      "     |        x  = tf.constant([1.0, 2.0])\n",
      "     |        g.watch(x)\n",
      "     |        y = x * x\n",
      "     |      jacobian = g.jacobian(y, x)\n",
      "     |      # jacobian value is [[2., 0.], [0., 4.]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: Tensor to be differentiated.\n",
      "     |        sources: a list or nested structure of Tensors or Variables. `target`\n",
      "     |          will be differentiated against elements in `sources`.\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      "     |          in parallel. This knob can be used to control the total memory usage.\n",
      "     |        experimental_use_pfor: If true, vectorizes the jacobian computation. Else\n",
      "     |          falls back to a sequential while_loop. Vectorization can sometimes fail\n",
      "     |          or lead to excessive memory usage. This option can be used to disable\n",
      "     |          vectorization in such cases.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list or nested structure of Tensors (or None), one for each element in\n",
      "     |        `sources`. Returned structure is the same as the structure of `sources`.\n",
      "     |        Note if any gradient is sparse (IndexedSlices), jacobian function\n",
      "     |        currently makes it dense and returns a Tensor instead. This may change in\n",
      "     |        the future.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      "     |          enabled and without enabling experimental_use_pfor.\n",
      "     |        ValueError: If vectorization of jacobian computation fails.\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |      Clears all information stored in this tape.\n",
      "     |      \n",
      "     |      Equivalent to exiting and reentering the tape context manager with a new\n",
      "     |      tape. For example, the two following code blocks are equivalent:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = loss_fn()\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss += other_loss_fn()\n",
      "     |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      "     |      \n",
      "     |      \n",
      "     |      # The following is equivalent to the above\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = loss_fn()\n",
      "     |        t.reset()\n",
      "     |        loss += other_loss_fn()\n",
      "     |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This is useful if you don't want to exit the context manager for the tape,\n",
      "     |      or can't because the desired reset point is inside a control flow construct:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = ...\n",
      "     |        if loss > k:\n",
      "     |          t.reset()\n",
      "     |      ```\n",
      "     |  \n",
      "     |  stop_recording(self)\n",
      "     |      Temporarily stops recording operations on this tape.\n",
      "     |      \n",
      "     |      Operations executed while this context manager is active will not be\n",
      "     |      recorded on the tape. This is useful for reducing the memory used by tracing\n",
      "     |      all computations.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(4.0)\n",
      "     |      >>> with tf.GradientTape() as tape:\n",
      "     |      ...   with tape.stop_recording():\n",
      "     |      ...     y = x ** 2\n",
      "     |      >>> dy_dx = tape.gradient(y, x)\n",
      "     |      >>> print(dy_dx)\n",
      "     |      None\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        None\n",
      "     |      Raises:\n",
      "     |        RuntimeError: if the tape is not currently recording.\n",
      "     |  \n",
      "     |  watch(self, tensor)\n",
      "     |      Ensures that `tensor` is being traced by this tape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: a Tensor/Variable or list of Tensors/Variables.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if it encounters something that is not a tensor.\n",
      "     |  \n",
      "     |  watched_variables(self)\n",
      "     |      Returns variables watched by this tape in order of construction.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class Graph(tensorflow.python.client._pywrap_tf_session.PyGraph)\n",
      "     |  Graph() -> None\n",
      "     |  \n",
      "     |  A TensorFlow computation, represented as a dataflow graph.\n",
      "     |  \n",
      "     |  Graphs are used by `tf.function`s to represent the function's computations.\n",
      "     |  Each graph contains a set of `tf.Operation` objects, which represent units of\n",
      "     |  computation; and `tf.Tensor` objects, which represent the units of data that\n",
      "     |  flow between operations.\n",
      "     |  \n",
      "     |  ### Using graphs directly (deprecated)\n",
      "     |  \n",
      "     |  A `tf.Graph` can be constructed and used directly without a `tf.function`, as\n",
      "     |  was required in TensorFlow 1, but this is deprecated and it is recommended to\n",
      "     |  use a `tf.function` instead. If a graph is directly used, other deprecated\n",
      "     |  TensorFlow 1 classes are also required to execute the graph, such as a\n",
      "     |  `tf.compat.v1.Session`.\n",
      "     |  \n",
      "     |  A default graph can be registered with the `tf.Graph.as_default` context\n",
      "     |  manager. Then, operations will be added to the graph instead of being executed\n",
      "     |  eagerly. For example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  g = tf.Graph()\n",
      "     |  with g.as_default():\n",
      "     |    # Define operations and tensors in `g`.\n",
      "     |    c = tf.constant(30.0)\n",
      "     |    assert c.graph is g\n",
      "     |  ```\n",
      "     |  \n",
      "     |  `tf.compat.v1.get_default_graph()` can be used to obtain the default graph.\n",
      "     |  \n",
      "     |  Important note: This class *is not* thread-safe for graph construction. All\n",
      "     |  operations should be created from a single thread, or external\n",
      "     |  synchronization must be provided. Unless otherwise specified, all methods\n",
      "     |  are not thread-safe.\n",
      "     |  \n",
      "     |  A `Graph` instance supports an arbitrary number of \"collections\"\n",
      "     |  that are identified by name. For convenience when building a large\n",
      "     |  graph, collections can store groups of related objects: for\n",
      "     |  example, the `tf.Variable` uses a collection (named\n",
      "     |  `tf.GraphKeys.GLOBAL_VARIABLES`) for\n",
      "     |  all variables that are created during the construction of a graph. The caller\n",
      "     |  may define additional collections by specifying a new name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Graph\n",
      "     |      tensorflow.python.client._pywrap_tf_session.PyGraph\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self: ~GraphType) -> ~GraphType\n",
      "     |  \n",
      "     |  __exit__(self, *args) -> None\n",
      "     |  \n",
      "     |  __init__(self) -> None\n",
      "     |      Creates a new, empty Graph.\n",
      "     |  \n",
      "     |  add_to_collection(self, name, value) -> None\n",
      "     |      Stores `value` in the collection with the given `name`.\n",
      "     |      \n",
      "     |      Note that collections are not sets, so it is possible to add a value to\n",
      "     |      a collection several times.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. The `GraphKeys` class contains many\n",
      "     |          standard names for collections.\n",
      "     |        value: The value to add to the collection.\n",
      "     |  \n",
      "     |  add_to_collections(self, names, value) -> None\n",
      "     |      Stores `value` in the collections given by `names`.\n",
      "     |      \n",
      "     |      Note that collections are not sets, so it is possible to add a value to\n",
      "     |      a collection several times. This function makes sure that duplicates in\n",
      "     |      `names` are ignored, but it will not check for pre-existing membership of\n",
      "     |      `value` in any of the collections in `names`.\n",
      "     |      \n",
      "     |      `names` can be any iterable, but if `names` is a string, it is treated as a\n",
      "     |      single collection name.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        names: The keys for the collections to add to. The `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |        value: The value to add to the collections.\n",
      "     |  \n",
      "     |  as_default(self) -> ContextManager[ForwardRef('Graph')]\n",
      "     |      Returns a context manager that makes this `Graph` the default graph.\n",
      "     |      \n",
      "     |      This method should be used if you want to create multiple graphs\n",
      "     |      in the same process. For convenience, a global default graph is\n",
      "     |      provided, and all ops will be added to this graph if you do not\n",
      "     |      create a new graph explicitly.\n",
      "     |      \n",
      "     |      Use this method with the `with` keyword to specify that ops created within\n",
      "     |      the scope of a block should be added to this graph. In this case, once\n",
      "     |      the scope of the `with` is exited, the previous default graph is set again\n",
      "     |      as default. There is a stack, so it's ok to have multiple nested levels\n",
      "     |      of `as_default` calls.\n",
      "     |      \n",
      "     |      The default graph is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default graph in that\n",
      "     |      thread, you must explicitly add a `with g.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      The following code examples are equivalent:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # 1. Using Graph.as_default():\n",
      "     |      g = tf.Graph()\n",
      "     |      with g.as_default():\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        assert c.graph is g\n",
      "     |      \n",
      "     |      # 2. Constructing and making default:\n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        assert c.graph is g\n",
      "     |      ```\n",
      "     |      \n",
      "     |      If eager execution is enabled ops created under this context manager will be\n",
      "     |      added to the graph instead of executed eagerly.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager for using this graph as the default graph.\n",
      "     |  \n",
      "     |  as_graph_def(self, from_version=None, add_shapes=False, use_pybind11_proto=False) -> tensorflow.core.framework.graph_pb2.GraphDef\n",
      "     |      Returns a serialized `GraphDef` representation of this graph.\n",
      "     |      \n",
      "     |      The serialized `GraphDef` can be imported into another `Graph`\n",
      "     |      (using `tf.import_graph_def`) or used with the\n",
      "     |      [C++ Session API](../../api_docs/cc/index.md).\n",
      "     |      \n",
      "     |      This method is thread-safe.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        from_version: Optional.  If this is set, returns a `GraphDef` containing\n",
      "     |          only the nodes that were added to this graph since its `version`\n",
      "     |          property had the given value.\n",
      "     |        add_shapes: If true, adds an \"_output_shapes\" list attr to each node with\n",
      "     |          the inferred shapes of each of its outputs.\n",
      "     |        use_pybind11_proto: If true, If true, uses the c++ pybind11_proto api to\n",
      "     |          get the GraphDef proto directly from c++, instead of through a TF\n",
      "     |          buffer. See https://github.com/pybind/pybind11_protobuf for reference.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A\n",
      "     |        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      "     |        protocol buffer.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If the `graph_def` would be too large.\n",
      "     |  \n",
      "     |  as_graph_element(self, obj, allow_tensor=True, allow_operation=True) -> Union[tensorflow.python.framework.tensor.Tensor, ForwardRef('Operation')]\n",
      "     |      Returns the object referred to by `obj`, as an `Operation` or `Tensor`.\n",
      "     |      \n",
      "     |      This function validates that `obj` represents an element of this\n",
      "     |      graph, and gives an informative error message if it is not.\n",
      "     |      \n",
      "     |      This function is the canonical way to get/validate an object of\n",
      "     |      one of the allowed types from an external argument reference in the\n",
      "     |      Session API.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        obj: A `Tensor`, an `Operation`, or the name of a tensor or operation. Can\n",
      "     |          also be any object with an `_as_graph_element()` method that returns a\n",
      "     |          value of one of these types. Note: `_as_graph_element` will be called\n",
      "     |          inside the graph's lock and so may not modify the graph.\n",
      "     |        allow_tensor: If true, `obj` may refer to a `Tensor`.\n",
      "     |        allow_operation: If true, `obj` may refer to an `Operation`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Tensor` or `Operation` in the Graph corresponding to `obj`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `obj` is not a type we support attempting to convert\n",
      "     |          to types.\n",
      "     |        ValueError: If `obj` is of an appropriate type but invalid. For\n",
      "     |          example, an invalid string.\n",
      "     |        KeyError: If `obj` is not an object in the graph.\n",
      "     |  \n",
      "     |  clear_collection(self, name) -> None\n",
      "     |      Clears all values in a collection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. The `GraphKeys` class contains many\n",
      "     |          standard names for collections.\n",
      "     |  \n",
      "     |  colocate_with(self, op, ignore_existing=False) -> collections.abc.Iterator[None]\n",
      "     |      Returns a context manager that specifies an op to colocate with.\n",
      "     |      \n",
      "     |      Note: this function is not for public use, only for internal libraries.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = tf.Variable([1.0])\n",
      "     |      with g.colocate_with(a):\n",
      "     |        b = tf.constant(1.0)\n",
      "     |        c = tf.add(a, b)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      `b` and `c` will always be colocated with `a`, no matter where `a`\n",
      "     |      is eventually placed.\n",
      "     |      \n",
      "     |      **NOTE** Using a colocation scope resets any existing device constraints.\n",
      "     |      \n",
      "     |      If `op` is `None` then `ignore_existing` must be `True` and the new\n",
      "     |      scope resets all colocation and device constraints.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op: The op to colocate all created ops with, or `None`.\n",
      "     |        ignore_existing: If true, only applies colocation of this op within the\n",
      "     |          context, rather than applying all colocation properties on the stack.\n",
      "     |          If `op` is `None`, this value must be `True`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if op is None but ignore_existing is False.\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        A context manager that specifies the op with which to colocate\n",
      "     |        newly created ops.\n",
      "     |  \n",
      "     |  container(self, container_name) -> collections.abc.Iterator[str]\n",
      "     |      Returns a context manager that specifies the resource container to use.\n",
      "     |      \n",
      "     |      Stateful operations, such as variables and queues, can maintain their\n",
      "     |      states on devices so that they can be shared by multiple processes.\n",
      "     |      A resource container is a string name under which these stateful\n",
      "     |      operations are tracked. These resources can be released or cleared\n",
      "     |      with `tf.Session.reset()`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.container('experiment0'):\n",
      "     |        # All stateful Operations constructed in this context will be placed\n",
      "     |        # in resource container \"experiment0\".\n",
      "     |        v1 = tf.Variable([1.0])\n",
      "     |        v2 = tf.Variable([2.0])\n",
      "     |        with g.container(\"experiment1\"):\n",
      "     |          # All stateful Operations constructed in this context will be\n",
      "     |          # placed in resource container \"experiment1\".\n",
      "     |          v3 = tf.Variable([3.0])\n",
      "     |          q1 = tf.queue.FIFOQueue(10, tf.float32)\n",
      "     |        # All stateful Operations constructed in this context will be\n",
      "     |        # be created in the \"experiment0\".\n",
      "     |        v4 = tf.Variable([4.0])\n",
      "     |        q1 = tf.queue.FIFOQueue(20, tf.float32)\n",
      "     |        with g.container(\"\"):\n",
      "     |          # All stateful Operations constructed in this context will be\n",
      "     |          # be placed in the default resource container.\n",
      "     |          v5 = tf.Variable([5.0])\n",
      "     |          q3 = tf.queue.FIFOQueue(30, tf.float32)\n",
      "     |      \n",
      "     |      # Resets container \"experiment0\", after which the state of v1, v2, v4, q1\n",
      "     |      # will become undefined (such as uninitialized).\n",
      "     |      tf.Session.reset(target, [\"experiment0\"])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        container_name: container name string.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager for defining resource containers for stateful ops,\n",
      "     |          yields the container name.\n",
      "     |  \n",
      "     |  control_dependencies(self, control_inputs) -> tensorflow.python.framework.ops.Graph._ControlDependenciesController\n",
      "     |      Returns a context manager that specifies control dependencies.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that all operations constructed\n",
      "     |      within the context should have control dependencies on\n",
      "     |      `control_inputs`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b, c]):\n",
      "     |        # `d` and `e` will only run after `a`, `b`, and `c` have executed.\n",
      "     |        d = ...\n",
      "     |        e = ...\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Multiple calls to `control_dependencies()` can be nested, and in\n",
      "     |      that case a new `Operation` will have control dependencies on the union\n",
      "     |      of `control_inputs` from all active contexts.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b]):\n",
      "     |        # Ops constructed here run after `a` and `b`.\n",
      "     |        with g.control_dependencies([c, d]):\n",
      "     |          # Ops constructed here run after `a`, `b`, `c`, and `d`.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      You can pass None to clear the control dependencies:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b]):\n",
      "     |        # Ops constructed here run after `a` and `b`.\n",
      "     |        with g.control_dependencies(None):\n",
      "     |          # Ops constructed here run normally, not waiting for either `a` or `b`.\n",
      "     |          with g.control_dependencies([c, d]):\n",
      "     |            # Ops constructed here run after `c` and `d`, also not waiting\n",
      "     |            # for either `a` or `b`.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      *N.B.* The control dependencies context applies *only* to ops that\n",
      "     |      are constructed within the context. Merely using an op or tensor\n",
      "     |      in the context does not add a control dependency. The following\n",
      "     |      example illustrates this point:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # WRONG\n",
      "     |      def my_func(pred, tensor):\n",
      "     |        t = tf.matmul(tensor, tensor)\n",
      "     |        with tf.control_dependencies([pred]):\n",
      "     |          # The matmul op is created outside the context, so no control\n",
      "     |          # dependency will be added.\n",
      "     |          return t\n",
      "     |      \n",
      "     |      # RIGHT\n",
      "     |      def my_func(pred, tensor):\n",
      "     |        with tf.control_dependencies([pred]):\n",
      "     |          # The matmul op is created in the context, so a control dependency\n",
      "     |          # will be added.\n",
      "     |          return tf.matmul(tensor, tensor)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Also note that though execution of ops created under this scope will trigger\n",
      "     |      execution of the dependencies, the ops created under this scope might still\n",
      "     |      be pruned from a normal tensorflow graph. For example, in the following\n",
      "     |      snippet of code the dependencies are never executed:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |        loss = model.loss()\n",
      "     |        with tf.control_dependencies(dependencies):\n",
      "     |          loss = loss + tf.constant(1)  # note: dependencies ignored in the\n",
      "     |                                        # backward pass\n",
      "     |        return tf.gradients(loss, model.variables)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This is because evaluating the gradient graph does not require evaluating\n",
      "     |      the constant(1) op created in the forward pass.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      "     |          executed or computed before running the operations defined in the\n",
      "     |          context.  Can also be `None` to clear the control dependencies.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |       A context manager that specifies control dependencies for all\n",
      "     |       operations constructed within the context.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `control_inputs` is not a list of `Operation` or\n",
      "     |          `Tensor` objects.\n",
      "     |  \n",
      "     |  create_op(self, op_type, inputs, dtypes=None, input_types=None, name=None, attrs=None, op_def=None, compute_shapes=True, compute_device=True) -> 'Operation'\n",
      "     |      Creates an `Operation` in this graph. (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(compute_shapes)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "     |      \n",
      "     |      This is a low-level interface for creating an `Operation`. Most\n",
      "     |      programs will not call this method directly, and instead use the\n",
      "     |      Python op constructors, such as `tf.constant()`, which add ops to\n",
      "     |      the default graph.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type: The `Operation` type to create. This corresponds to the\n",
      "     |          `OpDef.name` field for the proto that defines the operation.\n",
      "     |        inputs: A list of `Tensor` objects that will be inputs to the `Operation`.\n",
      "     |        dtypes: (Optional) A list of `DType` objects that will be the types of the\n",
      "     |          tensors that the operation produces.\n",
      "     |        input_types: (Optional.) A list of `DType`s that will be the types of the\n",
      "     |          tensors that the operation consumes. By default, uses the base `DType`\n",
      "     |          of each input in `inputs`. Operations that expect reference-typed inputs\n",
      "     |          must specify `input_types` explicitly.\n",
      "     |        name: (Optional.) A string name for the operation. If not specified, a\n",
      "     |          name is generated based on `op_type`.\n",
      "     |        attrs: (Optional.) A dictionary where the key is the attribute name (a\n",
      "     |          string) and the value is the respective `attr` attribute of the\n",
      "     |          `NodeDef` proto that will represent the operation (an `AttrValue`\n",
      "     |          proto).\n",
      "     |        op_def: (Optional.) The `OpDef` proto that describes the `op_type` that\n",
      "     |          the operation will have.\n",
      "     |        compute_shapes: (Optional.) Deprecated. Has no effect (shapes are always\n",
      "     |          computed).\n",
      "     |        compute_device: (Optional.) If True, device functions will be executed to\n",
      "     |          compute the device property of the Operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if any of the inputs is not a `Tensor`.\n",
      "     |        ValueError: if colocation conflicts with existing device assignment.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An `Operation` object.\n",
      "     |  \n",
      "     |  device(self, device_name_or_function) -> collections.abc.Iterator[None]\n",
      "     |      Returns a context manager that specifies the default device to use.\n",
      "     |      \n",
      "     |      The `device_name_or_function` argument may either be a device name\n",
      "     |      string, a device function, or None:\n",
      "     |      \n",
      "     |      * If it is a device name string, all operations constructed in\n",
      "     |        this context will be assigned to the device with that name, unless\n",
      "     |        overridden by a nested `device()` context.\n",
      "     |      * If it is a function, it will be treated as a function from\n",
      "     |        Operation objects to device name strings, and invoked each time\n",
      "     |        a new Operation is created. The Operation will be assigned to\n",
      "     |        the device with the returned name.\n",
      "     |      * If it is None, all `device()` invocations from the enclosing context\n",
      "     |        will be ignored.\n",
      "     |      \n",
      "     |      For information about the valid syntax of device name strings, see\n",
      "     |      the documentation in\n",
      "     |      [`DeviceNameUtils`](https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.device('/device:GPU:0'):\n",
      "     |        # All operations constructed in this context will be placed\n",
      "     |        # on GPU 0.\n",
      "     |        with g.device(None):\n",
      "     |          # All operations constructed in this context will have no\n",
      "     |          # assigned device.\n",
      "     |      \n",
      "     |      # Defines a function from `Operation` to device string.\n",
      "     |      def matmul_on_gpu(n):\n",
      "     |        if n.type == \"MatMul\":\n",
      "     |          return \"/device:GPU:0\"\n",
      "     |        else:\n",
      "     |          return \"/cpu:0\"\n",
      "     |      \n",
      "     |      with g.device(matmul_on_gpu):\n",
      "     |        # All operations of type \"MatMul\" constructed in this context\n",
      "     |        # will be placed on GPU 0; all other operations will be placed\n",
      "     |        # on CPU 0.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      **N.B.** The device scope may be overridden by op wrappers or\n",
      "     |      other library code. For example, a variable assignment op\n",
      "     |      `v.assign()` must be colocated with the `tf.Variable` `v`, and\n",
      "     |      incompatible device scopes will be ignored.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        device_name_or_function: The device name or function to use in the\n",
      "     |          context.\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        A context manager that specifies the default device to use for newly\n",
      "     |        created ops.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If device scopes are not properly nested.\n",
      "     |  \n",
      "     |  finalize(self) -> None\n",
      "     |      Finalizes this graph, making it read-only.\n",
      "     |      \n",
      "     |      After calling `g.finalize()`, no new operations can be added to\n",
      "     |      `g`.  This method is used to ensure that no operations are added\n",
      "     |      to a graph when it is shared between multiple threads, for example\n",
      "     |      when using a `tf.compat.v1.train.QueueRunner`.\n",
      "     |  \n",
      "     |  get(self: ~GraphType) -> ~GraphType\n",
      "     |  \n",
      "     |  get_all_collection_keys(self) -> list[str]\n",
      "     |      Returns a list of collections used in this graph.\n",
      "     |  \n",
      "     |  get_collection(self, name, scope=None) -> list[typing.Any]\n",
      "     |      Returns a list of values in the collection with the given `name`.\n",
      "     |      \n",
      "     |      This is different from `get_collection_ref()` which always returns the\n",
      "     |      actual collection list if it exists in that it returns a new list each time\n",
      "     |      it is called.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. For example, the `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |        scope: (Optional.) A string. If supplied, the resulting list is filtered\n",
      "     |          to include only items whose `name` attribute matches `scope` using\n",
      "     |          `re.match`. Items without a `name` attribute are never returned if a\n",
      "     |          scope is supplied. The choice of `re.match` means that a `scope` without\n",
      "     |          special tokens filters by prefix.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of values in the collection with the given `name`, or\n",
      "     |        an empty list if no value has been added to that collection. The\n",
      "     |        list contains the values in the order under which they were\n",
      "     |        collected.\n",
      "     |  \n",
      "     |  get_collection_ref(self, name) -> list[typing.Any]\n",
      "     |      Returns a list of values in the collection with the given `name`.\n",
      "     |      \n",
      "     |      If the collection exists, this returns the list itself, which can\n",
      "     |      be modified in place to change the collection.  If the collection does\n",
      "     |      not exist, it is created as an empty list and the list is returned.\n",
      "     |      \n",
      "     |      This is different from `get_collection()` which always returns a copy of\n",
      "     |      the collection list if it exists and never creates an empty collection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. For example, the `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of values in the collection with the given `name`, or an empty\n",
      "     |        list if no value has been added to that collection.\n",
      "     |  \n",
      "     |  get_name_scope(self) -> str\n",
      "     |      Returns the current name scope.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.name_scope('scope1'):\n",
      "     |        with tf.name_scope('scope2'):\n",
      "     |          print(tf.compat.v1.get_default_graph().get_name_scope())\n",
      "     |      ```\n",
      "     |      would print the string `scope1/scope2`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string representing the current name scope.\n",
      "     |  \n",
      "     |  get_operation_by_name(self, name) -> 'Operation'\n",
      "     |      Returns the `Operation` with the given `name`.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the `Operation` to return.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Operation` with the given `name`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `name` is not a string.\n",
      "     |        KeyError: If `name` does not correspond to an operation in this graph.\n",
      "     |  \n",
      "     |  get_tensor_by_name(self, name) -> tensorflow.python.framework.tensor.Tensor\n",
      "     |      Returns the `Tensor` with the given `name`.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the `Tensor` to return.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Tensor` with the given `name`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `name` is not a string.\n",
      "     |        KeyError: If `name` does not correspond to a tensor in this graph.\n",
      "     |  \n",
      "     |  gradient_override_map(self, op_type_map) -> collections.abc.Iterator[None]\n",
      "     |      EXPERIMENTAL: A context manager for overriding gradient functions.\n",
      "     |      \n",
      "     |      This context manager can be used to override the gradient function\n",
      "     |      that will be used for ops within the scope of the context.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      @tf.RegisterGradient(\"CustomSquare\")\n",
      "     |      def _custom_square_grad(op, grad):\n",
      "     |        # ...\n",
      "     |      \n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        s_1 = tf.square(c)  # Uses the default gradient for tf.square.\n",
      "     |        with g.gradient_override_map({\"Square\": \"CustomSquare\"}):\n",
      "     |          s_2 = tf.square(s_2)  # Uses _custom_square_grad to compute the\n",
      "     |                                # gradient of s_2.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type_map: A dictionary mapping op type strings to alternative op type\n",
      "     |          strings.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager that sets the alternative op type to be used for one\n",
      "     |        or more ops created in that context.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `op_type_map` is not a dictionary mapping strings to\n",
      "     |          strings.\n",
      "     |  \n",
      "     |  is_feedable(self, tensor) -> bool\n",
      "     |      Returns `True` if and only if `tensor` is feedable.\n",
      "     |  \n",
      "     |  is_fetchable(self, tensor_or_op) -> bool\n",
      "     |      Returns `True` if and only if `tensor_or_op` is fetchable.\n",
      "     |  \n",
      "     |  name_scope(self, name) -> collections.abc.Iterator[str]\n",
      "     |      Returns a context manager that creates hierarchical names for operations.\n",
      "     |      \n",
      "     |      A graph maintains a stack of name scopes. A `with name_scope(...):`\n",
      "     |      statement pushes a new name onto the stack for the lifetime of the context.\n",
      "     |      \n",
      "     |      The `name` argument will be interpreted as follows:\n",
      "     |      \n",
      "     |      * A string (not ending with '/') will create a new name scope, in which\n",
      "     |        `name` is appended to the prefix of all operations created in the\n",
      "     |        context. If `name` has been used before, it will be made unique by\n",
      "     |        calling `self.unique_name(name)`.\n",
      "     |      * A scope previously captured from a `with g.name_scope(...) as\n",
      "     |        scope:` statement will be treated as an \"absolute\" name scope, which\n",
      "     |        makes it possible to re-enter existing scopes.\n",
      "     |      * A value of `None` or the empty string will reset the current name scope\n",
      "     |        to the top-level (empty) name scope.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0, name=\"c\")\n",
      "     |        assert c.op.name == \"c\"\n",
      "     |        c_1 = tf.constant(6.0, name=\"c\")\n",
      "     |        assert c_1.op.name == \"c_1\"\n",
      "     |      \n",
      "     |        # Creates a scope called \"nested\"\n",
      "     |        with g.name_scope(\"nested\") as scope:\n",
      "     |          nested_c = tf.constant(10.0, name=\"c\")\n",
      "     |          assert nested_c.op.name == \"nested/c\"\n",
      "     |      \n",
      "     |          # Creates a nested scope called \"inner\".\n",
      "     |          with g.name_scope(\"inner\"):\n",
      "     |            nested_inner_c = tf.constant(20.0, name=\"c\")\n",
      "     |            assert nested_inner_c.op.name == \"nested/inner/c\"\n",
      "     |      \n",
      "     |          # Create a nested scope called \"inner_1\".\n",
      "     |          with g.name_scope(\"inner\"):\n",
      "     |            nested_inner_1_c = tf.constant(30.0, name=\"c\")\n",
      "     |            assert nested_inner_1_c.op.name == \"nested/inner_1/c\"\n",
      "     |      \n",
      "     |            # Treats `scope` as an absolute name scope, and\n",
      "     |            # switches to the \"nested/\" scope.\n",
      "     |            with g.name_scope(scope):\n",
      "     |              nested_d = tf.constant(40.0, name=\"d\")\n",
      "     |              assert nested_d.op.name == \"nested/d\"\n",
      "     |      \n",
      "     |              with g.name_scope(\"\"):\n",
      "     |                e = tf.constant(50.0, name=\"e\")\n",
      "     |                assert e.op.name == \"e\"\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The name of the scope itself can be captured by `with\n",
      "     |      g.name_scope(...) as scope:`, which stores the name of the scope\n",
      "     |      in the variable `scope`. This value can be used to name an\n",
      "     |      operation that represents the overall result of executing the ops\n",
      "     |      in a scope. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      inputs = tf.constant(...)\n",
      "     |      with g.name_scope('my_layer') as scope:\n",
      "     |        weights = tf.Variable(..., name=\"weights\")\n",
      "     |        biases = tf.Variable(..., name=\"biases\")\n",
      "     |        affine = tf.matmul(inputs, weights) + biases\n",
      "     |        output = tf.nn.relu(affine, name=scope)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      NOTE: This constructor validates the given `name`. Valid scope\n",
      "     |      names match one of the following regular expressions:\n",
      "     |      \n",
      "     |          [A-Za-z0-9.][A-Za-z0-9_.\\-/]* (for scopes at the root)\n",
      "     |          [A-Za-z0-9_.\\-/]* (for other scopes)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the scope.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager that installs `name` as a new name scope.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `name` is not a valid scope name, according to the rules\n",
      "     |          above.\n",
      "     |  \n",
      "     |  op_def_for_type(self, type) -> tensorflow.core.framework.op_def_pb2.OpDef\n",
      "     |      Returns the `OpDef` proto for `type`. `type` is a string.\n",
      "     |  \n",
      "     |  prevent_feeding(self, tensor) -> None\n",
      "     |      Marks the given `tensor` as unfeedable in this graph.\n",
      "     |  \n",
      "     |  prevent_fetching(self, op) -> None\n",
      "     |      Marks the given `op` as unfetchable in this graph.\n",
      "     |  \n",
      "     |  switch_to_thread_local(self) -> None\n",
      "     |      Make device, colocation and dependencies stacks thread-local.\n",
      "     |      \n",
      "     |      Device, colocation and dependencies stacks are not thread-local be default.\n",
      "     |      If multiple threads access them, then the state is shared.  This means that\n",
      "     |      one thread may affect the behavior of another thread.\n",
      "     |      \n",
      "     |      After this method is called, the stacks become thread-local.  If multiple\n",
      "     |      threads access them, then the state is not shared.  Each thread uses its own\n",
      "     |      value; a thread doesn't affect other threads by mutating such a stack.\n",
      "     |      \n",
      "     |      The initial value for every thread's stack is set to the current value\n",
      "     |      of the stack when `switch_to_thread_local()` was first called.\n",
      "     |  \n",
      "     |  unique_name(self, name, mark_as_used=True) -> str\n",
      "     |      Return a unique operation name for `name`.\n",
      "     |      \n",
      "     |      Note: You rarely need to call `unique_name()` directly.  Most of\n",
      "     |      the time you just need to create `with g.name_scope()` blocks to\n",
      "     |      generate structured names.\n",
      "     |      \n",
      "     |      `unique_name` is used to generate structured names, separated by\n",
      "     |      `\"/\"`, to help identify operations when debugging a graph.\n",
      "     |      Operation names are displayed in error messages reported by the\n",
      "     |      TensorFlow runtime, and in various visualization tools such as\n",
      "     |      TensorBoard.\n",
      "     |      \n",
      "     |      If `mark_as_used` is set to `True`, which is the default, a new\n",
      "     |      unique name is created and marked as in use. If it's set to `False`,\n",
      "     |      the unique name is returned without actually being marked as used.\n",
      "     |      This is useful when the caller simply wants to know what the name\n",
      "     |      to be created will be.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name for an operation.\n",
      "     |        mark_as_used: Whether to mark this name as being used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string to be passed to `create_op()` that will be used\n",
      "     |        to name the operation being created.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  building_function\n",
      "     |      Returns True iff this graph represents a function.\n",
      "     |  \n",
      "     |  collections\n",
      "     |      Returns the names of the collections known to this graph.\n",
      "     |  \n",
      "     |  finalized\n",
      "     |      True if this graph has been finalized.\n",
      "     |  \n",
      "     |  graph_def_versions\n",
      "     |      The GraphDef version information of this graph.\n",
      "     |      \n",
      "     |      For details on the meaning of each version, see\n",
      "     |      [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `VersionDef`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  seed\n",
      "     |      The graph-level random seed of this graph.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  Dismantle = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> None\n",
      "     |  \n",
      "     |  get_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> list\n",
      "     |  \n",
      "     |  new_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> List[TF_Operation]\n",
      "     |  \n",
      "     |  num_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  operations\n",
      "     |  \n",
      "     |  version\n",
      "    \n",
      "    class GraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  A protobuf containing the graph of operations.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  This API is not available in TensorFlow 2.x.\n",
      "     |  \n",
      "     |  You should not need to use `GraphDef`s directly in TF2. To load `GraphDef`s in\n",
      "     |  TF2, use SavedModel. The SavedModel contains the `GraphDef`.\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.io.gfile.GFile('/tmp/graph.pb', 'rb') as f:\n",
      "     |    graph_def = tf.compat.v1.GraphDef()\n",
      "     |    graph_def.ParseFromString(f.read())\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.saved_model.load('/tmp/saved_model')\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If you would like to create a `GraphDef` in TF2, use `tf.function` and\n",
      "     |  `get_concrete_function`.\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  >>> def f(x):\n",
      "     |  >>>   return x\n",
      "     |  >>>\n",
      "     |  >>> graph_def = f.get_concrete_function(1.).graph.as_graph_def()\n",
      "     |  >>> print(graph_def)\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphDef\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class GraphKeys(builtins.object)\n",
      "     |  Standard names to use for graph collections.\n",
      "     |  \n",
      "     |  The standard library uses various well-known names to collect and\n",
      "     |  retrieve values associated with a graph. For example, the\n",
      "     |  `tf.Optimizer` subclasses default to optimizing the variables\n",
      "     |  collected under `tf.GraphKeys.TRAINABLE_VARIABLES` if none is\n",
      "     |  specified, but it is also possible to pass an explicit list of\n",
      "     |  variables.\n",
      "     |  \n",
      "     |  The following standard keys are defined:\n",
      "     |  \n",
      "     |  * `GLOBAL_VARIABLES`: the default collection of `Variable` objects, shared\n",
      "     |    across distributed environment (model variables are subset of these). See\n",
      "     |    `tf.compat.v1.global_variables`\n",
      "     |    for more details.\n",
      "     |    Commonly, all `TRAINABLE_VARIABLES` variables will be in `MODEL_VARIABLES`,\n",
      "     |    and all `MODEL_VARIABLES` variables will be in `GLOBAL_VARIABLES`.\n",
      "     |  * `LOCAL_VARIABLES`: the subset of `Variable` objects that are local to each\n",
      "     |    machine. Usually used for temporarily variables, like counters.\n",
      "     |  * `MODEL_VARIABLES`: the subset of `Variable` objects that are used in the\n",
      "     |    model for inference (feed forward).\n",
      "     |  * `TRAINABLE_VARIABLES`: the subset of `Variable` objects that will\n",
      "     |    be trained by an optimizer. See\n",
      "     |    `tf.compat.v1.trainable_variables`\n",
      "     |    for more details.\n",
      "     |  * `SUMMARIES`: the summary `Tensor` objects that have been created in the\n",
      "     |    graph. See\n",
      "     |    `tf.compat.v1.summary.merge_all`\n",
      "     |    for more details.\n",
      "     |  * `QUEUE_RUNNERS`: the `QueueRunner` objects that are used to\n",
      "     |    produce input for a computation. See\n",
      "     |    `tf.compat.v1.train.start_queue_runners`\n",
      "     |    for more details.\n",
      "     |  * `MOVING_AVERAGE_VARIABLES`: the subset of `Variable` objects that will also\n",
      "     |    keep moving averages.  See\n",
      "     |    `tf.compat.v1.moving_average_variables`\n",
      "     |    for more details.\n",
      "     |  * `REGULARIZATION_LOSSES`: regularization losses collected during graph\n",
      "     |    construction.\n",
      "     |  \n",
      "     |  The following standard keys are _defined_, but their collections are **not**\n",
      "     |  automatically populated as many of the others are:\n",
      "     |  \n",
      "     |  * `WEIGHTS`\n",
      "     |  * `BIASES`\n",
      "     |  * `ACTIVATIONS`\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ACTIVATIONS = 'activations'\n",
      "     |  \n",
      "     |  ASSET_FILEPATHS = 'asset_filepaths'\n",
      "     |  \n",
      "     |  BIASES = 'biases'\n",
      "     |  \n",
      "     |  CONCATENATED_VARIABLES = 'concatenated_variables'\n",
      "     |  \n",
      "     |  COND_CONTEXT = 'cond_context'\n",
      "     |  \n",
      "     |  EVAL_STEP = 'eval_step'\n",
      "     |  \n",
      "     |  GLOBAL_STEP = 'global_step'\n",
      "     |  \n",
      "     |  GLOBAL_VARIABLES = 'variables'\n",
      "     |  \n",
      "     |  INIT_OP = 'init_op'\n",
      "     |  \n",
      "     |  LOCAL_INIT_OP = 'local_init_op'\n",
      "     |  \n",
      "     |  LOCAL_RESOURCES = 'local_resources'\n",
      "     |  \n",
      "     |  LOCAL_VARIABLES = 'local_variables'\n",
      "     |  \n",
      "     |  LOSSES = 'losses'\n",
      "     |  \n",
      "     |  METRIC_VARIABLES = 'metric_variables'\n",
      "     |  \n",
      "     |  MODEL_VARIABLES = 'model_variables'\n",
      "     |  \n",
      "     |  MOVING_AVERAGE_VARIABLES = 'moving_average_variables'\n",
      "     |  \n",
      "     |  QUEUE_RUNNERS = 'queue_runners'\n",
      "     |  \n",
      "     |  READY_FOR_LOCAL_INIT_OP = 'ready_for_local_init_op'\n",
      "     |  \n",
      "     |  READY_OP = 'ready_op'\n",
      "     |  \n",
      "     |  REGULARIZATION_LOSSES = 'regularization_losses'\n",
      "     |  \n",
      "     |  RESOURCES = 'resources'\n",
      "     |  \n",
      "     |  SAVEABLE_OBJECTS = 'saveable_objects'\n",
      "     |  \n",
      "     |  SAVERS = 'savers'\n",
      "     |  \n",
      "     |  SUMMARIES = 'summaries'\n",
      "     |  \n",
      "     |  SUMMARY_OP = 'summary_op'\n",
      "     |  \n",
      "     |  TABLE_INITIALIZERS = 'table_initializer'\n",
      "     |  \n",
      "     |  TRAINABLE_RESOURCE_VARIABLES = 'trainable_resource_variables'\n",
      "     |  \n",
      "     |  TRAINABLE_VARIABLES = 'trainable_variables'\n",
      "     |  \n",
      "     |  TRAIN_OP = 'train_op'\n",
      "     |  \n",
      "     |  UPDATE_OPS = 'update_ops'\n",
      "     |  \n",
      "     |  VARIABLES = 'variables'\n",
      "     |  \n",
      "     |  WEIGHTS = 'weights'\n",
      "     |  \n",
      "     |  WHILE_CONTEXT = 'while_context'\n",
      "    \n",
      "    class GraphOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      GraphOptions\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class HistogramProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      HistogramProto\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class IdentityReader(ReaderBase)\n",
      "     |  IdentityReader(name=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the queued work as both the key and value.\n",
      "     |  \n",
      "     |  To use, enqueue strings in a Queue.  Read will take the front\n",
      "     |  work string and output (work, work).\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IdentityReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Create a IdentityReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(...)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  IndexedSlices(values, indices, dense_shape=None)\n",
      "     |  \n",
      "     |  A sparse representation of a set of tensor slices at given indices.\n",
      "     |  \n",
      "     |  This class is a simple wrapper for a pair of `Tensor` objects:\n",
      "     |  \n",
      "     |  * `values`: A `Tensor` of any dtype with shape `[D0, D1, ..., Dn]`.\n",
      "     |  * `indices`: A 1-D integer `Tensor` with shape `[D0]`.\n",
      "     |  \n",
      "     |  An `IndexedSlices` is typically used to represent a subset of a larger\n",
      "     |  tensor `dense` of shape `[LARGE0, D1, .. , DN]` where `LARGE0 >> D0`.\n",
      "     |  The values in `indices` are the indices in the first dimension of\n",
      "     |  the slices that have been extracted from the larger tensor.\n",
      "     |  \n",
      "     |  The dense tensor `dense` represented by an `IndexedSlices` `slices` has\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dense[slices.indices[i], :, :, :, ...] = slices.values[i, :, :, :, ...]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The `IndexedSlices` class is used principally in the definition of\n",
      "     |  gradients for operations that have sparse gradients\n",
      "     |  (e.g. `tf.gather`).\n",
      "     |  \n",
      "     |  >>> v = tf.Variable([[0.,1, 2], [2, 3, 4], [4, 5, 6], [6, 7, 8]])\n",
      "     |  >>> with tf.GradientTape() as tape:\n",
      "     |  ...   r = tf.gather(v, [1,3])\n",
      "     |  >>> index_slices = tape.gradient(r,v)\n",
      "     |  >>> index_slices\n",
      "     |  <...IndexedSlices object ...>\n",
      "     |  >>> index_slices.indices.numpy()\n",
      "     |  array([1, 3], dtype=int32)\n",
      "     |  >>> index_slices.values.numpy()\n",
      "     |  array([[1., 1., 1.],\n",
      "     |         [1., 1., 1.]], dtype=float32)\n",
      "     |  \n",
      "     |  Contrast this representation with\n",
      "     |  `tf.sparse.SparseTensor`,\n",
      "     |  which uses multi-dimensional indices and scalar values.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexedSlices\n",
      "     |      tensorflow.python.types.internal.IndexedSlices\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, values, indices, dense_shape=None)\n",
      "     |      Creates an `IndexedSlices`.\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      A 1-D `Tensor` containing the shape of the corresponding dense tensor.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device on which `values` will be produced, or `None`.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains the values, indices, and shape tensors.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      A 1-D `Tensor` containing the indices of the slices.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of this `IndexedSlices`.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces `values` as an output.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Gets the `tf.TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` object.\n",
      "     |  \n",
      "     |  values\n",
      "     |      A `Tensor` containing the values of the slices.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __composite_gradient__ = <tensorflow.python.framework.indexed_slices.I...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.IndexedSlices:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "    \n",
      "    class IndexedSlicesSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  IndexedSlicesSpec(shape=None, dtype=tf.float32, indices_dtype=tf.int64, dense_shape_dtype=None, indices_shape=None)\n",
      "     |  \n",
      "     |  Type specification for a `tf.IndexedSlices`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexedSlicesSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32, indices_dtype=tf.int64, dense_shape_dtype=None, indices_shape=None)\n",
      "     |      Constructs a type specification for a `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The dense shape of the `IndexedSlices`, or `None` to allow any\n",
      "     |          dense shape.\n",
      "     |        dtype: `tf.DType` of values in the `IndexedSlices`.\n",
      "     |        indices_dtype: `tf.DType` of the `indices` in the `IndexedSlices`.  One\n",
      "     |          of `tf.int32` or `tf.int64`.\n",
      "     |        dense_shape_dtype: `tf.DType` of the `dense_shape` in the `IndexedSlices`.\n",
      "     |          One of `tf.int32`, `tf.int64`, or `None` (if the `IndexedSlices` has\n",
      "     |          no `dense_shape` tensor).\n",
      "     |        indices_shape: The shape of the `indices` component, which indicates\n",
      "     |          how many slices are in the `IndexedSlices`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class InteractiveSession(BaseSession)\n",
      "     |  InteractiveSession(target='', graph=None, config=None)\n",
      "     |  \n",
      "     |  A TensorFlow `Session` for use in interactive contexts, such as a shell.\n",
      "     |  \n",
      "     |  The only difference with a regular `Session` is that an `InteractiveSession`\n",
      "     |  installs itself as the default session on construction.\n",
      "     |  The methods `tf.Tensor.eval`\n",
      "     |  and `tf.Operation.run`\n",
      "     |  will use that session to run ops.\n",
      "     |  \n",
      "     |  This is convenient in interactive shells and [IPython\n",
      "     |  notebooks](http://ipython.org), as it avoids having to pass an explicit\n",
      "     |  `Session` object to run ops.\n",
      "     |  \n",
      "     |  For example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  sess = tf.compat.v1.InteractiveSession()\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  # We can just use 'c.eval()' without passing 'sess'\n",
      "     |  print(c.eval())\n",
      "     |  sess.close()\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that a regular session installs itself as the default session when it\n",
      "     |  is created in a `with` statement.  The common usage in non-interactive\n",
      "     |  programs is to follow that pattern:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  with tf.compat.v1.Session():\n",
      "     |    # We can also use 'c.eval()' here.\n",
      "     |    print(c.eval())\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InteractiveSession\n",
      "     |      BaseSession\n",
      "     |      SessionInterface\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, target='', graph=None, config=None)\n",
      "     |      Creates a new interactive TensorFlow session.\n",
      "     |      \n",
      "     |      If no `graph` argument is specified when constructing the session,\n",
      "     |      the default graph will be launched in the session. If you are\n",
      "     |      using more than one graph (created with `tf.Graph()`) in the same\n",
      "     |      process, you will have to use different sessions for each graph,\n",
      "     |      but each graph can be used in multiple sessions. In this case, it\n",
      "     |      is often clearer to pass the graph to be launched explicitly to\n",
      "     |      the session constructor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: (Optional.) The execution engine to connect to. Defaults to using\n",
      "     |          an in-process engine.\n",
      "     |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      "     |        config: (Optional) `ConfigProto` proto used to configure the session.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes an `InteractiveSession`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSession:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  as_default(self)\n",
      "     |      Returns a context manager that makes this object the default session.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that calls to\n",
      "     |      `tf.Operation.run` or `tf.Tensor.eval` should be executed in\n",
      "     |      this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(..)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      \n",
      "     |      with sess.as_default():\n",
      "     |        assert tf.compat.v1.get_default_session() is sess\n",
      "     |        print(c.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      To get the current default session, use `tf.compat.v1.get_default_session`.\n",
      "     |      \n",
      "     |      *N.B.* The `as_default` context manager *does not* close the\n",
      "     |      session when you exit the context, and you must close the session\n",
      "     |      explicitly.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(...)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      # ...\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      \n",
      "     |      sess.close()\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Alternatively, you can use `with tf.compat.v1.Session():` to create a\n",
      "     |      session that is automatically closed on exiting the context,\n",
      "     |      including when an uncaught exception is raised.\n",
      "     |      \n",
      "     |      *N.B.* The default session is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default session in that\n",
      "     |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      "     |      the current default graph. If you are using multiple graphs, and\n",
      "     |      `sess.graph` is different from the value of\n",
      "     |      `tf.compat.v1.get_default_graph`, you must explicitly enter a\n",
      "     |      `with sess.graph.as_default():` block to make `sess.graph` the default\n",
      "     |      graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager using this session as the default session.\n",
      "     |  \n",
      "     |  list_devices(self)\n",
      "     |      Lists available devices in this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      devices = sess.list_devices()\n",
      "     |      for d in devices:\n",
      "     |        print(d.name)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Where:\n",
      "     |        Each element in the list has the following properties\n",
      "     |        name: A string with the full name of the device. ex:\n",
      "     |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      "     |        device_type: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      "     |        memory_limit: The maximum amount of memory available on the device.\n",
      "     |            Note: depending on the device, it is possible the usable memory could\n",
      "     |            be substantially less.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      "     |        invalid state, or network errors occur).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of devices in the session.\n",
      "     |  \n",
      "     |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      "     |      Returns a Python callable that runs a particular step.\n",
      "     |      \n",
      "     |      The returned callable will take `len(feed_list)` arguments whose types\n",
      "     |      must be compatible feed values for the respective elements of `feed_list`.\n",
      "     |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      "     |      argument to the returned callable must be a numpy ndarray (or something\n",
      "     |      convertible to an ndarray) with matching element type and shape. See\n",
      "     |      `tf.Session.run` for details of the allowable feed key and value types.\n",
      "     |      \n",
      "     |      The returned callable will have the same return type as\n",
      "     |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      "     |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      "     |      it will return `None`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A value or list of values to fetch. See `tf.Session.run` for\n",
      "     |          details of the allowable fetch types.\n",
      "     |        feed_list: (Optional.) A list of `feed_dict` keys. See `tf.Session.run`\n",
      "     |          for details of the allowable feed key types.\n",
      "     |        accept_options: (Optional.) If `True`, the returned `Callable` will be\n",
      "     |          able to accept `tf.compat.v1.RunOptions` and `tf.compat.v1.RunMetadata`\n",
      "     |          as optional keyword arguments `options` and `run_metadata`,\n",
      "     |          respectively, with the same syntax and semantics as `tf.Session.run`,\n",
      "     |          which is useful for certain use cases (profiling and debugging) but will\n",
      "     |          result in measurable slowdown of the `Callable`'s\n",
      "     |          performance. Default: `False`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A function that when called will execute the step defined by\n",
      "     |        `feed_list` and `fetches` in this session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      "     |          as arguments to `tf.Session.run`.\n",
      "     |  \n",
      "     |  partial_run(self, handle, fetches, feed_dict=None)\n",
      "     |      Continues the execution with more feeds and fetches. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2023-06-01.\n",
      "     |      Instructions for updating:\n",
      "     |      This function is deprecated and we do not expect adding newfunctionality to it. Please do not have your code dependingon this function.\n",
      "     |      \n",
      "     |      NOTE: This function is deprecated and we do not expect adding new\n",
      "     |      functionality to it. Please do not have your code depending on this\n",
      "     |      function.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      "     |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      "     |      list of feeds and fetches that will be used in the subsequent\n",
      "     |      `partial_run` calls.\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. See run() for more information.\n",
      "     |      \n",
      "     |      Below is a simple example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      r1 = math_ops.add(a, b)\n",
      "     |      r2 = math_ops.multiply(r1, c)\n",
      "     |      \n",
      "     |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      "     |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      "     |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        handle: A handle for a sequence of partial runs.\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (see\n",
      "     |          documentation for `run`).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary\n",
      "     |        (see documentation for `run`).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses on error.\n",
      "     |  \n",
      "     |  partial_run_setup(self, fetches, feeds=None)\n",
      "     |      Sets up a graph with feeds and fetches for partial run. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2023-06-01.\n",
      "     |      Instructions for updating:\n",
      "     |      This function is deprecated and we do not expect adding newfunctionality to it. Please do not have your code dependingon this function.\n",
      "     |      \n",
      "     |      NOTE: This function is deprecated and we do not expect adding new\n",
      "     |      functionality to it. Please do not have your code depending on this\n",
      "     |      function.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      "     |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, or a list of graph elements.\n",
      "     |        feeds: A single graph element, or a list of graph elements.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A handle for partial run.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      "     |  \n",
      "     |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      "     |      Runs operations and evaluates tensors in `fetches`.\n",
      "     |      \n",
      "     |      This method runs one \"step\" of TensorFlow computation, by\n",
      "     |      running the necessary graph fragment to execute every `Operation`\n",
      "     |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      "     |      `feed_dict` for the corresponding input values.\n",
      "     |      \n",
      "     |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      "     |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      "     |      elements at its leaves.  A graph element can be one of the following types:\n",
      "     |      \n",
      "     |      * A `tf.Operation`.\n",
      "     |        The corresponding fetched value will be `None`.\n",
      "     |      * A `tf.Tensor`.\n",
      "     |        The corresponding fetched value will be a numpy ndarray containing the\n",
      "     |        value of that tensor.\n",
      "     |      * A `tf.sparse.SparseTensor`.\n",
      "     |        The corresponding fetched value will be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`\n",
      "     |        containing the value of that sparse tensor.\n",
      "     |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      "     |        numpy ndarray containing the handle of that tensor.\n",
      "     |      * A `string` which is the name of a tensor or operation in the graph.\n",
      "     |      \n",
      "     |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      "     |      where the leaves are replaced by the corresponding values returned by\n",
      "     |      TensorFlow.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |         a = tf.constant([10, 20])\n",
      "     |         b = tf.constant([1.0, 2.0])\n",
      "     |         # 'fetches' can be a singleton\n",
      "     |         v = session.run(a)\n",
      "     |         # v is the numpy array [10, 20]\n",
      "     |         # 'fetches' can be a list.\n",
      "     |         v = session.run([a, b])\n",
      "     |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      "     |         # 1-D array [1.0, 2.0]\n",
      "     |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      "     |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      "     |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      "     |         # v is a dict with\n",
      "     |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      "     |         # 'b' (the numpy array [1.0, 2.0])\n",
      "     |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      "     |         # [10, 20].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      "     |      one of the following types:\n",
      "     |      \n",
      "     |      * If the key is a `tf.Tensor`, the\n",
      "     |        value may be a Python scalar, string, list, or numpy ndarray\n",
      "     |        that can be converted to the same `dtype` as that\n",
      "     |        tensor. Additionally, if the key is a\n",
      "     |        `tf.compat.v1.placeholder`, the shape of\n",
      "     |        the value will be checked for compatibility with the placeholder.\n",
      "     |      * If the key is a\n",
      "     |        `tf.sparse.SparseTensor`,\n",
      "     |        the value should be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`.\n",
      "     |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      "     |        should be a nested tuple with the same structure that maps to their\n",
      "     |        corresponding values as above.\n",
      "     |      \n",
      "     |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      "     |      of the corresponding key.\n",
      "     |      \n",
      "     |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      "     |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      "     |      on).\n",
      "     |      \n",
      "     |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      "     |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      "     |      example, when users turn on tracing in `options`, the profiled info will be\n",
      "     |      collected into this argument and passed back.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (described\n",
      "     |          above).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |        options: A [`RunOptions`] protocol buffer\n",
      "     |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary (described above).\n",
      "     |        Order in which `fetches` operations are evaluated inside the call\n",
      "     |        is undefined.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      "     |          `Tensor` that doesn't exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSession:\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The graph that was launched in this session.\n",
      "     |  \n",
      "     |  graph_def\n",
      "     |      A serializable version of the underlying TensorFlow graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      "     |        the underlying TensorFlow graph.\n",
      "     |  \n",
      "     |  sess_str\n",
      "     |      The TensorFlow process to which this session will connect.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SessionInterface:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class LMDBReader(ReaderBase)\n",
      "     |  LMDBReader(name=None, options=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the records from a LMDB file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LMDBReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, options=None)\n",
      "     |      Create a LMDBReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.contrib.data.LMDBDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        options: A LMDBRecordOptions object (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class LogMessage(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      LogMessage\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class MetaGraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      MetaGraphDef\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CollectionDefEntry = <class 'tensorflow.core.protobuf.meta_graph_pb2.C...\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  MetaInfoDef = <class 'tensorflow.core.protobuf.meta_graph_pb2.MetaInfo...\n",
      "     |  \n",
      "     |  SignatureDefEntry = <class 'tensorflow.core.protobuf.meta_graph_pb2.Si...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class Module(tensorflow.python.trackable.autotrackable.AutoTrackable)\n",
      "     |  Module(name=None)\n",
      "     |  \n",
      "     |  Base neural network module class.\n",
      "     |  \n",
      "     |  A module is a named container for `tf.Variable`s, other `tf.Module`s and\n",
      "     |  functions which apply to user input. For example a dense layer in a neural\n",
      "     |  network might be implemented as a `tf.Module`:\n",
      "     |  \n",
      "     |  >>> class Dense(tf.Module):\n",
      "     |  ...   def __init__(self, input_dim, output_size, name=None):\n",
      "     |  ...     super().__init__(name=name)\n",
      "     |  ...     self.w = tf.Variable(\n",
      "     |  ...       tf.random.normal([input_dim, output_size]), name='w')\n",
      "     |  ...     self.b = tf.Variable(tf.zeros([output_size]), name='b')\n",
      "     |  ...   def __call__(self, x):\n",
      "     |  ...     y = tf.matmul(x, self.w) + self.b\n",
      "     |  ...     return tf.nn.relu(y)\n",
      "     |  \n",
      "     |  You can use the Dense layer as you would expect:\n",
      "     |  \n",
      "     |  >>> d = Dense(input_dim=3, output_size=2)\n",
      "     |  >>> d(tf.ones([1, 3]))\n",
      "     |  <tf.Tensor: shape=(1, 2), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |  \n",
      "     |  \n",
      "     |  By subclassing `tf.Module` instead of `object` any `tf.Variable` or\n",
      "     |  `tf.Module` instances assigned to object properties can be collected using\n",
      "     |  the `variables`, `trainable_variables` or `submodules` property:\n",
      "     |  \n",
      "     |  >>> d.variables\n",
      "     |      (<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=...,\n",
      "     |      dtype=float32)>,\n",
      "     |      <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=..., dtype=float32)>)\n",
      "     |  \n",
      "     |  \n",
      "     |  Subclasses of `tf.Module` can also take advantage of the `_flatten` method\n",
      "     |  which can be used to implement tracking of any other types.\n",
      "     |  \n",
      "     |  All `tf.Module` classes have an associated `tf.name_scope` which can be used\n",
      "     |  to group operations in TensorBoard and create hierarchies for variable names\n",
      "     |  which can help with debugging. We suggest using the name scope when creating\n",
      "     |  nested submodules/parameters or for forward methods whose graph you might want\n",
      "     |  to inspect in TensorBoard. You can enter the name scope explicitly using\n",
      "     |  `with self.name_scope:` or you can annotate methods (apart from `__init__`)\n",
      "     |  with `@tf.Module.with_name_scope`.\n",
      "     |  \n",
      "     |  >>> class MLP(tf.Module):\n",
      "     |  ...   def __init__(self, input_size, sizes, name=None):\n",
      "     |  ...     super().__init__(name=name)\n",
      "     |  ...     self.layers = []\n",
      "     |  ...     with self.name_scope:\n",
      "     |  ...       for size in sizes:\n",
      "     |  ...         self.layers.append(Dense(input_dim=input_size, output_size=size))\n",
      "     |  ...         input_size = size\n",
      "     |  ...   @tf.Module.with_name_scope\n",
      "     |  ...   def __call__(self, x):\n",
      "     |  ...     for layer in self.layers:\n",
      "     |  ...       x = layer(x)\n",
      "     |  ...     return x\n",
      "     |  \n",
      "     |  >>> module = MLP(input_size=5, sizes=[5, 5])\n",
      "     |  >>> module.variables\n",
      "     |  (<tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,\n",
      "     |     dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,\n",
      "     |     dtype=float32)>)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Module\n",
      "     |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      "     |      tensorflow.python.trackable.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  with_name_scope(method) from builtins.type\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  non_trainable_variables\n",
      "     |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of trainable variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class NameAttrList(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      NameAttrList\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AttrEntry = <class 'tensorflow.core.framework.attr_value_pb2.AttrEntry...\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class NodeDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      NodeDef\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AttrEntry = <class 'tensorflow.core.framework.node_def_pb2.AttrEntry'>\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ExperimentalDebugInfo = <class 'tensorflow.core.framework.node_def_pb2...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class OpError(builtins.Exception)\n",
      "     |  OpError(node_def, op, message, error_code, *args)\n",
      "     |  \n",
      "     |  The base class for TensorFlow exceptions.\n",
      "     |  \n",
      "     |  Usually, TensorFlow will raise a more specific subclass of `OpError` from the\n",
      "     |  `tf.errors` module.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, node_def, op, message, error_code, *args)\n",
      "     |      Creates a new `OpError` indicating that a particular op failed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        node_def: The `node_def_pb2.NodeDef` proto representing the op that\n",
      "     |          failed, if known; otherwise None.\n",
      "     |        op: The `ops.Operation` that failed, if known; otherwise None. During\n",
      "     |          eager execution, this field is always `None`.\n",
      "     |        message: The message string describing the failure.\n",
      "     |        error_code: The `error_codes_pb2.Code` describing the error.\n",
      "     |        *args: If not empty, it should contain a dictionary describing details\n",
      "     |          about the error. This argument is inspired by Abseil payloads:\n",
      "     |          https://github.com/abseil/abseil-cpp/blob/master/absl/status/status.h\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  error_code\n",
      "     |      The integer error code that describes the error.\n",
      "     |  \n",
      "     |  experimental_payloads\n",
      "     |      A dictionary describing the details of the error.\n",
      "     |  \n",
      "     |  message\n",
      "     |      The error message that describes the error.\n",
      "     |  \n",
      "     |  node_def\n",
      "     |      The `NodeDef` proto representing the op that failed.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The operation that failed, if known.\n",
      "     |      \n",
      "     |      *N.B.* If the failed op was synthesized at runtime, e.g. a `Send`\n",
      "     |      or `Recv` op, there will be no corresponding\n",
      "     |      `tf.Operation`\n",
      "     |      object.  In that case, this will return `None`, and you should\n",
      "     |      instead use the `tf.errors.OpError.node_def` to\n",
      "     |      discover information about the op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Operation` that failed, or None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  add_note(...)\n",
      "     |      Exception.add_note(note) --\n",
      "     |      add a note to the exception\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class Operation(tensorflow.python.client._pywrap_tf_session.PyOperation)\n",
      "     |  Represents a graph node that performs computation on tensors.\n",
      "     |  \n",
      "     |  An `Operation` is a node in a `tf.Graph` that takes zero or more `Tensor`\n",
      "     |  objects as input, and produces zero or more `Tensor` objects as output.\n",
      "     |  Objects of type `Operation` are created by calling a Python op constructor\n",
      "     |  (such as `tf.matmul`) within a `tf.function` or under a `tf.Graph.as_default`\n",
      "     |  context manager.\n",
      "     |  \n",
      "     |  For example, within a `tf.function`, `c = tf.matmul(a, b)` creates an\n",
      "     |  `Operation` of type \"MatMul\" that takes tensors `a` and `b` as input, and\n",
      "     |  produces `c` as output.\n",
      "     |  \n",
      "     |  If a `tf.compat.v1.Session` is used, an `Operation` of a `tf.Graph` can be\n",
      "     |  executed by passing it to `tf.Session.run`. `op.run()` is a shortcut for\n",
      "     |  calling `tf.compat.v1.get_default_session().run(op)`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Operation\n",
      "     |      tensorflow.python.client._pywrap_tf_session.PyOperation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self) -> str\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __tf_tensor__(self, dtype=None, name=None) -> NoReturn\n",
      "     |      Raises a helpful error.\n",
      "     |  \n",
      "     |  colocation_groups(self) -> list[bytes]\n",
      "     |      Returns the list of colocation groups of the op.\n",
      "     |  \n",
      "     |  experimental_set_type(self, type_proto) -> None\n",
      "     |      Sets the corresponding node's `experimental_type` field.\n",
      "     |      \n",
      "     |      See the description of `NodeDef.experimental_type` for more info.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        type_proto: A FullTypeDef proto message. The root type_if of this object\n",
      "     |          must be `TFT_PRODUCT`, even for ops which only have a singlre return\n",
      "     |          value.\n",
      "     |  \n",
      "     |  get_attr(self, name)\n",
      "     |      Returns the value of the attr of this op with the given `name`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the attr to fetch.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of the attr, as a Python object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If this op does not have an attr with the given `name`.\n",
      "     |  \n",
      "     |  run(self, feed_dict=None, session=None) -> None\n",
      "     |      Runs this operation in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for this operation.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `Operation.run()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to run to this operation. If\n",
      "     |          none, the default session will be used.\n",
      "     |  \n",
      "     |  values(self) -> tuple[typing.Any, ...]\n",
      "     |      DEPRECATED: Use outputs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_node_def(node_def, g, inputs=None, output_types=None, control_inputs=None, input_types=None, original_op=None, op_def=None) -> ~OperationType from builtins.type\n",
      "     |      Creates an `Operation`.\n",
      "     |      \n",
      "     |      NOTE: This constructor validates the name of the `Operation` (passed\n",
      "     |      as `node_def.name`). Valid `Operation` names match the following\n",
      "     |      regular expression:\n",
      "     |      \n",
      "     |          [A-Za-z0-9.][A-Za-z0-9_.\\\\-/]*\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        node_def: `node_def_pb2.NodeDef`.  `NodeDef` for the `Operation`. Used for\n",
      "     |          attributes of `node_def_pb2.NodeDef`, typically `name`, `op`, and\n",
      "     |          `device`.  The `input` attribute is irrelevant here as it will be\n",
      "     |          computed when generating the model.\n",
      "     |        g: `Graph`. The parent graph.\n",
      "     |        inputs: list of `Tensor` objects. The inputs to this `Operation`.\n",
      "     |        output_types: list of `DType` objects.  List of the types of the `Tensors`\n",
      "     |          computed by this operation.  The length of this list indicates the\n",
      "     |          number of output endpoints of the `Operation`.\n",
      "     |        control_inputs: list of operations or tensors from which to have a control\n",
      "     |          dependency.\n",
      "     |        input_types: List of `DType` objects representing the types of the tensors\n",
      "     |          accepted by the `Operation`.  By default uses `[x.dtype.base_dtype for x\n",
      "     |          in inputs]`.  Operations that expect reference-typed inputs must specify\n",
      "     |          these explicitly.\n",
      "     |        original_op: Optional. Used to associate the new `Operation` with an\n",
      "     |          existing `Operation` (for example, a replica with the op that was\n",
      "     |          replicated).\n",
      "     |        op_def: Optional. The `op_def_pb2.OpDef` proto that describes the op type\n",
      "     |          that this `Operation` represents.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if control inputs are not Operations or Tensors,\n",
      "     |          or if `node_def` is not a `NodeDef`,\n",
      "     |          or if `g` is not a `Graph`,\n",
      "     |          or if `inputs` are not tensors,\n",
      "     |          or if `inputs` and `input_types` are incompatible.\n",
      "     |        ValueError: if the `node_def` name is not valid.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device to which this op has been assigned, if any.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The string name of the device to which this op has been\n",
      "     |        assigned, or an empty string if it has not been assigned to a\n",
      "     |        device.\n",
      "     |  \n",
      "     |  inputs\n",
      "     |      The sequence of `Tensor` objects representing the data inputs of this op.\n",
      "     |  \n",
      "     |  node_def\n",
      "     |  \n",
      "     |  op_def\n",
      "     |  \n",
      "     |  traceback\n",
      "     |      Returns the call stack from when this operation was constructed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  control_inputs\n",
      "     |      The `Operation` objects on which this op has a control dependency.\n",
      "     |      \n",
      "     |      Before this op is executed, TensorFlow will ensure that the\n",
      "     |      operations in `self.control_inputs` have finished executing. This\n",
      "     |      mechanism can be used to run ops sequentially for performance\n",
      "     |      reasons, or to ensure that the side effects of an op are observed\n",
      "     |      in the correct order.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of `Operation` objects.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  outputs\n",
      "     |  \n",
      "     |  type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  graph\n",
      "    \n",
      "    class OptimizerOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      OptimizerOptions\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class OptionalSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  OptionalSpec(element_spec)\n",
      "     |  \n",
      "     |  Type specification for `tf.experimental.Optional`.\n",
      "     |  \n",
      "     |  For instance, `tf.OptionalSpec` can be used to define a tf.function that takes\n",
      "     |  `tf.experimental.Optional` as an input argument:\n",
      "     |  \n",
      "     |  >>> @tf.function(input_signature=[tf.OptionalSpec(\n",
      "     |  ...   tf.TensorSpec(shape=(), dtype=tf.int32, name=None))])\n",
      "     |  ... def maybe_square(optional):\n",
      "     |  ...   if optional.has_value():\n",
      "     |  ...     x = optional.get_value()\n",
      "     |  ...     return x * x\n",
      "     |  ...   return -1\n",
      "     |  >>> optional = tf.experimental.Optional.from_value(5)\n",
      "     |  >>> print(maybe_square(optional))\n",
      "     |  tf.Tensor(25, shape=(), dtype=int32)\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |    element_spec: A (nested) structure of `TypeSpec` objects that represents the\n",
      "     |      type specification of the optional element.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OptionalSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, element_spec)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_value(value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class PaddingFIFOQueue(QueueBase)\n",
      "     |  PaddingFIFOQueue(capacity, dtypes, shapes, names=None, shared_name=None, name='padding_fifo_queue')\n",
      "     |  \n",
      "     |  A FIFOQueue that supports batching variable-sized tensors by padding.\n",
      "     |  \n",
      "     |  A `PaddingFIFOQueue` may contain components with dynamic shape, while also\n",
      "     |  supporting `dequeue_many`.  See the constructor for more details.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PaddingFIFOQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, dtypes, shapes, names=None, shared_name=None, name='padding_fifo_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `PaddingFIFOQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `PaddingFIFOQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `dtypes`, and whose shapes are described by the `shapes`\n",
      "     |      argument.\n",
      "     |      \n",
      "     |      The `shapes` argument must be specified; each component of a queue\n",
      "     |      element must have the respective shape.  Shapes of fixed\n",
      "     |      rank but variable size are allowed by setting any shape dimension to None.\n",
      "     |      In this case, the inputs' shape may vary along the given dimension, and\n",
      "     |      `dequeue_many` will pad the given dimension with zeros up to the maximum\n",
      "     |      shape of all elements in the given batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: A list of `TensorShape` objects, with the same length as\n",
      "     |          `dtypes`.  Any dimension in the `TensorShape` containing value\n",
      "     |          `None` is dynamic and allows values to be enqueued with\n",
      "     |           variable size in that dimension.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If shapes is not a list of shapes, or the lengths of dtypes\n",
      "     |          and shapes do not match, or if names is specified and the lengths of\n",
      "     |          dtypes and names do not match.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from QueueBase:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class PriorityQueue(QueueBase)\n",
      "     |  PriorityQueue(capacity, types, shapes=None, names=None, shared_name=None, name='priority_queue')\n",
      "     |  \n",
      "     |  A queue implementation that dequeues elements in prioritized order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PriorityQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, types, shapes=None, names=None, shared_name=None, name='priority_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `PriorityQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `PriorityQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `types`, and whose shapes are optionally described\n",
      "     |      by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      Enqueues and Dequeues to the `PriorityQueue` must include an additional\n",
      "     |      tuple entry at the beginning: the `priority`.  The priority must be\n",
      "     |      an int64 scalar (for `enqueue`) or an int64 vector (for `enqueue_many`).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        types:  A list of `DType` objects. The length of `types` must equal\n",
      "     |          the number of tensors in each queue element, except the first priority\n",
      "     |          element.  The first tensor in each element is the priority,\n",
      "     |          which must be type int64.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects,\n",
      "     |          with the same length as `types`, or `None`.\n",
      "     |        names: (Optional.) A list of strings naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified, the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from QueueBase:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class QueueBase(builtins.object)\n",
      "     |  QueueBase(dtypes, shapes, names, queue_ref)\n",
      "     |  \n",
      "     |  Base class for queue implementations.\n",
      "     |  \n",
      "     |  A queue is a TensorFlow data structure that stores tensors across\n",
      "     |  multiple steps, and exposes operations that enqueue and dequeue\n",
      "     |  tensors.\n",
      "     |  \n",
      "     |  Each queue element is a tuple of one or more tensors, where each\n",
      "     |  tuple component has a static dtype, and may have a static shape. The\n",
      "     |  queue implementations support versions of enqueue and dequeue that\n",
      "     |  handle single elements, versions that support enqueuing and\n",
      "     |  dequeuing a batch of elements at once.\n",
      "     |  \n",
      "     |  See `tf.queue.FIFOQueue` and\n",
      "     |  `tf.queue.RandomShuffleQueue` for concrete\n",
      "     |  implementations of this class, and instructions on how to create\n",
      "     |  them.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtypes, shapes, names, queue_ref)\n",
      "     |      Constructs a queue object from a queue reference.\n",
      "     |      \n",
      "     |      The two optional lists, `shapes` and `names`, must be of the same length\n",
      "     |      as `dtypes` if provided.  The values at a given index `i` indicate the\n",
      "     |      shape and name to use for the corresponding queue component in `dtypes`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtypes:  A list of types.  The length of dtypes must equal the number\n",
      "     |          of tensors in each element.\n",
      "     |        shapes: Constraints on the shapes of tensors in an element:\n",
      "     |          A list of shape tuples or None. This list is the same length\n",
      "     |          as dtypes.  If the shape of any tensors in the element are constrained,\n",
      "     |          all must be; shapes can be None if the shapes should not be constrained.\n",
      "     |        names: Optional list of names.  If provided, the `enqueue()` and\n",
      "     |          `dequeue()` methods will use dictionaries with these names as keys.\n",
      "     |          Must be None or a list or tuple of the same length as `dtypes`.\n",
      "     |        queue_ref: The queue reference, i.e. the output of the queue op.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If one of the arguments is invalid.\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.internal.RaggedTensor)\n",
      "     |  RaggedTensor(values, row_partition, internal=False)\n",
      "     |  \n",
      "     |  Represents a ragged tensor.\n",
      "     |  \n",
      "     |  A `RaggedTensor` is a tensor with one or more *ragged dimensions*, which are\n",
      "     |  dimensions whose slices may have different lengths.  For example, the inner\n",
      "     |  (column) dimension of `rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is ragged,\n",
      "     |  since the column slices (`rt[0, :]`, ..., `rt[4, :]`) have different lengths.\n",
      "     |  Dimensions whose slices all have the same length are called *uniform\n",
      "     |  dimensions*.  The outermost dimension of a `RaggedTensor` is always uniform,\n",
      "     |  since it consists of a single slice (and so there is no possibility for\n",
      "     |  differing slice lengths).\n",
      "     |  \n",
      "     |  The total number of dimensions in a `RaggedTensor` is called its *rank*,\n",
      "     |  and the number of ragged dimensions in a `RaggedTensor` is called its\n",
      "     |  *ragged-rank*.  A `RaggedTensor`'s ragged-rank is fixed at graph creation\n",
      "     |  time: it can't depend on the runtime values of `Tensor`s, and can't vary\n",
      "     |  dynamically for different session runs.\n",
      "     |  \n",
      "     |  Note that the `__init__` constructor is private. Please use one of the\n",
      "     |  following methods to construct a `RaggedTensor`:\n",
      "     |  \n",
      "     |  * `tf.RaggedTensor.from_row_lengths`\n",
      "     |  * `tf.RaggedTensor.from_value_rowids`\n",
      "     |  * `tf.RaggedTensor.from_row_splits`\n",
      "     |  * `tf.RaggedTensor.from_row_starts`\n",
      "     |  * `tf.RaggedTensor.from_row_limits`\n",
      "     |  * `tf.RaggedTensor.from_nested_row_splits`\n",
      "     |  * `tf.RaggedTensor.from_nested_row_lengths`\n",
      "     |  * `tf.RaggedTensor.from_nested_value_rowids`\n",
      "     |  \n",
      "     |  ### Potentially Ragged Tensors\n",
      "     |  \n",
      "     |  Many ops support both `Tensor`s and `RaggedTensor`s\n",
      "     |  (see [tf.ragged](https://www.tensorflow.org/api_docs/python/tf/ragged) for a\n",
      "     |  full listing). The term \"potentially ragged tensor\" may be used to refer to a\n",
      "     |  tensor that might be either a `Tensor` or a `RaggedTensor`.  The ragged-rank\n",
      "     |  of a `Tensor` is zero.\n",
      "     |  \n",
      "     |  ### Documenting RaggedTensor Shapes\n",
      "     |  \n",
      "     |  When documenting the shape of a RaggedTensor, ragged dimensions can be\n",
      "     |  indicated by enclosing them in parentheses.  For example, the shape of\n",
      "     |  a 3-D `RaggedTensor` that stores the fixed-size word embedding for each\n",
      "     |  word in a sentence, for each sentence in a batch, could be written as\n",
      "     |  `[num_sentences, (num_words), embedding_size]`.  The parentheses around\n",
      "     |  `(num_words)` indicate that dimension is ragged, and that the length\n",
      "     |  of each element list in that dimension may vary for each item.\n",
      "     |  \n",
      "     |  ### Component Tensors\n",
      "     |  \n",
      "     |  Internally, a `RaggedTensor` consists of a concatenated list of values that\n",
      "     |  are partitioned into variable-length rows.  In particular, each `RaggedTensor`\n",
      "     |  consists of:\n",
      "     |  \n",
      "     |    * A `values` tensor, which concatenates the variable-length rows into a\n",
      "     |      flattened list.  For example, the `values` tensor for\n",
      "     |      `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is `[3, 1, 4, 1, 5, 9, 2, 6]`.\n",
      "     |  \n",
      "     |    * A `row_splits` vector, which indicates how those flattened values are\n",
      "     |      divided into rows.  In particular, the values for row `rt[i]` are stored\n",
      "     |      in the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  >>> print(tf.RaggedTensor.from_row_splits(\n",
      "     |  ...       values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |  ...       row_splits=[0, 4, 4, 7, 8, 8]))\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  ### Alternative Row-Partitioning Schemes\n",
      "     |  \n",
      "     |  In addition to `row_splits`, ragged tensors provide support for five other\n",
      "     |  row-partitioning schemes:\n",
      "     |  \n",
      "     |    * `row_lengths`: a vector with shape `[nrows]`, which specifies the length\n",
      "     |      of each row.\n",
      "     |  \n",
      "     |    * `value_rowids` and `nrows`: `value_rowids` is a vector with shape\n",
      "     |      `[nvals]`, corresponding one-to-one with `values`, which specifies\n",
      "     |      each value's row index.  In particular, the row `rt[row]` consists of the\n",
      "     |      values `rt.values[j]` where `value_rowids[j]==row`.  `nrows` is an\n",
      "     |      integer scalar that specifies the number of rows in the\n",
      "     |      `RaggedTensor`. (`nrows` is used to indicate trailing empty rows.)\n",
      "     |  \n",
      "     |    * `row_starts`: a vector with shape `[nrows]`, which specifies the start\n",
      "     |      offset of each row.  Equivalent to `row_splits[:-1]`.\n",
      "     |  \n",
      "     |    * `row_limits`: a vector with shape `[nrows]`, which specifies the stop\n",
      "     |      offset of each row.  Equivalent to `row_splits[1:]`.\n",
      "     |  \n",
      "     |    * `uniform_row_length`: A scalar tensor, specifying the length of every\n",
      "     |      row.  This row-partitioning scheme may only be used if all rows have\n",
      "     |      the same length.\n",
      "     |  \n",
      "     |  Example: The following ragged tensors are equivalent, and all represent the\n",
      "     |  nested list `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]`.\n",
      "     |  \n",
      "     |  >>> values = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "     |  >>> RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_value_rowids(\n",
      "     |  ...     values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)\n",
      "     |  <tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>\n",
      "     |  \n",
      "     |  ### Multiple Ragged Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with multiple ragged dimensions can be defined by using\n",
      "     |  a nested `RaggedTensor` for the `values` tensor.  Each nested `RaggedTensor`\n",
      "     |  adds a single ragged dimension.\n",
      "     |  \n",
      "     |  >>> inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above\n",
      "     |  ...     values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])\n",
      "     |  >>> outer_rt = RaggedTensor.from_row_splits(\n",
      "     |  ...     values=inner_rt, row_splits=[0, 3, 3, 5])\n",
      "     |  >>> print(outer_rt.to_list())\n",
      "     |  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]\n",
      "     |  >>> print(outer_rt.ragged_rank)\n",
      "     |  2\n",
      "     |  \n",
      "     |  The factory function `RaggedTensor.from_nested_row_splits` may be used to\n",
      "     |  construct a `RaggedTensor` with multiple ragged dimensions directly, by\n",
      "     |  providing a list of `row_splits` tensors:\n",
      "     |  \n",
      "     |  >>> RaggedTensor.from_nested_row_splits(\n",
      "     |  ...     flat_values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |  ...     nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()\n",
      "     |  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]\n",
      "     |  \n",
      "     |  ### Uniform Inner Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with uniform inner dimensions can be defined\n",
      "     |  by using a multidimensional `Tensor` for `values`.\n",
      "     |  \n",
      "     |  >>> rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),\n",
      "     |  ...                                   row_splits=[0, 2, 5])\n",
      "     |  >>> print(rt.to_list())\n",
      "     |  [[[1, 1, 1], [1, 1, 1]],\n",
      "     |   [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]\n",
      "     |  >>> print(rt.shape)\n",
      "     |  (2, None, 3)\n",
      "     |  \n",
      "     |  ### Uniform Outer Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with uniform outer dimensions can be defined by using\n",
      "     |  one or more `RaggedTensor` with a `uniform_row_length` row-partitioning\n",
      "     |  tensor.  For example, a `RaggedTensor` with shape `[2, 2, None]` can be\n",
      "     |  constructed with this method from a `RaggedTensor` values with shape\n",
      "     |  `[4, None]`:\n",
      "     |  \n",
      "     |  >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |  >>> print(values.shape)\n",
      "     |  (4, None)\n",
      "     |  >>> rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |  >>> print(rt6)\n",
      "     |  <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |  >>> print(rt6.shape)\n",
      "     |  (2, 2, None)\n",
      "     |  \n",
      "     |  Note that `rt6` only contains one ragged dimension (the innermost\n",
      "     |  dimension). In contrast, if `from_row_splits` is used to construct a similar\n",
      "     |  `RaggedTensor`, then that `RaggedTensor` will have two ragged dimensions:\n",
      "     |  \n",
      "     |  >>> rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])\n",
      "     |  >>> print(rt7.shape)\n",
      "     |  (2, None, None)\n",
      "     |  \n",
      "     |  Uniform and ragged outer dimensions may be interleaved, meaning that a\n",
      "     |  tensor with any combination of ragged and uniform dimensions may be created.\n",
      "     |  For example, a RaggedTensor `t4` with shape `[3, None, 4, 8, None, 2]` could\n",
      "     |  be constructed as follows:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]\n",
      "     |  t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]\n",
      "     |  t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]\n",
      "     |  t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]\n",
      "     |  t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RaggedTensor\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.types.internal.RaggedTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = ragged_abs(self, name=None)\n",
      "     |      Computes the absolute value of a ragged tensor.\n",
      "     |      \n",
      "     |      Given a ragged tensor of integer or floating-point values, this operation\n",
      "     |      returns a ragged tensor of the same type, where each element contains the\n",
      "     |      absolute value of the corresponding element in the input.\n",
      "     |      \n",
      "     |      Given a ragged tensor `x` of complex numbers, this operation returns a tensor\n",
      "     |      of type `float32` or `float64` that is the absolute value of each element in\n",
      "     |      `x`. For a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
      "     |      \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # real number\n",
      "     |      >>> x = tf.ragged.constant([[-2.2, 3.2], [-4.2]])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.RaggedTensor [[2.2, 3.2], [4.2]]>\n",
      "     |      \n",
      "     |      >>> # complex number\n",
      "     |      >>> x = tf.ragged.constant([[-2.2 + 4.7j], [-3.2 + 5.7j], [-4.2 + 6.7j]])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.RaggedTensor [[5.189412298131649],\n",
      "     |       [6.536818798161687],\n",
      "     |       [7.907591289387685]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` of the same size and type as `x`, with absolute values.\n",
      "     |        Note, for `complex64` or `complex128` input, the returned `RaggedTensor`\n",
      "     |        will be of type `float32` or `float64`, respectively.\n",
      "     |  \n",
      "     |  __add__ = add(x, y, name=None)\n",
      "     |      Returns x + y element-wise.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Add a scalar and a list:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `+` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x + y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Add a tensor and a list of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**7 + 1, 2**7 + 2]\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "     |      \n",
      "     |      When adding two input values of different shapes, `Add` follows NumPy\n",
      "     |      broadcasting rules. The two input array shapes are compared element-wise.\n",
      "     |      Starting with the trailing dimensions, the two dimensions either have to be\n",
      "     |      equal or one of them needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [2, 2, 3, 3]\n",
      "     |      \n",
      "     |      Another example with two arrays of different dimension.\n",
      "     |      \n",
      "     |      >>> x = np.ones([1, 2, 1, 4])\n",
      "     |      >>> y = np.ones([3, 4])\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [1, 2, 3, 4]\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "     |          float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "     |          int32, int64, complex64, complex128, string.\n",
      "     |        y: A `tf.Tensor`. Must have the same type as x.\n",
      "     |        name: A name for the operation (optional)\n",
      "     |  \n",
      "     |  __and__ = ragged_and(self, y, name=None)\n",
      "     |      Returns the truth value of elementwise `x & y`.\n",
      "     |      \n",
      "     |      Logical AND function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `y` can be:\n",
      "     |      \n",
      "     |        - A single Python boolean, where the result will be calculated by applying\n",
      "     |          logical AND with the single element to each element in `x`.\n",
      "     |        - A `tf.Tensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |        - A `tf.RaggedTensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # `y` is a Python boolean\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = True\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.logical_and(x, y)  # Equivalent of x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> y & x\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.reduce_all(x & y)  # Reduce to a scalar bool Tensor.\n",
      "     |      <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True, False]])\n",
      "     |      >>> y = tf.constant([[True, False], [False, True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False, False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.constant([[True], [False]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.ragged.constant([[False, True], [True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[False, False], [True]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[[True, True, False]], [[]], [[True, False]]])\n",
      "     |      >>> y = tf.ragged.constant([[[True]], [[True]], [[False]]], ragged_rank=1)\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[[True, True, False]], [[]], [[False, False]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        y: A Python boolean or a `tf.Tensor` or `tf.RaggedTensor` of dtype\n",
      "     |          `tf.bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `x` and `y`\n",
      "     |        broadcast to.\n",
      "     |  \n",
      "     |  __bool__ = ragged_bool(self)\n",
      "     |      Raises TypeError when a RaggedTensor is used as a Python bool.\n",
      "     |      \n",
      "     |      To prevent RaggedTensor from being used as a bool, this function always raise\n",
      "     |      TypeError when being called.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> result = True if x else False  # Evaluate x as a bool value.\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1]])\n",
      "     |      >>> r = (x == 1)  # tf.RaggedTensor [[True]]\n",
      "     |      >>> if r:  # Evaluate r as a bool value.\n",
      "     |      ...   pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |  \n",
      "     |  __div__ = div(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __eq__ = ragged_eq(self, other)\n",
      "     |      Returns result of elementwise `==` or False if not broadcast-compatible.\n",
      "     |      \n",
      "     |      Compares two ragged tensors elemewise for equality if they are\n",
      "     |      broadcast-compatible; or returns False if they are not\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).\n",
      "     |      \n",
      "     |      Note that this behavior differs from `tf.math.equal`, which raises an\n",
      "     |      exception if the two ragged tensors are not broadcast-compatible.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> rt1 == rt1\n",
      "     |      <tf.RaggedTensor [[True, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt2 = tf.ragged.constant([[1, 2], [4]])\n",
      "     |      >>> rt1 == rt2\n",
      "     |      <tf.RaggedTensor [[True, True], [False]]>\n",
      "     |      \n",
      "     |      >>> rt3 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> # rt1 and rt3 are not broadcast-compatible.\n",
      "     |      >>> rt1 == rt3\n",
      "     |      False\n",
      "     |      \n",
      "     |      >>> # You can also compare a `tf.RaggedTensor` to a `tf.Tensor`.\n",
      "     |      >>> t = tf.constant([[1, 2], [3, 4]])\n",
      "     |      >>> rt1 == t\n",
      "     |      False\n",
      "     |      >>> t == rt1\n",
      "     |      False\n",
      "     |      >>> rt4 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> rt4 == t\n",
      "     |      <tf.RaggedTensor [[True, True], [True, True]]>\n",
      "     |      >>> t == rt4\n",
      "     |      <tf.RaggedTensor [[True, True], [True, True]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: The right-hand side of the `==` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The ragged tensor result of the elementwise `==` operation, or `False` if\n",
      "     |        the arguments are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __floordiv__ = floordiv(x, y, name=None)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __ge__ = ragged_ge(self, other)\n",
      "     |      Elementwise `>=` comparison of two convertible-to-ragged-tensor values.\n",
      "     |      \n",
      "     |      Computes the elemewise `>=` comparison of two values that are convertible to\n",
      "     |      ragged tenors, with [broadcasting]\n",
      "     |      (http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) support.\n",
      "     |      Raises an exception if two values are not broadcast-compatible.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> rt1 >= rt1\n",
      "     |      <tf.RaggedTensor [[True, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt2 = tf.ragged.constant([[2, 1], [3]])\n",
      "     |      >>> rt1 >= rt2\n",
      "     |      <tf.RaggedTensor [[False, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt3 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> # rt1 and rt3 are not broadcast-compatible.\n",
      "     |      >>> rt1 >= rt3\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      InvalidArgumentError: ...\n",
      "     |      \n",
      "     |      >>> # You can also compare a `tf.RaggedTensor` to a `tf.Tensor`.\n",
      "     |      >>> rt4 = tf.ragged.constant([[1, 2],[3, 4]])\n",
      "     |      >>> t1 = tf.constant([[2, 1], [4, 3]])\n",
      "     |      >>> rt4 >= t1\n",
      "     |      <tf.RaggedTensor [[False, True],\n",
      "     |       [False, True]]>\n",
      "     |      >>> t1 >= rt4\n",
      "     |      <tf.RaggedTensor [[True, False],\n",
      "     |       [True, False]]>\n",
      "     |      \n",
      "     |      >>> # Compares a `tf.RaggedTensor` to a `tf.Tensor` with broadcasting.\n",
      "     |      >>> t2 = tf.constant([[2]])\n",
      "     |      >>> rt4 >= t2\n",
      "     |      <tf.RaggedTensor [[False, True],\n",
      "     |       [True, True]]>\n",
      "     |      >>> t2 >= rt4\n",
      "     |      <tf.RaggedTensor [[True, True],\n",
      "     |       [False, False]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: The right-hand side of the `>=` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `self` and\n",
      "     |        `other` broadcast to.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `self` and `other` are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __getitem__ = ragged_tensor_getitem(rt_input, key)\n",
      "     |      Returns the specified piece of this RaggedTensor.\n",
      "     |      \n",
      "     |      Supports multidimensional indexing and slicing, with one restriction:\n",
      "     |      indexing into a ragged inner dimension is not allowed.  This case is\n",
      "     |      problematic because the indicated value may exist in some rows but not\n",
      "     |      others.  In such cases, it's not obvious whether we should (1) report an\n",
      "     |      IndexError; (2) use a default value; or (3) skip that value and return a\n",
      "     |      tensor with fewer rows than we started with.  Following the guiding\n",
      "     |      principles of Python (\"In the face of ambiguity, refuse the temptation to\n",
      "     |      guess\"), we simply disallow this operation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rt_input: The RaggedTensor to slice.\n",
      "     |        key: Indicates which piece of the RaggedTensor to return, using standard\n",
      "     |          Python semantics (e.g., negative values index from the end).  `key`\n",
      "     |          may have any of the following types:\n",
      "     |      \n",
      "     |          * `int` constant\n",
      "     |          * Scalar integer `Tensor`\n",
      "     |          * `slice` containing integer constants and/or scalar integer\n",
      "     |            `Tensor`s\n",
      "     |          * `Ellipsis`\n",
      "     |          * `tf.newaxis`\n",
      "     |          * `tuple` containing any of the above (for multidimensional indexing)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `RaggedTensor` object.  Values that include at least one\n",
      "     |        ragged dimension are returned as `RaggedTensor`.  Values that include no\n",
      "     |        ragged dimensions are returned as `Tensor`.  See above for examples of\n",
      "     |        expressions that return `Tensor`s vs `RaggedTensor`s.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `key` is out of bounds.\n",
      "     |        ValueError: If `key` is not supported.\n",
      "     |        TypeError: If the indices in `key` have an unsupported type.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> # A 2-D ragged tensor with 1 ragged dimension.\n",
      "     |      >>> rt = tf.ragged.constant([['a', 'b', 'c'], ['d', 'e'], ['f'], ['g']])\n",
      "     |      >>> rt[0].numpy()                 # First row (1-D `Tensor`)\n",
      "     |      array([b'a', b'b', b'c'], dtype=object)\n",
      "     |      >>> rt[:3].to_list()              # First three rows (2-D RaggedTensor)\n",
      "     |      [[b'a', b'b', b'c'], [b'd', b'e'], [b'f']]\n",
      "     |      >>> rt[3, 0].numpy()              # 1st element of 4th row (scalar)\n",
      "     |      b'g'\n",
      "     |      \n",
      "     |      >>> # A 3-D ragged tensor with 2 ragged dimensions.\n",
      "     |      >>> rt = tf.ragged.constant([[[1, 2, 3], [4]],\n",
      "     |      ...                          [[5], [], [6]],\n",
      "     |      ...                          [[7]],\n",
      "     |      ...                          [[8, 9], [10]]])\n",
      "     |      >>> rt[1].to_list()               # Second row (2-D RaggedTensor)\n",
      "     |      [[5], [], [6]]\n",
      "     |      >>> rt[3, 0].numpy()              # First element of fourth row (1-D Tensor)\n",
      "     |      array([8, 9], dtype=int32)\n",
      "     |      >>> rt[:, 1:3].to_list()          # Items 1-3 of each row (3-D RaggedTensor)\n",
      "     |      [[[4]], [[], [6]], [], [[10]]]\n",
      "     |      >>> rt[:, -1:].to_list()          # Last item of each row (3-D RaggedTensor)\n",
      "     |      [[[4]], [[6]], [[7]], [[10]]]\n",
      "     |  \n",
      "     |  __gt__ = greater(x: typing.Annotated[_any, ~TV_Greater_T], y: typing.Annotated[_any, ~TV_Greater_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__ = ragged_hash(self)\n",
      "     |      The operation invoked by the `RaggedTensor.__hash__` operator.\n",
      "     |  \n",
      "     |  __init__(self, values, row_partition, internal=False)\n",
      "     |      Creates a `RaggedTensor` with a specified partitioning for `values`.\n",
      "     |      \n",
      "     |      This constructor is private -- please use one of the following ops to\n",
      "     |      build `RaggedTensor`s:\n",
      "     |      \n",
      "     |        * `tf.RaggedTensor.from_row_lengths`\n",
      "     |        * `tf.RaggedTensor.from_value_rowids`\n",
      "     |        * `tf.RaggedTensor.from_row_splits`\n",
      "     |        * `tf.RaggedTensor.from_row_starts`\n",
      "     |        * `tf.RaggedTensor.from_row_limits`\n",
      "     |        * `tf.RaggedTensor.from_nested_row_splits`\n",
      "     |        * `tf.RaggedTensor.from_nested_row_lengths`\n",
      "     |        * `tf.RaggedTensor.from_nested_value_rowids`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor of any dtype and shape `[nvals, ...]`.\n",
      "     |        row_partition: A `RowPartition` object, representing the arrangement of\n",
      "     |          the lists at the top level.\n",
      "     |        internal: True if the constructor is being called by one of the factory\n",
      "     |          methods.  If false, an exception will be raised.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If internal = False. Note that this method is intended only\n",
      "     |                   for internal use.\n",
      "     |        TypeError: If values is not a `RaggedTensor` or `Tensor`, or\n",
      "     |                   row_partition is not a `RowPartition`.\n",
      "     |  \n",
      "     |  __invert__ = logical_not(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of `NOT x` element-wise.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> tf.math.logical_not(tf.constant([True, False]))\n",
      "     |      <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`. A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __le__ = less_equal(x: typing.Annotated[_any, ~TV_LessEqual_T], y: typing.Annotated[_any, ~TV_LessEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __lt__ = less(x: typing.Annotated[_any, ~TV_Less_T], y: typing.Annotated[_any, ~TV_Less_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __mod__ = floor_mod(x: typing.Annotated[_any, ~TV_FloorMod_T], y: typing.Annotated[_any, ~TV_FloorMod_T], name=None) -> typing.Annotated[_any, ~TV_FloorMod_T]\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __mul__ = multiply(x, y, name=None)\n",
      "     |      Returns an element-wise x * y.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "     |      >>> tf.math.multiply(x, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "     |      \n",
      "     |      Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "     |      pass in non-`Tensor` arguments:\n",
      "     |      \n",
      "     |      >>> tf.math.multiply(7,6)\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "     |      \n",
      "     |      If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "     |      compatible shape. (More about broadcasting\n",
      "     |      [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ones([1, 2]);\n",
      "     |      >>> y = tf.ones([2, 1]);\n",
      "     |      >>> x * y  # Taking advantage of operator overriding\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "     |      array([[1., 1.],\n",
      "     |           [1., 1.]], dtype=float32)>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "     |          `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "     |          `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      \n",
      "     |      A `Tensor`.  Has the same type as `x`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |      \n",
      "     |       * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "     |  \n",
      "     |  __ne__ = tensor_not_equals(self, other)\n",
      "     |      The operation invoked by the `Tensor.__ne__` operator.\n",
      "     |      \n",
      "     |      Compares two tensors element-wise for inequality if they are\n",
      "     |      broadcast-compatible; or returns True if they are not broadcast-compatible.\n",
      "     |      (Note that this behavior differs from `tf.math.not_equal`, which raises an\n",
      "     |      exception if the two tensors are not broadcast-compatible.)\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__ne__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The left-hand side of the `!=` operator.\n",
      "     |        other: The right-hand side of the `!=` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `!=` operation, or `True` if the arguments\n",
      "     |        are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __neg__ = neg(x: typing.Annotated[_any, ~TV_Neg_T], name=None) -> typing.Annotated[_any, ~TV_Neg_T]\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __nonzero__ = ragged_bool(self)\n",
      "     |      Raises TypeError when a RaggedTensor is used as a Python bool.\n",
      "     |      \n",
      "     |      To prevent RaggedTensor from being used as a bool, this function always raise\n",
      "     |      TypeError when being called.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> result = True if x else False  # Evaluate x as a bool value.\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1]])\n",
      "     |      >>> r = (x == 1)  # tf.RaggedTensor [[True]]\n",
      "     |      >>> if r:  # Evaluate r as a bool value.\n",
      "     |      ...   pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |  \n",
      "     |  __or__ = logical_or(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], y: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      Logical OR function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`.\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical OR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical OR of the two input tensors.\n",
      "     |      \n",
      "     |      You can also use the `|` operator instead.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |        >>> a = tf.constant([True])\n",
      "     |        >>> b = tf.constant([False])\n",
      "     |        >>> tf.math.logical_or(a, b)\n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |        >>> a | b\n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |        >>> c = tf.constant([False])\n",
      "     |        >>> x = tf.constant([False, True, True, False])\n",
      "     |        >>> tf.math.logical_or(c, x)\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |        >>> c | x\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |      \n",
      "     |        >>> y = tf.constant([False, False, True, True])\n",
      "     |        >>> z = tf.constant([False, True, False, True])\n",
      "     |        >>> tf.math.logical_or(y, z)\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |        >>> y | z\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |      \n",
      "     |        This op also supports broadcasting\n",
      "     |      \n",
      "     |        >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "     |        <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "     |        array([[ True,  True],\n",
      "     |             [ True, False]])>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` of type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __pow__ = pow(x, y, name=None)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __radd__ = add(x, y, name=None)\n",
      "     |      Returns x + y element-wise.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Add a scalar and a list:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `+` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x + y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Add a tensor and a list of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**7 + 1, 2**7 + 2]\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "     |      \n",
      "     |      When adding two input values of different shapes, `Add` follows NumPy\n",
      "     |      broadcasting rules. The two input array shapes are compared element-wise.\n",
      "     |      Starting with the trailing dimensions, the two dimensions either have to be\n",
      "     |      equal or one of them needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [2, 2, 3, 3]\n",
      "     |      \n",
      "     |      Another example with two arrays of different dimension.\n",
      "     |      \n",
      "     |      >>> x = np.ones([1, 2, 1, 4])\n",
      "     |      >>> y = np.ones([3, 4])\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [1, 2, 3, 4]\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "     |          float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "     |          int32, int64, complex64, complex128, string.\n",
      "     |        y: A `tf.Tensor`. Must have the same type as x.\n",
      "     |        name: A name for the operation (optional)\n",
      "     |  \n",
      "     |  __rand__ = ragged_and(self, y, name=None)\n",
      "     |      Returns the truth value of elementwise `x & y`.\n",
      "     |      \n",
      "     |      Logical AND function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `y` can be:\n",
      "     |      \n",
      "     |        - A single Python boolean, where the result will be calculated by applying\n",
      "     |          logical AND with the single element to each element in `x`.\n",
      "     |        - A `tf.Tensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |        - A `tf.RaggedTensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # `y` is a Python boolean\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = True\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.logical_and(x, y)  # Equivalent of x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> y & x\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.reduce_all(x & y)  # Reduce to a scalar bool Tensor.\n",
      "     |      <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True, False]])\n",
      "     |      >>> y = tf.constant([[True, False], [False, True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False, False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.constant([[True], [False]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.ragged.constant([[False, True], [True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[False, False], [True]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[[True, True, False]], [[]], [[True, False]]])\n",
      "     |      >>> y = tf.ragged.constant([[[True]], [[True]], [[False]]], ragged_rank=1)\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[[True, True, False]], [[]], [[False, False]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        y: A Python boolean or a `tf.Tensor` or `tf.RaggedTensor` of dtype\n",
      "     |          `tf.bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `x` and `y`\n",
      "     |        broadcast to.\n",
      "     |  \n",
      "     |  __rdiv__ = div(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = floordiv(x, y, name=None)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __rmod__ = floor_mod(x: typing.Annotated[_any, ~TV_FloorMod_T], y: typing.Annotated[_any, ~TV_FloorMod_T], name=None) -> typing.Annotated[_any, ~TV_FloorMod_T]\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rmul__ = multiply(x, y, name=None)\n",
      "     |      Returns an element-wise x * y.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "     |      >>> tf.math.multiply(x, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "     |      \n",
      "     |      Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "     |      pass in non-`Tensor` arguments:\n",
      "     |      \n",
      "     |      >>> tf.math.multiply(7,6)\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "     |      \n",
      "     |      If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "     |      compatible shape. (More about broadcasting\n",
      "     |      [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ones([1, 2]);\n",
      "     |      >>> y = tf.ones([2, 1]);\n",
      "     |      >>> x * y  # Taking advantage of operator overriding\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "     |      array([[1., 1.],\n",
      "     |           [1., 1.]], dtype=float32)>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "     |          `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "     |          `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      \n",
      "     |      A `Tensor`.  Has the same type as `x`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |      \n",
      "     |       * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "     |  \n",
      "     |  __ror__ = logical_or(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], y: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      Logical OR function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`.\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical OR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical OR of the two input tensors.\n",
      "     |      \n",
      "     |      You can also use the `|` operator instead.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |        >>> a = tf.constant([True])\n",
      "     |        >>> b = tf.constant([False])\n",
      "     |        >>> tf.math.logical_or(a, b)\n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |        >>> a | b\n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |        >>> c = tf.constant([False])\n",
      "     |        >>> x = tf.constant([False, True, True, False])\n",
      "     |        >>> tf.math.logical_or(c, x)\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |        >>> c | x\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |      \n",
      "     |        >>> y = tf.constant([False, False, True, True])\n",
      "     |        >>> z = tf.constant([False, True, False, True])\n",
      "     |        >>> tf.math.logical_or(y, z)\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |        >>> y | z\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |      \n",
      "     |        This op also supports broadcasting\n",
      "     |      \n",
      "     |        >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "     |        <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "     |        array([[ True,  True],\n",
      "     |             [ True, False]])>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` of type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rpow__ = pow(x, y, name=None)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __rsub__ = subtract(x, y, name=None)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x - y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      array([[[0., 0., 0.],\n",
      "     |              [0., 0., 0.],\n",
      "     |              [0., 0., 0.]],\n",
      "     |             [[0., 0., 0.],\n",
      "     |              [0., 0., 0.],\n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rtruediv__ = truediv(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __rxor__ = logical_xor(x, y, name='LogicalXor')\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical XOR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical XOR of the two input tensors.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([True])\n",
      "     |      >>> b = tf.constant([False])\n",
      "     |      >>> tf.math.logical_xor(a, b)\n",
      "     |      <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |      >>> c = tf.constant([True])\n",
      "     |      >>> x = tf.constant([False, True, True, False])\n",
      "     |      >>> tf.math.logical_xor(c, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>\n",
      "     |      \n",
      "     |      >>> y = tf.constant([False, False, True, True])\n",
      "     |      >>> z = tf.constant([False, True, False, True])\n",
      "     |      >>> tf.math.logical_xor(y, z)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  __sub__ = subtract(x, y, name=None)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x - y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      array([[[0., 0., 0.],\n",
      "     |              [0., 0., 0.],\n",
      "     |              [0., 0., 0.]],\n",
      "     |             [[0., 0., 0.],\n",
      "     |              [0., 0., 0.],\n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __truediv__ = truediv(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __xor__ = logical_xor(x, y, name='LogicalXor')\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical XOR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical XOR of the two input tensors.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([True])\n",
      "     |      >>> b = tf.constant([False])\n",
      "     |      >>> tf.math.logical_xor(a, b)\n",
      "     |      <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |      >>> c = tf.constant([True])\n",
      "     |      >>> x = tf.constant([False, True, True, False])\n",
      "     |      >>> tf.math.logical_xor(c, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>\n",
      "     |      \n",
      "     |      >>> y = tf.constant([False, False, True, True])\n",
      "     |      >>> z = tf.constant([False, True, False, True])\n",
      "     |      >>> tf.math.logical_xor(y, z)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  bounding_shape(self, axis=None, name=None, out_type=None)\n",
      "     |      Returns the tight bounding box shape for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        axis: An integer scalar or vector indicating which axes to return the\n",
      "     |          bounding box for.  If not specified, then the full bounding box is\n",
      "     |          returned.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |        out_type: `dtype` for the returned tensor.  Defaults to\n",
      "     |          `self.row_splits.dtype`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An integer `Tensor` (`dtype=self.row_splits.dtype`).  If `axis` is not\n",
      "     |        specified, then `output` is a vector with\n",
      "     |        `output.shape=[self.shape.ndims]`.  If `axis` is a scalar, then the\n",
      "     |        `output` is a scalar.  If `axis` is a vector, then `output` is a vector,\n",
      "     |        where `output[i]` is the bounding size for dimension `axis[i]`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])\n",
      "     |      >>> rt.bounding_shape().numpy()\n",
      "     |      array([5, 4])\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  get_shape(self) -> tensorflow.python.framework.tensor_shape.TensorShape\n",
      "     |      The statically known shape of this ragged tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the statically known shape of this ragged\n",
      "     |        tensor.  Ragged dimensions have a size of `None`.\n",
      "     |      \n",
      "     |      Alias for `shape` property.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[0], [1, 2]]).get_shape()\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant(\n",
      "     |      ...    [[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).get_shape()\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |  \n",
      "     |  merge_dims(self, outer_axis, inner_axis)\n",
      "     |      Merges outer_axis...inner_axis into a single dimension.\n",
      "     |      \n",
      "     |      Returns a copy of this RaggedTensor with the specified range of dimensions\n",
      "     |      flattened into a single dimension, with elements in row-major order.\n",
      "     |      \n",
      "     |      #### Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[1, 2], [3]], [[4, 5, 6]]])\n",
      "     |      >>> print(rt.merge_dims(0, 1))\n",
      "     |      <tf.RaggedTensor [[1, 2], [3], [4, 5, 6]]>\n",
      "     |      >>> print(rt.merge_dims(1, 2))\n",
      "     |      <tf.RaggedTensor [[1, 2, 3], [4, 5, 6]]>\n",
      "     |      >>> print(rt.merge_dims(0, 2))\n",
      "     |      tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n",
      "     |      \n",
      "     |      To mimic the behavior of `np.flatten` (which flattens all dimensions), use\n",
      "     |      `rt.merge_dims(0, -1).  To mimic the behavior of `tf.layers.Flatten` (which\n",
      "     |      flattens all dimensions except the outermost batch dimension), use\n",
      "     |      `rt.merge_dims(1, -1)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        outer_axis: `int`: The first dimension in the range of dimensions to\n",
      "     |          merge. May be negative if `self.shape.rank` is statically known.\n",
      "     |        inner_axis: `int`: The last dimension in the range of dimensions to merge.\n",
      "     |          May be negative if `self.shape.rank` is statically known.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A copy of this tensor, with the specified dimensions merged into a\n",
      "     |        single dimension.  The shape of the returned tensor will be\n",
      "     |        `self.shape[:outer_axis] + [N] + self.shape[inner_axis + 1:]`, where `N`\n",
      "     |        is the total number of slices in the merged dimensions.\n",
      "     |  \n",
      "     |  nested_row_lengths(self, name=None)\n",
      "     |      Returns a tuple containing the row_lengths for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_row_lengths()` is a tuple containing the `row_lengths` tensors\n",
      "     |      for all ragged dimensions in `rt`, ordered from outermost to innermost.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensors`.  The length of the tuple is equal to\n",
      "     |        `self.ragged_rank`.\n",
      "     |  \n",
      "     |  nested_value_rowids(self, name=None)\n",
      "     |      Returns a tuple containing the value_rowids for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_value_rowids` is a tuple containing the `value_rowids` tensors\n",
      "     |      for\n",
      "     |      all ragged dimensions in `rt`, ordered from outermost to innermost.  In\n",
      "     |      particular, `rt.nested_value_rowids = (rt.value_rowids(),) + value_ids`\n",
      "     |      where:\n",
      "     |      \n",
      "     |      * `value_ids = ()` if `rt.values` is a `Tensor`.\n",
      "     |      * `value_ids = rt.values.nested_value_rowids` otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensor`s.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])\n",
      "     |      >>> for i, ids in enumerate(rt.nested_value_rowids()):\n",
      "     |      ...   print('row ids for dimension %d: %s' % (i+1, ids.numpy()))\n",
      "     |      row ids for dimension 1: [0 0 0]\n",
      "     |      row ids for dimension 2: [0 0 0 2 2]\n",
      "     |      row ids for dimension 3: [0 0 0 0 2 2 2 3]\n",
      "     |  \n",
      "     |  nrows(self, out_type=None, name=None)\n",
      "     |      Returns the number of rows in this ragged tensor.\n",
      "     |      \n",
      "     |      I.e., the size of the outermost dimension of the tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        out_type: `dtype` for the returned tensor.  Defaults to\n",
      "     |          `self.row_splits.dtype`.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar `Tensor` with dtype `out_type`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.nrows())  # rt has 5 rows.\n",
      "     |      tf.Tensor(5, shape=(), dtype=int64)\n",
      "     |  \n",
      "     |  numpy(self)\n",
      "     |      Returns a numpy `array` with the values for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Requires that this `RaggedTensor` was constructed in eager execution mode.\n",
      "     |      \n",
      "     |      Ragged dimensions are encoded using numpy `arrays` with `dtype=object` and\n",
      "     |      `rank=1`, where each element is a single row.\n",
      "     |      \n",
      "     |      #### Examples\n",
      "     |      \n",
      "     |      In the following example, the value returned by `RaggedTensor.numpy()`\n",
      "     |      contains three numpy `array` objects: one for each row (with `rank=1` and\n",
      "     |      `dtype=int64`), and one to combine them (with `rank=1` and `dtype=object`):\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[1, 2, 3], [4, 5]], dtype=tf.int64).numpy()\n",
      "     |      array([array([1, 2, 3]), array([4, 5])], dtype=object)\n",
      "     |      \n",
      "     |      Uniform dimensions are encoded using multidimensional numpy `array`s.  In\n",
      "     |      the following example, the value returned by `RaggedTensor.numpy()` contains\n",
      "     |      a single numpy `array` object, with `rank=2` and `dtype=int64`:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.int64).numpy()\n",
      "     |      array([[1, 2, 3], [4, 5, 6]])\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy `array`.\n",
      "     |  \n",
      "     |  row_lengths(self, axis=1, name=None)\n",
      "     |      Returns the lengths of the rows in this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.row_lengths()[i]` indicates the number of values in the\n",
      "     |      `i`th row of `rt`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        axis: An integer constant indicating the axis whose row lengths should be\n",
      "     |          returned.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A potentially ragged integer Tensor with shape `self.shape[:axis]`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `axis` is out of bounds.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []])\n",
      "     |      >>> print(rt.row_lengths())  # lengths of rows in rt\n",
      "     |      tf.Tensor([2 0 2 1 0], shape=(5,), dtype=int64)\n",
      "     |      >>> print(rt.row_lengths(axis=2))  # lengths of axis=2 rows.\n",
      "     |      <tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]>\n",
      "     |  \n",
      "     |  row_limits(self, name=None)\n",
      "     |      Returns the limit indices for rows in this ragged tensor.\n",
      "     |      \n",
      "     |      These indices specify where the values for each row end in\n",
      "     |      `self.values`.  `rt.row_limits(self)` is equal to `rt.row_splits[:-1]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer Tensor with shape `[nrows]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.row_limits())  # indices of row limits in rt.values\n",
      "     |      tf.Tensor([4 4 7 8 8], shape=(5,), dtype=int64)\n",
      "     |  \n",
      "     |  row_starts(self, name=None)\n",
      "     |      Returns the start indices for rows in this ragged tensor.\n",
      "     |      \n",
      "     |      These indices specify where the values for each row begin in\n",
      "     |      `self.values`.  `rt.row_starts()` is equal to `rt.row_splits[:-1]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer Tensor with shape `[nrows]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.row_starts())  # indices of row starts in rt.values\n",
      "     |      tf.Tensor([0 4 4 7 8], shape=(5,), dtype=int64)\n",
      "     |  \n",
      "     |  to_list(self)\n",
      "     |      Returns a nested Python `list` with the values for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Requires that `rt` was constructed in eager execution mode.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A nested Python `list`.\n",
      "     |  \n",
      "     |  to_sparse(self, name=None)\n",
      "     |      Converts this `RaggedTensor` into a `tf.sparse.SparseTensor`.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3], [4], [], [5, 6]])\n",
      "     |      >>> print(rt.to_sparse())\n",
      "     |      SparseTensor(indices=tf.Tensor(\n",
      "     |                       [[0 0] [0 1] [0 2] [1 0] [3 0] [3 1]],\n",
      "     |                       shape=(6, 2), dtype=int64),\n",
      "     |                   values=tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32),\n",
      "     |                   dense_shape=tf.Tensor([4 3], shape=(2,), dtype=int64))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A SparseTensor with the same values as `self`.\n",
      "     |  \n",
      "     |  to_tensor(self, default_value=None, name=None, shape=None)\n",
      "     |      Converts this `RaggedTensor` into a `tf.Tensor`.\n",
      "     |      \n",
      "     |      If `shape` is specified, then the result is padded and/or truncated to\n",
      "     |      the specified shape.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]])\n",
      "     |      >>> print(rt.to_tensor())\n",
      "     |      tf.Tensor(\n",
      "     |          [[9 8 7] [0 0 0] [6 5 0] [4 0 0]], shape=(4, 3), dtype=int32)\n",
      "     |      >>> print(rt.to_tensor(shape=[5, 2]))\n",
      "     |      tf.Tensor(\n",
      "     |          [[9 8] [0 0] [6 5] [4 0] [0 0]], shape=(5, 2), dtype=int32)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        default_value: Value to set for indices not specified in `self`. Defaults\n",
      "     |          to zero.  `default_value` must be broadcastable to\n",
      "     |          `self.shape[self.ragged_rank + 1:]`.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        shape: The shape of the resulting dense tensor.  In particular,\n",
      "     |          `result.shape[i]` is `shape[i]` (if `shape[i]` is not None), or\n",
      "     |          `self.bounding_shape(i)` (otherwise).`shape.rank` must be `None` or\n",
      "     |          equal to `self.rank`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` with shape `ragged.bounding_shape(self)` and the\n",
      "     |        values specified by the non-empty values in `self`.  Empty values are\n",
      "     |        assigned `default_value`.\n",
      "     |  \n",
      "     |  value_rowids(self, name=None)\n",
      "     |      Returns the row indices for the `values` in this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.value_rowids()` corresponds one-to-one with the outermost dimension of\n",
      "     |      `rt.values`, and specifies the row containing each value.  In particular,\n",
      "     |      the row `rt[row]` consists of the values `rt.values[j]` where\n",
      "     |      `rt.value_rowids()[j] == row`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer `Tensor` with shape `self.values.shape[:1]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.value_rowids())  # corresponds 1:1 with rt.values\n",
      "     |      tf.Tensor([0 0 0 0 2 2 2 3], shape=(8,), dtype=int64)\n",
      "     |  \n",
      "     |  with_flat_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `flat_values` replaced by `new_value`.\n",
      "     |      \n",
      "     |      Preserves cached row-partitioning tensors such as `self.cached_nrows` and\n",
      "     |      `self.cached_value_rowids` if they have values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: Potentially ragged tensor that should replace\n",
      "     |          `self.flat_values`.  Must have `rank > 0`, and must have the same number\n",
      "     |          of rows as `self.flat_values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.\n",
      "     |        `result.rank = self.ragged_rank + new_values.rank`.\n",
      "     |        `result.ragged_rank = self.ragged_rank + new_values.ragged_rank`.\n",
      "     |  \n",
      "     |  with_row_splits_dtype(self, dtype)\n",
      "     |      Returns a copy of this RaggedTensor with the given `row_splits` dtype.\n",
      "     |      \n",
      "     |      For RaggedTensors with multiple ragged dimensions, the `row_splits` for all\n",
      "     |      nested `RaggedTensor` objects are cast to the given dtype.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: The dtype for `row_splits`.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A copy of this RaggedTensor, with the `row_splits` cast to the given\n",
      "     |        type.\n",
      "     |  \n",
      "     |  with_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `values` replaced by `new_value`.\n",
      "     |      \n",
      "     |      Preserves cached row-partitioning tensors such as `self.cached_nrows` and\n",
      "     |      `self.cached_value_rowids` if they have values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: Potentially ragged tensor to use as the `values` for the\n",
      "     |          returned `RaggedTensor`.  Must have `rank > 0`, and must have the same\n",
      "     |          number of rows as `self.values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = 1 + new_values.rank`.\n",
      "     |        `result.ragged_rank = 1 + new_values.ragged_rank`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_nested_row_lengths(flat_values, nested_row_lengths, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `row_lengths` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for row_lengths in reversed(nested_row_lengths):\n",
      "     |        result = from_row_lengths(result, row_lengths)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_row_lengths: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `row_lengths` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_row_lengths` is empty).\n",
      "     |  \n",
      "     |  from_nested_row_splits(flat_values, nested_row_splits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `row_splits` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for row_splits in reversed(nested_row_splits):\n",
      "     |        result = from_row_splits(result, row_splits)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_row_splits: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `row_splits` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_row_splits` is empty).\n",
      "     |  \n",
      "     |  from_nested_value_rowids(flat_values, nested_value_rowids, nested_nrows=None, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `value_rowids` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):\n",
      "     |        result = from_value_rowids(result, rowids, nrows)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_value_rowids: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `value_rowids` for the `i`th ragged dimension.\n",
      "     |        nested_nrows: A list of integer scalars.  The `i`th scalar is used as the\n",
      "     |          `nrows` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_value_rowids` is empty).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `len(nested_values_rowids) != len(nested_nrows)`.\n",
      "     |  \n",
      "     |  from_row_lengths(values, row_lengths, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_lengths`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [[values.pop(0) for i in range(length)]\n",
      "     |                for length in row_lengths]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_lengths: A 1-D integer tensor with shape `[nrows]`.  Must be\n",
      "     |          nonnegative.  `sum(row_lengths)` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_lengths(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_lengths=[4, 0, 3, 1, 0]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_limits(values, row_limits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_limits`.\n",
      "     |      \n",
      "     |      Equivalent to: `from_row_splits(values, concat([0, row_limits]))`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_limits: A 1-D integer tensor with shape `[nrows]`.  Must be sorted in\n",
      "     |          ascending order.  If `nrows>0`, then `row_limits[-1]` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_limits(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_limits=[4, 4, 7, 8, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_splits(values, row_splits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_splits`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [values[row_splits[i]:row_splits[i + 1]]\n",
      "     |                for i in range(len(row_splits) - 1)]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_splits: A 1-D integer tensor with shape `[nrows+1]`.  Must not be\n",
      "     |          empty, and must be sorted in ascending order.  `row_splits[0]` must be\n",
      "     |          zero and `row_splits[-1]` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `row_splits` is an empty list.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_splits(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_splits=[0, 4, 4, 7, 8, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_starts(values, row_starts, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_starts`.\n",
      "     |      \n",
      "     |      Equivalent to: `from_row_splits(values, concat([row_starts, nvals]))`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_starts: A 1-D integer tensor with shape `[nrows]`.  Must be\n",
      "     |          nonnegative and sorted in ascending order.  If `nrows>0`, then\n",
      "     |          `row_starts[0]` must be zero.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_starts(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_starts=[0, 4, 4, 7, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_sparse(st_input, name=None, row_splits_dtype=tf.int64) from abc.ABCMeta\n",
      "     |      Converts a 2D `tf.sparse.SparseTensor` to a `RaggedTensor`.\n",
      "     |      \n",
      "     |      Each row of the `output` `RaggedTensor` will contain the explicit values\n",
      "     |      from the same row in `st_input`.  `st_input` must be ragged-right.  If not\n",
      "     |      it is not ragged-right, then an error will be generated.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> indices = [[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]]\n",
      "     |      >>> st = tf.sparse.SparseTensor(indices=indices,\n",
      "     |      ...                             values=[1, 2, 3, 4, 5],\n",
      "     |      ...                             dense_shape=[4, 3])\n",
      "     |      >>> tf.RaggedTensor.from_sparse(st).to_list()\n",
      "     |      [[1, 2, 3], [4], [], [5]]\n",
      "     |      \n",
      "     |      Currently, only two-dimensional `SparseTensors` are supported.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        st_input: The sparse tensor to convert.  Must have rank 2.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        row_splits_dtype: `dtype` for the returned `RaggedTensor`'s `row_splits`\n",
      "     |          tensor.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` with the same values as `st_input`.\n",
      "     |        `output.ragged_rank = rank(st_input) - 1`.\n",
      "     |        `output.shape = [st_input.dense_shape[0], None]`.\n",
      "     |      Raises:\n",
      "     |        ValueError: If the number of dimensions in `st_input` is not known\n",
      "     |          statically, or is not two.\n",
      "     |  \n",
      "     |  from_tensor(tensor, lengths=None, padding=None, ragged_rank=1, name=None, row_splits_dtype=tf.int64) from abc.ABCMeta\n",
      "     |      Converts a `tf.Tensor` into a `RaggedTensor`.\n",
      "     |      \n",
      "     |      The set of absent/default values may be specified using a vector of lengths\n",
      "     |      or a padding value (but not both).  If `lengths` is specified, then the\n",
      "     |      output tensor will satisfy `output[row] = tensor[row][:lengths[row]]`. If\n",
      "     |      'lengths' is a list of lists or tuple of lists, those lists will be used\n",
      "     |      as nested row lengths. If `padding` is specified, then any row *suffix*\n",
      "     |      consisting entirely of `padding` will be excluded from the returned\n",
      "     |      `RaggedTensor`.  If neither `lengths` nor `padding` is specified, then the\n",
      "     |      returned `RaggedTensor` will have no absent/default values.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt)\n",
      "     |      <tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]>\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])\n",
      "     |      <tf.RaggedTensor [[5], [], [6, 0, 0]]>\n",
      "     |      \n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, padding=0)\n",
      "     |      <tf.RaggedTensor [[5, 7], [0, 3], [6]]>\n",
      "     |      \n",
      "     |      >>> dt = tf.constant([[[5, 0], [7, 0], [0, 0]],\n",
      "     |      ...                   [[0, 0], [3, 0], [0, 0]],\n",
      "     |      ...                   [[6, 0], [0, 0], [0, 0]]])\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))\n",
      "     |      <tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: The `Tensor` to convert.  Must have rank `ragged_rank + 1` or\n",
      "     |          higher.\n",
      "     |        lengths: An optional set of row lengths, specified using a 1-D integer\n",
      "     |          `Tensor` whose length is equal to `tensor.shape[0]` (the number of rows\n",
      "     |          in `tensor`).  If specified, then `output[row]` will contain\n",
      "     |          `tensor[row][:lengths[row]]`.  Negative lengths are treated as zero. You\n",
      "     |            may optionally pass a list or tuple of lengths to this argument, which\n",
      "     |            will be used as nested row lengths to construct a ragged tensor with\n",
      "     |            multiple ragged dimensions.\n",
      "     |        padding: An optional padding value.  If specified, then any row suffix\n",
      "     |          consisting entirely of `padding` will be excluded from the returned\n",
      "     |          RaggedTensor.  `padding` is a `Tensor` with the same dtype as `tensor`\n",
      "     |          and with `shape=tensor.shape[ragged_rank + 1:]`.\n",
      "     |        ragged_rank: Integer specifying the ragged rank for the returned\n",
      "     |          `RaggedTensor`.  Must be greater than zero.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        row_splits_dtype: `dtype` for the returned `RaggedTensor`'s `row_splits`\n",
      "     |          tensor.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` with the specified `ragged_rank`.  The shape of the\n",
      "     |        returned ragged tensor is compatible with the shape of `tensor`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If both `lengths` and `padding` are specified.\n",
      "     |        ValueError: If the rank of `tensor` is 0 or 1.\n",
      "     |  \n",
      "     |  from_uniform_row_length(values, uniform_row_length, nrows=None, validate=True, name=None) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `uniform_row_length`.\n",
      "     |      \n",
      "     |      This method can be used to create `RaggedTensor`s with multiple uniform\n",
      "     |      outer dimensions.  For example, a `RaggedTensor` with shape `[2, 2, None]`\n",
      "     |      can be constructed with this method from a `RaggedTensor` values with shape\n",
      "     |      `[4, None]`:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> print(values.shape)\n",
      "     |      (4, None)\n",
      "     |      >>> rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> print(rt1)\n",
      "     |      <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |      >>> print(rt1.shape)\n",
      "     |      (2, 2, None)\n",
      "     |      \n",
      "     |      Note that `rt1` only contains one ragged dimension (the innermost\n",
      "     |      dimension). In contrast, if `from_row_splits` is used to construct a similar\n",
      "     |      `RaggedTensor`, then that `RaggedTensor` will have two ragged dimensions:\n",
      "     |      \n",
      "     |      >>> rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])\n",
      "     |      >>> print(rt2.shape)\n",
      "     |      (2, None, None)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        uniform_row_length: A scalar integer tensor.  Must be nonnegative. The\n",
      "     |          size of the outer axis of `values` must be evenly divisible by\n",
      "     |          `uniform_row_length`.\n",
      "     |        nrows: The number of rows in the constructed RaggedTensor.  If not\n",
      "     |          specified, then it defaults to `nvals/uniform_row_length` (or `0` if\n",
      "     |          `uniform_row_length==0`).  `nrows` only needs to be specified if\n",
      "     |          `uniform_row_length` might be zero.  `uniform_row_length*nrows` must be\n",
      "     |          `nvals`.\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` that corresponds with the python list defined by:\n",
      "     |      \n",
      "     |        ```python\n",
      "     |        result = [[values.pop(0) for i in range(uniform_row_length)]\n",
      "     |                  for _ in range(nrows)]\n",
      "     |        ```\n",
      "     |      \n",
      "     |        `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |  \n",
      "     |  from_value_rowids(values, value_rowids, nrows=None, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `value_rowids`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]\n",
      "     |                for row in range(nrows)]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        value_rowids: A 1-D integer tensor with shape `[nvals]`, which corresponds\n",
      "     |          one-to-one with `values`, and specifies each value's row index.  Must be\n",
      "     |          nonnegative, and must be sorted in ascending order.\n",
      "     |        nrows: An integer scalar specifying the number of rows.  This should be\n",
      "     |          specified if the `RaggedTensor` may containing empty training rows. Must\n",
      "     |          be greater than `value_rowids[-1]` (or zero if `value_rowids` is empty).\n",
      "     |          Defaults to `value_rowids[-1] + 1` (or zero if `value_rowids` is empty).\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `nrows` is incompatible with `value_rowids`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_value_rowids(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],\n",
      "     |      ...     nrows=5))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of values in this tensor.\n",
      "     |  \n",
      "     |  flat_values\n",
      "     |      The innermost `values` tensor for this ragged tensor.\n",
      "     |      \n",
      "     |      Concretely, if `rt.values` is a `Tensor`, then `rt.flat_values` is\n",
      "     |      `rt.values`; otherwise, `rt.flat_values` is `rt.values.flat_values`.\n",
      "     |      \n",
      "     |      Conceptually, `flat_values` is the tensor formed by flattening the\n",
      "     |      outermost dimension and all of the ragged dimensions into a single\n",
      "     |      dimension.\n",
      "     |      \n",
      "     |      `rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]`\n",
      "     |      (where `nvals` is the number of items in the flattened dimensions).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])\n",
      "     |      >>> print(rt.flat_values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |  \n",
      "     |  nested_row_splits\n",
      "     |      A tuple containing the row_splits for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_row_splits` is a tuple containing the `row_splits` tensors for\n",
      "     |      all ragged dimensions in `rt`, ordered from outermost to innermost.  In\n",
      "     |      particular, `rt.nested_row_splits = (rt.row_splits,) + value_splits` where:\n",
      "     |      \n",
      "     |          * `value_splits = ()` if `rt.values` is a `Tensor`.\n",
      "     |          * `value_splits = rt.values.nested_row_splits` otherwise.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensor`s.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])\n",
      "     |      >>> for i, splits in enumerate(rt.nested_row_splits):\n",
      "     |      ...   print('Splits for dimension %d: %s' % (i+1, splits.numpy()))\n",
      "     |      Splits for dimension 1: [0 3]\n",
      "     |      Splits for dimension 2: [0 3 3 5]\n",
      "     |      Splits for dimension 3: [0 4 4 7 8 8]\n",
      "     |  \n",
      "     |  ragged_rank\n",
      "     |      The number of times the RaggedTensor's flat_values is partitioned.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> values.ragged_rank\n",
      "     |      1\n",
      "     |      \n",
      "     |      >>> rt = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> rt.ragged_rank\n",
      "     |      2\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Python `int` indicating the number of times the underlying `flat_values`\n",
      "     |        Tensor has been partitioned to add a new dimension.\n",
      "     |        I.e., `tf.rank(rt) = tf.rank(rt.flat_values) + rt.ragged_rank`.\n",
      "     |  \n",
      "     |  row_splits\n",
      "     |      The row-split indices for this ragged tensor's `values`.\n",
      "     |      \n",
      "     |      `rt.row_splits` specifies where the values for each row begin and end in\n",
      "     |      `rt.values`.  In particular, the values for row `rt[i]` are stored in\n",
      "     |      the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer `Tensor` with shape `[self.nrows+1]`.\n",
      "     |        The returned tensor is non-empty, and is sorted in ascending order.\n",
      "     |        `self.row_splits[0]` is zero, and `self.row_splits[-1]` is equal to\n",
      "     |        `self.values.shape[0]`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.row_splits)  # indices of row splits in rt.values\n",
      "     |      tf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The statically known shape of this ragged tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the statically known shape of this ragged\n",
      "     |        tensor.  Ragged dimensions have a size of `None`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[0], [1, 2]]).shape\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |  \n",
      "     |  uniform_row_length\n",
      "     |      The length of each row in this ragged tensor, or None if rows are ragged.\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> print(rt1.uniform_row_length)  # rows are ragged.\n",
      "     |      None\n",
      "     |      \n",
      "     |      >>> rt2 = tf.RaggedTensor.from_uniform_row_length(\n",
      "     |      ...     values=rt1, uniform_row_length=2)\n",
      "     |      >>> print(rt2)\n",
      "     |      <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |      >>> print(rt2.uniform_row_length)  # rows are not ragged (all have size 2).\n",
      "     |      tf.Tensor(2, shape=(), dtype=int64)\n",
      "     |      \n",
      "     |      A RaggedTensor's rows are only considered to be uniform (i.e. non-ragged)\n",
      "     |      if it can be determined statically (at graph construction time) that the\n",
      "     |      rows all have the same length.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar integer `Tensor`, specifying the length of every row in this\n",
      "     |        ragged tensor (for ragged tensors whose rows are uniform); or `None`\n",
      "     |        (for ragged tensors whose rows are ragged).\n",
      "     |  \n",
      "     |  values\n",
      "     |      The concatenated rows for this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.values` is a potentially ragged tensor formed by flattening the two\n",
      "     |      outermost dimensions of `rt` into a single dimension.\n",
      "     |      \n",
      "     |      `rt.values.shape = [nvals] + rt.shape[2:]` (where `nvals` is the\n",
      "     |      number of items in the outer two dimensions of `rt`).\n",
      "     |      \n",
      "     |      `rt.ragged_rank = self.ragged_rank - 1`\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A potentially ragged tensor.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __composite_gradient__ = <tensorflow.python.framework.composite_tensor...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class RaggedTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.python.types.internal.RaggedTensorSpec)\n",
      "     |  RaggedTensorSpec(shape=None, dtype=tf.float32, ragged_rank=None, row_splits_dtype=tf.int64, flat_values_spec=None)\n",
      "     |  \n",
      "     |  Type specification for a `tf.RaggedTensor`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RaggedTensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      tensorflow.python.types.internal.RaggedTensorSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32, ragged_rank=None, row_splits_dtype=tf.int64, flat_values_spec=None)\n",
      "     |      Constructs a type specification for a `tf.RaggedTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The shape of the RaggedTensor, or `None` to allow any shape.  If a\n",
      "     |          shape is specified, then all ragged dimensions must have size `None`.\n",
      "     |        dtype: `tf.DType` of values in the RaggedTensor.\n",
      "     |        ragged_rank: Python integer, the number of times the RaggedTensor's\n",
      "     |          flat_values is partitioned.  Defaults to `shape.ndims - 1`.\n",
      "     |        row_splits_dtype: `dtype` for the RaggedTensor's `row_splits` tensor. One\n",
      "     |          of `tf.int32` or `tf.int64`.\n",
      "     |        flat_values_spec: TypeSpec for flat_value of the RaggedTensor. It shall be\n",
      "     |          provided when the flat_values is a CompositeTensor rather then Tensor.\n",
      "     |          If both `dtype` and `flat_values_spec` and  are provided, `dtype` must\n",
      "     |          be the same as `flat_values_spec.dtype`. (experimental)\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `tf.dtypes.DType` specified by this type for the RaggedTensor.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[\"a\"], [\"b\", \"c\"]], dtype=tf.string)\n",
      "     |      >>> tf.type_spec_from_value(rt).dtype\n",
      "     |      tf.string\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.dtypes.DType` of the values in the RaggedTensor.\n",
      "     |  \n",
      "     |  flat_values_spec\n",
      "     |      The `TypeSpec` of the flat_values of RaggedTensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        - The TypeSpec of flat_values.\n",
      "     |        - None when the flat_values is a Tensor.\n",
      "     |  \n",
      "     |  ragged_rank\n",
      "     |      The number of times the RaggedTensor's flat_values is partitioned.\n",
      "     |      \n",
      "     |      Defaults to `shape.ndims - 1`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> tf.type_spec_from_value(values).ragged_rank\n",
      "     |      1\n",
      "     |      \n",
      "     |      >>> rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> tf.type_spec_from_value(rt1).ragged_rank\n",
      "     |      2\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Python `int` indicating the number of times the underlying `flat_values`\n",
      "     |        Tensor has been partitioned to add a new dimension.\n",
      "     |        I.e., `tf.rank(rt) = tf.rank(rt.flat_values) + rt.ragged_rank`.\n",
      "     |  \n",
      "     |  row_splits_dtype\n",
      "     |      The `tf.dtypes.DType` of the RaggedTensor's `row_splits`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3], [4]], row_splits_dtype=tf.int64)\n",
      "     |      >>> tf.type_spec_from_value(rt).row_splits_dtype\n",
      "     |      tf.int64\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.dtypes.DType` for the RaggedTensor's `row_splits` tensor. One\n",
      "     |        of `tf.int32` or `tf.int64`.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The statically known shape of the RaggedTensor.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[0], [1, 2]])\n",
      "     |      >>> tf.type_spec_from_value(rt).shape\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1)\n",
      "     |      >>> tf.type_spec_from_value(rt).shape\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` containing the statically known shape of the\n",
      "     |        RaggedTensor. Ragged dimensions have a size of `None`.\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class RandomShuffleQueue(QueueBase)\n",
      "     |  RandomShuffleQueue(capacity, min_after_dequeue, dtypes, shapes=None, names=None, seed=None, shared_name=None, name='random_shuffle_queue')\n",
      "     |  \n",
      "     |  A queue implementation that dequeues elements in a random order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomShuffleQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, min_after_dequeue, dtypes, shapes=None, names=None, seed=None, shared_name=None, name='random_shuffle_queue')\n",
      "     |      Create a queue that dequeues elements in a random order.\n",
      "     |      \n",
      "     |      A `RandomShuffleQueue` has bounded capacity; supports multiple\n",
      "     |      concurrent producers and consumers; and provides exactly-once\n",
      "     |      delivery.\n",
      "     |      \n",
      "     |      A `RandomShuffleQueue` holds a list of up to `capacity`\n",
      "     |      elements. Each element is a fixed-length tuple of tensors whose\n",
      "     |      dtypes are described by `dtypes`, and whose shapes are optionally\n",
      "     |      described by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      The `min_after_dequeue` argument allows the caller to specify a\n",
      "     |      minimum number of elements that will remain in the queue after a\n",
      "     |      `dequeue` or `dequeue_many` operation completes, to ensure a\n",
      "     |      minimum level of mixing of elements. This invariant is maintained\n",
      "     |      by blocking those operations until sufficient elements have been\n",
      "     |      enqueued. The `min_after_dequeue` argument is ignored after the\n",
      "     |      queue has been closed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        min_after_dequeue: An integer (described above).\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects\n",
      "     |          with the same length as `dtypes`, or `None`.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        seed: A Python integer. Used to create a random seed. See\n",
      "     |          `tf.compat.v1.set_random_seed`\n",
      "     |          for behavior.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from QueueBase:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class ReaderBase(builtins.object)\n",
      "     |  ReaderBase(reader_ref, supports_serialize=False)\n",
      "     |  \n",
      "     |  Base class for different Reader types, that produce a record every step.\n",
      "     |  \n",
      "     |  Conceptually, Readers convert string 'work units' into records (key,\n",
      "     |  value pairs).  Typically the 'work units' are filenames and the\n",
      "     |  records are extracted from the contents of those files.  We want a\n",
      "     |  single record produced per step, but a work unit can correspond to\n",
      "     |  many records.\n",
      "     |  \n",
      "     |  Therefore we introduce some decoupling using a queue.  The queue\n",
      "     |  contains the work units and the Reader dequeues from the queue when\n",
      "     |  it is asked to produce a record (via Read()) but it has finished the\n",
      "     |  last work unit.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, reader_ref, supports_serialize=False)\n",
      "     |      Creates a new ReaderBase.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reader_ref: The operation that implements the reader.\n",
      "     |        supports_serialize: True if the reader implementation can\n",
      "     |          serialize its state.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If eager execution is enabled.\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class RegisterGradient(builtins.object)\n",
      "     |  RegisterGradient(op_type)\n",
      "     |  \n",
      "     |  A decorator for registering the gradient function for an op type.\n",
      "     |  \n",
      "     |  This decorator is only used when defining a new op type. For an op\n",
      "     |  with `m` inputs and `n` outputs, the gradient function is a function\n",
      "     |  that takes the original `Operation` and `n` `Tensor` objects\n",
      "     |  (representing the gradients with respect to each output of the op),\n",
      "     |  and returns `m` `Tensor` objects (representing the partial gradients\n",
      "     |  with respect to each input of the op).\n",
      "     |  \n",
      "     |  For example, assuming that operations of type `\"Sub\"` take two\n",
      "     |  inputs `x` and `y`, and return a single output `x - y`, the\n",
      "     |  following gradient function would be registered:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  @tf.RegisterGradient(\"Sub\")\n",
      "     |  def _sub_grad(unused_op, grad):\n",
      "     |    return grad, tf.negative(grad)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The decorator argument `op_type` is the string type of an\n",
      "     |  operation. This corresponds to the `OpDef.name` field for the proto\n",
      "     |  that defines the operation.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, f: ~_T) -> ~_T\n",
      "     |      Registers the function `f` as gradient function for `op_type`.\n",
      "     |  \n",
      "     |  __init__(self, op_type)\n",
      "     |      Creates a new decorator with `op_type` as the Operation type.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type: The string type of an operation. This corresponds to the\n",
      "     |          `OpDef.name` field for the proto that defines the operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `op_type` is not string.\n",
      "    \n",
      "    class RunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      RunMetadata\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  FunctionGraphs = <class 'tensorflow.core.protobuf.config_pb2.FunctionG...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class RunOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      RunOptions\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class Session(BaseSession)\n",
      "     |  Session(target='', graph=None, config=None)\n",
      "     |  \n",
      "     |  A class for running TensorFlow operations.\n",
      "     |  \n",
      "     |  A `Session` object encapsulates the environment in which `Operation`\n",
      "     |  objects are executed, and `Tensor` objects are evaluated. For\n",
      "     |  example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
      "     |  # Build a graph.\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  \n",
      "     |  # Launch the graph in a session.\n",
      "     |  sess = tf.compat.v1.Session()\n",
      "     |  \n",
      "     |  # Evaluate the tensor `c`.\n",
      "     |  print(sess.run(c)) # prints 30.0\n",
      "     |  ```\n",
      "     |  \n",
      "     |  A session may own resources, such as\n",
      "     |  `tf.Variable`, `tf.queue.QueueBase`,\n",
      "     |  and `tf.compat.v1.ReaderBase`. It is important to release\n",
      "     |  these resources when they are no longer required. To do this, either\n",
      "     |  invoke the `tf.Session.close` method on the session, or use\n",
      "     |  the session as a context manager. The following two examples are\n",
      "     |  equivalent:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Using the `close()` method.\n",
      "     |  sess = tf.compat.v1.Session()\n",
      "     |  sess.run(...)\n",
      "     |  sess.close()\n",
      "     |  \n",
      "     |  # Using the context manager.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |    sess.run(...)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The\n",
      "     |  [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      "     |  protocol buffer exposes various configuration options for a\n",
      "     |  session. For example, to create a session that uses soft constraints\n",
      "     |  for device placement, and log the resulting placement decisions,\n",
      "     |  create a session as follows:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Launch the graph in a session that allows soft device placement and\n",
      "     |  # logs the placement decisions.\n",
      "     |  sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\n",
      "     |      allow_soft_placement=True,\n",
      "     |      log_device_placement=True))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  `Session` does not work with either eager execution or `tf.function`, and you\n",
      "     |  should not invoke it directly. To migrate code that uses sessions to TF2,\n",
      "     |  rewrite the code without it. See the\n",
      "     |  [migration\n",
      "     |  guide](https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls)\n",
      "     |  on replacing `Session.run` calls.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Session\n",
      "     |      BaseSession\n",
      "     |      SessionInterface\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self) -> 'Session'\n",
      "     |  \n",
      "     |  __exit__(self, exec_type, exec_value, exec_tb)\n",
      "     |  \n",
      "     |  __init__(self, target='', graph=None, config=None)\n",
      "     |      Creates a new TensorFlow session.\n",
      "     |      \n",
      "     |      If no `graph` argument is specified when constructing the session,\n",
      "     |      the default graph will be launched in the session. If you are\n",
      "     |      using more than one graph (created with `tf.Graph()`) in the same\n",
      "     |      process, you will have to use different sessions for each graph,\n",
      "     |      but each graph can be used in multiple sessions. In this case, it\n",
      "     |      is often clearer to pass the graph to be launched explicitly to\n",
      "     |      the session constructor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: (Optional.) The execution engine to connect to. Defaults to using\n",
      "     |          an in-process engine. See\n",
      "     |          [Distributed TensorFlow](https://tensorflow.org/deploy/distributed) for\n",
      "     |            more examples.\n",
      "     |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      "     |        config: (Optional.) A\n",
      "     |          [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      "     |            protocol buffer with configuration options for the session.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  reset(target, containers=None, config=None)\n",
      "     |      Resets resource containers on `target`, and close all connected sessions.\n",
      "     |      \n",
      "     |      A resource container is distributed across all workers in the\n",
      "     |      same cluster as `target`.  When a resource container on `target`\n",
      "     |      is reset, resources associated with that container will be cleared.\n",
      "     |      In particular, all Variables in the container will become undefined:\n",
      "     |      they lose their values and shapes.\n",
      "     |      \n",
      "     |      NOTE:\n",
      "     |      (i) reset() is currently only implemented for distributed sessions.\n",
      "     |      (ii) Any sessions on the master named by `target` will be closed.\n",
      "     |      \n",
      "     |      If no resource containers are provided, all containers are reset.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: The execution engine to connect to.\n",
      "     |        containers: A list of resource container name strings, or `None` if all of\n",
      "     |          all the containers are to be reset.\n",
      "     |        config: (Optional.) Protocol buffer with configuration options.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      "     |          resetting containers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSession:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  as_default(self)\n",
      "     |      Returns a context manager that makes this object the default session.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that calls to\n",
      "     |      `tf.Operation.run` or `tf.Tensor.eval` should be executed in\n",
      "     |      this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(..)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      \n",
      "     |      with sess.as_default():\n",
      "     |        assert tf.compat.v1.get_default_session() is sess\n",
      "     |        print(c.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      To get the current default session, use `tf.compat.v1.get_default_session`.\n",
      "     |      \n",
      "     |      *N.B.* The `as_default` context manager *does not* close the\n",
      "     |      session when you exit the context, and you must close the session\n",
      "     |      explicitly.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(...)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      # ...\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      \n",
      "     |      sess.close()\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Alternatively, you can use `with tf.compat.v1.Session():` to create a\n",
      "     |      session that is automatically closed on exiting the context,\n",
      "     |      including when an uncaught exception is raised.\n",
      "     |      \n",
      "     |      *N.B.* The default session is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default session in that\n",
      "     |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      "     |      the current default graph. If you are using multiple graphs, and\n",
      "     |      `sess.graph` is different from the value of\n",
      "     |      `tf.compat.v1.get_default_graph`, you must explicitly enter a\n",
      "     |      `with sess.graph.as_default():` block to make `sess.graph` the default\n",
      "     |      graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager using this session as the default session.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes this session.\n",
      "     |      \n",
      "     |      Calling this method frees all resources associated with the session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      "     |          closing the TensorFlow session.\n",
      "     |  \n",
      "     |  list_devices(self)\n",
      "     |      Lists available devices in this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      devices = sess.list_devices()\n",
      "     |      for d in devices:\n",
      "     |        print(d.name)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Where:\n",
      "     |        Each element in the list has the following properties\n",
      "     |        name: A string with the full name of the device. ex:\n",
      "     |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      "     |        device_type: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      "     |        memory_limit: The maximum amount of memory available on the device.\n",
      "     |            Note: depending on the device, it is possible the usable memory could\n",
      "     |            be substantially less.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      "     |        invalid state, or network errors occur).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of devices in the session.\n",
      "     |  \n",
      "     |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      "     |      Returns a Python callable that runs a particular step.\n",
      "     |      \n",
      "     |      The returned callable will take `len(feed_list)` arguments whose types\n",
      "     |      must be compatible feed values for the respective elements of `feed_list`.\n",
      "     |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      "     |      argument to the returned callable must be a numpy ndarray (or something\n",
      "     |      convertible to an ndarray) with matching element type and shape. See\n",
      "     |      `tf.Session.run` for details of the allowable feed key and value types.\n",
      "     |      \n",
      "     |      The returned callable will have the same return type as\n",
      "     |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      "     |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      "     |      it will return `None`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A value or list of values to fetch. See `tf.Session.run` for\n",
      "     |          details of the allowable fetch types.\n",
      "     |        feed_list: (Optional.) A list of `feed_dict` keys. See `tf.Session.run`\n",
      "     |          for details of the allowable feed key types.\n",
      "     |        accept_options: (Optional.) If `True`, the returned `Callable` will be\n",
      "     |          able to accept `tf.compat.v1.RunOptions` and `tf.compat.v1.RunMetadata`\n",
      "     |          as optional keyword arguments `options` and `run_metadata`,\n",
      "     |          respectively, with the same syntax and semantics as `tf.Session.run`,\n",
      "     |          which is useful for certain use cases (profiling and debugging) but will\n",
      "     |          result in measurable slowdown of the `Callable`'s\n",
      "     |          performance. Default: `False`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A function that when called will execute the step defined by\n",
      "     |        `feed_list` and `fetches` in this session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      "     |          as arguments to `tf.Session.run`.\n",
      "     |  \n",
      "     |  partial_run(self, handle, fetches, feed_dict=None)\n",
      "     |      Continues the execution with more feeds and fetches. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2023-06-01.\n",
      "     |      Instructions for updating:\n",
      "     |      This function is deprecated and we do not expect adding newfunctionality to it. Please do not have your code dependingon this function.\n",
      "     |      \n",
      "     |      NOTE: This function is deprecated and we do not expect adding new\n",
      "     |      functionality to it. Please do not have your code depending on this\n",
      "     |      function.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      "     |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      "     |      list of feeds and fetches that will be used in the subsequent\n",
      "     |      `partial_run` calls.\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. See run() for more information.\n",
      "     |      \n",
      "     |      Below is a simple example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      r1 = math_ops.add(a, b)\n",
      "     |      r2 = math_ops.multiply(r1, c)\n",
      "     |      \n",
      "     |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      "     |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      "     |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        handle: A handle for a sequence of partial runs.\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (see\n",
      "     |          documentation for `run`).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary\n",
      "     |        (see documentation for `run`).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses on error.\n",
      "     |  \n",
      "     |  partial_run_setup(self, fetches, feeds=None)\n",
      "     |      Sets up a graph with feeds and fetches for partial run. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2023-06-01.\n",
      "     |      Instructions for updating:\n",
      "     |      This function is deprecated and we do not expect adding newfunctionality to it. Please do not have your code dependingon this function.\n",
      "     |      \n",
      "     |      NOTE: This function is deprecated and we do not expect adding new\n",
      "     |      functionality to it. Please do not have your code depending on this\n",
      "     |      function.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      "     |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, or a list of graph elements.\n",
      "     |        feeds: A single graph element, or a list of graph elements.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A handle for partial run.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      "     |  \n",
      "     |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      "     |      Runs operations and evaluates tensors in `fetches`.\n",
      "     |      \n",
      "     |      This method runs one \"step\" of TensorFlow computation, by\n",
      "     |      running the necessary graph fragment to execute every `Operation`\n",
      "     |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      "     |      `feed_dict` for the corresponding input values.\n",
      "     |      \n",
      "     |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      "     |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      "     |      elements at its leaves.  A graph element can be one of the following types:\n",
      "     |      \n",
      "     |      * A `tf.Operation`.\n",
      "     |        The corresponding fetched value will be `None`.\n",
      "     |      * A `tf.Tensor`.\n",
      "     |        The corresponding fetched value will be a numpy ndarray containing the\n",
      "     |        value of that tensor.\n",
      "     |      * A `tf.sparse.SparseTensor`.\n",
      "     |        The corresponding fetched value will be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`\n",
      "     |        containing the value of that sparse tensor.\n",
      "     |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      "     |        numpy ndarray containing the handle of that tensor.\n",
      "     |      * A `string` which is the name of a tensor or operation in the graph.\n",
      "     |      \n",
      "     |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      "     |      where the leaves are replaced by the corresponding values returned by\n",
      "     |      TensorFlow.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |         a = tf.constant([10, 20])\n",
      "     |         b = tf.constant([1.0, 2.0])\n",
      "     |         # 'fetches' can be a singleton\n",
      "     |         v = session.run(a)\n",
      "     |         # v is the numpy array [10, 20]\n",
      "     |         # 'fetches' can be a list.\n",
      "     |         v = session.run([a, b])\n",
      "     |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      "     |         # 1-D array [1.0, 2.0]\n",
      "     |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      "     |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      "     |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      "     |         # v is a dict with\n",
      "     |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      "     |         # 'b' (the numpy array [1.0, 2.0])\n",
      "     |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      "     |         # [10, 20].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      "     |      one of the following types:\n",
      "     |      \n",
      "     |      * If the key is a `tf.Tensor`, the\n",
      "     |        value may be a Python scalar, string, list, or numpy ndarray\n",
      "     |        that can be converted to the same `dtype` as that\n",
      "     |        tensor. Additionally, if the key is a\n",
      "     |        `tf.compat.v1.placeholder`, the shape of\n",
      "     |        the value will be checked for compatibility with the placeholder.\n",
      "     |      * If the key is a\n",
      "     |        `tf.sparse.SparseTensor`,\n",
      "     |        the value should be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`.\n",
      "     |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      "     |        should be a nested tuple with the same structure that maps to their\n",
      "     |        corresponding values as above.\n",
      "     |      \n",
      "     |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      "     |      of the corresponding key.\n",
      "     |      \n",
      "     |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      "     |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      "     |      on).\n",
      "     |      \n",
      "     |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      "     |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      "     |      example, when users turn on tracing in `options`, the profiled info will be\n",
      "     |      collected into this argument and passed back.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (described\n",
      "     |          above).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |        options: A [`RunOptions`] protocol buffer\n",
      "     |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary (described above).\n",
      "     |        Order in which `fetches` operations are evaluated inside the call\n",
      "     |        is undefined.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      "     |          `Tensor` that doesn't exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSession:\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The graph that was launched in this session.\n",
      "     |  \n",
      "     |  graph_def\n",
      "     |      A serializable version of the underlying TensorFlow graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      "     |        the underlying TensorFlow graph.\n",
      "     |  \n",
      "     |  sess_str\n",
      "     |      The TensorFlow process to which this session will connect.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SessionInterface:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      SessionLog\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class SparseConditionalAccumulator(ConditionalAccumulatorBase)\n",
      "     |  SparseConditionalAccumulator(dtype, shape=None, shared_name=None, name='sparse_conditional_accumulator', reduction_type='MEAN')\n",
      "     |  \n",
      "     |  A conditional accumulator for aggregating sparse gradients.\n",
      "     |  \n",
      "     |  Sparse gradients are represented by `IndexedSlices`.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    dtype: Datatype of the accumulated gradients.\n",
      "     |    shape: Shape of the accumulated gradients.\n",
      "     |    shared_name: Optional. If non-empty, this accumulator will be shared under\n",
      "     |      the given name across multiple sessions.\n",
      "     |    name: Optional name for the accumulator.\n",
      "     |    reduction_type: Reduction type to use when taking the gradient.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseConditionalAccumulator\n",
      "     |      ConditionalAccumulatorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape=None, shared_name=None, name='sparse_conditional_accumulator', reduction_type='MEAN')\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        accumulator_ref: A handle to the conditional accumulator, created by sub-\n",
      "     |          classes\n",
      "     |  \n",
      "     |  apply_grad(self, grad_indices, grad_values, grad_shape=None, local_step=0, name=None)\n",
      "     |      Attempts to apply a sparse gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., `local_step`\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      A sparse gradient is represented by its indices, values and possibly empty\n",
      "     |      or None shape. Indices must be a vector representing the locations of\n",
      "     |      non-zero entries in the tensor. Values are the non-zero slices of the\n",
      "     |      gradient, and must have the same first dimension as indices, i.e., the nnz\n",
      "     |      represented by indices and values must be consistent. Shape, if not empty or\n",
      "     |      None, must be consistent with the accumulator's shape (if also provided).\n",
      "     |      \n",
      "     |      Example:\n",
      "     |        A tensor [[0, 0], [0, 1], [2, 3]] can be represented\n",
      "     |          indices: [1,2]\n",
      "     |          values: [[0,1],[2,3]]\n",
      "     |          shape: [3, 2]\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad_indices: Indices of the sparse gradient to be applied.\n",
      "     |        grad_values: Values of the sparse gradient to be applied.\n",
      "     |        grad_shape: Shape of the sparse gradient to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  apply_indexed_slices_grad(self, grad, local_step=0, name=None)\n",
      "     |      Attempts to apply a gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., `local_step`\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad: The gradient `IndexedSlices` to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  take_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of indices, values, and shape representing the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `num_required` < 1\n",
      "     |  \n",
      "     |  take_indexed_slices_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An `IndexedSlices` holding the value of the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `num_required` < 1\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class SparseFeature(SparseFeature)\n",
      "     |  SparseFeature(index_key, value_key, dtype, size, already_sorted=False)\n",
      "     |  \n",
      "     |  Configuration for parsing a sparse input feature from an `Example`.\n",
      "     |  \n",
      "     |  Note, preferably use `VarLenFeature` (possibly in combination with a\n",
      "     |  `SequenceExample`) in order to parse out `SparseTensor`s instead of\n",
      "     |  `SparseFeature` due to its simplicity.\n",
      "     |  \n",
      "     |  Closely mimicking the `SparseTensor` that will be obtained by parsing an\n",
      "     |  `Example` with a `SparseFeature` config, a `SparseFeature` contains a\n",
      "     |  \n",
      "     |  * `value_key`: The name of key for a `Feature` in the `Example` whose parsed\n",
      "     |    `Tensor` will be the resulting `SparseTensor.values`.\n",
      "     |  \n",
      "     |  * `index_key`: A list of names - one for each dimension in the resulting\n",
      "     |    `SparseTensor` whose `indices[i][dim]` indicating the position of\n",
      "     |    the `i`-th value in the `dim` dimension will be equal to the `i`-th value in\n",
      "     |    the Feature with key named `index_key[dim]` in the `Example`.\n",
      "     |  \n",
      "     |  * `size`: A list of ints for the resulting `SparseTensor.dense_shape`.\n",
      "     |  \n",
      "     |  For example, we can represent the following 2D `SparseTensor`\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseTensor(indices=[[3, 1], [20, 0]],\n",
      "     |               values=[0.5, -1.0]\n",
      "     |               dense_shape=[100, 3])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  with an `Example` input proto\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  features {\n",
      "     |    feature { key: \"val\" value { float_list { value: [ 0.5, -1.0 ] } } }\n",
      "     |    feature { key: \"ix0\" value { int64_list { value: [ 3, 20 ] } } }\n",
      "     |    feature { key: \"ix1\" value { int64_list { value: [ 1, 0 ] } } }\n",
      "     |  }\n",
      "     |  ```\n",
      "     |  \n",
      "     |  and `SparseFeature` config with 2 `index_key`s\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseFeature(index_key=[\"ix0\", \"ix1\"],\n",
      "     |                value_key=\"val\",\n",
      "     |                dtype=tf.float32,\n",
      "     |                size=[100, 3])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    index_key: A single string name or a list of string names of index features.\n",
      "     |      For each key the underlying feature's type must be `int64` and its length\n",
      "     |      must always match that of the `value_key` feature.\n",
      "     |      To represent `SparseTensor`s with a `dense_shape` of `rank` higher than 1\n",
      "     |      a list of length `rank` should be used.\n",
      "     |    value_key: Name of value feature.  The underlying feature's type must\n",
      "     |      be `dtype` and its length must always match that of all the `index_key`s'\n",
      "     |      features.\n",
      "     |    dtype: Data type of the `value_key` feature.\n",
      "     |    size: A Python int or list thereof specifying the dense shape. Should be a\n",
      "     |      list if and only if `index_key` is a list. In that case the list must be\n",
      "     |      equal to the length of `index_key`. Each for each entry `i` all values in\n",
      "     |      the `index_key`[i] feature must be in `[0, size[i])`.\n",
      "     |    already_sorted: A Python boolean to specify whether the values in\n",
      "     |      `value_key` are already sorted by their index position. If so skip\n",
      "     |      sorting. False by default (optional).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseFeature\n",
      "     |      SparseFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, index_key, value_key, dtype, size, already_sorted=False)\n",
      "     |      Create new instance of SparseFeature(index_key, value_key, dtype, size, already_sorted)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.SparseFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.SparseFeature', 'SparseFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from SparseFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new SparseFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from SparseFeature:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new SparseFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SparseFeature:\n",
      "     |  \n",
      "     |  index_key\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  value_key\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  size\n",
      "     |      Alias for field number 3\n",
      "     |  \n",
      "     |  already_sorted\n",
      "     |      Alias for field number 4\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from SparseFeature:\n",
      "     |  \n",
      "     |  __match_args__ = ('index_key', 'value_key', 'dtype', 'size', 'already_...\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('index_key', 'value_key', 'dtype', 'size', 'already_sorted'...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    class SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  SparseTensor(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  Represents a sparse tensor.\n",
      "     |  \n",
      "     |  TensorFlow represents a sparse tensor as three separate dense tensors:\n",
      "     |  `indices`, `values`, and `dense_shape`.  In Python, the three tensors are\n",
      "     |  collected into a `SparseTensor` class for ease of use.  If you have separate\n",
      "     |  `indices`, `values`, and `dense_shape` tensors, wrap them in a `SparseTensor`\n",
      "     |  object before passing to the ops below.\n",
      "     |  \n",
      "     |  Concretely, the sparse tensor `SparseTensor(indices, values, dense_shape)`\n",
      "     |  comprises the following components, where `N` and `ndims` are the number\n",
      "     |  of values and number of dimensions in the `SparseTensor`, respectively:\n",
      "     |  \n",
      "     |  * `indices`: A 2-D int64 tensor of shape `[N, ndims]`, which specifies the\n",
      "     |    indices of the elements in the sparse tensor that contain nonzero values\n",
      "     |    (elements are zero-indexed). For example, `indices=[[1,3], [2,4]]` specifies\n",
      "     |    that the elements with indexes of [1,3] and [2,4] have nonzero values.\n",
      "     |  \n",
      "     |  * `values`: A 1-D tensor of any type and shape `[N]`, which supplies the\n",
      "     |    values for each element in `indices`. For example, given `indices=[[1,3],\n",
      "     |    [2,4]]`, the parameter `values=[18, 3.6]` specifies that element [1,3] of\n",
      "     |    the sparse tensor has a value of 18, and element [2,4] of the tensor has a\n",
      "     |    value of 3.6.\n",
      "     |  \n",
      "     |  * `dense_shape`: A 1-D int64 tensor of shape `[ndims]`, which specifies the\n",
      "     |    dense_shape of the sparse tensor. Takes a list indicating the number of\n",
      "     |    elements in each dimension. For example, `dense_shape=[3,6]` specifies a\n",
      "     |    two-dimensional 3x6 tensor, `dense_shape=[2,3,4]` specifies a\n",
      "     |    three-dimensional 2x3x4 tensor, and `dense_shape=[9]` specifies a\n",
      "     |    one-dimensional tensor with 9 elements.\n",
      "     |  \n",
      "     |  The corresponding dense tensor satisfies:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dense.shape = dense_shape\n",
      "     |  dense[tuple(indices[i])] = values[i]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  By convention, `indices` should be sorted in row-major order (or equivalently\n",
      "     |  lexicographic order on the tuples `indices[i]`). This is not enforced when\n",
      "     |  `SparseTensor` objects are constructed, but most ops assume correct ordering.\n",
      "     |  If the ordering of sparse tensor `st` is wrong, a fixed version can be\n",
      "     |  obtained by calling `tf.sparse.reorder(st)`.\n",
      "     |  \n",
      "     |  Example: The sparse tensor\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  represents the dense tensor\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  [[1, 0, 0, 0]\n",
      "     |   [0, 0, 2, 0]\n",
      "     |   [0, 0, 0, 0]]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Component-wise divides a SparseTensor by a dense Tensor.\n",
      "     |      \n",
      "     |      *Limitation*: this Op only broadcasts the dense side to the sparse side, but not\n",
      "     |      the other direction.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sp_indices: A `Tensor` of type `int64`.\n",
      "     |          2-D.  `N x R` matrix with the indices of non-empty values in a\n",
      "     |          SparseTensor, possibly not in canonical ordering.\n",
      "     |        sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "     |          1-D.  `N` non-empty values corresponding to `sp_indices`.\n",
      "     |        sp_shape: A `Tensor` of type `int64`.\n",
      "     |          1-D.  Shape of the input SparseTensor.\n",
      "     |        dense: A `Tensor`. Must have the same type as `sp_values`.\n",
      "     |          `R`-D.  The dense Tensor operand.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `sp_values`.\n",
      "     |  \n",
      "     |  __init__(self, indices, values, dense_shape)\n",
      "     |      Creates a `SparseTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A 2-D int64 tensor of shape `[N, ndims]`.\n",
      "     |        values: A 1-D tensor of any type and shape `[N]`.\n",
      "     |        dense_shape: A 1-D int64 tensor of shape `[ndims]`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: When building an eager SparseTensor if `dense_shape` is\n",
      "     |          unknown or contains unknown elements (None or -1).\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Component-wise multiplies a SparseTensor by a dense Tensor.\n",
      "     |      \n",
      "     |      The output locations corresponding to the implicitly zero elements in the sparse\n",
      "     |      tensor will be zero (i.e., will not take up storage space), regardless of the\n",
      "     |      contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).\n",
      "     |      \n",
      "     |      *Limitation*: this Op only broadcasts the dense side to the sparse side, but not\n",
      "     |      the other direction.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sp_indices: A `Tensor` of type `int64`.\n",
      "     |          2-D.  `N x R` matrix with the indices of non-empty values in a\n",
      "     |          SparseTensor, possibly not in canonical ordering.\n",
      "     |        sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "     |          1-D.  `N` non-empty values corresponding to `sp_indices`.\n",
      "     |        sp_shape: A `Tensor` of type `int64`.\n",
      "     |          1-D.  Shape of the input SparseTensor.\n",
      "     |        dense: A `Tensor`. Must have the same type as `sp_values`.\n",
      "     |          `R`-D.  The dense Tensor operand.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `sp_values`.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Internal helper function for 'sp_t / dense_t'.\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  eval(self, feed_dict=None, session=None)\n",
      "     |      Evaluates this sparse tensor in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for the operation that produces this\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `SparseTensor.eval()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to evaluate this sparse\n",
      "     |          tensor. If none, the default session will be used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `SparseTensorValue` object.\n",
      "     |  \n",
      "     |  get_shape(self) -> tensorflow.python.framework.tensor_shape.TensorShape\n",
      "     |      Get the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` object.\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Updates the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      With eager execution this operates as a shape assertion.\n",
      "     |      Here the shapes match:\n",
      "     |      \n",
      "     |      >>> st = tf.SparseTensor(\n",
      "     |      ...   indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
      "     |      >>> st.set_shape([3, 4])\n",
      "     |      \n",
      "     |      Passing a `None` in the new shape allows any value for that axis:\n",
      "     |      \n",
      "     |      >>> st.set_shape([3, None])\n",
      "     |      \n",
      "     |      An error is raised if an incompatible shape is passed.\n",
      "     |      \n",
      "     |      >>> st.set_shape([1, 4])\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Tensor's shape (3, 4) is not compatible with supplied\n",
      "     |      shape [1, 4]\n",
      "     |      \n",
      "     |      When executing in a `tf.function`, or building a model using\n",
      "     |      `tf.keras.Input`, `SparseTensor.set_shape` will *merge* the given `shape`\n",
      "     |      with the current shape of this tensor, and set the tensor's shape to the\n",
      "     |      merged value (see `tf.TensorShape.merge_with` for details):\n",
      "     |      \n",
      "     |      >>> st = tf.keras.Input(shape=[None, None, 3], sparse=True)\n",
      "     |      >>> print(st.shape)\n",
      "     |      (None, None, None, 3)\n",
      "     |      \n",
      "     |      Dimensions set to `None` are not updated:\n",
      "     |      \n",
      "     |      >>> st.set_shape([None, 224, 224, None])\n",
      "     |      >>> print(st.shape)\n",
      "     |      (None, 224, 224, 3)\n",
      "     |      \n",
      "     |      The main use case for this is to provide additional shape information\n",
      "     |      that cannot be inferred from the graph alone.\n",
      "     |      \n",
      "     |      Caution: `set_shape` ensures that the applied shape is compatible with\n",
      "     |      the existing shape, but it does not check at runtime. Setting\n",
      "     |      incorrect shapes can result in inconsistencies between the\n",
      "     |      statically-known graph and the runtime value of tensors.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: A `TensorShape` representing the shape of this tensor, a\n",
      "     |          `TensorShapeProto`, a list, a tuple, or None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `shape` is not compatible with the current shape of\n",
      "     |          this tensor.\n",
      "     |  \n",
      "     |  with_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `values` replaced by `new_values`.\n",
      "     |      \n",
      "     |      This method produces a new `SparseTensor` that has the same nonzero\n",
      "     |      `indices` and same `dense_shape`, but updated values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: The values of the new `SparseTensor`. Needs to have the same\n",
      "     |          shape as the current `.values` `Tensor`. May have a different type than\n",
      "     |          the current `values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `SparseTensor` with identical indices and shape but updated values.\n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      >>> st = tf.sparse.from_dense([[1, 0, 2, 0], [3, 0, 0, 4]])\n",
      "     |      >>> tf.sparse.to_dense(st.with_values([10, 20, 30, 40]))  # 4 nonzero values\n",
      "     |      <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "     |      array([[10,  0, 20,  0],\n",
      "     |             [30,  0,  0, 40]], dtype=int32)>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(sparse_tensor_value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      A 1-D Tensor of int64 representing the shape of the dense tensor.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains the index, value, and dense_shape tensors.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      The indices of non-zero values in the represented dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 2-D Tensor of int64 with dense_shape `[N, ndims]`, where `N` is the\n",
      "     |          number of non-zero values in the tensor, and `ndims` is the rank.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces `values` as an output.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Get the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` object.\n",
      "     |  \n",
      "     |  values\n",
      "     |      The non-zero values in the represented dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D Tensor of any data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.NativeObject:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "    \n",
      "    class SparseTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec)\n",
      "     |  SparseTensorSpec(shape=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Type specification for a `tf.sparse.SparseTensor`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32)\n",
      "     |      Constructs a type specification for a `tf.sparse.SparseTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The dense shape of the `SparseTensor`, or `None` to allow any dense\n",
      "     |          shape.\n",
      "     |        dtype: `tf.DType` of values in the `SparseTensor`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `tf.dtypes.DType` specified by this type for the SparseTensor.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The `tf.TensorShape` specified by this type for the SparseTensor.\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class SparseTensorValue(builtins.tuple)\n",
      "     |  SparseTensorValue(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  SparseTensorValue(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensorValue\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new SparseTensorValue object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new SparseTensorValue object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(_cls, indices, values, dense_shape)\n",
      "     |      Create new instance of SparseTensorValue(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  indices\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  values\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __match_args__ = ('indices', 'values', 'dense_shape')\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('indices', 'values', 'dense_shape')\n",
      "     |  \n",
      "     |  _tf_api_names = ()\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['SparseTensorValue']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    class Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      Summary\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Audio = <class 'tensorflow.core.framework.summary_pb2.Audio'>\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  Image = <class 'tensorflow.core.framework.summary_pb2.Image'>\n",
      "     |  \n",
      "     |  Value = <class 'tensorflow.core.framework.summary_pb2.Value'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class SummaryMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      SummaryMetadata\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  PluginData = <class 'tensorflow.core.framework.summary_pb2.PluginData'...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class TFRecordReader(ReaderBase)\n",
      "     |  TFRecordReader(name=None, options=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the records from a TFRecords file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TFRecordReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, options=None)\n",
      "     |      Create a TFRecordReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        options: A TFRecordOptions object (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class Tensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "     |  A `tf.Tensor` represents a multidimensional array of elements.\n",
      "     |  \n",
      "     |  All elements are of a single known data type.\n",
      "     |  \n",
      "     |  When writing a TensorFlow program, the main object that is\n",
      "     |  manipulated and passed around is the `tf.Tensor`.\n",
      "     |  \n",
      "     |  A `tf.Tensor` has the following properties:\n",
      "     |  \n",
      "     |  * a single data type (float32, int32, or string, for example)\n",
      "     |  * a shape\n",
      "     |  \n",
      "     |  TensorFlow supports eager execution and graph execution.  In eager\n",
      "     |  execution, operations are evaluated immediately.  In graph\n",
      "     |  execution, a computational graph is constructed for later\n",
      "     |  evaluation.\n",
      "     |  \n",
      "     |  TensorFlow defaults to eager execution.  In the example below, the\n",
      "     |  matrix multiplication results are calculated immediately.\n",
      "     |  \n",
      "     |  >>> # Compute some values using a Tensor\n",
      "     |  >>> c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
      "     |  >>> d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
      "     |  >>> e = tf.matmul(c, d)\n",
      "     |  >>> print(e)\n",
      "     |  tf.Tensor(\n",
      "     |  [[1. 3.]\n",
      "     |   [3. 7.]], shape=(2, 2), dtype=float32)\n",
      "     |  \n",
      "     |  Note that during eager execution, you may discover your `Tensors` are actually\n",
      "     |  of type `EagerTensor`.  This is an internal detail, but it does give you\n",
      "     |  access to a useful function, `numpy`:\n",
      "     |  \n",
      "     |  >>> type(e)\n",
      "     |  <class '...ops.EagerTensor'>\n",
      "     |  >>> print(e.numpy())\n",
      "     |    [[1. 3.]\n",
      "     |     [3. 7.]]\n",
      "     |  \n",
      "     |  In TensorFlow, `tf.function`s are a common way to define graph execution.\n",
      "     |  \n",
      "     |  A Tensor's shape (that is, the rank of the Tensor and the size of\n",
      "     |  each dimension) may not always be fully known.  In `tf.function`\n",
      "     |  definitions, the shape may only be partially known.\n",
      "     |  \n",
      "     |  Most operations produce tensors of fully-known shapes if the shapes of their\n",
      "     |  inputs are also fully known, but in some cases it's only possible to find the\n",
      "     |  shape of a tensor at execution time.\n",
      "     |  \n",
      "     |  A number of specialized tensors are available: see `tf.Variable`,\n",
      "     |  `tf.constant`, `tf.placeholder`, `tf.sparse.SparseTensor`, and\n",
      "     |  `tf.RaggedTensor`.\n",
      "     |  \n",
      "     |  Caution: when constructing a tensor from a numpy array or pandas dataframe\n",
      "     |  the underlying buffer may be re-used:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = np.array([1, 2, 3])\n",
      "     |  b = tf.constant(a)\n",
      "     |  a[0] = 4\n",
      "     |  print(b)  # tf.Tensor([4 2 3], shape=(3,), dtype=int64)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note: this is an implementation detail that is subject to change and users\n",
      "     |  should not rely on this behaviour.\n",
      "     |  \n",
      "     |  For more on Tensors, see the [guide](https://tensorflow.org/guide/tensor).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Tensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.types.core.Symbol\n",
      "     |      tensorflow.python.types.core.Tensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = _abs_factory(x, name=None)\n",
      "     |  \n",
      "     |  __add__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __and__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Dummy method to prevent a tensor from being used as a Python `bool`.\n",
      "     |      \n",
      "     |      This overload raises a `TypeError` when the user inadvertently\n",
      "     |      treats a `Tensor` as a boolean (most commonly in an `if` or `while`\n",
      "     |      statement), in code that was not converted by AutoGraph. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      if tf.constant(True):  # Will raise.\n",
      "     |        # ...\n",
      "     |      \n",
      "     |      if tf.constant(5) < tf.constant(7):  # Will raise.\n",
      "     |        # ...\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        `TypeError`.\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __eq__ = _tensor_equals_factory(self, other)\n",
      "     |  \n",
      "     |  __floordiv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x: typing.Annotated[_any, ~TV_GreaterEqual_T], y: typing.Annotated[_any, ~TV_GreaterEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      y = tf.constant([5, 2, 5, 10])\n",
      "     |      tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |  \n",
      "     |  __getitem__ = _slice_helper(tensor, slice_spec, var=None)\n",
      "     |      Overload for Tensor.__getitem__.\n",
      "     |      \n",
      "     |      This operation extracts the specified region from the tensor.\n",
      "     |      The notation is similar to NumPy with the restriction that\n",
      "     |      currently only support basic indexing. That means that\n",
      "     |      using a non-scalar tensor as input is not currently allowed.\n",
      "     |      \n",
      "     |      Some useful examples:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # Strip leading and trailing 2 elements\n",
      "     |      foo = tf.constant([1,2,3,4,5,6])\n",
      "     |      print(foo[2:-2])  # => [3,4]\n",
      "     |      \n",
      "     |      # Skip every other row and reverse the order of the columns\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[::2,::-1])  # => [[3,2,1], [9,8,7]]\n",
      "     |      \n",
      "     |      # Use scalar tensors as indices on both dimensions\n",
      "     |      print(foo[tf.constant(0), tf.constant(2)])  # => 3\n",
      "     |      \n",
      "     |      # Insert another dimension\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[tf.newaxis, :, :]) # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[:, tf.newaxis, :]) # => [[[1,2,3]], [[4,5,6]], [[7,8,9]]]\n",
      "     |      print(foo[:, :, tf.newaxis]) # => [[[1],[2],[3]], [[4],[5],[6]],\n",
      "     |      [[7],[8],[9]]]\n",
      "     |      \n",
      "     |      # Ellipses (3 equivalent operations)\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[tf.newaxis, :, :])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[tf.newaxis, ...])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[tf.newaxis])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      \n",
      "     |      # Masks\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[foo > 2])  # => [3, 4, 5, 6, 7, 8, 9]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |        - `tf.newaxis` is `None` as in NumPy.\n",
      "     |        - An implicit ellipsis is placed at the end of the `slice_spec`\n",
      "     |        - NumPy advanced indexing is currently not supported.\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__getitem__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: An tensor.Tensor object.\n",
      "     |        slice_spec: The arguments to Tensor.__getitem__.\n",
      "     |        var: In the case of variable slice assignment, the Variable object to slice\n",
      "     |          (i.e. tensor is the read-only view of this variable).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If a slice range is negative size.\n",
      "     |        TypeError: If the slice indices aren't int, slice, ellipsis,\n",
      "     |          tf.newaxis or scalar int32/int64 tensors.\n",
      "     |  \n",
      "     |  __gt__ = greater(x: typing.Annotated[_any, ~TV_Greater_T], y: typing.Annotated[_any, ~TV_Greater_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__ = _invert_factory(x, name=None)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __le__ = less_equal(x: typing.Annotated[_any, ~TV_LessEqual_T], y: typing.Annotated[_any, ~TV_LessEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __lt__ = less(x: typing.Annotated[_any, ~TV_Less_T], y: typing.Annotated[_any, ~TV_Less_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __matmul__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __mod__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __ne__ = _tensor_not_equals_factory(self, other)\n",
      "     |  \n",
      "     |  __neg__ = neg(x: typing.Annotated[_any, ~TV_Neg_T], name=None) -> typing.Annotated[_any, ~TV_Neg_T]\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __nonzero__(self)\n",
      "     |      Dummy method to prevent a tensor from being used as a Python `bool`.\n",
      "     |      \n",
      "     |      This is the Python 2.x counterpart to `__bool__()` above.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        `TypeError`.\n",
      "     |  \n",
      "     |  __or__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __pow__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __radd__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rand__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmod__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmul__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __ror__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __round__ = around(a, decimals=0)\n",
      "     |      TensorFlow variant of NumPy's `around`.\n",
      "     |      \n",
      "     |      Unsupported arguments: `out`.\n",
      "     |      \n",
      "     |      See the NumPy documentation for [`numpy.around`](https://numpy.org/doc/stable/reference/generated/numpy.around.html).\n",
      "     |  \n",
      "     |  __rpow__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rsub__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rxor__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __tf_tensor__(self, dtype: Optional[tensorflow.python.framework.dtypes.DType] = None, name: Optional[str] = None) -> 'Tensor'\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, signature_context)\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __xor__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  eval(self, feed_dict=None, session=None)\n",
      "     |      Evaluates this tensor in a `Session`.\n",
      "     |      \n",
      "     |      Note: If you are not using `compat.v1` libraries, you should not need this,\n",
      "     |      (or `feed_dict` or `Session`).  In eager execution (or within `tf.function`)\n",
      "     |      you do not need to call `eval`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for the operation that produces this\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `Tensor.eval()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to evaluate this tensor. If\n",
      "     |          none, the default session will be used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy array corresponding to the value of this tensor.\n",
      "     |  \n",
      "     |  experimental_ref(self)\n",
      "     |      DEPRECATED FUNCTION\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use ref() instead.\n",
      "     |  \n",
      "     |  get_shape(self) -> tensorflow.python.framework.tensor_shape.TensorShape\n",
      "     |      Returns a `tf.TensorShape` that represents the shape of this tensor.\n",
      "     |      \n",
      "     |      In eager execution the shape is always fully-known.\n",
      "     |      \n",
      "     |      >>> a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
      "     |      >>> print(a.shape)\n",
      "     |      (2, 3)\n",
      "     |      \n",
      "     |      `tf.Tensor.get_shape()` is equivalent to `tf.Tensor.shape`.\n",
      "     |      \n",
      "     |      \n",
      "     |      When executing in a `tf.function` or building a model using\n",
      "     |      `tf.keras.Input`, `Tensor.shape` may return a partial shape (including\n",
      "     |      `None` for unknown dimensions). See `tf.TensorShape` for more details.\n",
      "     |      \n",
      "     |      >>> inputs = tf.keras.Input(shape = [10])\n",
      "     |      >>> # Unknown batch size\n",
      "     |      >>> print(inputs.shape)\n",
      "     |      (None, 10)\n",
      "     |      \n",
      "     |      The shape is computed using shape inference functions that are\n",
      "     |      registered for each `tf.Operation`.\n",
      "     |      \n",
      "     |      The returned `tf.TensorShape` is determined at *build* time, without\n",
      "     |      executing the underlying kernel. It is not a `tf.Tensor`. If you need a\n",
      "     |      shape *tensor*, either convert the `tf.TensorShape` to a `tf.constant`, or\n",
      "     |      use the `tf.shape(tensor)` function, which returns the tensor's shape at\n",
      "     |      *execution* time.\n",
      "     |      \n",
      "     |      This is useful for debugging and providing early errors. For\n",
      "     |      example, when tracing a `tf.function`, no ops are being executed, shapes\n",
      "     |      may be unknown (See the [Concrete Functions\n",
      "     |      Guide](https://www.tensorflow.org/guide/concrete_function) for details).\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_matmul(a, b):\n",
      "     |      ...   result = a@b\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Result shape: \", result.shape)\n",
      "     |      ...   return result\n",
      "     |      \n",
      "     |      The shape inference functions propagate shapes to the extent possible:\n",
      "     |      \n",
      "     |      >>> f = my_matmul.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None,3]),\n",
      "     |      ...   tf.TensorSpec([3,5]))\n",
      "     |      Result shape: (None, 5)\n",
      "     |      \n",
      "     |      Tracing may fail if a shape missmatch can be detected:\n",
      "     |      \n",
      "     |      >>> cf = my_matmul.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None,3]),\n",
      "     |      ...   tf.TensorSpec([4,5]))\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Dimensions must be equal, but are 3 and 4 for 'matmul' (op:\n",
      "     |      'MatMul') with input shapes: [?,3], [4,5].\n",
      "     |      \n",
      "     |      In some cases, the inferred shape may have unknown dimensions. If\n",
      "     |      the caller has additional information about the values of these\n",
      "     |      dimensions, `tf.ensure_shape` or `Tensor.set_shape()` can be used to augment\n",
      "     |      the inferred shape.\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_fun(a):\n",
      "     |      ...   a = tf.ensure_shape(a, [5, 5])\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Result shape: \", a.shape)\n",
      "     |      ...   return a\n",
      "     |      \n",
      "     |      >>> cf = my_fun.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None, None]))\n",
      "     |      Result shape: (5, 5)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` representing the shape of this tensor.\n",
      "     |  \n",
      "     |  ref(self)\n",
      "     |      Returns a hashable reference object to this Tensor.\n",
      "     |      \n",
      "     |      The primary use case for this API is to put tensors in a set/dictionary.\n",
      "     |      We can't put tensors in a set/dictionary as `tensor.__hash__()` is no longer\n",
      "     |      available starting Tensorflow 2.0.\n",
      "     |      \n",
      "     |      The following will raise an exception starting 2.0\n",
      "     |      \n",
      "     |      >>> x = tf.constant(5)\n",
      "     |      >>> y = tf.constant(10)\n",
      "     |      >>> z = tf.constant(10)\n",
      "     |      >>> tensor_set = {x, y, z}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      >>> tensor_dict = {x: 'five', y: 'ten'}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      \n",
      "     |      Instead, we can use `tensor.ref()`.\n",
      "     |      \n",
      "     |      >>> tensor_set = {x.ref(), y.ref(), z.ref()}\n",
      "     |      >>> x.ref() in tensor_set\n",
      "     |      True\n",
      "     |      >>> tensor_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}\n",
      "     |      >>> tensor_dict[y.ref()]\n",
      "     |      'ten'\n",
      "     |      \n",
      "     |      Also, the reference object provides `.deref()` function that returns the\n",
      "     |      original Tensor.\n",
      "     |      \n",
      "     |      >>> x = tf.constant(5)\n",
      "     |      >>> x.ref().deref()\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=5>\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Updates the shape of this tensor.\n",
      "     |      \n",
      "     |      Note: It is recommended to use `tf.ensure_shape` instead of\n",
      "     |      `Tensor.set_shape`, because `tf.ensure_shape` provides better checking for\n",
      "     |      programming errors and can create guarantees for compiler\n",
      "     |      optimization.\n",
      "     |      \n",
      "     |      With eager execution this operates as a shape assertion.\n",
      "     |      Here the shapes match:\n",
      "     |      \n",
      "     |      >>> t = tf.constant([[1,2,3]])\n",
      "     |      >>> t.set_shape([1, 3])\n",
      "     |      \n",
      "     |      Passing a `None` in the new shape allows any value for that axis:\n",
      "     |      \n",
      "     |      >>> t.set_shape([1,None])\n",
      "     |      \n",
      "     |      An error is raised if an incompatible shape is passed.\n",
      "     |      \n",
      "     |      >>> t.set_shape([1,5])\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Tensor's shape (1, 3) is not compatible with supplied\n",
      "     |      shape [1, 5]\n",
      "     |      \n",
      "     |      When executing in a `tf.function`, or building a model using\n",
      "     |      `tf.keras.Input`, `Tensor.set_shape` will *merge* the given `shape` with\n",
      "     |      the current shape of this tensor, and set the tensor's shape to the\n",
      "     |      merged value (see `tf.TensorShape.merge_with` for details):\n",
      "     |      \n",
      "     |      >>> t = tf.keras.Input(shape=[None, None, 3])\n",
      "     |      >>> print(t.shape)\n",
      "     |      (None, None, None, 3)\n",
      "     |      \n",
      "     |      Dimensions set to `None` are not updated:\n",
      "     |      \n",
      "     |      >>> t.set_shape([None, 224, 224, None])\n",
      "     |      >>> print(t.shape)\n",
      "     |      (None, 224, 224, 3)\n",
      "     |      \n",
      "     |      The main use case for this is to provide additional shape information\n",
      "     |      that cannot be inferred from the graph alone.\n",
      "     |      \n",
      "     |      For example if you know all the images in a dataset have shape [28,28,3] you\n",
      "     |      can set it with `tf.set_shape`:\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def load_image(filename):\n",
      "     |      ...   raw = tf.io.read_file(filename)\n",
      "     |      ...   image = tf.image.decode_png(raw, channels=3)\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Initial shape: \", image.shape)\n",
      "     |      ...   image.set_shape([28, 28, 3])\n",
      "     |      ...   print(\"Final shape: \", image.shape)\n",
      "     |      ...   return image\n",
      "     |      \n",
      "     |      Trace the function, see the [Concrete Functions\n",
      "     |      Guide](https://www.tensorflow.org/guide/concrete_function) for details.\n",
      "     |      \n",
      "     |      >>> cf = load_image.get_concrete_function(\n",
      "     |      ...     tf.TensorSpec([], dtype=tf.string))\n",
      "     |      Initial shape:  (None, None, 3)\n",
      "     |      Final shape: (28, 28, 3)\n",
      "     |      \n",
      "     |      Similarly the `tf.io.parse_tensor` function could return a tensor with\n",
      "     |      any shape, even the `tf.rank` is unknown. If you know that all your\n",
      "     |      serialized tensors will be 2d, set it with `set_shape`:\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_parse(string_tensor):\n",
      "     |      ...   result = tf.io.parse_tensor(string_tensor, out_type=tf.float32)\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Initial shape: \", result.shape)\n",
      "     |      ...   result.set_shape([None, None])\n",
      "     |      ...   print(\"Final shape: \", result.shape)\n",
      "     |      ...   return result\n",
      "     |      \n",
      "     |      Trace the function\n",
      "     |      \n",
      "     |      >>> concrete_parse = my_parse.get_concrete_function(\n",
      "     |      ...     tf.TensorSpec([], dtype=tf.string))\n",
      "     |      Initial shape:  <unknown>\n",
      "     |      Final shape:  (None, None)\n",
      "     |      \n",
      "     |      Make sure it works:\n",
      "     |      \n",
      "     |      >>> t = tf.ones([5,3], dtype=tf.float32)\n",
      "     |      >>> serialized = tf.io.serialize_tensor(t)\n",
      "     |      >>> print(serialized.dtype)\n",
      "     |      <dtype: 'string'>\n",
      "     |      >>> print(serialized.shape)\n",
      "     |      ()\n",
      "     |      >>> t2 = concrete_parse(serialized)\n",
      "     |      >>> print(t2.shape)\n",
      "     |      (5, 3)\n",
      "     |      \n",
      "     |      Caution: `set_shape` ensures that the applied shape is compatible with\n",
      "     |      the existing shape, but it does not check at runtime. Setting\n",
      "     |      incorrect shapes can result in inconsistencies between the\n",
      "     |      statically-known graph and the runtime value of tensors. For runtime\n",
      "     |      validation of the shape, use `tf.ensure_shape` instead. It also modifies\n",
      "     |      the `shape` of the tensor.\n",
      "     |      \n",
      "     |      >>> # Serialize a rank-3 tensor\n",
      "     |      >>> t = tf.ones([5,5,5], dtype=tf.float32)\n",
      "     |      >>> serialized = tf.io.serialize_tensor(t)\n",
      "     |      >>> # The function still runs, even though it `set_shape([None,None])`\n",
      "     |      >>> t2 = concrete_parse(serialized)\n",
      "     |      >>> print(t2.shape)\n",
      "     |      (5, 5, 5)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: A `TensorShape` representing the shape of this tensor, a\n",
      "     |          `TensorShapeProto`, a list, a tuple, or None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `shape` is not compatible with the current shape of\n",
      "     |          this tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ndim\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns a `tf.TensorShape` that represents the shape of this tensor.\n",
      "     |      \n",
      "     |      >>> t = tf.constant([1,2,3,4,5])\n",
      "     |      >>> t.shape\n",
      "     |      TensorShape([5])\n",
      "     |      \n",
      "     |      `tf.Tensor.shape` is equivalent to `tf.Tensor.get_shape()`.\n",
      "     |      \n",
      "     |      In a `tf.function` or when building a model using\n",
      "     |      `tf.keras.Input`, they return the build-time shape of the\n",
      "     |      tensor, which may be partially unknown.\n",
      "     |      \n",
      "     |      A `tf.TensorShape` is not a tensor. Use `tf.shape(t)` to get a tensor\n",
      "     |      containing the shape, calculated at runtime.\n",
      "     |      \n",
      "     |      See `tf.Tensor.get_shape()`, and `tf.TensorShape` for details and examples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  OVERLOADABLE_OPERATORS = {'__abs__', '__add__', '__and__', '__div__', ...\n",
      "     |  \n",
      "     |  __array_priority__ = 100\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.NativeObject:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TensorArray(builtins.object)\n",
      "     |  TensorArray(dtype, size=None, dynamic_size=None, clear_after_read=None, tensor_array_name=None, handle=None, flow=None, infer_shape=True, element_shape=None, colocate_with_first_write_call=True, name=None)\n",
      "     |  \n",
      "     |  Class wrapping dynamic-sized, per-time-step, Tensor arrays.\n",
      "     |  \n",
      "     |  This class is meant to be used with dynamic iteration primitives such as\n",
      "     |  `while_loop` and `map_fn`.  It supports gradient back-propagation via special\n",
      "     |  \"flow\" control flow dependencies.\n",
      "     |  \n",
      "     |  Note that although the array can be read multiple times and positions can be\n",
      "     |  overwritten, behavior may be undefined when storing multiple references to\n",
      "     |  the same array and clear_after_read is False. In particular, avoid using\n",
      "     |  methods like concat() to convert an intermediate TensorArray to a Tensor,\n",
      "     |  then further modifying the TensorArray, particularly if you need to backprop\n",
      "     |  through it later.\n",
      "     |  \n",
      "     |  Example 1: Plain reading and writing.\n",
      "     |  \n",
      "     |  >>> ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
      "     |  >>> ta = ta.write(0, 10)\n",
      "     |  >>> ta = ta.write(1, 20)\n",
      "     |  >>> ta = ta.write(2, 30)\n",
      "     |  >>>\n",
      "     |  >>> ta.read(0)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=10.0>\n",
      "     |  >>> ta.read(1)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=20.0>\n",
      "     |  >>> ta.read(2)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=30.0>\n",
      "     |  >>> ta.stack()\n",
      "     |  <tf.Tensor: shape=(3,), dtype=float32, numpy=array([10., 20., 30.],\n",
      "     |  dtype=float32)>\n",
      "     |  \n",
      "     |  Example 2: Fibonacci sequence algorithm that writes in a loop then returns.\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def fibonacci(n):\n",
      "     |  ...   ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
      "     |  ...   ta = ta.unstack([0., 1.])\n",
      "     |  ...\n",
      "     |  ...   for i in range(2, n):\n",
      "     |  ...     ta = ta.write(i, ta.read(i - 1) + ta.read(i - 2))\n",
      "     |  ...\n",
      "     |  ...   return ta.stack()\n",
      "     |  >>>\n",
      "     |  >>> fibonacci(7)\n",
      "     |  <tf.Tensor: shape=(7,), dtype=float32,\n",
      "     |  numpy=array([0., 1., 1., 2., 3., 5., 8.], dtype=float32)>\n",
      "     |  \n",
      "     |  Example 3: A simple loop interacting with a `tf.Variable`.\n",
      "     |  \n",
      "     |  >>> v = tf.Variable(1)\n",
      "     |  >>> @tf.function\n",
      "     |  ... def f(x):\n",
      "     |  ...   ta = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
      "     |  ...   for i in tf.range(x):\n",
      "     |  ...     v.assign_add(i)\n",
      "     |  ...     ta = ta.write(i, v)\n",
      "     |  ...   return ta.stack()\n",
      "     |  >>> f(5)\n",
      "     |  <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 1,  2,  4,  7, 11],\n",
      "     |  dtype=int32)>\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, size=None, dynamic_size=None, clear_after_read=None, tensor_array_name=None, handle=None, flow=None, infer_shape=True, element_shape=None, colocate_with_first_write_call=True, name=None)\n",
      "     |      Construct a new TensorArray or wrap an existing TensorArray handle.\n",
      "     |      \n",
      "     |      A note about the parameter `name`:\n",
      "     |      \n",
      "     |      The name of the `TensorArray` (even if passed in) is uniquified: each time\n",
      "     |      a new `TensorArray` is created at runtime it is assigned its own name for\n",
      "     |      the duration of the run.  This avoids name collisions if a `TensorArray`\n",
      "     |      is created within a `while_loop`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: (required) data type of the TensorArray.\n",
      "     |        size: (optional) int32 scalar `Tensor`: the size of the TensorArray.\n",
      "     |          Required if handle is not provided.\n",
      "     |        dynamic_size: (optional) Python bool: If true, writes to the TensorArray\n",
      "     |          can grow the TensorArray past its initial size.  Default: False.\n",
      "     |        clear_after_read: Boolean (optional, default: True).  If True, clear\n",
      "     |          TensorArray values after reading them.  This disables read-many\n",
      "     |          semantics, but allows early release of memory.\n",
      "     |        tensor_array_name: (optional) Python string: the name of the TensorArray.\n",
      "     |          This is used when creating the TensorArray handle.  If this value is\n",
      "     |          set, handle should be None.\n",
      "     |        handle: (optional) A `Tensor` handle to an existing TensorArray.  If this\n",
      "     |          is set, tensor_array_name should be None. Only supported in graph mode.\n",
      "     |        flow: (optional) A float `Tensor` scalar coming from an existing\n",
      "     |          `TensorArray.flow`. Only supported in graph mode.\n",
      "     |        infer_shape: (optional, default: True) If True, shape inference is\n",
      "     |          enabled.  In this case, all elements must have the same shape.\n",
      "     |        element_shape: (optional, default: None) A `TensorShape` object specifying\n",
      "     |          the shape constraints of each of the elements of the TensorArray. Need\n",
      "     |          not be fully defined.\n",
      "     |        colocate_with_first_write_call: If `True`, the TensorArray will be\n",
      "     |          colocated on the same device as the Tensor used on its first write\n",
      "     |          (write operations include `write`, `unstack`, and `split`).  If `False`,\n",
      "     |          the TensorArray will be placed on the device determined by the device\n",
      "     |          context available during its initialization.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if both handle and tensor_array_name are provided.\n",
      "     |        TypeError: if handle is provided but is not a Tensor.\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, _)\n",
      "     |  \n",
      "     |  close(self, name=None)\n",
      "     |      Close the current TensorArray.\n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  concat(self, name=None)\n",
      "     |      Return the values in the TensorArray as a concatenated `Tensor`.\n",
      "     |      \n",
      "     |      All of the values must have been written, their ranks must match, and\n",
      "     |      and their shapes must all match for all dimensions except the first.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        All the tensors in the TensorArray concatenated into one tensor.\n",
      "     |  \n",
      "     |  gather(self, indices, name=None)\n",
      "     |      Return selected values in the TensorArray as a packed `Tensor`.\n",
      "     |      \n",
      "     |      All of selected values must have been written and their shapes\n",
      "     |      must all match.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `1-D` `Tensor` taking values in `[0, max_value)`.  If the\n",
      "     |          `TensorArray` is not dynamic, `max_value=size()`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensors in the `TensorArray` selected by `indices`, packed into one\n",
      "     |        tensor.\n",
      "     |  \n",
      "     |  grad(self, source, flow=None, name=None)\n",
      "     |  \n",
      "     |  identity(self)\n",
      "     |      Returns a TensorArray with the same content and properties.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the control dependencies\n",
      "     |        from the contexts will become control dependencies for writes, reads, etc.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |  \n",
      "     |  read(self, index, name=None)\n",
      "     |      Read the value at location `index` in the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: 0-D.  int32 tensor with the index to read from.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensor at index `index`.\n",
      "     |  \n",
      "     |  scatter(self, indices, value, name=None)\n",
      "     |      Scatter the values of a `Tensor` in specific indices of a `TensorArray`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `1-D` `Tensor` taking values in `[0, max_value)`.  If the\n",
      "     |          `TensorArray` is not dynamic, `max_value=size()`.\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to unpack.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the scatter occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Return the size of the TensorArray.\n",
      "     |  \n",
      "     |  split(self, value, lengths, name=None)\n",
      "     |      Split the values of a `Tensor` into the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to split.\n",
      "     |        lengths: 1-D.  int32 vector with the lengths to use when splitting `value`\n",
      "     |          along its first dimension.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the split occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  stack(self, name=None)\n",
      "     |      Return the values in the TensorArray as a stacked `Tensor`.\n",
      "     |      \n",
      "     |      All of the values must have been written and their shapes must all match.\n",
      "     |      If input shapes have rank-`R`, then output shape will have rank-`(R+1)`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      \n",
      "     |      >>> ta = tf.TensorArray(tf.int32, size=3)\n",
      "     |      >>> ta = ta.write(0, tf.constant([1, 2]))\n",
      "     |      >>> ta = ta.write(1, tf.constant([3, 4]))\n",
      "     |      >>> ta = ta.write(2, tf.constant([5, 6]))\n",
      "     |      >>> ta.stack()\n",
      "     |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4],\n",
      "     |             [5, 6]], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        All the tensors in the TensorArray stacked into one tensor.\n",
      "     |  \n",
      "     |  unstack(self, value, name=None)\n",
      "     |      Unstack the values of a `Tensor` in the TensorArray.\n",
      "     |      \n",
      "     |      If input value shapes have rank-`R`, then the output TensorArray will\n",
      "     |      contain elements whose shapes are rank-`(R-1)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to unstack.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the unstack occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  write(self, index, value, name=None)\n",
      "     |      Write `value` into index `index` of the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: 0-D.  int32 scalar with the index to write to.\n",
      "     |        value: N-D.  Tensor of type `dtype`.  The Tensor to write to this index.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the write occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if there are more writers than specified.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The data type of this TensorArray.\n",
      "     |  \n",
      "     |  dynamic_size\n",
      "     |      Python bool; if `True` the TensorArray can grow dynamically.\n",
      "     |  \n",
      "     |  element_shape\n",
      "     |      The `tf.TensorShape` of elements in this TensorArray.\n",
      "     |  \n",
      "     |  flow\n",
      "     |      The flow `Tensor` forcing ops leading to this TensorArray state.\n",
      "     |  \n",
      "     |  handle\n",
      "     |      The reference to the TensorArray.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TensorArraySpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  TensorArraySpec(element_shape=None, dtype=tf.float32, dynamic_size=False, infer_shape=True)\n",
      "     |  \n",
      "     |  Type specification for a `tf.TensorArray`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorArraySpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, element_shape=None, dtype=tf.float32, dynamic_size=False, infer_shape=True)\n",
      "     |      Constructs a type specification for a `tf.TensorArray`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        element_shape: The shape of each element in the `TensorArray`.\n",
      "     |        dtype: Data type of the `TensorArray`.\n",
      "     |        dynamic_size: Whether the `TensorArray` can grow past its initial size.\n",
      "     |        infer_shape: Whether shape inference is enabled.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other)\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others)\n",
      "     |      Returns the most specific supertype of `self` and `others`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A Sequence of `TypeSpec`.\n",
      "     |      \n",
      "     |      Returns `None` if a supertype does not exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_value(value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TensorInfo(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      TensorInfo\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CompositeTensor = <class 'tensorflow.core.protobuf.meta_graph_pb2.Comp...\n",
      "     |  \n",
      "     |  CooSparse = <class 'tensorflow.core.protobuf.meta_graph_pb2.CooSparse'...\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  TensorShape(dims)\n",
      "     |  \n",
      "     |  Represents the shape of a `Tensor`.\n",
      "     |  \n",
      "     |  >>> t = tf.constant([[1,2,3],[4,5,6]])\n",
      "     |  >>> t.shape\n",
      "     |  TensorShape([2, 3])\n",
      "     |  \n",
      "     |  `TensorShape` is the *static* shape representation of a Tensor.\n",
      "     |  During eager execution a Tensor always has a fully specified shape but\n",
      "     |  when tracing a `tf.function` it may be one of the following:\n",
      "     |  \n",
      "     |  * *Fully-known shape:* has a known number of dimensions and a known size\n",
      "     |    for each dimension. e.g. `TensorShape([16, 256])`\n",
      "     |  * *Partially-known shape:* has a known number of dimensions, and an unknown\n",
      "     |    size for one or more dimension. e.g. `TensorShape([None, 256])`\n",
      "     |  * *Unknown shape:* has an unknown number of dimensions, and an unknown\n",
      "     |    size in all dimensions. e.g. `TensorShape(None)`\n",
      "     |  \n",
      "     |  During function tracing `t.shape` will return a `TensorShape` object\n",
      "     |  representing the shape of Tensor as it is known during tracing.\n",
      "     |  This static representation will be partially defined in cases where the\n",
      "     |  exact shape depends on the values within the tensors. To get the\n",
      "     |  *dynamic* representation, please use `tf.shape(t)`\n",
      "     |  which will return Tensor representing the fully defined shape of `t`.\n",
      "     |  This way, you can express logic that manipulates the shapes of tensors by\n",
      "     |  building other tensors that depend on the dynamic shape of `t`.\n",
      "     |  \n",
      "     |  Note: `tf.RaggedTensor.shape` also returns a `tf.TensorShape`,\n",
      "     |  the lengths of any ragged dimensions are unknown (`None`).\n",
      "     |  \n",
      "     |  For example, this function prints the `TensorShape' (`t.shape`), when you\n",
      "     |  trace the function, and returns a tensor `tf.shape(t)` for given input `t`:\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def get_dynamic_shape(t):\n",
      "     |  ...   print(\"tracing...\")\n",
      "     |  ...   print(f\"static shape is {t.shape}\")\n",
      "     |  ...   return tf.shape(t)\n",
      "     |  \n",
      "     |  Just calling the function traces it with a fully-specified static shape:\n",
      "     |  \n",
      "     |  >>> result = get_dynamic_shape(tf.constant([[1, 1, 1], [0, 0, 0]]))\n",
      "     |  tracing...\n",
      "     |  static shape is (2, 3)\n",
      "     |  >>> result.numpy()\n",
      "     |  array([2, 3], dtype=int32)\n",
      "     |  \n",
      "     |  But `tf.function` can also trace the function with a partially specified\n",
      "     |  (or even unspecified) shape:\n",
      "     |  \n",
      "     |  >>> cf1 = get_dynamic_shape.get_concrete_function(tf.TensorSpec(\n",
      "     |  ...                                               shape=[None, 2]))\n",
      "     |  tracing...\n",
      "     |  static shape is (None, 2)\n",
      "     |  >>> cf1(tf.constant([[1., 0],[1, 0],[1, 0]])).numpy()\n",
      "     |  array([3, 2], dtype=int32)\n",
      "     |  \n",
      "     |  >>> cf2 = get_dynamic_shape.get_concrete_function(tf.TensorSpec(shape=None))\n",
      "     |  tracing...\n",
      "     |  static shape is <unknown>\n",
      "     |  >>> cf2(tf.constant([[[[[1., 0]]]]])).numpy()\n",
      "     |  array([1, 1, 1, 1, 2], dtype=int32)\n",
      "     |  \n",
      "     |  If a tensor is produced by an operation of type `\"Foo\"`, its shape\n",
      "     |  may be inferred if there is a registered shape function for\n",
      "     |  `\"Foo\"`. See [Shape\n",
      "     |  functions](https://www.tensorflow.org/guide/create_op#shape_functions_in_c)\n",
      "     |  for details of shape functions and how to register them. Alternatively,\n",
      "     |  you may set the shape explicitly using `tf.Tensor.ensure_shape`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorShape\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Returns True if this shape contains non-zero information.\n",
      "     |  \n",
      "     |  __concat__(self, other)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns True if `self` is equivalent to `other`.\n",
      "     |      \n",
      "     |      It first tries to convert `other` to `TensorShape`. `TypeError` is thrown\n",
      "     |      when the conversion fails. Otherwise, it compares each element in the\n",
      "     |      TensorShape dimensions.\n",
      "     |      \n",
      "     |      * Two *Fully known* shapes, return True iff each element is equal.\n",
      "     |      >>> t_a = tf.TensorShape([1,2])\n",
      "     |      >>> a = [1, 2]\n",
      "     |      >>> t_b = tf.TensorShape([1,2])\n",
      "     |      >>> t_c = tf.TensorShape([1,2,3])\n",
      "     |      >>> t_a.__eq__(a)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(t_b)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(t_c)\n",
      "     |      False\n",
      "     |      \n",
      "     |      * Two *Partially-known* shapes, return True iff each element is equal.\n",
      "     |      >>> p_a = tf.TensorShape([1,None])\n",
      "     |      >>> p_b = tf.TensorShape([1,None])\n",
      "     |      >>> p_c = tf.TensorShape([2,None])\n",
      "     |      >>> p_a.__eq__(p_b)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(p_a)\n",
      "     |      False\n",
      "     |      >>> p_a.__eq__(p_c)\n",
      "     |      False\n",
      "     |      \n",
      "     |      * Two *Unknown shape*, return True.\n",
      "     |      >>> unk_a = tf.TensorShape(None)\n",
      "     |      >>> unk_b = tf.TensorShape(None)\n",
      "     |      >>> unk_a.__eq__(unk_b)\n",
      "     |      True\n",
      "     |      >>> unk_a.__eq__(t_a)\n",
      "     |      False\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TensorShape` or type that can be converted to `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the dimensions are all equal.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError if `other` can not be converted to `TensorShape`.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Returns the value of a dimension or a shape, depending on the key.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        key: If `key` is an integer, returns the dimension at that index;\n",
      "     |          otherwise if `key` is a slice, returns a TensorShape whose dimensions\n",
      "     |          are those selected by the slice from `self`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An integer if `key` is an integer, or a `TensorShape` if `key` is a\n",
      "     |        slice.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `key` is a slice and `self` is completely unknown and\n",
      "     |          the step is set.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, dims)\n",
      "     |      Creates a new TensorShape with the given dimensions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dims: A list of Dimensions, or None if the shape is unspecified.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If dims cannot be converted to a list of dimensions.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Returns `self.dims` if the rank is known, otherwise raises ValueError.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Returns the rank of this shape, or raises ValueError if unspecified.\n",
      "     |  \n",
      "     |  __nonzero__ = __bool__(self)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  as_list(self)\n",
      "     |      Returns a list of integers or `None` for each dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of integers or `None` for each dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` is an unknown shape with an unknown rank.\n",
      "     |  \n",
      "     |  as_proto(self)\n",
      "     |      Returns this shape as a `TensorShapeProto`.\n",
      "     |  \n",
      "     |  assert_has_rank(self, rank)\n",
      "     |      Raises an exception if `self` is not compatible with the given `rank`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with the given `rank`.\n",
      "     |  \n",
      "     |  assert_is_compatible_with(self, other)\n",
      "     |      Raises exception if `self` and `other` do not represent the same shape.\n",
      "     |      \n",
      "     |      This method can be used to assert that there exists a shape that both\n",
      "     |      `self` and `other` represent.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another TensorShape.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` do not represent the same shape.\n",
      "     |  \n",
      "     |  assert_is_fully_defined(self)\n",
      "     |      Raises an exception if `self` is not fully defined in every dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not have a known value for every dimension.\n",
      "     |  \n",
      "     |  assert_same_rank(self, other)\n",
      "     |      Raises an exception if `self` and `other` do not have compatible ranks.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` do not represent shapes with the\n",
      "     |          same rank.\n",
      "     |  \n",
      "     |  cast(self, value, cast_context)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  concatenate(self, other)\n",
      "     |      Returns the concatenation of the dimension in `self` and `other`.\n",
      "     |      \n",
      "     |      *N.B.* If either `self` or `other` is completely unknown,\n",
      "     |      concatenation will discard information about the other shape. In\n",
      "     |      future, we might support concatenation that preserves this\n",
      "     |      information for use with slicing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` whose dimensions are the concatenation of the\n",
      "     |        dimensions in `self` and `other`.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto\n",
      "     |      Returns a proto representation of the TensorShape instance.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns True iff `self` is compatible with `other`.\n",
      "     |      \n",
      "     |      Two possibly-partially-defined shapes are compatible if there\n",
      "     |      exists a fully-defined shape that both shapes can represent. Thus,\n",
      "     |      compatibility allows the shape inference code to reason about\n",
      "     |      partially-defined shapes. For example:\n",
      "     |      \n",
      "     |      * TensorShape(None) is compatible with all shapes.\n",
      "     |      \n",
      "     |      * TensorShape([None, None]) is compatible with all two-dimensional\n",
      "     |        shapes, such as TensorShape([32, 784]), and also TensorShape(None). It is\n",
      "     |        not compatible with, for example, TensorShape([None]) or\n",
      "     |        TensorShape([None, None, None]).\n",
      "     |      \n",
      "     |      * TensorShape([32, None]) is compatible with all two-dimensional shapes\n",
      "     |        with size 32 in the 0th dimension, and also TensorShape([None, None])\n",
      "     |        and TensorShape(None). It is not compatible with, for example,\n",
      "     |        TensorShape([32]), TensorShape([32, None, 1]) or TensorShape([64, None]).\n",
      "     |      \n",
      "     |      * TensorShape([32, 784]) is compatible with itself, and also\n",
      "     |        TensorShape([32, None]), TensorShape([None, 784]), TensorShape([None,\n",
      "     |        None]) and TensorShape(None). It is not compatible with, for example,\n",
      "     |        TensorShape([32, 1, 784]) or TensorShape([None]).\n",
      "     |      \n",
      "     |      The compatibility relation is reflexive and symmetric, but not\n",
      "     |      transitive. For example, TensorShape([32, 784]) is compatible with\n",
      "     |      TensorShape(None), and TensorShape(None) is compatible with\n",
      "     |      TensorShape([4, 4]), but TensorShape([32, 784]) is not compatible with\n",
      "     |      TensorShape([4, 4]).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another TensorShape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True iff `self` is compatible with `other`.\n",
      "     |  \n",
      "     |  is_fully_defined(self)\n",
      "     |      Returns True iff `self` is fully defined in every dimension.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True iff `self` is subtype of `other`.\n",
      "     |      \n",
      "     |      Shape A is a subtype of shape B if shape B can successfully represent it:\n",
      "     |      \n",
      "     |      * A `TensorShape` of any rank is a subtype of `TensorShape(None)`.\n",
      "     |      \n",
      "     |      *  TensorShapes of equal ranks are covariant, i.e.\n",
      "     |        `TensorShape([A1, A2, ..])` is a subtype of\n",
      "     |        `TensorShape([B1, B2, ..])` iff An is a subtype of Bn.\n",
      "     |      \n",
      "     |        An is subtype of Bn iff An == Bn or Bn is None.\n",
      "     |      \n",
      "     |      * TensorShapes of different defined ranks have no subtyping relation.\n",
      "     |      \n",
      "     |      The subtyping relation is reflexive and transitive, but not symmetric.\n",
      "     |      \n",
      "     |      Some examples:\n",
      "     |      * `TensorShape([32, 784])` is a subtype of `TensorShape(None)`, and\n",
      "     |        `TensorShape([4, 4])` is also a subtype of `TensorShape(None)` but\n",
      "     |        `TensorShape([32, 784])` and `TensorShape([4, 4])` are not subtypes of\n",
      "     |        each other.\n",
      "     |      \n",
      "     |      * All two-dimensional shapes are subtypes of `TensorShape([None, None])`,\n",
      "     |        such as `TensorShape([32, 784])`. There is no subtype relationship with,\n",
      "     |        for example, `TensorShape([None])` or `TensorShape([None, None, None])`.\n",
      "     |      \n",
      "     |      * `TensorShape([32, None])` is also a subtype of `TensorShape([None, None])`\n",
      "     |        and `TensorShape(None)`. It is not a subtype of, for example,\n",
      "     |        `TensorShape([32])`, `TensorShape([32, None, 1])`,\n",
      "     |        `TensorShape([64, None])` or `TensorShape([None, 32])`.\n",
      "     |      \n",
      "     |      * `TensorShape([32, 784])` is a subtype of itself, and also\n",
      "     |        `TensorShape([32, None])`, `TensorShape([None, 784])`,\n",
      "     |        `TensorShape([None, None])` and `TensorShape(None)`.\n",
      "     |        It has no subtype relation with, for example, `TensorShape([32, 1, 784])`\n",
      "     |        or `TensorShape([None])`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True iff `self` is subtype of `other`.\n",
      "     |  \n",
      "     |  merge_with(self, other)\n",
      "     |      Returns a `TensorShape` combining the information in `self` and `other`.\n",
      "     |      \n",
      "     |      The dimensions in `self` and `other` are merged element-wise,\n",
      "     |      according to the rules below:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      Dimension(n).merge_with(Dimension(None)) == Dimension(n)\n",
      "     |      Dimension(None).merge_with(Dimension(n)) == Dimension(n)\n",
      "     |      Dimension(None).merge_with(Dimension(None)) == Dimension(None)\n",
      "     |      # raises ValueError for n != m\n",
      "     |      Dimension(n).merge_with(Dimension(m))\n",
      "     |      ```\n",
      "     |      >> ts = tf.TensorShape([1,2])\n",
      "     |      >> ot1 = tf.TensorShape([1,2])\n",
      "     |      >> ts.merge_with(ot).as_list()\n",
      "     |      [1,2]\n",
      "     |      \n",
      "     |      >> ot2 = tf.TensorShape([1,None])\n",
      "     |      >> ts.merge_with(ot2).as_list()\n",
      "     |      [1,2]\n",
      "     |      \n",
      "     |      >> ot3 = tf.TensorShape([None, None])\n",
      "     |      >> ot3.merge_with(ot2).as_list()\n",
      "     |      [1, None]\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the combined information of `self` and\n",
      "     |        `other`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TensorShape')]\n",
      "     |      Returns the most specific supertype `TensorShape` of self and others.\n",
      "     |      \n",
      "     |      * `TensorShape([None, 1])` is the most specific `TensorShape` supertyping\n",
      "     |        both `TensorShape([2, 1])` and `TensorShape([5, 1])`. Note that\n",
      "     |        `TensorShape(None)` is also a supertype but it is not \"most specific\".\n",
      "     |      \n",
      "     |      * `TensorShape([1, 2, 3])` is the most specific `TensorShape` supertyping\n",
      "     |        both `TensorShape([1, 2, 3])` and `TensorShape([1, 2, 3]`). There are\n",
      "     |        other less specific TensorShapes that supertype above mentioned\n",
      "     |        TensorShapes, e.g. `TensorShape([1, 2, None])`, `TensorShape(None)`.\n",
      "     |      \n",
      "     |       * `TensorShape([None, None])` is the most specific `TensorShape`\n",
      "     |         supertyping both `TensorShape([2, None])` and `TensorShape([None, 3])`.\n",
      "     |         As always, `TensorShape(None)` is also a supertype but not the most\n",
      "     |         specific one.\n",
      "     |      \n",
      "     |       * `TensorShape(None`) is the only `TensorShape` supertyping both\n",
      "     |         `TensorShape([1, 2, 3])` and `TensorShape([1, 2])`. In general, any two\n",
      "     |         shapes that have different ranks will only have `TensorShape(None)`\n",
      "     |         as a common supertype.\n",
      "     |      \n",
      "     |       * `TensorShape(None)` is the only `TensorShape` supertyping both\n",
      "     |         `TensorShape([1, 2, 3])` and `TensorShape(None)`. In general, the common\n",
      "     |         supertype of any shape with `TensorShape(None)` is `TensorShape(None)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: Sequence of `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` which is the most specific supertype shape of `self`\n",
      "     |        and `others`. None if it does not exist.\n",
      "     |  \n",
      "     |  most_specific_compatible_shape(self, other) -> 'TensorShape'\n",
      "     |      Returns the most specific TensorShape compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      * TensorShape([None, 1]) is the most specific TensorShape compatible with\n",
      "     |        both TensorShape([2, 1]) and TensorShape([5, 1]). Note that\n",
      "     |        TensorShape(None) is also compatible with above mentioned TensorShapes.\n",
      "     |      \n",
      "     |      * TensorShape([1, 2, 3]) is the most specific TensorShape compatible with\n",
      "     |        both TensorShape([1, 2, 3]) and TensorShape([1, 2, 3]). There are more\n",
      "     |        less specific TensorShapes compatible with above mentioned TensorShapes,\n",
      "     |        e.g. TensorShape([1, 2, None]), TensorShape(None).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` which is the most specific compatible shape of `self`\n",
      "     |        and `other`.\n",
      "     |  \n",
      "     |  num_elements(self)\n",
      "     |      Returns the total number of elements, or none for incomplete shapes.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  with_rank(self, rank)\n",
      "     |      Returns a shape based on `self` with the given rank.\n",
      "     |      \n",
      "     |      This method promotes a completely unknown shape to one with a\n",
      "     |      known rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with the given rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with the given `rank`.\n",
      "     |  \n",
      "     |  with_rank_at_least(self, rank)\n",
      "     |      Returns a shape based on `self` with at least the given rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with at least the given\n",
      "     |        rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with at least the given\n",
      "     |          `rank`.\n",
      "     |  \n",
      "     |  with_rank_at_most(self, rank)\n",
      "     |      Returns a shape based on `self` with at most the given rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with at most the given\n",
      "     |        rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with at most the given\n",
      "     |          `rank`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto) -> 'TensorShape' from abc.ABCMeta\n",
      "     |      Returns a TensorShape instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TensorShape serialization.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dims\n",
      "     |      Deprecated.  Returns list of dimensions for this shape.\n",
      "     |      \n",
      "     |      Suggest `TensorShape.as_list` instead.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list containing `tf.compat.v1.Dimension`s, or None if the shape is\n",
      "     |        unspecified.\n",
      "     |  \n",
      "     |  ndims\n",
      "     |      Deprecated accessor for `rank`.\n",
      "     |  \n",
      "     |  rank\n",
      "     |      Returns the rank of this shape, or None if it is unspecified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.trace.TraceType:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TensorSpec(DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "     |  TensorSpec(shape, dtype=tf.float32, name=None)\n",
      "     |  \n",
      "     |  Describes the type of a tf.Tensor.\n",
      "     |  \n",
      "     |  >>> t = tf.constant([[1,2,3],[4,5,6]])\n",
      "     |  >>> tf.TensorSpec.from_tensor(t)\n",
      "     |  TensorSpec(shape=(2, 3), dtype=tf.int32, name=None)\n",
      "     |  \n",
      "     |  Contains metadata for describing the nature of `tf.Tensor` objects\n",
      "     |  accepted or returned by some TensorFlow APIs.\n",
      "     |  \n",
      "     |  For example, it can be used to constrain the type of inputs accepted by\n",
      "     |  a tf.function:\n",
      "     |  \n",
      "     |  >>> @tf.function(input_signature=[tf.TensorSpec([1, None])])\n",
      "     |  ... def constrained_foo(t):\n",
      "     |  ...   print(\"tracing...\")\n",
      "     |  ...   return t\n",
      "     |  \n",
      "     |  Now the `tf.function` is able to assume that `t` is always of the type\n",
      "     |  `tf.TensorSpec([1, None])` which will avoid retracing as well as enforce the\n",
      "     |  type restriction on inputs.\n",
      "     |  \n",
      "     |  As a result, the following call with tensor of type `tf.TensorSpec([1, 2])`\n",
      "     |  triggers a trace and succeeds:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2]])).numpy()\n",
      "     |  tracing...\n",
      "     |  array([[1., 2.]], dtype=float32)\n",
      "     |  \n",
      "     |  The following subsequent call with tensor of type `tf.TensorSpec([1, 4])`\n",
      "     |  does not trigger a trace and succeeds:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2, 3, 4]])).numpy()\n",
      "     |  array([[1., 2., 3., 4.], dtype=float32)\n",
      "     |  \n",
      "     |  But the following call with tensor of type `tf.TensorSpec([2, 2])` fails:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2], [3, 4]])).numpy()\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: Binding inputs to tf.function `constrained_foo` failed ...\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorSpec\n",
      "     |      DenseSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      tensorflow.python.types.internal.TensorSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      Cast value to a tensor that is a subtype of this TensorSpec.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TensorSpecProto\n",
      "     |      Returns a proto representation of the TensorSpec instance.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_tensor)\n",
      "     |      Returns True if spec_or_tensor is compatible with this TensorSpec.\n",
      "     |      \n",
      "     |      Two tensors are considered compatible if they have the same dtype\n",
      "     |      and their shapes are compatible (see `tf.TensorShape.is_compatible_with`).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_tensor: A tf.TensorSpec or a tf.Tensor\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if spec_or_tensor is compatible with self.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other)\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Generates a graph placholder with the given TensorSpec information.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TensorSpecProto) -> 'TensorSpec' from abc.ABCMeta\n",
      "     |      Returns a TensorSpec instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TensorSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TensorSpec serialization.\n",
      "     |  \n",
      "     |  from_spec(spec, name=None) from abc.ABCMeta\n",
      "     |      Returns a `TensorSpec` with the same shape and dtype as `spec`.\n",
      "     |      \n",
      "     |      >>> spec = tf.TensorSpec(shape=[8, 3], dtype=tf.int32, name=\"OriginalName\")\n",
      "     |      >>> tf.TensorSpec.from_spec(spec, \"NewName\")\n",
      "     |      TensorSpec(shape=(8, 3), dtype=tf.int32, name='NewName')\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: The `TypeSpec` used to create the new `TensorSpec`.\n",
      "     |        name: The name for the new `TensorSpec`.  Defaults to `spec.name`.\n",
      "     |  \n",
      "     |  from_tensor(tensor, name=None) from abc.ABCMeta\n",
      "     |      Returns a `TensorSpec` that describes `tensor`.\n",
      "     |      \n",
      "     |      >>> tf.TensorSpec.from_tensor(tf.constant([1, 2, 3]))\n",
      "     |      TensorSpec(shape=(3,), dtype=tf.int32, name=None)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: The `tf.Tensor` that should be described.\n",
      "     |        name: A name for the `TensorSpec`.  Defaults to `tensor.op.name`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorSpec` that describes `tensor`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, shape, dtype=tf.float32, name=None)\n",
      "     |      Creates a TensorSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Value convertible to `tf.TensorShape`. The shape of the tensor.\n",
      "     |        dtype: Value convertible to `tf.DType`. The type of the tensor values.\n",
      "     |        name: Optional name for the Tensor.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If shape is not convertible to a `tf.TensorShape`, or dtype is\n",
      "     |          not convertible to a `tf.DType`.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from DenseSpec:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Returns the `dtype` of elements in the tensor.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the (optionally provided) name of the described tensor.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns the `TensorShape` that represents the shape of the tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TextLineReader(ReaderBase)\n",
      "     |  TextLineReader(skip_header_lines=None, name=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the lines of a file delimited by newlines.\n",
      "     |  \n",
      "     |  Newlines are stripped from the output.\n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TextLineReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, skip_header_lines=None, name=None)\n",
      "     |      Create a TextLineReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        skip_header_lines: An optional int. Defaults to 0.  Number of lines\n",
      "     |          to skip from the beginning of every file.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  Specifies a TensorFlow value type.\n",
      "     |  \n",
      "     |  A `tf.TypeSpec` provides metadata describing an object accepted or returned\n",
      "     |  by TensorFlow APIs.  Concrete subclasses, such as `tf.TensorSpec` and\n",
      "     |  `tf.RaggedTensorSpec`, are used to describe different value types.\n",
      "     |  \n",
      "     |  For example, `tf.function`'s `input_signature` argument accepts a list\n",
      "     |  (or nested structure) of `TypeSpec`s.\n",
      "     |  \n",
      "     |  Creating new subclasses of `TypeSpec` (outside of TensorFlow core) is not\n",
      "     |  currently supported.  In particular, we may make breaking changes to the\n",
      "     |  private methods and properties defined by this base class.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  >>> spec = tf.TensorSpec(shape=[None, None], dtype=tf.int32)\n",
      "     |  >>> @tf.function(input_signature=[spec])\n",
      "     |  ... def double(x):\n",
      "     |  ...   return x * 2\n",
      "     |  >>> double(tf.constant([[1, 2], [3, 4]]))\n",
      "     |  <tf.Tensor: shape=(2, 2), dtype=int32,\n",
      "     |      numpy=array([[2, 4], [6, 8]], dtype=int32)>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'_component_specs', '_from_components...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class UnconnectedGradients(enum.Enum)\n",
      "     |  UnconnectedGradients(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)\n",
      "     |  \n",
      "     |  Controls how gradient computation behaves when y does not depend on x.\n",
      "     |  \n",
      "     |  The gradient of y with respect to x can be zero in two different ways: there\n",
      "     |  could be no differentiable path in the graph connecting x to y (and so we can\n",
      "     |  statically prove that the gradient is zero) or it could be that runtime values\n",
      "     |  of tensors in a particular execution lead to a gradient of zero (say, if a\n",
      "     |  relu unit happens to not be activated). To allow you to distinguish between\n",
      "     |  these two cases you can choose what value gets returned for the gradient when\n",
      "     |  there is no path in the graph from x to y:\n",
      "     |  \n",
      "     |  * `NONE`: Indicates that [None] will be returned if there is no path from x\n",
      "     |    to y\n",
      "     |  * `ZERO`: Indicates that a zero tensor will be returned in the shape of x.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnconnectedGradients\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  NONE = <UnconnectedGradients.NONE: 'none'>\n",
      "     |  \n",
      "     |  ZERO = <UnconnectedGradients.ZERO: 'zero'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __contains__(member) from enum.EnumType\n",
      "     |      Return True if member is a member of this enum\n",
      "     |      raises TypeError if member is not an enum member\n",
      "     |      \n",
      "     |      note: in 3.12 TypeError will no longer be raised, and True will also be\n",
      "     |      returned if member is the value of a member in this enum\n",
      "     |  \n",
      "     |  __getitem__(name) from enum.EnumType\n",
      "     |      Return the member matching `name`.\n",
      "     |  \n",
      "     |  __iter__() from enum.EnumType\n",
      "     |      Return members in definition order.\n",
      "     |  \n",
      "     |  __len__() from enum.EnumType\n",
      "     |      Return the number of members (no aliases)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class VarLenFeature(VarLenFeature)\n",
      "     |  VarLenFeature(dtype)\n",
      "     |  \n",
      "     |  Configuration for parsing a variable-length input feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    dtype: Data type of input.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VarLenFeature\n",
      "     |      VarLenFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.VarLenFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['VarLenFeature', 'io.VarLenFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new VarLenFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new VarLenFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  __new__(_cls, dtype)\n",
      "     |      Create new instance of VarLenFeature(dtype,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  __match_args__ = ('dtype',)\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('dtype',)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    Variable = class VariableV1(tensorflow.python.ops.variables.Variable)\n",
      "     |  Variable(*args, **kwargs)\n",
      "     |  \n",
      "     |  See the [Variables Guide](https://tensorflow.org/guide/variables).\n",
      "     |  \n",
      "     |  A variable maintains state in the graph across calls to `run()`. You add a\n",
      "     |  variable to the graph by constructing an instance of the class `Variable`.\n",
      "     |  \n",
      "     |  The `Variable()` constructor requires an initial value for the variable,\n",
      "     |  which can be a `Tensor` of any type and shape. The initial value defines the\n",
      "     |  type and shape of the variable. After construction, the type and shape of\n",
      "     |  the variable are fixed. The value can be changed using one of the assign\n",
      "     |  methods.\n",
      "     |  \n",
      "     |  If you want to change the shape of a variable later you have to use an\n",
      "     |  `assign` Op with `validate_shape=False`.\n",
      "     |  \n",
      "     |  Just like any `Tensor`, variables created with `Variable()` can be used as\n",
      "     |  inputs for other Ops in the graph. Additionally, all the operators\n",
      "     |  overloaded for the `Tensor` class are carried over to variables, so you can\n",
      "     |  also add nodes to the graph by just doing arithmetic on variables.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  import tensorflow as tf\n",
      "     |  \n",
      "     |  # Create a variable.\n",
      "     |  w = tf.Variable(<initial-value>, name=<optional-name>)\n",
      "     |  \n",
      "     |  # Use the variable in the graph like any Tensor.\n",
      "     |  y = tf.matmul(w, ...another variable or tensor...)\n",
      "     |  \n",
      "     |  # The overloaded operators are available too.\n",
      "     |  z = tf.sigmoid(w + y)\n",
      "     |  \n",
      "     |  # Assign a new value to the variable with `assign()` or a related method.\n",
      "     |  w.assign(w + 1.0)\n",
      "     |  w.assign_add(1.0)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  When you launch the graph, variables have to be explicitly initialized before\n",
      "     |  you can run Ops that use their value. You can initialize a variable by\n",
      "     |  running its *initializer op*, restoring the variable from a save file, or\n",
      "     |  simply running an `assign` Op that assigns a value to the variable. In fact,\n",
      "     |  the variable *initializer op* is just an `assign` Op that assigns the\n",
      "     |  variable's initial value to the variable itself.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Launch the graph in a session.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |      # Run the variable initializer.\n",
      "     |      sess.run(w.initializer)\n",
      "     |      # ...you now can run ops that use the value of 'w'...\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The most common initialization pattern is to use the convenience function\n",
      "     |  `global_variables_initializer()` to add an Op to the graph that initializes\n",
      "     |  all the variables. You then run that Op after launching the graph.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Add an Op to initialize global variables.\n",
      "     |  init_op = tf.compat.v1.global_variables_initializer()\n",
      "     |  \n",
      "     |  # Launch the graph in a session.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |      # Run the Op that initializes global variables.\n",
      "     |      sess.run(init_op)\n",
      "     |      # ...you can now run any Op that uses variable values...\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If you need to create a variable with an initial value dependent on another\n",
      "     |  variable, use the other variable's `initialized_value()`. This ensures that\n",
      "     |  variables are initialized in the right order.\n",
      "     |  \n",
      "     |  All variables are automatically collected in the graph where they are\n",
      "     |  created. By default, the constructor adds the new variable to the graph\n",
      "     |  collection `GraphKeys.GLOBAL_VARIABLES`. The convenience function\n",
      "     |  `global_variables()` returns the contents of that collection.\n",
      "     |  \n",
      "     |  When building a machine learning model it is often convenient to distinguish\n",
      "     |  between variables holding the trainable model parameters and other variables\n",
      "     |  such as a `global step` variable used to count training steps. To make this\n",
      "     |  easier, the variable constructor supports a `trainable=<bool>` parameter. If\n",
      "     |  `True`, the new variable is also added to the graph collection\n",
      "     |  `GraphKeys.TRAINABLE_VARIABLES`. The convenience function\n",
      "     |  `trainable_variables()` returns the contents of this collection. The\n",
      "     |  various `Optimizer` classes use this collection as the default list of\n",
      "     |  variables to optimize.\n",
      "     |  \n",
      "     |  WARNING: tf.Variable objects by default have a non-intuitive memory model. A\n",
      "     |  Variable is represented internally as a mutable Tensor which can\n",
      "     |  non-deterministically alias other Tensors in a graph. The set of operations\n",
      "     |  which consume a Variable and can lead to aliasing is undetermined and can\n",
      "     |  change across TensorFlow versions. Avoid writing code which relies on the\n",
      "     |  value of a Variable either changing or not changing as other operations\n",
      "     |  happen. For example, using Variable objects or simple functions thereof as\n",
      "     |  predicates in a `tf.cond` is dangerous and error-prone:\n",
      "     |  \n",
      "     |  ```\n",
      "     |  v = tf.Variable(True)\n",
      "     |  tf.cond(v, lambda: v.assign(False), my_false_fn)  # Note: this is broken.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Here, adding `use_resource=True` when constructing the variable will\n",
      "     |  fix any nondeterminism issues:\n",
      "     |  ```\n",
      "     |  v = tf.Variable(True, use_resource=True)\n",
      "     |  tf.cond(v, lambda: v.assign(False), my_false_fn)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  To use the replacement for variables which does\n",
      "     |  not have these issues:\n",
      "     |  \n",
      "     |  * Add `use_resource=True` when constructing `tf.Variable`;\n",
      "     |  * Call `tf.compat.v1.get_variable_scope().set_use_resource(True)` inside a\n",
      "     |    `tf.compat.v1.variable_scope` before the `tf.compat.v1.get_variable()` call.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableV1\n",
      "     |      tensorflow.python.ops.variables.Variable\n",
      "     |      tensorflow.python.trackable.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, initial_value=None, trainable=None, collections=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, expected_shape=None, import_scope=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, shape=None)\n",
      "     |      Creates a new variable with value `initial_value`.\n",
      "     |      \n",
      "     |      The new variable is added to the graph collections listed in `collections`,\n",
      "     |      which defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "     |      \n",
      "     |      If `trainable` is `True` the variable is also added to the graph collection\n",
      "     |      `GraphKeys.TRAINABLE_VARIABLES`.\n",
      "     |      \n",
      "     |      This constructor creates both a `variable` Op and an `assign` Op to set the\n",
      "     |      variable to its initial value.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
      "     |          which is the initial value for the Variable. The initial value must have\n",
      "     |          a shape specified unless `validate_shape` is set to False. Can also be a\n",
      "     |          callable with no argument that returns the initial value when called. In\n",
      "     |          that case, `dtype` must be specified. (Note that initializer functions\n",
      "     |          from init_ops.py must first be bound to a shape before being used here.)\n",
      "     |        trainable: If `True`, also adds the variable to the graph collection\n",
      "     |          `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as the default\n",
      "     |          list of variables to use by the `Optimizer` classes. Defaults to `True`,\n",
      "     |          unless `synchronization` is set to `ON_READ`, in which case it defaults\n",
      "     |          to `False`.\n",
      "     |        collections: List of graph collections keys. The new variable is added to\n",
      "     |          these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "     |        validate_shape: If `False`, allows the variable to be initialized with a\n",
      "     |          value of unknown shape. If `True`, the default, the shape of\n",
      "     |          `initial_value` must be known.\n",
      "     |        caching_device: Optional device string describing where the Variable\n",
      "     |          should be cached for reading.  Defaults to the Variable's device. If not\n",
      "     |          `None`, caches on another device.  Typical use is to cache on the device\n",
      "     |          where the Ops using the Variable reside, to deduplicate copying through\n",
      "     |          `Switch` and other conditional statements.\n",
      "     |        name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
      "     |          uniquified automatically.\n",
      "     |        variable_def: `VariableDef` protocol buffer. If not `None`, recreates the\n",
      "     |          Variable object with its contents, referencing the variable's nodes in\n",
      "     |          the graph, which must already exist. The graph is not changed.\n",
      "     |          `variable_def` and the other arguments are mutually exclusive.\n",
      "     |        dtype: If set, initial_value will be converted to the given type. If\n",
      "     |          `None`, either the datatype will be kept (if `initial_value` is a\n",
      "     |          Tensor), or `convert_to_tensor` will decide.\n",
      "     |        expected_shape: A TensorShape. If set, initial_value is expected to have\n",
      "     |          this shape.\n",
      "     |        import_scope: Optional `string`. Name scope to add to the `Variable.` Only\n",
      "     |          used when initializing from protocol buffer.\n",
      "     |        constraint: An optional projection function to be applied to the variable\n",
      "     |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |          constraints or value constraints for layer weights). The function must\n",
      "     |          take as input the unprojected Tensor representing the value of the\n",
      "     |          variable and return the Tensor for the projected value (which must have\n",
      "     |          the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |          distributed training.\n",
      "     |        use_resource: whether to use resource variables.\n",
      "     |        synchronization: Indicates when a distributed a variable will be\n",
      "     |          aggregated. Accepted values are constants defined in the class\n",
      "     |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "     |          `AUTO` and the current `DistributionStrategy` chooses when to\n",
      "     |          synchronize.\n",
      "     |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      "     |          Accepted values are constants defined in the class\n",
      "     |          `tf.VariableAggregation`.\n",
      "     |        shape: (optional) The shape of this variable. If None, the shape of\n",
      "     |          `initial_value` will be used. When setting this argument to\n",
      "     |          `tf.TensorShape(None)` (representing an unspecified shape), the variable\n",
      "     |          can be assigned with values of different shapes.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If both `variable_def` and initial_value are specified.\n",
      "     |        ValueError: If the initial value is not specified, or does not have a\n",
      "     |          shape and `validate_shape` is `True`.\n",
      "     |        RuntimeError: If eager execution is enabled.\n",
      "     |  \n",
      "     |  initialized_value(self)\n",
      "     |      Returns the value of the initialized variable. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "     |      \n",
      "     |      You should use this instead of the variable itself to initialize another\n",
      "     |      variable with a value that depends on the value of this variable.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # Initialize 'v' with a random tensor.\n",
      "     |      v = tf.Variable(tf.random.truncated_normal([10, 40]))\n",
      "     |      # Use `initialized_value` to guarantee that `v` has been\n",
      "     |      # initialized before its value is used to initialize `w`.\n",
      "     |      # The random values are picked only once.\n",
      "     |      w = tf.Variable(v.initialized_value() * 2.0)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` holding the value of this variable after its initializer\n",
      "     |        has run.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_proto(variable_def, import_scope=None)\n",
      "     |      Returns a `Variable` object created from `variable_def`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  SaveSliceInfo = <class 'tensorflow.python.ops.variables.Variable.SaveS...\n",
      "     |      Information on how to save this Variable as a slice.\n",
      "     |      \n",
      "     |      Provides internal support for saving variables as slices of a larger\n",
      "     |      variable.  This API is not public and is subject to change.\n",
      "     |      \n",
      "     |      Available properties:\n",
      "     |      \n",
      "     |      * full_name\n",
      "     |      * full_shape\n",
      "     |      * var_offset\n",
      "     |      * var_shape\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.ops.variables.Variable:\n",
      "     |  \n",
      "     |  __abs__ = _abs_factory(x, name=None)\n",
      "     |  \n",
      "     |  __add__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __and__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Compares two variables element-wise for equality.\n",
      "     |  \n",
      "     |  __floordiv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x: typing.Annotated[_any, ~TV_GreaterEqual_T], y: typing.Annotated[_any, ~TV_GreaterEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      y = tf.constant([5, 2, 5, 10])\n",
      "     |      tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getitem__ = _slice_helper_var(var, slice_spec)\n",
      "     |      Creates a slice helper object given a variable.\n",
      "     |      \n",
      "     |      This allows creating a sub-tensor from part of the current contents\n",
      "     |      of a variable. See `tf.Tensor.__getitem__` for detailed examples\n",
      "     |      of slicing.\n",
      "     |      \n",
      "     |      This function in addition also allows assignment to a sliced range.\n",
      "     |      This is similar to `__setitem__` functionality in Python. However,\n",
      "     |      the syntax is different so that the user can capture the assignment\n",
      "     |      operation for grouping or passing to `sess.run()` in TF1.\n",
      "     |      For example,\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      import tensorflow as tf\n",
      "     |      A = tf.Variable([[1,2,3], [4,5,6], [7,8,9]], dtype=tf.float32)\n",
      "     |      print(A[:2, :2])  # => [[1,2], [4,5]]\n",
      "     |      \n",
      "     |      A[:2,:2].assign(22. * tf.ones((2, 2))))\n",
      "     |      print(A) # => [[22, 22, 3], [22, 22, 6], [7,8,9]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Note that assignments currently do not support NumPy broadcasting\n",
      "     |      semantics.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        var: An `ops.Variable` object.\n",
      "     |        slice_spec: The arguments to `Tensor.__getitem__`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
      "     |        As an operator. The operator also has a `assign()` method\n",
      "     |        that can be used to generate an assignment operator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If a slice range is negative size.\n",
      "     |        TypeError: TypeError: If the slice indices aren't int, slice,\n",
      "     |          ellipsis, tf.newaxis or int32/int64 tensors.\n",
      "     |  \n",
      "     |  __gt__ = greater(x: typing.Annotated[_any, ~TV_Greater_T], y: typing.Annotated[_any, ~TV_Greater_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__ = _invert_factory(x, name=None)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      When executing eagerly, iterates over the value of the variable.\n",
      "     |  \n",
      "     |  __le__ = less_equal(x: typing.Annotated[_any, ~TV_LessEqual_T], y: typing.Annotated[_any, ~TV_LessEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __lt__ = less(x: typing.Annotated[_any, ~TV_Less_T], y: typing.Annotated[_any, ~TV_Less_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __matmul__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __mod__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Compares two variables element-wise for equality.\n",
      "     |  \n",
      "     |  __neg__ = neg(x: typing.Annotated[_any, ~TV_Neg_T], name=None) -> typing.Annotated[_any, ~TV_Neg_T]\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __or__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __pow__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __radd__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rand__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmod__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmul__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __ror__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rpow__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rsub__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rxor__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __sub__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __xor__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  assign(self, value, use_locking=False, name=None, read_value=True)\n",
      "     |      Assigns a new value to the variable.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `assign(self, value)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: A `Tensor`. The new value for this variable.\n",
      "     |        use_locking: If `True`, use locking during the assignment.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  assign_add(self, delta, use_locking=False, name=None, read_value=True)\n",
      "     |      Adds a value to this variable.\n",
      "     |      \n",
      "     |       This is essentially a shortcut for `assign_add(self, delta)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        delta: A `Tensor`. The value to add to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  assign_sub(self, delta, use_locking=False, name=None, read_value=True)\n",
      "     |      Subtracts a value from this variable.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `assign_sub(self, delta)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        delta: A `Tensor`. The value to subtract from this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  batch_scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Assigns `tf.IndexedSlices` to this variable batch-wise.\n",
      "     |      \n",
      "     |      Analogous to `batch_gather`. This assumes that this variable and the\n",
      "     |      sparse_delta IndexedSlices have a series of leading dimensions that are the\n",
      "     |      same for all of them, and the updates are performed on the last dimension of\n",
      "     |      indices. In other words, the dimensions should be the following:\n",
      "     |      \n",
      "     |      `num_prefix_dims = sparse_delta.indices.ndims - 1`\n",
      "     |      `batch_dim = num_prefix_dims + 1`\n",
      "     |      `sparse_delta.updates.shape = sparse_delta.indices.shape + var.shape[\n",
      "     |           batch_dim:]`\n",
      "     |      \n",
      "     |      where\n",
      "     |      \n",
      "     |      `sparse_delta.updates.shape[:num_prefix_dims]`\n",
      "     |      `== sparse_delta.indices.shape[:num_prefix_dims]`\n",
      "     |      `== var.shape[:num_prefix_dims]`\n",
      "     |      \n",
      "     |      And the operation performed can be expressed as:\n",
      "     |      \n",
      "     |      `var[i_1, ..., i_n,\n",
      "     |           sparse_delta.indices[i_1, ..., i_n, j]] = sparse_delta.updates[\n",
      "     |              i_1, ..., i_n, j]`\n",
      "     |      \n",
      "     |      When sparse_delta.indices is a 1D tensor, this operation is equivalent to\n",
      "     |      `scatter_update`.\n",
      "     |      \n",
      "     |      To avoid this operation one can looping over the first `ndims` of the\n",
      "     |      variable and using `scatter_update` on the subtensors that result of slicing\n",
      "     |      the first dimension. This is a valid option for `ndims = 1`, but less\n",
      "     |      efficient than this implementation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  count_up_to(self, limit)\n",
      "     |      Increments this variable until it reaches `limit`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Prefer Dataset.range instead.\n",
      "     |      \n",
      "     |      When that Op is run it tries to increment the variable by `1`. If\n",
      "     |      incrementing the variable would bring it above `limit` then the Op raises\n",
      "     |      the exception `OutOfRangeError`.\n",
      "     |      \n",
      "     |      If no error is raised, the Op outputs the value of the variable before\n",
      "     |      the increment.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `count_up_to(self, limit)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        limit: value at which incrementing the variable raises an error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the variable value before the increment. If no\n",
      "     |        other Op modifies this variable, the values produced will all be\n",
      "     |        distinct.\n",
      "     |  \n",
      "     |  eval(self, session=None)\n",
      "     |      In a session, computes and returns the value of this variable.\n",
      "     |      \n",
      "     |      This is not a graph construction method, it does not add ops to the graph.\n",
      "     |      \n",
      "     |      This convenience method requires a session where the graph\n",
      "     |      containing this variable has been launched. If no session is\n",
      "     |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
      "     |      information on launching a graph and on sessions.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      v = tf.Variable([1, 2])\n",
      "     |      init = tf.compat.v1.global_variables_initializer()\n",
      "     |      \n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |          sess.run(init)\n",
      "     |          # Usage passing the session explicitly.\n",
      "     |          print(v.eval(sess))\n",
      "     |          # Usage with the default session.  The 'with' block\n",
      "     |          # above makes 'sess' the default session.\n",
      "     |          print(v.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        session: The session to use to evaluate this variable. If none, the\n",
      "     |          default session is used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy `ndarray` with a copy of the value of this variable.\n",
      "     |  \n",
      "     |  experimental_ref(self)\n",
      "     |      DEPRECATED FUNCTION\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use ref() instead.\n",
      "     |  \n",
      "     |  gather_nd(self, indices, name=None)\n",
      "     |      Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
      "     |      \n",
      "     |      See tf.gather_nd for details.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "     |          Index tensor.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `params`.\n",
      "     |  \n",
      "     |  get_shape(self) -> tensorflow.python.framework.tensor_shape.TensorShape\n",
      "     |      Alias of `Variable.shape`.\n",
      "     |  \n",
      "     |  load(self, value, session=None)\n",
      "     |      Load new value into this variable. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "     |      \n",
      "     |      Writes new value to variable's memory. Doesn't add ops to the graph.\n",
      "     |      \n",
      "     |      This convenience method requires a session where the graph\n",
      "     |      containing this variable has been launched. If no session is\n",
      "     |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
      "     |      information on launching a graph and on sessions.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      v = tf.Variable([1, 2])\n",
      "     |      init = tf.compat.v1.global_variables_initializer()\n",
      "     |      \n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |          sess.run(init)\n",
      "     |          # Usage passing the session explicitly.\n",
      "     |          v.load([2, 3], sess)\n",
      "     |          print(v.eval(sess)) # prints [2 3]\n",
      "     |          # Usage with the default session.  The 'with' block\n",
      "     |          # above makes 'sess' the default session.\n",
      "     |          v.load([3, 4], sess)\n",
      "     |          print(v.eval()) # prints [3 4]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          value: New variable value\n",
      "     |          session: The session to use to evaluate this variable. If none, the\n",
      "     |            default session is used.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: Session is not passed and no default session\n",
      "     |  \n",
      "     |  read_value(self)\n",
      "     |      Returns the value of this variable, read in the current context.\n",
      "     |      \n",
      "     |      Can be different from value() if it's on another device, with control\n",
      "     |      dependencies, etc.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` containing the value of the variable.\n",
      "     |  \n",
      "     |  ref(self)\n",
      "     |      Returns a hashable reference object to this Variable.\n",
      "     |      \n",
      "     |      The primary use case for this API is to put variables in a set/dictionary.\n",
      "     |      We can't put variables in a set/dictionary as `variable.__hash__()` is no\n",
      "     |      longer available starting Tensorflow 2.0.\n",
      "     |      \n",
      "     |      The following will raise an exception starting 2.0\n",
      "     |      \n",
      "     |      >>> x = tf.Variable(5)\n",
      "     |      >>> y = tf.Variable(10)\n",
      "     |      >>> z = tf.Variable(10)\n",
      "     |      >>> variable_set = {x, y, z}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      >>> variable_dict = {x: 'five', y: 'ten'}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      \n",
      "     |      Instead, we can use `variable.ref()`.\n",
      "     |      \n",
      "     |      >>> variable_set = {x.ref(), y.ref(), z.ref()}\n",
      "     |      >>> x.ref() in variable_set\n",
      "     |      True\n",
      "     |      >>> variable_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}\n",
      "     |      >>> variable_dict[y.ref()]\n",
      "     |      'ten'\n",
      "     |      \n",
      "     |      Also, the reference object provides `.deref()` function that returns the\n",
      "     |      original Variable.\n",
      "     |      \n",
      "     |      >>> x = tf.Variable(5)\n",
      "     |      >>> x.ref().deref()\n",
      "     |      <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>\n",
      "     |  \n",
      "     |  scatter_add(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Adds `tf.IndexedSlices` to this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be added to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_div(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Divide this variable by `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to divide this variable by.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_max(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Updates this variable with the max of `tf.IndexedSlices` and itself.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to use as an argument of max with this\n",
      "     |          variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_min(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Updates this variable with the min of `tf.IndexedSlices` and itself.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to use as an argument of min with this\n",
      "     |          variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_mul(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Multiply this variable by `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to multiply this variable by.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_nd_add(self, indices, updates, name=None)\n",
      "     |      Applies sparse addition to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_add(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, 13, 3, 14, 14, 6, 7, 20]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_nd_sub(self, indices, updates, name=None)\n",
      "     |      Applies sparse subtraction to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      Assuming the variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_sub(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      After the update `v` would look like this:\n",
      "     |      \n",
      "     |          [1, -9, 3, -6, -4, 6, 7, -4]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_nd_update(self, indices, updates, name=None)\n",
      "     |      Applies sparse assignment to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_update(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, 11, 3, 10, 9, 6, 7, 12]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_sub(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Subtracts `tf.IndexedSlices` from this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be subtracted from this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Assigns `tf.IndexedSlices` to this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Overrides the shape for this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: the `TensorShape` representing the overridden shape.\n",
      "     |  \n",
      "     |  sparse_read(self, indices, name=None)\n",
      "     |      Gather slices from params axis axis according to indices.\n",
      "     |      \n",
      "     |      This function supports a subset of tf.gather, see tf.gather for details on\n",
      "     |      usage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
      "     |          `int64`. Must be in range `[0, params.shape[axis])`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `params`.\n",
      "     |  \n",
      "     |  to_proto(self, export_scope=None)\n",
      "     |      Converts a `Variable` to a `VariableDef` protocol buffer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        export_scope: Optional `string`. Name scope to remove.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `VariableDef` protocol buffer, or `None` if the `Variable` is not\n",
      "     |        in the specified name scope.\n",
      "     |  \n",
      "     |  value(self)\n",
      "     |      Returns the last snapshot of this variable.\n",
      "     |      \n",
      "     |      You usually do not need to call this method as all ops that need the value\n",
      "     |      of the variable call it automatically through a `convert_to_tensor()` call.\n",
      "     |      \n",
      "     |      Returns a `Tensor` which holds the value of the variable.  You can not\n",
      "     |      assign a new value to this tensor as it is not a reference to the variable.\n",
      "     |      \n",
      "     |      To avoid copies, if the consumer of the returned value is on the same device\n",
      "     |      as the variable, this actually returns the live value of the variable, not\n",
      "     |      a copy.  Updates to the variable are seen by the consumer.  If the consumer\n",
      "     |      is on a different device it will get a copy of the variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` containing the value of the variable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.ops.variables.Variable:\n",
      "     |  \n",
      "     |  aggregation\n",
      "     |  \n",
      "     |  constraint\n",
      "     |      Returns the constraint function associated with this variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The constraint function that was passed to the variable constructor.\n",
      "     |        Can be `None` if no constraint was passed.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The device of this variable.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of this variable.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` of this variable.\n",
      "     |  \n",
      "     |  initial_value\n",
      "     |      Returns the Tensor used as the initial value for the variable.\n",
      "     |      \n",
      "     |      Note that this is different from `initialized_value()` which runs\n",
      "     |      the op that initializes the variable before returning its value.\n",
      "     |      This method returns the tensor that is used by the op that initializes\n",
      "     |      the variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  initializer\n",
      "     |      The initializer operation for this variable.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of this variable.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` of this variable.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The `TensorShape` of this variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape`.\n",
      "     |  \n",
      "     |  synchronization\n",
      "     |  \n",
      "     |  trainable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.ops.variables.Variable:\n",
      "     |  \n",
      "     |  __array_priority__ = 100\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class VariableAggregation(enum.Enum)\n",
      "     |  VariableAggregation(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)\n",
      "     |  \n",
      "     |  Indicates how a distributed variable will be aggregated.\n",
      "     |  \n",
      "     |  `tf.distribute.Strategy` distributes a model by making multiple copies\n",
      "     |  (called \"replicas\") acting on different elements of the input batch in a\n",
      "     |  data parallel model. When performing some variable-update operation,\n",
      "     |  for example `var.assign_add(x)`, in a model, we need to resolve how to combine\n",
      "     |  the different values for `x` computed in the different replicas.\n",
      "     |  \n",
      "     |  * `NONE`: This is the default, giving an error if you use a\n",
      "     |    variable-update operation with multiple replicas.\n",
      "     |  * `SUM`: Add the updates across replicas.\n",
      "     |  * `MEAN`: Take the arithmetic mean (\"average\") of the updates across replicas.\n",
      "     |  * `ONLY_FIRST_REPLICA`: This is for when every replica is performing the same\n",
      "     |    update, but we only want to perform the update once. Used, e.g., for the\n",
      "     |    global step counter.\n",
      "     |  \n",
      "     |  For example:\n",
      "     |  \n",
      "     |  >>> strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\n",
      "     |  >>> with strategy.scope():\n",
      "     |  ...   v = tf.Variable(5.0, aggregation=tf.VariableAggregation.MEAN)\n",
      "     |  >>> @tf.function\n",
      "     |  ... def update_fn():\n",
      "     |  ...   return v.assign_add(1.0)\n",
      "     |  >>> strategy.run(update_fn)\n",
      "     |  PerReplica:{\n",
      "     |    0: <tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
      "     |    1: <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
      "     |  }\n",
      "     |  \n",
      "     |  * `ONLY_FIRST_TOWER`: Deprecated alias for `ONLY_FIRST_REPLICA`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableAggregation\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MEAN = <VariableAggregation.MEAN: 2>\n",
      "     |  \n",
      "     |  NONE = <VariableAggregation.NONE: 0>\n",
      "     |  \n",
      "     |  ONLY_FIRST_REPLICA = <VariableAggregation.ONLY_FIRST_REPLICA: 3>\n",
      "     |  \n",
      "     |  SUM = <VariableAggregation.SUM: 1>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __contains__(member) from enum.EnumType\n",
      "     |      Return True if member is a member of this enum\n",
      "     |      raises TypeError if member is not an enum member\n",
      "     |      \n",
      "     |      note: in 3.12 TypeError will no longer be raised, and True will also be\n",
      "     |      returned if member is the value of a member in this enum\n",
      "     |  \n",
      "     |  __getitem__(name) from enum.EnumType\n",
      "     |      Return the member matching `name`.\n",
      "     |  \n",
      "     |  __iter__() from enum.EnumType\n",
      "     |      Return members in definition order.\n",
      "     |  \n",
      "     |  __len__() from enum.EnumType\n",
      "     |      Return the number of members (no aliases)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class VariableScope(builtins.object)\n",
      "     |  VariableScope(reuse, name='', initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, name_scope='', dtype=tf.float32, use_resource=None, constraint=None)\n",
      "     |  \n",
      "     |  Variable scope object to carry defaults to provide to `get_variable`.\n",
      "     |  \n",
      "     |  Many of the arguments we need for `get_variable` in a variable store are most\n",
      "     |  easily handled with a context. This object is used for the defaults.\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |    name: name of the current scope, used as prefix in get_variable.\n",
      "     |    initializer: default initializer passed to get_variable.\n",
      "     |    regularizer: default regularizer passed to get_variable.\n",
      "     |    reuse: Boolean, None, or tf.compat.v1.AUTO_REUSE, setting the reuse in\n",
      "     |      get_variable. When eager execution is enabled this argument is always\n",
      "     |      forced to be False.\n",
      "     |    caching_device: string, callable, or None: the caching device passed to\n",
      "     |      get_variable.\n",
      "     |    partitioner: callable or `None`: the partitioner passed to `get_variable`.\n",
      "     |    custom_getter: default custom getter passed to get_variable.\n",
      "     |    name_scope: The name passed to `tf.name_scope`.\n",
      "     |    dtype: default type passed to get_variable (defaults to DT_FLOAT).\n",
      "     |    use_resource: if False, create a normal Variable; if True create an\n",
      "     |      experimental ResourceVariable with well-defined semantics. Defaults to\n",
      "     |      False (will later change to True). When eager execution is enabled this\n",
      "     |      argument is always forced to be True.\n",
      "     |    constraint: An optional projection function to be applied to the variable\n",
      "     |      after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |      constraints or value constraints for layer weights). The function must\n",
      "     |      take as input the unprojected Tensor representing the value of the\n",
      "     |      variable and return the Tensor for the projected value (which must have\n",
      "     |      the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |      distributed training.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, reuse, name='', initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, name_scope='', dtype=tf.float32, use_resource=None, constraint=None)\n",
      "     |      Creates a new VariableScope with the given properties.\n",
      "     |  \n",
      "     |  get_collection(self, name)\n",
      "     |      Get this scope's variables.\n",
      "     |  \n",
      "     |  get_variable(self, var_store, name, shape=None, dtype=None, initializer=None, regularizer=None, reuse=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "     |      Gets an existing variable with this name or create a new one.\n",
      "     |  \n",
      "     |  global_variables(self)\n",
      "     |      Get this scope's global variables.\n",
      "     |  \n",
      "     |  local_variables(self)\n",
      "     |      Get this scope's local variables.\n",
      "     |  \n",
      "     |  reuse_variables(self)\n",
      "     |      Reuse variables in this scope.\n",
      "     |  \n",
      "     |  set_caching_device(self, caching_device)\n",
      "     |      Set caching_device for this scope.\n",
      "     |  \n",
      "     |  set_custom_getter(self, custom_getter)\n",
      "     |      Set custom getter for this scope.\n",
      "     |  \n",
      "     |  set_dtype(self, dtype)\n",
      "     |      Set data type for this scope.\n",
      "     |  \n",
      "     |  set_initializer(self, initializer)\n",
      "     |      Set initializer for this scope.\n",
      "     |  \n",
      "     |  set_partitioner(self, partitioner)\n",
      "     |      Set partitioner for this scope.\n",
      "     |  \n",
      "     |  set_regularizer(self, regularizer)\n",
      "     |      Set regularizer for this scope.\n",
      "     |  \n",
      "     |  set_use_resource(self, use_resource)\n",
      "     |      Sets whether to use ResourceVariables for this scope.\n",
      "     |  \n",
      "     |  trainable_variables(self)\n",
      "     |      Get this scope's trainable variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  caching_device\n",
      "     |  \n",
      "     |  constraint\n",
      "     |  \n",
      "     |  custom_getter\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  initializer\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  original_name_scope\n",
      "     |  \n",
      "     |  partitioner\n",
      "     |  \n",
      "     |  regularizer\n",
      "     |  \n",
      "     |  reuse\n",
      "     |  \n",
      "     |  use_resource\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class VariableSynchronization(enum.Enum)\n",
      "     |  VariableSynchronization(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)\n",
      "     |  \n",
      "     |  Indicates when a distributed variable will be synced.\n",
      "     |  \n",
      "     |  * `AUTO`: Indicates that the synchronization will be determined by the current\n",
      "     |    `DistributionStrategy` (eg. With `MirroredStrategy` this would be\n",
      "     |    `ON_WRITE`).\n",
      "     |  * `NONE`: Indicates that there will only be one copy of the variable, so\n",
      "     |    there is no need to sync.\n",
      "     |  * `ON_WRITE`: Indicates that the variable will be updated across devices\n",
      "     |    every time it is written.\n",
      "     |  * `ON_READ`: Indicates that the variable will be aggregated across devices\n",
      "     |    when it is read (eg. when checkpointing or when evaluating an op that uses\n",
      "     |    the variable).\n",
      "     |  \n",
      "     |    Example:\n",
      "     |  >>> temp_grad=[tf.Variable([0.], trainable=False,\n",
      "     |  ...                      synchronization=tf.VariableSynchronization.ON_READ,\n",
      "     |  ...                      aggregation=tf.VariableAggregation.MEAN\n",
      "     |  ...                      )]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableSynchronization\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AUTO = <VariableSynchronization.AUTO: 0>\n",
      "     |  \n",
      "     |  NONE = <VariableSynchronization.NONE: 1>\n",
      "     |  \n",
      "     |  ON_READ = <VariableSynchronization.ON_READ: 3>\n",
      "     |  \n",
      "     |  ON_WRITE = <VariableSynchronization.ON_WRITE: 2>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __contains__(member) from enum.EnumType\n",
      "     |      Return True if member is a member of this enum\n",
      "     |      raises TypeError if member is not an enum member\n",
      "     |      \n",
      "     |      note: in 3.12 TypeError will no longer be raised, and True will also be\n",
      "     |      returned if member is the value of a member in this enum\n",
      "     |  \n",
      "     |  __getitem__(name) from enum.EnumType\n",
      "     |      Return the member matching `name`.\n",
      "     |  \n",
      "     |  __iter__() from enum.EnumType\n",
      "     |      Return members in definition order.\n",
      "     |  \n",
      "     |  __len__() from enum.EnumType\n",
      "     |      Return the number of members (no aliases)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class WholeFileReader(ReaderBase)\n",
      "     |  WholeFileReader(name=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the entire contents of a file as a value.\n",
      "     |  \n",
      "     |  To use, enqueue filenames in a Queue.  The output of Read will\n",
      "     |  be a filename (key) and the contents of that file (value).\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WholeFileReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Create a WholeFileReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    constant_initializer = class Constant(Initializer)\n",
      "     |  constant_initializer(value=0, dtype=tf.float32, verify_shape=False)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with constant values.\n",
      "     |  \n",
      "     |  The resulting tensor is populated with values of type `dtype`, as\n",
      "     |  specified by arguments `value` following the desired `shape` of the\n",
      "     |  new tensor (see examples below).\n",
      "     |  \n",
      "     |  The argument `value` can be a constant value, or a list of values of type\n",
      "     |  `dtype`. If `value` is a list, then the length of the list must be less\n",
      "     |  than or equal to the number of elements implied by the desired shape of the\n",
      "     |  tensor. In the case where the total number of elements in `value` is less\n",
      "     |  than the number of elements required by the tensor shape, the last element\n",
      "     |  in `value` will be used to fill the remaining entries. If the total number of\n",
      "     |  elements in `value` is greater than the number of elements required by the\n",
      "     |  tensor shape, the initializer will raise a `ValueError`.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    value: A Python scalar, list or tuple of values, or a N-dimensional numpy\n",
      "     |      array. All elements of the initialized variable will be set to the\n",
      "     |      corresponding value in the `value` argument.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer.\n",
      "     |    verify_shape: Boolean that enables verification of the shape of `value`. If\n",
      "     |      `True`, the initializer will throw an error if the shape of `value` is not\n",
      "     |      compatible with the shape of the initialized tensor.\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |    TypeError: If the input `value` is not one of the expected types.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |    The following example can be rewritten using a numpy.ndarray instead\n",
      "     |    of the `value` list, even reshaped, as shown in the two commented lines\n",
      "     |    below the `value` list initialization.\n",
      "     |  \n",
      "     |  >>> value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "     |  >>> init = tf.compat.v1.constant_initializer(value)\n",
      "     |  >>> # fitting shape\n",
      "     |  >>> with tf.compat.v1.Session():\n",
      "     |  ...   x = tf.compat.v1.get_variable('x', shape=[2, 4], initializer=init)\n",
      "     |  ...   x.initializer.run()\n",
      "     |  ...   print(x.eval())\n",
      "     |  [[0. 1. 2. 3.]\n",
      "     |   [4. 5. 6. 7.]]\n",
      "     |  >>> # Larger shape\n",
      "     |  >>> with tf.compat.v1.Session():\n",
      "     |  ...   y = tf.compat.v1.get_variable('y', shape=[3, 4], initializer=init)\n",
      "     |  ...   y.initializer.run()\n",
      "     |  ...   print(y.eval())\n",
      "     |  [[0.  1.  2.  3.]\n",
      "     |   [4.  5.  6.  7.]\n",
      "     |   [7.  7.  7.  7.]]\n",
      "     |  >>> # Smaller shape\n",
      "     |  >>> with tf.compat.v1.Session():\n",
      "     |  ...   z = tf.compat.v1.get_variable('z', shape=[2, 3], initializer=init)\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  ValueError: Too many elements provided. Needed at most 6, but received 8\n",
      "     |  >>> # Shape verification\n",
      "     |  >>> init_verify = tf.compat.v1.constant_initializer(value, verify_shape=True)\n",
      "     |  >>> with tf.compat.v1.Session():\n",
      "     |  ...  u = tf.compat.v1.get_variable('u', shape=[3, 4],\n",
      "     |  ...                                initializer=init_verify)\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: Expected Tensor's shape: (3, 4), got (8,).\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy API endpoint, `tf.compat.v1.constant_initializer`\n",
      "     |  is compatible with eager execution and `tf.function`.\n",
      "     |  \n",
      "     |  To migrate to a non-legacy TF2 API, please use `tf.constant_initializer`\n",
      "     |  instead. The `dtype`\n",
      "     |  argument in `tf.compat.v1.constant_initializer.__init__()` does not exist in\n",
      "     |  `tf.constant_initializer.__init__()`. However, you can specify the `dtype` in\n",
      "     |  `__call__()` in both cases.\n",
      "     |  \n",
      "     |  In the `compat.v1` symbol, if `verify_shape` is set to `True`, an exception\n",
      "     |  is raised when initializing a variable with a different shape from\n",
      "     |  `value`. If set to `False`, `value` is reshaped to initialize the variable\n",
      "     |  if necessary. An exception would only be raised when the number of\n",
      "     |  elements are different.\n",
      "     |  \n",
      "     |  The `verify_shape` argument is not supported in TF2. Using\n",
      "     |  `tf.constant_initializer` is equivalent to setting `verify_shape` to `False`.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "     |  initializer = tf.compat.v1.constant_initializer(\n",
      "     |      value=value,\n",
      "     |      dtype=tf.float32,\n",
      "     |      verify_shape=False)\n",
      "     |  variable = tf.Variable(initializer(shape=[2, 4]))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "     |  initializer = tf.constant_initializer(value=value)\n",
      "     |  tf.Variable(initializer(shape=[2, 4], dtype=tf.float32))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name          | TF2 Arg Name     | Note                        |\n",
      "     |  | :-------------------- | :--------------- | :-------------------------- |\n",
      "     |  | `value`               | `value`          | In constructor              |\n",
      "     |  | `dtype`               | `dtype`          | In `__call__()` method      |\n",
      "     |  | `verify_shape`        | Not Supported    | Equivalent to set to `False`|\n",
      "     |  | `partition_info`      | - |  (`__call__` arg in TF1) Not supported     |\n",
      "     |  \n",
      "     |  \n",
      "     |  #### Before & After Usage Example\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  >>> value = [1., 2., 3., 4.]\n",
      "     |  >>> initializer = tf.compat.v1.constant_initializer(\n",
      "     |  ...     value=value, dtype=tf.float32, verify_shape=True)\n",
      "     |  >>> tf.Variable(initializer(shape=[2, 2])).numpy()\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: Expected Tensor's shape: (2, 2), got (4,).\n",
      "     |  >>> initializer = tf.compat.v1.constant_initializer(\n",
      "     |  ...     value=value, dtype=tf.float32, verify_shape=False)\n",
      "     |  >>> tf.Variable(initializer(shape=[2, 2])).numpy()\n",
      "     |  array([[1., 2.],\n",
      "     |         [3., 4.]], dtype=float32)\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  >>> value = [1., 2., 3., 4.]\n",
      "     |  >>> initializer = tf.constant_initializer(value=value)\n",
      "     |  >>> tf.Variable(initializer(shape=[2, 2], dtype=tf.float32)).numpy()\n",
      "     |  array([[1., 2.],\n",
      "     |         [3., 4.]], dtype=float32)\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Constant\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None, verify_shape=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, value=0, dtype=tf.float32, verify_shape=False)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(verify_shape)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Objects must now be the required shape or no shape can be specified\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    glorot_normal_initializer = class GlorotNormal(VarianceScaling)\n",
      "     |  glorot_normal_initializer(seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  The Glorot normal initializer, also called Xavier normal initializer.\n",
      "     |  \n",
      "     |  It draws samples from a truncated normal distribution centered on 0\n",
      "     |  with standard deviation (after truncation) given by\n",
      "     |  `stddev = sqrt(2 / (fan_in + fan_out))` where `fan_in` is the number\n",
      "     |  of input units in the weight tensor and `fan_out` is the number of\n",
      "     |  output units in the weight tensor.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)\n",
      "     |      ([pdf](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlorotNormal\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarianceScaling:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    glorot_uniform_initializer = class GlorotUniform(VarianceScaling)\n",
      "     |  glorot_uniform_initializer(seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  The Glorot uniform initializer, also called Xavier uniform initializer.\n",
      "     |  \n",
      "     |  It draws samples from a uniform distribution within [-limit, limit]\n",
      "     |  where `limit` is `sqrt(6 / (fan_in + fan_out))`\n",
      "     |  where `fan_in` is the number of input units in the weight tensor\n",
      "     |  and `fan_out` is the number of output units in the weight tensor.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)\n",
      "     |      ([pdf](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlorotUniform\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarianceScaling:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    name_scope = class name_scope_v1(contextlib.AbstractContextManager)\n",
      "     |  name_scope(name, default_name=None, values=None) -> None\n",
      "     |  \n",
      "     |  A context manager for use when defining a Python op.\n",
      "     |  \n",
      "     |  This context manager validates that the given `values` are from the\n",
      "     |  same graph, makes that graph the default graph, and pushes a\n",
      "     |  name scope in that graph (see\n",
      "     |  `tf.Graph.name_scope`\n",
      "     |  for more details on that).\n",
      "     |  \n",
      "     |  For example, to define a new Python op called `my_op`:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  def my_op(a, b, c, name=None):\n",
      "     |    with tf.name_scope(name, \"MyOp\", [a, b, c]) as scope:\n",
      "     |      a = tf.convert_to_tensor(a, name=\"a\")\n",
      "     |      b = tf.convert_to_tensor(b, name=\"b\")\n",
      "     |      c = tf.convert_to_tensor(c, name=\"c\")\n",
      "     |      # Define some computation that uses `a`, `b`, and `c`.\n",
      "     |      return foo_op(..., name=scope)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      name_scope_v1\n",
      "     |      contextlib.AbstractContextManager\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self) -> Optional[str]\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  __exit__(self, *exc_info) -> Optional[bool]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __init__(self, name, default_name=None, values=None) -> None\n",
      "     |      Initialize the context manager.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name argument that is passed to the op function.\n",
      "     |        default_name: The default name to use if the `name` argument is `None`.\n",
      "     |        values: The list of `Tensor` arguments that are passed to the op function.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `default_name` is passed in but not a string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __orig_bases__ = (contextlib.AbstractContextManager[typing.Optional[st...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractContextManager:\n",
      "     |  \n",
      "     |  __class_getitem__ = GenericAlias(...) from abc.ABCMeta\n",
      "     |      Represent a PEP 585 generic type\n",
      "     |      \n",
      "     |      E.g. for t = list[int], t.__origin__ is list and t.__args__ is (int,).\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    ones_initializer = class Ones(Initializer)\n",
      "     |  ones_initializer(dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors initialized to 1.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  This API is compatible with TF2 behavior and `tf.function`, and can be\n",
      "     |  migrated immediately with `tf.keras.initializers.ones`.\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  >>> initializer = tf.compat.v1.keras.initializers.ones()\n",
      "     |  >>> initializer((1, 1))\n",
      "     |  <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.]], dtype=float32)>\n",
      "     |  \n",
      "     |  After:\n",
      "     |  >>> initializer = tf.keras.initializers.ones()\n",
      "     |  >>> initializer((1, 1))\n",
      "     |  <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.]], dtype=float32)>\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Ones\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    orthogonal_initializer = class Orthogonal(Initializer)\n",
      "     |  orthogonal_initializer(gain=1.0, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates an orthogonal matrix.\n",
      "     |  \n",
      "     |  If the shape of the tensor to initialize is two-dimensional, it is initialized\n",
      "     |  with an orthogonal matrix obtained from the QR decomposition of a matrix of\n",
      "     |  random numbers drawn from a normal distribution.\n",
      "     |  If the matrix has fewer rows than columns then the output will have orthogonal\n",
      "     |  rows. Otherwise, the output will have orthogonal columns.\n",
      "     |  \n",
      "     |  If the shape of the tensor to initialize is more than two-dimensional,\n",
      "     |  a matrix of shape `(shape[0] * ... * shape[n - 2], shape[n - 1])`\n",
      "     |  is initialized, where `n` is the length of the shape vector.\n",
      "     |  The matrix is subsequently reshaped to give a tensor of the desired shape.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    gain: multiplicative factor to apply to the orthogonal matrix\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Saxe et al., 2014](https://openreview.net/forum?id=_wzZwKpTDF_9C)\n",
      "     |      ([pdf](https://arxiv.org/pdf/1312.6120.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Orthogonal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, gain=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    random_normal_initializer = class RandomNormal(Initializer)\n",
      "     |  random_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with a normal distribution.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    mean: a python scalar or a scalar tensor. Mean of the random values to\n",
      "     |      generate.\n",
      "     |    stddev: a python scalar or a scalar tensor. Standard deviation of the random\n",
      "     |      values to generate.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy `compat.v1` API, this symbol is compatible with eager\n",
      "     |  execution and `tf.function`.\n",
      "     |  \n",
      "     |  To switch to TF2, switch to using either\n",
      "     |  `tf.initializers.RandomNormal` or `tf.keras.initializers.RandomNormal`\n",
      "     |  (neither from `compat.v1`) and\n",
      "     |  pass the dtype when calling the initializer. Keep in mind that\n",
      "     |  the default stddev and the behavior of fixed seeds have changed.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.random_normal_initializer(\n",
      "     |    mean=mean,\n",
      "     |    stddev=stddev,\n",
      "     |    seed=seed,\n",
      "     |    dtype=dtype)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.initializers.RandomNormal(\n",
      "     |    mean=mean,\n",
      "     |    seed=seed,\n",
      "     |    stddev=stddev)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one, dtype=dtype))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two, dtype=dtype))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name       | TF2 Arg Name    | Note                       |\n",
      "     |  | :----------------- | :-------------- | :------------------------- |\n",
      "     |  | `mean`             | `mean`          | No change to defaults |\n",
      "     |  | `stddev`           | `stddev`        | Default changes from 1.0 to 0.05 |\n",
      "     |  | `seed`             | `seed`          |                                  |\n",
      "     |  | `dtype`            | `dtype`  | The TF2 native api only takes it as a |\n",
      "     |  :                    :          : `__call__` arg, not a constructor arg. :\n",
      "     |  | `partition_info`   | -     |  (`__call__` arg in TF1) Not supported.  |\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomNormal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    random_uniform_initializer = class RandomUniform(Initializer)\n",
      "     |  random_uniform_initializer(minval=0.0, maxval=None, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with a uniform distribution.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    minval: A python scalar or a scalar tensor. Lower bound of the range of\n",
      "     |      random values to generate.\n",
      "     |    maxval: A python scalar or a scalar tensor. Upper bound of the range of\n",
      "     |      random values to generate.  Defaults to 1 for float types.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy compat.v1 API, this symbol is compatible with eager\n",
      "     |  execution and `tf.function`.\n",
      "     |  \n",
      "     |  To switch to TF2, switch to using either\n",
      "     |  `tf.initializers.RandomUniform` or `tf.keras.initializers.RandomUniform`\n",
      "     |  (neither from `compat.v1`) and\n",
      "     |  pass the dtype when calling the initializer. Keep in mind that\n",
      "     |  the default minval, maxval and the behavior of fixed seeds have changed.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.random_uniform_initializer(\n",
      "     |    minval=minval,\n",
      "     |    maxval=maxval,\n",
      "     |    seed=seed,\n",
      "     |    dtype=dtype)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.initializers.RandomUniform(\n",
      "     |    minval=minval,\n",
      "     |    maxval=maxval,\n",
      "     |    seed=seed)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one, dtype=dtype))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two, dtype=dtype))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "     |  | :-------------------- | :-------------- | :------------------------- |\n",
      "     |  | `minval`               | `minval`    | Default changes from 0 to -0.05 |\n",
      "     |  | `maxval`         | `maxval`        | Default changes from 1.0 to 0.05 |\n",
      "     |  | `seed`             | `seed` |  |\n",
      "     |  | `dtype` | `dtype`   | The TF2 native api only takes it  |\n",
      "     |  :                     :      : as a `__call__` arg, not a constructor arg. :\n",
      "     |  | `partition_info`     | - |  (`__call__` arg in TF1) Not supported       |\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomUniform\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, minval=0.0, maxval=None, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    truncated_normal_initializer = class TruncatedNormal(Initializer)\n",
      "     |  truncated_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates a truncated normal distribution.\n",
      "     |  \n",
      "     |  These values are similar to values from a `random_normal_initializer`\n",
      "     |  except that values more than two standard deviations from the mean\n",
      "     |  are discarded and re-drawn. This is the recommended initializer for\n",
      "     |  neural network weights and filters.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    mean: a python scalar or a scalar tensor. Mean of the random values to\n",
      "     |      generate.\n",
      "     |    stddev: a python scalar or a scalar tensor. Standard deviation of the random\n",
      "     |      values to generate.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy `compat.v1` API, this symbol is compatible with eager\n",
      "     |  execution and `tf.function`.\n",
      "     |  \n",
      "     |  To switch to TF2, switch to using either\n",
      "     |  `tf.initializers.truncated_normal` or `tf.keras.initializers.TruncatedNormal`\n",
      "     |  (neither from `compat.v1`) and\n",
      "     |  pass the dtype when calling the initializer. Keep in mind that\n",
      "     |  the default stddev and the behavior of fixed seeds have changed.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.truncated_normal_initializer(\n",
      "     |    mean=mean,\n",
      "     |    stddev=stddev,\n",
      "     |    seed=seed,\n",
      "     |    dtype=dtype)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.initializers.truncated_normal(\n",
      "     |    mean=mean,\n",
      "     |    seed=seed,\n",
      "     |    stddev=stddev)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one, dtype=dtype))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two, dtype=dtype))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "     |  | :-------------------- | :-------------- | :------------------------- |\n",
      "     |  | `mean`               | `mean`        | No change to defaults |\n",
      "     |  | `stddev`         | `stddev`        | Default changes from 1.0 to 0.05 |\n",
      "     |  | `seed`             | `seed` | |\n",
      "     |  | `dtype` | `dtype`   | The TF2 native api only takes it  |\n",
      "     |  :                     :      : as a `__call__` arg, not a constructor arg. :\n",
      "     |  | `partition_info`     | - |  (`__call__` arg in TF1) Not supported       |\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TruncatedNormal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    uniform_unit_scaling_initializer = class UniformUnitScaling(Initializer)\n",
      "     |  uniform_unit_scaling_initializer(factor=1.0, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors without scaling variance.\n",
      "     |  \n",
      "     |  When initializing a deep network, it is in principle advantageous to keep\n",
      "     |  the scale of the input variance constant, so it does not explode or diminish\n",
      "     |  by reaching the final layer. If the input is `x` and the operation `x * W`,\n",
      "     |  and we want to initialize `W` uniformly at random, we need to pick `W` from\n",
      "     |  \n",
      "     |      [-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]\n",
      "     |  \n",
      "     |  to keep the scale intact, where `dim = W.shape[0]` (the size of the input).\n",
      "     |  A similar calculation for convolutional networks gives an analogous result\n",
      "     |  with `dim` equal to the product of the first 3 dimensions.  When\n",
      "     |  nonlinearities are present, we need to multiply this by a constant `factor`.\n",
      "     |  See (Sussillo et al., 2014) for deeper motivation, experiments\n",
      "     |  and the calculation of constants. In section 2.3 there, the constants were\n",
      "     |  numerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    factor: Float.  A multiplicative factor by which the values will be scaled.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Sussillo et al., 2014](https://arxiv.org/abs/1412.6558)\n",
      "     |      ([pdf](http://arxiv.org/pdf/1412.6558.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UniformUnitScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, factor=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class variable_scope(builtins.object)\n",
      "     |  variable_scope(name_or_scope, default_name=None, values=None, initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, reuse=None, dtype=None, use_resource=None, constraint=None, auxiliary_name_scope=True)\n",
      "     |  \n",
      "     |  A context manager for defining ops that creates variables (layers).\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy `compat.v1` api,\n",
      "     |  `tf.compat.v1.variable_scope` is mostly compatible with eager\n",
      "     |  execution and `tf.function` as long as you combine it with the\n",
      "     |  `tf.compat.v1.keras.utils.track_tf1_style_variables` decorator (though\n",
      "     |  it will behave as if reuse is always set to `AUTO_REUSE`.)\n",
      "     |  \n",
      "     |  See the\n",
      "     |  [model migration guide](\n",
      "     |      https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "     |  for more info on\n",
      "     |  migrating code that relies on `variable_scope`-based variable reuse.\n",
      "     |  \n",
      "     |  When you use it with eager execution enabled but without\n",
      "     |  `tf.compat.v1.keras.utils.track_tf1_style_variables`,\n",
      "     |  `tf.compat.v1.variable_scope` will still be able to prefix the names\n",
      "     |  of variables created within the scope but it will not enable variable reuse\n",
      "     |  or error-raising checks around variable reuse (`get_variable` calls within\n",
      "     |  it would always create new variables).\n",
      "     |  \n",
      "     |  Once you have switched away from `get_variable`-based variable reuse\n",
      "     |  mechanisms, to switch to TF2 APIs you can just use\n",
      "     |  `tf.name_scope` to prefix variable names.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  This context manager validates that the (optional) `values` are from the same\n",
      "     |  graph, ensures that graph is the default graph, and pushes a name scope and a\n",
      "     |  variable scope.\n",
      "     |  \n",
      "     |  If `name_or_scope` is not None, it is used as is. If `name_or_scope` is None,\n",
      "     |  then `default_name` is used.  In that case, if the same name has been\n",
      "     |  previously used in the same scope, it will be made unique by appending `_N`\n",
      "     |  to it.\n",
      "     |  \n",
      "     |  Variable scope allows you to create new variables and to share already created\n",
      "     |  ones while providing checks to not create or share by accident. For details,\n",
      "     |  see the [Variable Scope How To](https://tensorflow.org/guide/variables), here\n",
      "     |  we present only a few basic examples.\n",
      "     |  \n",
      "     |  The Variable Scope works as expected when the Eager Execution is Disabled.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.compat.v1.disable_eager_execution()\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Simple example of how to create a new variable:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      with tf.compat.v1.variable_scope(\"bar\"):\n",
      "     |          v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |          assert v.name == \"foo/bar/v:0\"\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Simple example of how to reenter a premade variable scope safely:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\") as vs:\n",
      "     |    pass\n",
      "     |  \n",
      "     |  # Re-enter the variable scope.\n",
      "     |  with tf.compat.v1.variable_scope(vs,\n",
      "     |                         auxiliary_name_scope=False) as vs1:\n",
      "     |    # Restore the original name_scope.\n",
      "     |    with tf.name_scope(vs1.original_name_scope):\n",
      "     |        v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |        assert v.name == \"foo/v:0\"\n",
      "     |        c = tf.constant([1], name=\"c\")\n",
      "     |        assert c.name == \"foo/c:0\"\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Keep in mind that the counters for `default_name` are discarded once the\n",
      "     |  parent scope is exited. Therefore when the code re-enters the scope (for\n",
      "     |  instance by saving it), all nested default_name counters will be restarted.\n",
      "     |  \n",
      "     |  For instance:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\") as vs:\n",
      "     |    with tf.compat.v1.variable_scope(None, default_name=\"bar\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"a\", [1])\n",
      "     |      assert v.name == \"foo/bar/a:0\", v.name\n",
      "     |    with tf.compat.v1.variable_scope(None, default_name=\"bar\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"b\", [1])\n",
      "     |      assert v.name == \"foo/bar_1/b:0\"\n",
      "     |  \n",
      "     |  with tf.compat.v1.variable_scope(vs):\n",
      "     |    with tf.compat.v1.variable_scope(None, default_name=\"bar\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"c\", [1])\n",
      "     |      assert v.name == \"foo/bar/c:0\"   # Uses bar instead of bar_2!\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Basic example of sharing a variable AUTO_REUSE:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  def foo():\n",
      "     |    with tf.compat.v1.variable_scope(\"foo\", reuse=tf.compat.v1.AUTO_REUSE):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |    return v\n",
      "     |  \n",
      "     |  v1 = foo()  # Creates v.\n",
      "     |  v2 = foo()  # Gets the same, existing v.\n",
      "     |  assert v1 == v2\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Basic example of sharing a variable with reuse=True:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\", reuse=True):\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  assert v1 == v\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Sharing a variable by capturing a scope and setting reuse:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\") as scope:\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      scope.reuse_variables()\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  assert v1 == v\n",
      "     |  ```\n",
      "     |  \n",
      "     |  To prevent accidental sharing of variables, we raise an exception when getting\n",
      "     |  an existing variable in a non-reusing scope.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      #  Raises ValueError(\"... v already exists ...\").\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Similarly, we raise an exception when trying to get a variable that does not\n",
      "     |  exist in reuse mode.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\", reuse=True):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      #  Raises ValueError(\"... v does not exists ...\").\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that the `reuse` flag is inherited: if we open a reusing scope, then all\n",
      "     |  its sub-scopes become reusing as well.\n",
      "     |  \n",
      "     |  A note about name scoping: Setting `reuse` does not impact the naming of other\n",
      "     |  ops such as mult. See related discussion on\n",
      "     |  [github#6189](https://github.com/tensorflow/tensorflow/issues/6189)\n",
      "     |  \n",
      "     |  Note that up to and including version 1.0, it was allowed (though explicitly\n",
      "     |  discouraged) to pass False to the reuse argument, yielding undocumented\n",
      "     |  behaviour slightly different from None. Starting at 1.1.0 passing None and\n",
      "     |  False as reuse has exactly the same effect.\n",
      "     |  \n",
      "     |  A note about using variable scopes in multi-threaded environment: Variable\n",
      "     |  scopes are thread local, so one thread will not see another thread's current\n",
      "     |  scope. Also, when using `default_name`, unique scopes names are also generated\n",
      "     |  only on a per thread basis. If the same name was used within a different\n",
      "     |  thread, that doesn't prevent a new thread from creating the same scope.\n",
      "     |  However, the underlying variable store is shared across threads (within the\n",
      "     |  same graph). As such, if another thread tries to create a new variable with\n",
      "     |  the same name as a variable created by a previous thread, it will fail unless\n",
      "     |  reuse is True.\n",
      "     |  \n",
      "     |  Further, each thread starts with an empty variable scope. So if you wish to\n",
      "     |  preserve name prefixes from a scope from the main thread, you should capture\n",
      "     |  the main thread's scope and re-enter it in each thread. For e.g.\n",
      "     |  \n",
      "     |  ```\n",
      "     |  main_thread_scope = variable_scope.get_variable_scope()\n",
      "     |  \n",
      "     |  # Thread's target function:\n",
      "     |  def thread_target_fn(captured_scope):\n",
      "     |    with variable_scope.variable_scope(captured_scope):\n",
      "     |      # .... regular code for this thread\n",
      "     |  \n",
      "     |  \n",
      "     |  thread = threading.Thread(target=thread_target_fn, args=(main_thread_scope,))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, type_arg, value_arg, traceback_arg)\n",
      "     |  \n",
      "     |  __init__(self, name_or_scope, default_name=None, values=None, initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, reuse=None, dtype=None, use_resource=None, constraint=None, auxiliary_name_scope=True)\n",
      "     |      Initialize the context manager.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name_or_scope: `string` or `VariableScope`: the scope to open.\n",
      "     |        default_name: The default name to use if the `name_or_scope` argument is\n",
      "     |          `None`, this name will be uniquified. If name_or_scope is provided it\n",
      "     |          won't be used and therefore it is not required and can be None.\n",
      "     |        values: The list of `Tensor` arguments that are passed to the op function.\n",
      "     |        initializer: default initializer for variables within this scope.\n",
      "     |        regularizer: default regularizer for variables within this scope.\n",
      "     |        caching_device: default caching device for variables within this scope.\n",
      "     |        partitioner: default partitioner for variables within this scope.\n",
      "     |        custom_getter: default custom getter for variables within this scope.\n",
      "     |        reuse: `True`, None, or tf.compat.v1.AUTO_REUSE; if `True`, we go into\n",
      "     |          reuse mode for this scope as well as all sub-scopes; if\n",
      "     |          tf.compat.v1.AUTO_REUSE, we create variables if they do not exist, and\n",
      "     |          return them otherwise; if None, we inherit the parent scope's reuse\n",
      "     |          flag. When eager execution is enabled, new variables are always created\n",
      "     |          unless an EagerVariableStore or template is currently active.\n",
      "     |        dtype: type of variables created in this scope (defaults to the type in\n",
      "     |          the passed scope, or inherited from parent scope).\n",
      "     |        use_resource: If False, all variables will be regular Variables. If True,\n",
      "     |          experimental ResourceVariables with well-defined semantics will be used\n",
      "     |          instead. Defaults to False (will later change to True). When eager\n",
      "     |          execution is enabled this argument is always forced to be True.\n",
      "     |        constraint: An optional projection function to be applied to the variable\n",
      "     |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |          constraints or value constraints for layer weights). The function must\n",
      "     |          take as input the unprojected Tensor representing the value of the\n",
      "     |          variable and return the Tensor for the projected value (which must have\n",
      "     |          the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |          distributed training.\n",
      "     |        auxiliary_name_scope: If `True`, we create an auxiliary name scope with\n",
      "     |          the scope. If `False`, we don't create it. Note that the argument is not\n",
      "     |          inherited, and it only takes effect for once when creating. You should\n",
      "     |          only use it for re-entering a premade variable scope.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scope that can be captured and reused.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: when trying to reuse within a create scope, or create within\n",
      "     |          a reuse scope.\n",
      "     |        TypeError: when the types of some arguments are not appropriate.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    variance_scaling_initializer = class VarianceScaling(Initializer)\n",
      "     |  variance_scaling_initializer(scale=1.0, mode='fan_in', distribution='truncated_normal', seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer capable of adapting its scale to the shape of weights tensors.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy `compat.v1` API, this symbol is compatible with eager\n",
      "     |  execution and `tf.function`.\n",
      "     |  \n",
      "     |  To switch to TF2 APIs, move to using either\n",
      "     |  `tf.initializers.variance_scaling` or `tf.keras.initializers.VarianceScaling`\n",
      "     |  (neither from `compat.v1`) and\n",
      "     |  pass the dtype when calling the initializer.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.variance_scaling_initializer(\n",
      "     |    scale=scale,\n",
      "     |    mode=mode,\n",
      "     |    distribution=distribution\n",
      "     |    seed=seed,\n",
      "     |    dtype=dtype)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.keras.initializers.VarianceScaling(\n",
      "     |    scale=scale,\n",
      "     |    mode=mode,\n",
      "     |    distribution=distribution\n",
      "     |    seed=seed)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one, dtype=dtype))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two, dtype=dtype))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name       | TF2 Arg Name    | Note                       |\n",
      "     |  | :----------------- | :-------------- | :------------------------- |\n",
      "     |  | `scale`            | `scale`        | No change to defaults       |\n",
      "     |  | `mode`             | `mode`         | No change to defaults       |\n",
      "     |  | `distribution`     | `distribution` | No change to defaults.      |\n",
      "     |  :                    :                : 'normal' maps to 'truncated_normal' :\n",
      "     |  | `seed`             | `seed`         | |\n",
      "     |  | `dtype`        |  `dtype` | The TF2 api only takes it  |\n",
      "     |  :                :          : as a `__call__` arg, not a constructor arg. :\n",
      "     |  | `partition_info`     | - |  (`__call__` arg in TF1) Not supported       |\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  With `distribution=\"truncated_normal\" or \"untruncated_normal\"`,\n",
      "     |  samples are drawn from a truncated/untruncated normal\n",
      "     |  distribution with a mean of zero and a standard deviation (after truncation,\n",
      "     |  if used) `stddev = sqrt(scale / n)`\n",
      "     |  where n is:\n",
      "     |    - number of input units in the weight tensor, if mode = \"fan_in\"\n",
      "     |    - number of output units, if mode = \"fan_out\"\n",
      "     |    - average of the numbers of input and output units, if mode = \"fan_avg\"\n",
      "     |  \n",
      "     |  With `distribution=\"uniform\"`, samples are drawn from a uniform distribution\n",
      "     |  within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    scale: Scaling factor (positive float).\n",
      "     |    mode: One of \"fan_in\", \"fan_out\", \"fan_avg\".\n",
      "     |    distribution: Random distribution to use. One of \"normal\", \"uniform\".\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |    ValueError: In case of an invalid value for the \"scale\", mode\" or\n",
      "     |      \"distribution\" arguments.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, scale=1.0, mode='fan_in', distribution='truncated_normal', seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENT VALUES (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENT VALUES ARE DEPRECATED: `(distribution='normal')`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      `normal` is a deprecated alias for `truncated_normal`\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    zeros_initializer = class Zeros(Initializer)\n",
      "     |  zeros_initializer(dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors initialized to 0.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  `tf.compat.v1.zeros_initializer` is compatible with eager execution\n",
      "     |  and `tf.function`.\n",
      "     |  \n",
      "     |  To migrate to TF2, please use `tf.zeros_initializer` instead. The `dtype`\n",
      "     |  argument in `tf.compat.v1.zeros_initializer.__init__()` does not exist in\n",
      "     |  `tf.zeros_initializer.__init__()`. However, you can specify the `dtype` in\n",
      "     |  `__call__()` in both cases.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.zeros_initializer(dtype=tf.float32)\n",
      "     |  variable = tf.Variable(initializer(shape=[3, 3]))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.zeros_initializer()\n",
      "     |  variable = tf.Variable(initializer(shape=[3, 3], dtype=tf.float32))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name         | TF2 Arg Name     | Note                       |\n",
      "     |  | :------------------- | :--------------- | :------------------------- |\n",
      "     |  | `dtype`              | `dtype`          | In `__call__()` method     |\n",
      "     |  | `partition_info`     | - |  (`__call__` arg in TF1) Not supported    |\n",
      "     |  \n",
      "     |  \n",
      "     |  #### Before & After Usage Example\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  >>> initializer = tf.compat.v1.zeros_initializer(dtype=tf.float32)\n",
      "     |  >>> tf.Variable(initializer(shape=[3])).numpy()\n",
      "     |  array([0., 0., 0.], dtype=float32)\n",
      "     |  >>> tf.Variable(initializer(shape=[3, 3])).numpy()\n",
      "     |  array([[0., 0., 0.],\n",
      "     |         [0., 0., 0.],\n",
      "     |         [0., 0., 0.]], dtype=float32)\n",
      "     |  >>> initializer = tf.compat.v1.zeros_initializer()\n",
      "     |  >>> tf.Variable(initializer(shape=[3], dtype=tf.float32)).numpy()\n",
      "     |  array([0., 0., 0.], dtype=float32)\n",
      "     |  >>> tf.Variable(initializer(shape=[3, 3], dtype=tf.float32)).numpy()\n",
      "     |  array([[0., 0., 0.],\n",
      "     |         [0., 0., 0.],\n",
      "     |         [0., 0., 0.]], dtype=float32)\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  >>> initializer = tf.zeros_initializer()\n",
      "     |  >>> tf.Variable(initializer(shape=[3], dtype=tf.float32)).numpy()\n",
      "     |  array([0., 0., 0.], dtype=float32)\n",
      "     |  >>> tf.Variable(initializer(shape=[3, 3], dtype=tf.float32)).numpy()\n",
      "     |  array([[0., 0., 0.],\n",
      "     |         [0., 0., 0.],\n",
      "     |         [0., 0., 0.]], dtype=float32)\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Zeros\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "FUNCTIONS\n",
      "    Assert(condition, data, summarize=None, name=None)\n",
      "        Asserts that the given condition is true.\n",
      "        \n",
      "        If `condition` evaluates to false, print the list of tensors in `data`.\n",
      "        `summarize` determines how many entries of the tensors to print.\n",
      "        \n",
      "        Args:\n",
      "          condition: The condition to evaluate.\n",
      "          data: The tensors to print out when condition is false.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          assert_op: An `Operation` that, when executed, raises a\n",
      "          `tf.errors.InvalidArgumentError` if `condition` is not true.\n",
      "          @compatibility(eager)\n",
      "          returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          @compatibility(TF1)\n",
      "          When in TF V1 mode (that is, outside `tf.function`) Assert needs a control\n",
      "          dependency on the output to ensure the assertion executes:\n",
      "        \n",
      "        ```python\n",
      "        # Ensure maximum element of x is smaller or equal to 1\n",
      "        assert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])\n",
      "        with tf.control_dependencies([assert_op]):\n",
      "          ... code using x ...\n",
      "        ```\n",
      "        \n",
      "          @end_compatibility\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    NoGradient = no_gradient(op_type: str) -> None\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    NotDifferentiable = no_gradient(op_type: str) -> None\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    Print(input_, data, message=None, first_n=None, summarize=None, name=None)\n",
      "        Prints a list of tensors. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2018-08-20.\n",
      "        Instructions for updating:\n",
      "        Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "        \n",
      "        \n",
      "        This is an identity op (behaves like `tf.identity`) with the side effect\n",
      "        of printing `data` when evaluating.\n",
      "        \n",
      "        Note: This op prints to the standard error. It is not currently compatible\n",
      "          with jupyter notebook (printing to the notebook *server's* output, not into\n",
      "          the notebook).\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is deprecated. Use `tf.print` instead. `tf.print` does not need the\n",
      "        `input_` argument.\n",
      "        \n",
      "        `tf.print` works in TF2 when executing eagerly and inside a `tf.function`.\n",
      "        \n",
      "        In TF1-styled sessions, an explicit control dependency declaration is needed\n",
      "        to execute the `tf.print` operation. Refer to the documentation of\n",
      "        `tf.print` for more details.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          input_: A tensor passed through this op.\n",
      "          data: A list of tensors to print out when op is evaluated.\n",
      "          message: A string, prefix of the error message.\n",
      "          first_n: Only log `first_n` number of times. Negative numbers log always;\n",
      "            this is the default.\n",
      "          summarize: Only print this many entries of each tensor. If None, then a\n",
      "            maximum of 3 elements are printed per input tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type and contents as `input_`.\n",
      "        \n",
      "          ```python\n",
      "          sess = tf.compat.v1.Session()\n",
      "          with sess.as_default():\n",
      "              tensor = tf.range(10)\n",
      "              print_op = tf.print(tensor)\n",
      "              with tf.control_dependencies([print_op]):\n",
      "                out = tf.add(tensor, tensor)\n",
      "              sess.run(out)\n",
      "          ```\n",
      "    \n",
      "    abs(x, name=None)\n",
      "        Computes the absolute value of a tensor.\n",
      "        \n",
      "        Given a tensor of integer or floating-point values, this operation returns a\n",
      "        tensor of the same type, where each element contains the absolute value of the\n",
      "        corresponding element in the input.\n",
      "        \n",
      "        Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "        `float32` or `float64` that is the absolute value of each element in `x`. For\n",
      "        a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
      "        \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> # real number\n",
      "        >>> x = tf.constant([-2.25, 3.25])\n",
      "        >>> tf.abs(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32,\n",
      "        numpy=array([2.25, 3.25], dtype=float32)>\n",
      "        \n",
      "        >>> # complex number\n",
      "        >>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "        >>> tf.abs(x)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
      "        array([[5.25594901],\n",
      "               [6.60492241]])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "            `int32`, `int64`, `complex64` or `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` of the same size, type and sparsity as `x`,\n",
      "            with absolute values. Note, for `complex64` or `complex128` input, the\n",
      "            returned `Tensor` will be of type `float32` or `float64`, respectively.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    accumulate_n(inputs, shape=None, tensor_dtype=None, name=None)\n",
      "        Returns the element-wise sum of a list of tensors. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.math.add_n` Instead\n",
      "        \n",
      "        Optionally, pass `shape` and `tensor_dtype` for shape and type checking,\n",
      "        otherwise, these are inferred.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([[1, 2], [3, 4]])\n",
      "        >>> b = tf.constant([[5, 0], [0, 6]])\n",
      "        >>> tf.math.accumulate_n([a, b, a]).numpy()\n",
      "        array([[ 7, 4],\n",
      "               [ 6, 14]], dtype=int32)\n",
      "        \n",
      "        >>> # Explicitly pass shape and type\n",
      "        >>> tf.math.accumulate_n(\n",
      "        ...     [a, b, a], shape=[2, 2], tensor_dtype=tf.int32).numpy()\n",
      "        array([[ 7,  4],\n",
      "               [ 6, 14]], dtype=int32)\n",
      "        \n",
      "        Note: The input must be a list or tuple. This function does not handle\n",
      "        `IndexedSlices`\n",
      "        \n",
      "        See Also:\n",
      "        \n",
      "        * `tf.reduce_sum(inputs, axis=0)` - This performe the same mathematical\n",
      "          operation, but `tf.add_n` may be more efficient because it sums the\n",
      "          tensors directly. `reduce_sum` on the other hand calls\n",
      "          `tf.convert_to_tensor` on the list of tensors, unncessairly stacking them\n",
      "          into a single tensor before summing.\n",
      "        * `tf.add_n` - This is another python wrapper for the same Op. It has\n",
      "          nearly identical functionality.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `Tensor` objects, each with same shape and type.\n",
      "          shape: Expected shape of elements of `inputs` (optional). Also controls the\n",
      "            output shape of this op, which may affect type inference in other ops. A\n",
      "            value of `None` means \"infer the input shape from the shapes in `inputs`\".\n",
      "          tensor_dtype: Expected data type of `inputs` (optional). A value of `None`\n",
      "            means \"infer the input dtype from `inputs[0]`\".\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of same shape and type as the elements of `inputs`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `inputs` don't all have same shape and dtype or the shape\n",
      "          cannot be inferred.\n",
      "    \n",
      "    acos(x, name=None)\n",
      "        Computes acos of x element-wise.\n",
      "        \n",
      "        Provided an input tensor, the `tf.math.acos` operation\n",
      "        returns the inverse cosine of each element of the tensor.\n",
      "        If `y = tf.math.cos(x)` then, `x = tf.math.acos(y)`.\n",
      "        \n",
      "        Input range is `[-1, 1]` and the output has a range of `[0, pi]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.0, -0.5, 3.4, 0.2, 0.0, -2], dtype = tf.float32)\n",
      "        >>> tf.math.acos(x)\n",
      "        <tf.Tensor: shape=(6,), dtype=float32,\n",
      "        numpy= array([0. , 2.0943952, nan, 1.3694383, 1.5707964, nan],\n",
      "        dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as x.\n",
      "    \n",
      "    acosh(x: Annotated[Any, ~TV_Acosh_T], name=None) -> Annotated[Any, ~TV_Acosh_T]\n",
      "        Computes inverse hyperbolic cosine of x element-wise.\n",
      "        \n",
      "        Given an input tensor, the function computes inverse hyperbolic cosine of every element.\n",
      "        Input range is `[1, inf]`. It returns `nan` if the input lies outside the range.\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "        tf.math.acosh(x) ==> [nan nan 0. 0.62236255 5.9914584 9.903487 inf]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    add(x, y, name=None)\n",
      "        Returns x + y element-wise.\n",
      "        \n",
      "        Example usages below.\n",
      "        \n",
      "        Add a scalar and a list:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = 1\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        Note that binary `+` operator can be used instead:\n",
      "        \n",
      "        >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "        >>> y = tf.convert_to_tensor(1)\n",
      "        >>> x + y\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        Add a tensor and a list of same shape:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "        \n",
      "        **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "        non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "        of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "        conversion.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "        >>> y = [2**7 + 1, 2**7 + 2]\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "        \n",
      "        When adding two input values of different shapes, `Add` follows NumPy\n",
      "        broadcasting rules. The two input array shapes are compared element-wise.\n",
      "        Starting with the trailing dimensions, the two dimensions either have to be\n",
      "        equal or one of them needs to be `1`.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "        >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "        >>> tf.add(x, y).shape.as_list()\n",
      "        [2, 2, 3, 3]\n",
      "        \n",
      "        Another example with two arrays of different dimension.\n",
      "        \n",
      "        >>> x = np.ones([1, 2, 1, 4])\n",
      "        >>> y = np.ones([3, 4])\n",
      "        >>> tf.add(x, y).shape.as_list()\n",
      "        [1, 2, 3, 4]\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "            float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "            int32, int64, complex64, complex128, string.\n",
      "          y: A `tf.Tensor`. Must have the same type as x.\n",
      "          name: A name for the operation (optional)\n",
      "    \n",
      "    add_check_numerics_ops()\n",
      "        Connect a `tf.debugging.check_numerics` to every floating point tensor.\n",
      "        \n",
      "        `check_numerics` operations themselves are added for each `half`, `float`,\n",
      "        or `double` tensor in the current default graph. For all ops in the graph, the\n",
      "        `check_numerics` op for all of its (`half`, `float`, or `double`) inputs\n",
      "        is guaranteed to run before the `check_numerics` op on any of its outputs.\n",
      "        \n",
      "        Note: This API is not compatible with the use of `tf.cond` or\n",
      "        `tf.while_loop`, and will raise a `ValueError` if you attempt to call it\n",
      "        in such a graph.\n",
      "        \n",
      "        Returns:\n",
      "          A `group` op depending on all `check_numerics` ops added.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the graph contains any numeric operations in a control flow\n",
      "            structure.\n",
      "          RuntimeError: If called with eager execution enabled.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Not compatible with eager execution. To check for `Inf`s and `NaN`s under\n",
      "        eager execution, call `tf.debugging.enable_check_numerics()` once before\n",
      "        executing the checked operations.\n",
      "        @end_compatibility\n",
      "    \n",
      "    add_n(inputs, name=None)\n",
      "        Returns the element-wise sum of a list of tensors.\n",
      "        \n",
      "        All inputs in the list must have the same shape. This op does not\n",
      "        [broadcast](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)\n",
      "        its inputs. If you need broadcasting, use `tf.math.add` (or the `+` operator)\n",
      "        instead.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([[3, 5], [4, 8]])\n",
      "        >>> b = tf.constant([[1, 6], [2, 9]])\n",
      "        >>> tf.math.add_n([a, b, a]).numpy()\n",
      "        array([[ 7, 16],\n",
      "               [10, 25]], dtype=int32)\n",
      "        \n",
      "        See Also:\n",
      "        \n",
      "        * `tf.reduce_sum(inputs, axis=0)` - This performs the same mathematical\n",
      "          operation, but `tf.add_n` may be more efficient because it sums the\n",
      "          tensors directly. `reduce_sum` on the other hand calls\n",
      "          `tf.convert_to_tensor` on the list of tensors, unnecessarily stacking them\n",
      "          into a single tensor before summing.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `tf.Tensor` or `tf.IndexedSlices` objects, each with the\n",
      "            same shape and type. `tf.IndexedSlices` objects will be converted into\n",
      "            dense tensors prior to adding.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of the same shape and type as the elements of `inputs`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `inputs` don't all have same shape and dtype or the shape\n",
      "          cannot be inferred.\n",
      "    \n",
      "    add_to_collection(name, value) -> None\n",
      "        Wrapper for `Graph.add_to_collection()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.add_to_collection`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          name: The key for the collection. For example, the `GraphKeys` class\n",
      "            contains many standard names for collections.\n",
      "          value: The value to add to the collection.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are only supported in eager when variables are created inside\n",
      "        an EagerVariableStore (e.g. as part of a layer or template).\n",
      "        @end_compatibility\n",
      "    \n",
      "    add_to_collections(names, value) -> None\n",
      "        Wrapper for `Graph.add_to_collections()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.add_to_collections`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          names: The key for the collections. The `GraphKeys` class contains many\n",
      "            standard names for collections.\n",
      "          value: The value to add to the collections.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are only supported in eager when variables are created inside\n",
      "        an EagerVariableStore (e.g. as part of a layer or template).\n",
      "        @end_compatibility\n",
      "    \n",
      "    all_variables()\n",
      "        Use `tf.compat.v1.global_variables` instead. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Please use tf.global_variables instead.\n",
      "    \n",
      "    angle(input, name=None)\n",
      "        Returns the element-wise argument of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the argument of each element in `input` considered as a complex number.\n",
      "        \n",
      "        The elements in `input` are considered to be complex numbers of the form\n",
      "        \\\\(a + bj\\\\), where *a* is the real part and *b* is the imaginary part.\n",
      "        If `input` is real then *b* is zero by definition.\n",
      "        \n",
      "        The argument returned by this function is of the form \\\\(atan2(b, a)\\\\).\n",
      "        If `input` is real, a tensor of all zeros is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        input = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j], dtype=tf.complex64)\n",
      "        tf.math.angle(input).numpy()\n",
      "        # ==> array([2.0131705, 1.056345 ], dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float`, `double`,\n",
      "            `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    approx_top_k(input: Annotated[Any, ~TV_ApproxTopK_T], k: int, reduction_dimension: int = -1, recall_target: float = 0.95, is_max_k: bool = True, reduction_input_size_override: int = -1, aggregate_to_topk: bool = True, name=None)\n",
      "        Returns min/max k values and their indices of the input operand in an approximate manner.\n",
      "        \n",
      "        See https://arxiv.org/abs/2206.14286 for the algorithm details.\n",
      "        This op is only optimized on TPU currently.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.\n",
      "            Array to search. Must be at least 1-D of the floating type\n",
      "          k: An `int` that is `>= 0`. Specifies the number of min/max-k.\n",
      "          reduction_dimension: An optional `int`. Defaults to `-1`.\n",
      "            Integer dimension along which to search. Default: -1.\n",
      "          recall_target: An optional `float`. Defaults to `0.95`.\n",
      "            Recall target for the approximation. Range in (0,1]\n",
      "          is_max_k: An optional `bool`. Defaults to `True`.\n",
      "            When true, computes max-k; otherwise computes min-k.\n",
      "          reduction_input_size_override: An optional `int`. Defaults to `-1`.\n",
      "            When set to a positive value, it overrides the size determined by\n",
      "            `input[reduction_dim]` for evaluating the recall. This option is useful when\n",
      "            the given `input` is only a subset of the overall computation in SPMD or\n",
      "            distributed pipelines, where the true input size cannot be deferred by the\n",
      "            `input` shape.\n",
      "          aggregate_to_topk: An optional `bool`. Defaults to `True`.\n",
      "            When true, aggregates approximate results to top-k. When false, returns the\n",
      "            approximate results. The number of the approximate results is implementation\n",
      "            defined and is greater equals to the specified `k`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (values, indices).\n",
      "        \n",
      "          values: A `Tensor`. Has the same type as `input`.\n",
      "          indices: A `Tensor` of type `int32`.\n",
      "    \n",
      "    arg_max(input: typing.Annotated[_any, ~TV_ArgMax_T], dimension: typing.Annotated[_any, ~TV_ArgMax_Tidx], output_type: ~TV_ArgMax_output_type = tf.int64, name=None) -> typing.Annotated[_any, ~TV_ArgMax_output_type]\n",
      "        Returns the index with the largest value across dimensions of a tensor. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.math.argmax` instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmax(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 4\n",
      "          # here a[4] = 166.32 which is the largest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`, `bool`.\n",
      "          dimension: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            int16, int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which dimension of the input Tensor to reduce across. For vectors,\n",
      "            use dimension = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int16, tf.uint16, tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    arg_min(input: typing.Annotated[_any, ~TV_ArgMin_T], dimension: typing.Annotated[_any, ~TV_ArgMin_Tidx], output_type: ~TV_ArgMin_output_type = tf.int64, name=None) -> typing.Annotated[_any, ~TV_ArgMin_output_type]\n",
      "        Returns the index with the smallest value across dimensions of a tensor. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.math.argmin` instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmin(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 0\n",
      "          # here a[0] = 1 which is the smallest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`, `bool`.\n",
      "          dimension: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which dimension of the input Tensor to reduce across. For vectors,\n",
      "            use dimension = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argmax(input, axis=None, name=None, dimension=None, output_type=tf.int64)\n",
      "        Returns the index with the largest value across axes of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dimension)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmax(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 4\n",
      "          # here a[4] = 166.32 which is the largest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`, `bool`.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            int16, int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which axis of the input Tensor to reduce across. For vectors,\n",
      "            use axis = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int16, tf.uint16, tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argmin(input, axis=None, name=None, dimension=None, output_type=tf.int64)\n",
      "        Returns the index with the smallest value across axes of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dimension)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmin(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 0\n",
      "          # here a[0] = 1 which is the smallest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`, `bool`.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which axis of the input Tensor to reduce across. For vectors,\n",
      "            use axis = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argsort(values, axis=-1, direction='ASCENDING', stable=False, name=None)\n",
      "        Returns the indices of a tensor that give its sorted order along an axis.\n",
      "        \n",
      "        >>> values = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        >>> sort_order = tf.argsort(values)\n",
      "        >>> sort_order.numpy()\n",
      "        array([0, 3, 1, 2, 5, 4], dtype=int32)\n",
      "        \n",
      "        For a 1D tensor:\n",
      "        \n",
      "        >>> sorted = tf.gather(values, sort_order)\n",
      "        >>> assert tf.reduce_all(sorted == tf.sort(values))\n",
      "        \n",
      "        For higher dimensions, the output has the same shape as\n",
      "        `values`, but along the given axis, values represent the index of the sorted\n",
      "        element in that slice of the tensor at the given position.\n",
      "        \n",
      "        >>> mat = [[30,20,10],\n",
      "        ...        [20,10,30],\n",
      "        ...        [10,30,20]]\n",
      "        >>> indices = tf.argsort(mat)\n",
      "        >>> indices.numpy()\n",
      "        array([[2, 1, 0],\n",
      "               [1, 0, 2],\n",
      "               [0, 2, 1]], dtype=int32)\n",
      "        \n",
      "        If `axis=-1` these indices can be used to apply a sort using `tf.gather`:\n",
      "        \n",
      "        >>> tf.gather(mat, indices, batch_dims=-1).numpy()\n",
      "        array([[10, 20, 30],\n",
      "               [10, 20, 30],\n",
      "               [10, 20, 30]], dtype=int32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "          * `tf.sort`: Sort along an axis.\n",
      "          * `tf.math.top_k`: A partial sort that returns a fixed number of top values\n",
      "            and corresponding indices.\n",
      "        \n",
      "        Args:\n",
      "          values: 1-D or higher **numeric** `Tensor`.\n",
      "          axis: The axis along which to sort. The default is -1, which sorts the last\n",
      "            axis.\n",
      "          direction: The direction in which to sort the values (`'ASCENDING'` or\n",
      "            `'DESCENDING'`).\n",
      "          stable: If True, equal elements in the original tensor will not be\n",
      "            re-ordered in the returned order. Unstable sort is not yet implemented,\n",
      "            but will eventually be the default for performance reasons. If you require\n",
      "            a stable order, pass `stable=True` for forwards compatibility.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          An int32 `Tensor` with the same shape as `values`. The indices that would\n",
      "              sort each slice of the given `values` along the given `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If axis is not a constant scalar, or the direction is invalid.\n",
      "          tf.errors.InvalidArgumentError: If the `values.dtype` is not a `float` or\n",
      "              `int` type.\n",
      "    \n",
      "    as_dtype(type_value)\n",
      "        Converts the given `type_value` to a `tf.DType`.\n",
      "        \n",
      "        Inputs can be existing `tf.DType` objects, a [`DataType`\n",
      "        enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),\n",
      "        a string type name, or a\n",
      "        [`numpy.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html).\n",
      "        \n",
      "        Examples:\n",
      "        >>> tf.as_dtype(2)  # Enum value for float64.\n",
      "        tf.float64\n",
      "        \n",
      "        >>> tf.as_dtype('float')\n",
      "        tf.float32\n",
      "        \n",
      "        >>> tf.as_dtype(np.int32)\n",
      "        tf.int32\n",
      "        \n",
      "        Note: `DType` values are interned (i.e. a single instance of each dtype is\n",
      "        stored in a map). When passed a new `DType` object, `as_dtype` always returns\n",
      "        the interned value.\n",
      "        \n",
      "        Args:\n",
      "          type_value: A value that can be converted to a `tf.DType` object.\n",
      "        \n",
      "        Returns:\n",
      "          A `DType` corresponding to `type_value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `type_value` cannot be converted to a `DType`.\n",
      "    \n",
      "    as_string(input: Annotated[Any, ~TV_AsString_T], precision: int = -1, scientific: bool = False, shortest: bool = False, width: int = -1, fill: str = '', name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Converts each entry in the given tensor to strings.\n",
      "        \n",
      "        Supports many numeric types and boolean.\n",
      "        \n",
      "        For Unicode, see the\n",
      "        [https://www.tensorflow.org/tutorials/representation/unicode](Working with Unicode text)\n",
      "        tutorial.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.strings.as_string([3, 2])\n",
      "        <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'3', b'2'], dtype=object)>\n",
      "        >>> tf.strings.as_string([3.1415926, 2.71828], precision=2).numpy()\n",
      "        array([b'3.14', b'2.72'], dtype=object)\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `complex64`, `complex128`, `bool`, `variant`, `string`.\n",
      "          precision: An optional `int`. Defaults to `-1`.\n",
      "            The post-decimal precision to use for floating point numbers.\n",
      "            Only used if precision > -1.\n",
      "          scientific: An optional `bool`. Defaults to `False`.\n",
      "            Use scientific notation for floating point numbers.\n",
      "          shortest: An optional `bool`. Defaults to `False`.\n",
      "            Use shortest representation (either scientific or standard) for\n",
      "            floating point numbers.\n",
      "          width: An optional `int`. Defaults to `-1`.\n",
      "            Pad pre-decimal numbers to this width.\n",
      "            Applies to both floating point and integer numbers.\n",
      "            Only used if width > -1.\n",
      "          fill: An optional `string`. Defaults to `\"\"`.\n",
      "            The value to pad if width > -1.  If empty, pads with spaces.\n",
      "            Another typical value is '0'.  String cannot be longer than 1 character.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    asin(x: typing.Annotated[_any, ~TV_Asin_T], name=None) -> typing.Annotated[_any, ~TV_Asin_T]\n",
      "        Computes the trignometric inverse sine of x element-wise.\n",
      "        \n",
      "        The `tf.math.asin` operation returns the inverse of `tf.math.sin`, such that\n",
      "        if `y = tf.math.sin(x)` then, `x = tf.math.asin(y)`.\n",
      "        \n",
      "        **Note**: The output of `tf.math.asin` will lie within the invertible range\n",
      "        of sine, i.e [-pi/2, pi/2].\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]\n",
      "        x = tf.constant([1.047, 0.785])\n",
      "        y = tf.math.sin(x) # [0.8659266, 0.7068252]\n",
      "        \n",
      "        tf.math.asin(y) # [1.047, 0.785] = x\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    asinh(x: typing.Annotated[_any, ~TV_Asinh_T], name=None) -> typing.Annotated[_any, ~TV_Asinh_T]\n",
      "        Computes inverse hyperbolic sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes inverse hyperbolic sine\n",
      "          for every element in the tensor. Both input and output has a range of\n",
      "          `[-inf, inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -2, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.asinh(x) ==> [-inf -1.4436355 -0.4812118 0.8813736 1.0159732 5.991471 9.903487 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    assert_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x == y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] == y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x == y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x == y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_equal` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_equal` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_equal(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_equal(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_equal(a, b,\n",
      "        ...     message='\"a == b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[1, 2]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_equal(a, b, message=\n",
      "        ...   '\"a == b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_greater(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x > y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] > y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_greater(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_greater\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x > y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x > y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_greater` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_greater` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_greater(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_greater(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_greater(a, b,\n",
      "        ...     message='\"a > b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[0, 1]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([0, 1], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_greater(a, b, message=\n",
      "        ...   '\"a > b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_greater_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x >= y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] >= y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_greater_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_greater_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x >= y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x >= y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_greater_equal` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_greater_equal` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_greater_equal(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_greater_equal(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_greater_equal(a, b,\n",
      "        ...     message='\"a >= b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[1, 0]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([1, 0], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_greater_equal(a, b, message=\n",
      "        ...   '\"a >= b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_integer(x, message=None, name=None)\n",
      "        Assert that `x` is of integer dtype.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_integer(x)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` whose basetype is integer and is not quantized.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_integer\".\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  If `x.dtype` is anything other than non-quantized integer.\n",
      "        \n",
      "        Returns:\n",
      "          A `no_op` that does nothing.  Type can be determined statically.\n",
      "    \n",
      "    assert_less(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x < y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] < y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_less(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_less\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x < y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x < y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_less` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_less` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_less(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_less(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_less(a, b,\n",
      "        ...     message='\"a < b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[2, 3]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([2, 3], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_less(a, b, message=\n",
      "        ...   '\"a < b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_less_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x <= y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] <= y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_less_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_less_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x <= y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x <= y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_less_equal` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_less_equal` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_less_equal(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_less_equal(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_less_equal(a, b,\n",
      "        ...     message='\"a <= b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[1, 3]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([1, 3], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_less_equal(a, b, message=\n",
      "        ...   '\"a <= b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_near(x, y, rtol=None, atol=None, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x` and `y` are close element-wise.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_near(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have\n",
      "        \n",
      "        ```tf.abs(x[i] - y[i]) <= atol + rtol * tf.abs(y[i])```.\n",
      "        \n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        The default `atol` and `rtol` is `10 * eps`, where `eps` is the smallest\n",
      "        representable positive number such that `1 + eps != 1`.  This is about\n",
      "        `1.2e-6` in `32bit`, `2.22e-15` in `64bit`, and `0.00977` in `16bit`.\n",
      "        See `numpy.finfo`.\n",
      "        \n",
      "        Args:\n",
      "          x:  Float or complex `Tensor`.\n",
      "          y:  Float or complex `Tensor`, same `dtype` as, and broadcastable to, `x`.\n",
      "          rtol:  `Tensor`.  Same `dtype` as, and broadcastable to, `x`.\n",
      "            The relative tolerance.  Default is `10 * eps`.\n",
      "          atol:  `Tensor`.  Same `dtype` as, and broadcastable to, `x`.\n",
      "            The absolute tolerance.  Default is `10 * eps`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_near\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x` and `y` are not close enough.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Similar to `numpy.testing.assert_allclose`, except tolerance depends on data\n",
      "        type. This is due to the fact that `TensorFlow` is often used with `32bit`,\n",
      "        `64bit`, and even `16bit` data.\n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_negative(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x < 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_negative(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Negative means, for every element `x[i]` of `x`, we have `x[i] < 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_negative\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x < 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x < 0` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_non_negative(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x >= 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_non_negative(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Non-negative means, for every element `x[i]` of `x`, we have `x[i] >= 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_non_negative\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x >= 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x >= 0` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_non_positive(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x <= 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_non_positive(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Non-positive means, for every element `x[i]` of `x`, we have `x[i] <= 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_non_positive\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x <= 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x <= 0` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_none_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x != y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] != y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_none_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_none_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x != y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x != y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_none_equal` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_none_equal` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_none_equal(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_none_equal(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_none_equal(a, b,\n",
      "        ...     message='\"a != b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[2, 1]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([2, 1], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_none_equal(a, b, message=\n",
      "        ...   '\"a != b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_positive(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x > 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_positive(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Positive means, for every element `x[i]` of `x`, we have `x[i] > 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_positive\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x > 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x > 0` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_proper_iterable(values)\n",
      "        Static assert that values is a \"proper\" iterable.\n",
      "        \n",
      "        `Ops` that expect iterables of `Tensor` can call this to validate input.\n",
      "        Useful since `Tensor`, `ndarray`, byte/text type are all iterables themselves.\n",
      "        \n",
      "        Args:\n",
      "          values:  Object to be checked.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  If `values` is not iterable or is one of\n",
      "            `Tensor`, `SparseTensor`, `np.array`, `tf.compat.bytes_or_text_types`.\n",
      "    \n",
      "    assert_rank(x, rank, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank equal to `rank`.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank(x, 2)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          rank:  Scalar integer `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and the shape of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_rank\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless `x` has specified rank.\n",
      "          If static checks determine `x` has correct rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has wrong rank.\n",
      "    \n",
      "    assert_rank_at_least(x, rank, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank equal to `rank` or higher.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank_at_least(x, 2)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          rank:  Scalar `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"assert_rank_at_least\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless `x` has specified rank or higher.\n",
      "          If static checks determine `x` has correct rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has wrong rank.\n",
      "    \n",
      "    assert_rank_in(x, ranks, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank in `ranks`.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank_in(x, (2, 4))]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          ranks:  Iterable of scalar `Tensor` objects.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"assert_rank_in\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless rank of `x` is in `ranks`.\n",
      "          If static checks determine `x` has matching rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has mismatched rank.\n",
      "    \n",
      "    assert_same_float_dtype(tensors=None, dtype=None)\n",
      "        Validate and return float type based on `tensors` and `dtype`.\n",
      "        \n",
      "        For ops such as matrix multiplication, inputs and weights must be of the\n",
      "        same float type. This function validates that all `tensors` are the same type,\n",
      "        validates that type is `dtype` (if supplied), and returns the type. Type must\n",
      "        be a floating point type. If neither `tensors` nor `dtype` is supplied,\n",
      "        the function will return `dtypes.float32`.\n",
      "        \n",
      "        Args:\n",
      "          tensors: Tensors of input values. Can include `None` elements, which will be\n",
      "              ignored.\n",
      "          dtype: Expected type.\n",
      "        \n",
      "        Returns:\n",
      "          Validated type.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if neither `tensors` nor `dtype` is supplied, or result is not\n",
      "              float, or the common type of the inputs is not a floating point type.\n",
      "    \n",
      "    assert_scalar(tensor, name=None, message=None)\n",
      "        Asserts that the given `tensor` is a scalar (i.e. zero-dimensional).\n",
      "        \n",
      "        This function raises `ValueError` unless it can be certain that the given\n",
      "        `tensor` is a scalar. `ValueError` is also raised if the shape of `tensor` is\n",
      "        unknown.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          name:  A name for this operation. Defaults to \"assert_scalar\"\n",
      "          message: A string to prefix to the default message.\n",
      "        \n",
      "        Returns:\n",
      "          The input tensor (potentially converted to a `Tensor`).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the tensor is not scalar (rank 0), or if its shape is\n",
      "            unknown.\n",
      "    \n",
      "    assert_type(tensor, tf_type, message=None, name=None)\n",
      "        Statically asserts that the given `Tensor` is of the specified type.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor` or `SparseTensor`.\n",
      "          tf_type: A tensorflow type (`dtypes.float32`, `tf.int64`, `dtypes.bool`,\n",
      "            etc).\n",
      "          message: A string to prefix to the default message.\n",
      "          name:  A name to give this `Op`.  Defaults to \"assert_type\"\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the tensors data type doesn't match `tf_type`.\n",
      "        \n",
      "        Returns:\n",
      "          A `no_op` that does nothing.  Type can be determined statically.\n",
      "    \n",
      "    assert_variables_initialized(var_list=None)\n",
      "        Returns an Op to check if variables are initialized.\n",
      "        \n",
      "        NOTE: This function is obsolete and will be removed in 6 months.  Please\n",
      "        change your implementation to use `report_uninitialized_variables()`.\n",
      "        \n",
      "        When run, the returned Op will raise the exception `FailedPreconditionError`\n",
      "        if any of the variables has not yet been initialized.\n",
      "        \n",
      "        Note: This function is implemented by trying to fetch the values of the\n",
      "        variables. If one of the variables is not initialized a message may be\n",
      "        logged by the C++ runtime. This is expected.\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to check. Defaults to the value of\n",
      "            `global_variables().`\n",
      "        \n",
      "        Returns:\n",
      "          An Op, or None if there are no variables.\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    assign(ref, value, validate_shape=None, use_locking=None, name=None)\n",
      "        Update `ref` by assigning `value` to it.\n",
      "        \n",
      "        This operation outputs a Tensor that holds the new value of `ref` after\n",
      "        the value has been assigned. This makes it easier to chain operations that\n",
      "        need to use the reset value.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Should be from a `Variable` node. May be\n",
      "            uninitialized.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be assigned to the variable.\n",
      "          validate_shape: An optional `bool`. Defaults to `True`. If true, the\n",
      "            operation will validate that the shape of 'value' matches the shape of the\n",
      "            Tensor being assigned to.  If false, 'ref' will take on the shape of\n",
      "            'value'.\n",
      "          use_locking: An optional `bool`. Defaults to `True`. If True, the assignment\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that will hold the new value of `ref` after\n",
      "            the assignment has completed.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assign` is mostly compatible with eager\n",
      "        execution and `tf.function`. However, argument 'validate_shape' will be\n",
      "        ignored. To avoid shape validation, set 'shape' to tf.TensorShape(None) when\n",
      "        constructing the variable:\n",
      "        \n",
      "        >>> import tensorflow as tf\n",
      "        >>> a = tf.Variable([1], shape=tf.TensorShape(None))\n",
      "        >>> tf.compat.v1.assign(a, [2,3])\n",
      "        \n",
      "        To switch to the native TF2 style, one could use method 'assign' of\n",
      "        `tf.Variable`:\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "        | :-------------------- | :-------------- | :------------------------- |\n",
      "        | `ref`                 | `self`          | In `assign()` method       |\n",
      "        | `value`               | `value`         | In `assign()` method       |\n",
      "        | `validate_shape`      | Not supported   | Specify `shape` in the     |\n",
      "        :                       :                 : constructor to replicate   :\n",
      "        :                       :                 : behavior                   :\n",
      "        | `use_locking`         | `use_locking`   | In `assign()` method       |\n",
      "        | `name`                | `name`          | In `assign()` method       |\n",
      "        | -                     | `read_value`    | Set to True to replicate   |\n",
      "        :                       :                 : behavior (True is default) :\n",
      "        @end_compatibility\n",
      "        \n",
      "        \n",
      "        #### Before & After Usage Example\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> with tf.Graph().as_default():\n",
      "        ...   with tf.compat.v1.Session() as sess:\n",
      "        ...     a = tf.compat.v1.Variable(0, dtype=tf.int64)\n",
      "        ...     sess.run(a.initializer)\n",
      "        ...     update_op = tf.compat.v1.assign(a, 2)\n",
      "        ...     res_a = sess.run(update_op)\n",
      "        ...     res_a\n",
      "        2\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> b = tf.Variable(0, dtype=tf.int64)\n",
      "        >>> res_b = b.assign(2)\n",
      "        >>> res_b.numpy()\n",
      "        2\n",
      "    \n",
      "    assign_add(ref, value, use_locking=None, name=None)\n",
      "        Update `ref` by adding `value` to it.\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        Unlike `tf.math.add`, this op does not broadcast. `ref` and `value` must have\n",
      "        the same shape.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`,\n",
      "            `complex64`, `complex128`, `qint8`, `quint8`, `qint32`, `half`. Should be\n",
      "            from a `Variable` node.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be added to the variable.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the addition\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the new value after the variable has been updated.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assign_add` is mostly compatible with eager\n",
      "        execution and `tf.function`.\n",
      "        \n",
      "        To switch to the native TF2 style, one could use method 'assign_add' of\n",
      "        `tf.Variable`:\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "        | :-------------------- | :-------------- | :------------------------- |\n",
      "        | `ref`                 | `self`          | In `assign_add()` method   |\n",
      "        | `value`               | `value`         | In `assign_add()` method   |\n",
      "        | `use_locking`         | `use_locking`   | In `assign_add()` method   |\n",
      "        | `name`                | `name`          | In `assign_add()` method   |\n",
      "        | -                     | `read_value`    | Set to True to replicate   |\n",
      "        :                       :                 : behavior (True is default) :\n",
      "        \n",
      "        \n",
      "        #### Before & After Usage Example\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> with tf.Graph().as_default():\n",
      "        ...   with tf.compat.v1.Session() as sess:\n",
      "        ...     a = tf.compat.v1.Variable(0, dtype=tf.int64)\n",
      "        ...     sess.run(a.initializer)\n",
      "        ...     update_op = tf.compat.v1.assign_add(a, 1)\n",
      "        ...     res_a = sess.run(update_op)\n",
      "        ...     res_a\n",
      "        1\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> b = tf.Variable(0, dtype=tf.int64)\n",
      "        >>> res_b = b.assign_add(1)\n",
      "        >>> res_b.numpy()\n",
      "        1\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assign_sub(ref, value, use_locking=None, name=None)\n",
      "        Update `ref` by subtracting `value` from it.\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        Unlike `tf.math.subtract`, this op does not broadcast. `ref` and `value`\n",
      "        must have the same shape.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`,\n",
      "            `complex64`, `complex128`, `qint8`, `quint8`, `qint32`, `half`. Should be\n",
      "            from a `Variable` node.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be subtracted to the variable.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the\n",
      "            subtraction will be protected by a lock; otherwise the behavior is\n",
      "            undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the new value after the variable has been updated.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assign_sub` is mostly compatible with eager\n",
      "        execution and `tf.function`.\n",
      "        \n",
      "        To switch to the native TF2 style, one could use method 'assign_sub' of\n",
      "        `tf.Variable`:\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "        | :-------------------- | :-------------- | :------------------------- |\n",
      "        | `ref`                 | `self`          | In `assign_sub()` method   |\n",
      "        | `value`               | `value`         | In `assign_sub()` method   |\n",
      "        | `use_locking`         | `use_locking`   | In `assign_sub()` method   |\n",
      "        | `name`                | `name`          | In `assign_sub()` method   |\n",
      "        | -                     | `read_value`    | Set to True to replicate   |\n",
      "        :                       :                 : behavior (True is default) :\n",
      "        \n",
      "        \n",
      "        #### Before & After Usage Example\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> with tf.Graph().as_default():\n",
      "        ...   with tf.compat.v1.Session() as sess:\n",
      "        ...     a = tf.compat.v1.Variable(1, dtype=tf.int64)\n",
      "        ...     sess.run(a.initializer)\n",
      "        ...     update_op = tf.compat.v1.assign_sub(a, 1)\n",
      "        ...     res_a = sess.run(update_op)\n",
      "        ...     res_a\n",
      "        0\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> b = tf.Variable(1, dtype=tf.int64)\n",
      "        >>> res_b = b.assign_sub(1)\n",
      "        >>> res_b.numpy()\n",
      "        0\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    atan(x: typing.Annotated[_any, ~TV_Atan_T], name=None) -> typing.Annotated[_any, ~TV_Atan_T]\n",
      "        Computes the trignometric inverse tangent of x element-wise.\n",
      "        \n",
      "        The `tf.math.atan` operation returns the inverse of `tf.math.tan`, such that\n",
      "        if `y = tf.math.tan(x)` then, `x = tf.math.atan(y)`.\n",
      "        \n",
      "        **Note**: The output of `tf.math.atan` will lie within the invertible range\n",
      "        of tan, i.e (-pi/2, pi/2).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]\n",
      "        x = tf.constant([1.047, 0.785])\n",
      "        y = tf.math.tan(x) # [1.731261, 0.99920404]\n",
      "        \n",
      "        tf.math.atan(y) # [1.047, 0.785] = x\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    atan2(y: typing.Annotated[_any, ~TV_Atan2_T], x: typing.Annotated[_any, ~TV_Atan2_T], name=None) -> typing.Annotated[_any, ~TV_Atan2_T]\n",
      "        Computes arctangent of `y/x` element-wise, respecting signs of the arguments.\n",
      "        \n",
      "        This is the angle \\\\( \\theta \\in [-\\pi, \\pi] \\\\) such that\n",
      "        \\\\[ x = r \\cos(\\theta) \\\\]\n",
      "        and\n",
      "        \\\\[ y = r \\sin(\\theta) \\\\]\n",
      "        where \\\\(r = \\sqrt{x^2 + y^2} \\\\).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = [1., 1.]\n",
      "        >>> y = [1., -1.]\n",
      "        >>> print((tf.math.atan2(y,x) * (180 / np.pi)).numpy())\n",
      "        [ 45. -45.]\n",
      "        \n",
      "        Args:\n",
      "          y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `y`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `y`.\n",
      "    \n",
      "    atanh(x: typing.Annotated[_any, ~TV_Atanh_T], name=None) -> typing.Annotated[_any, ~TV_Atanh_T]\n",
      "        Computes inverse hyperbolic tangent of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes inverse hyperbolic tangent\n",
      "          for every element in the tensor. Input range is `[-1,1]` and output range is\n",
      "          `[-inf, inf]`. If input is `-1`, output will be `-inf` and if the\n",
      "          input is `1`, output will be `inf`. Values outside the range will have\n",
      "          `nan` as output.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -1, -0.5, 1, 0, 0.5, 10, float(\"inf\")])\n",
      "          tf.math.atanh(x) ==> [nan -inf -0.54930615 inf  0. 0.54930615 nan nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    batch_gather(params, indices, name=None)\n",
      "        Gather slices from params according to indices with leading batch dims. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-10-25.\n",
      "        Instructions for updating:\n",
      "        `tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=tf.rank(indices) - 1` instead.\n",
      "    \n",
      "    batch_scatter_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Generalization of `tf.compat.v1.scatter_update` to axis different than 0. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2018-11-29.\n",
      "        Instructions for updating:\n",
      "        Use the batch_scatter_update method of Variable instead.\n",
      "        \n",
      "        Analogous to `batch_gather`. This assumes that `ref`, `indices` and `updates`\n",
      "        have a series of leading dimensions that are the same for all of them, and the\n",
      "        updates are performed on the last dimension of indices. In other words, the\n",
      "        dimensions should be the following:\n",
      "        \n",
      "        `num_prefix_dims = indices.ndims - 1`\n",
      "        `batch_dim = num_prefix_dims + 1`\n",
      "        `updates.shape = indices.shape + var.shape[batch_dim:]`\n",
      "        \n",
      "        where\n",
      "        \n",
      "        `updates.shape[:num_prefix_dims]`\n",
      "        `== indices.shape[:num_prefix_dims]`\n",
      "        `== var.shape[:num_prefix_dims]`\n",
      "        \n",
      "        And the operation performed can be expressed as:\n",
      "        \n",
      "        `var[i_1, ..., i_n, indices[i_1, ..., i_n, j]] = updates[i_1, ..., i_n, j]`\n",
      "        \n",
      "        When indices is a 1D tensor, this operation is equivalent to\n",
      "        `tf.compat.v1.scatter_update`.\n",
      "        \n",
      "        To avoid this operation there would be 2 alternatives:\n",
      "        1) Reshaping the variable by merging the first `ndims` dimensions. However,\n",
      "           this is not possible because `tf.reshape` returns a Tensor, which we\n",
      "           cannot use `tf.compat.v1.scatter_update` on.\n",
      "        2) Looping over the first `ndims` of the variable and using\n",
      "           `tf.compat.v1.scatter_update` on the subtensors that result of slicing the\n",
      "           first\n",
      "           dimension. This is a valid option for `ndims = 1`, but less efficient than\n",
      "           this implementation.\n",
      "        \n",
      "        See also `tf.compat.v1.scatter_update` and `tf.compat.v1.scatter_nd_update`.\n",
      "        \n",
      "        Args:\n",
      "          ref: `Variable` to scatter onto.\n",
      "          indices: Tensor containing indices as described above.\n",
      "          updates: Tensor of updates to apply to `ref`.\n",
      "          use_locking: Boolean indicating whether to lock the writing operation.\n",
      "          name: Optional scope name string.\n",
      "        \n",
      "        Returns:\n",
      "          Ref to `variable` after it has been modified.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the initial `ndims` of `ref`, `indices`, and `updates` are\n",
      "              not the same.\n",
      "    \n",
      "    batch_to_space(input, crops, block_size, name=None, block_shape=None)\n",
      "        BatchToSpace for 4-D tensors of type T.\n",
      "        \n",
      "        This is a legacy version of the more general BatchToSpaceND.\n",
      "        \n",
      "        Rearranges (permutes) data from batch into blocks of spatial data, followed by\n",
      "        cropping. This is the reverse transformation of SpaceToBatch. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `batch`\n",
      "        dimension are moved in spatial blocks to the `height` and `width` dimensions,\n",
      "        followed by cropping along the `height` and `width` dimensions.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. 4-D tensor with shape\n",
      "            `[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,\n",
      "              depth]`. Note that the batch size of the input tensor must be divisible by\n",
      "            `block_size * block_size`.\n",
      "          crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D tensor of non-negative integers with shape `[2, 2]`. It specifies\n",
      "            how many elements to crop from the intermediate result across the spatial\n",
      "            dimensions as follows:\n",
      "        \n",
      "                crops = [[crop_top, crop_bottom], [crop_left, crop_right]]\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    batch_to_space_nd(input: Annotated[Any, ~TV_BatchToSpaceND_T], block_shape: Annotated[Any, ~TV_BatchToSpaceND_Tblock_shape], crops: Annotated[Any, ~TV_BatchToSpaceND_Tcrops], name=None) -> Annotated[Any, ~TV_BatchToSpaceND_T]\n",
      "        BatchToSpace for N-D tensors of type T.\n",
      "        \n",
      "        This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of shape\n",
      "        `block_shape + [batch]`, interleaves these blocks back into the grid defined by\n",
      "        the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as\n",
      "        the input.  The spatial dimensions of this intermediate result are then\n",
      "        optionally cropped according to `crops` to produce the output.  This is the\n",
      "        reverse of SpaceToBatch.  See below for a precise description.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "            N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,\n",
      "            where spatial_shape has M dimensions.\n",
      "          block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with shape `[M]`, all values must be >= 1.\n",
      "          crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D with shape `[M, 2]`, all values must be >= 0.\n",
      "              `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input\n",
      "              dimension `i + 1`, which corresponds to spatial dimension `i`.  It is\n",
      "              required that\n",
      "              `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.\n",
      "        \n",
      "            This operation is equivalent to the following steps:\n",
      "        \n",
      "            1. Reshape `input` to `reshaped` of shape:\n",
      "                 [block_shape[0], ..., block_shape[M-1],\n",
      "                  batch / prod(block_shape),\n",
      "                  input_shape[1], ..., input_shape[N-1]]\n",
      "        \n",
      "            2. Permute dimensions of `reshaped` to produce `permuted` of shape\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1], block_shape[0],\n",
      "                  ...,\n",
      "                  input_shape[M], block_shape[M-1],\n",
      "        \n",
      "                  input_shape[M+1], ..., input_shape[N-1]]\n",
      "        \n",
      "            3. Reshape `permuted` to produce `reshaped_permuted` of shape\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1] * block_shape[0],\n",
      "                  ...,\n",
      "                  input_shape[M] * block_shape[M-1],\n",
      "        \n",
      "                  input_shape[M+1],\n",
      "                  ...,\n",
      "                  input_shape[N-1]]\n",
      "        \n",
      "            4. Crop the start and end of dimensions `[1, ..., M]` of\n",
      "               `reshaped_permuted` according to `crops` to produce the output of shape:\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],\n",
      "                  ...,\n",
      "                  input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],\n",
      "        \n",
      "                  input_shape[M+1], ..., input_shape[N-1]]\n",
      "        \n",
      "            Some examples:\n",
      "        \n",
      "            (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 2, 2, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [2]], [[3], [4]]]]\n",
      "            ```\n",
      "        \n",
      "            (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 2, 2, 3]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "                  [[7, 8, 9], [10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [3]], [[9], [11]]],\n",
      "                 [[[2], [4]], [[10], [12]]],\n",
      "                 [[[5], [7]], [[13], [15]]],\n",
      "                 [[[6], [8]], [[14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 4, 4, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                 [[5],   [6],  [7],  [8]],\n",
      "                 [[9],  [10], [11],  [12]],\n",
      "                 [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "        \n",
      "            (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [2, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[0], [1], [3]]], [[[0], [9], [11]]],\n",
      "                 [[[0], [2], [4]]], [[[0], [10], [12]]],\n",
      "                 [[[0], [5], [7]]], [[[0], [13], [15]]],\n",
      "                 [[[0], [6], [8]]], [[[0], [14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[2, 2, 4, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                  [[5],   [6],  [7],  [8]]],\n",
      "                 [[[9],  [10], [11],  [12]],\n",
      "                  [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    betainc(a: typing.Annotated[_any, ~TV_Betainc_T], b: typing.Annotated[_any, ~TV_Betainc_T], x: typing.Annotated[_any, ~TV_Betainc_T], name=None) -> typing.Annotated[_any, ~TV_Betainc_T]\n",
      "        Compute the regularized incomplete beta integral \\\\(I_x(a, b)\\\\).\n",
      "        \n",
      "        The regularized incomplete beta integral is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(I_x(a, b) = \\frac{B(x; a, b)}{B(a, b)}\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \n",
      "        \\\\(B(x; a, b) = \\int_0^x t^{a-1} (1 - t)^{b-1} dt\\\\)\n",
      "        \n",
      "        \n",
      "        is the incomplete beta function and \\\\(B(a, b)\\\\) is the *complete*\n",
      "        beta function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          b: A `Tensor`. Must have the same type as `a`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    bincount = bincount_v1(arr, weights=None, minlength=None, maxlength=None, dtype=tf.int32)\n",
      "        Counts the number of occurrences of each value in an integer array.\n",
      "        \n",
      "        If `minlength` and `maxlength` are not given, returns a vector with length\n",
      "        `tf.reduce_max(arr) + 1` if `arr` is non-empty, and length 0 otherwise.\n",
      "        If `weights` are non-None, then index `i` of the output stores the sum of the\n",
      "        value in `weights` at each index where the corresponding value in `arr` is\n",
      "        `i`.\n",
      "        \n",
      "        Args:\n",
      "          arr: An int32 tensor of non-negative values.\n",
      "          weights: If non-None, must be the same shape as arr. For each value in\n",
      "            `arr`, the bin will be incremented by the corresponding weight instead of\n",
      "            1.\n",
      "          minlength: If given, ensures the output has length at least `minlength`,\n",
      "            padding with zeros at the end if necessary.\n",
      "          maxlength: If given, skips values in `arr` that are equal or greater than\n",
      "            `maxlength`, ensuring that the output has length at most `maxlength`.\n",
      "          dtype: If `weights` is None, determines the type of the output bins.\n",
      "        \n",
      "        Returns:\n",
      "          A vector with the same dtype as `weights` or the given `dtype`. The bin\n",
      "          values.\n",
      "    \n",
      "    bitcast(input: Annotated[Any, ~TV_Bitcast_T], type: ~TV_Bitcast_type, name=None) -> Annotated[Any, ~TV_Bitcast_type]\n",
      "        Bitcasts a tensor from one type to another without copying data.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor that has the same buffer\n",
      "        data as `input` with datatype `type`.\n",
      "        \n",
      "        If the input datatype `T` is larger than the output datatype `type` then the\n",
      "        shape changes from [...] to [..., sizeof(`T`)/sizeof(`type`)].\n",
      "        \n",
      "        If `T` is smaller than `type`, the operator requires that the rightmost\n",
      "        dimension be equal to sizeof(`type`)/sizeof(`T`). The shape then goes from\n",
      "        [..., sizeof(`type`)/sizeof(`T`)] to [...].\n",
      "        \n",
      "        tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype\n",
      "        (e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast()\n",
      "        gives module error.\n",
      "        For example,\n",
      "        \n",
      "        Example 1:\n",
      "        \n",
      "        >>> a = [1., 2., 3.]\n",
      "        >>> equality_bitcast = tf.bitcast(a, tf.complex128)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError: Cannot bitcast from 1 to 18 [Op:Bitcast]\n",
      "        >>> equality_cast = tf.cast(a, tf.complex128)\n",
      "        >>> print(equality_cast)\n",
      "        tf.Tensor([1.+0.j 2.+0.j 3.+0.j], shape=(3,), dtype=complex128)\n",
      "        \n",
      "        Example 2:\n",
      "        \n",
      "        >>> tf.bitcast(tf.constant(0xffffffff, dtype=tf.uint32), tf.uint8)\n",
      "        <tf.Tensor: shape=(4,), dtype=uint8, numpy=array([255, 255, 255, 255], dtype=uint8)>\n",
      "        \n",
      "        Example 3:\n",
      "        \n",
      "        >>> x = [1., 2., 3.]\n",
      "        >>> y = [0., 2., 3.]\n",
      "        >>> equality= tf.equal(x,y)\n",
      "        >>> equality_cast = tf.cast(equality,tf.float32)\n",
      "        >>> equality_bitcast = tf.bitcast(equality_cast,tf.uint8)\n",
      "        >>> print(equality)\n",
      "        tf.Tensor([False True True], shape=(3,), dtype=bool)\n",
      "        >>> print(equality_cast)\n",
      "        tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)\n",
      "        >>> print(equality_bitcast)\n",
      "        tf.Tensor(\n",
      "            [[  0   0   0   0]\n",
      "             [  0   0 128  63]\n",
      "             [  0   0 128  63]], shape=(3, 4), dtype=uint8)\n",
      "        \n",
      "        *NOTE*: Bitcast is implemented as a low-level cast, so machines with different\n",
      "        endian orderings will give different results. A copy from input buffer to output\n",
      "        buffer is made on BE machines when types are of different sizes in order to get\n",
      "        the same casting results as on LE machines.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `complex64`, `complex128`, `qint8`, `quint8`, `qint16`, `quint16`, `qint32`.\n",
      "          type: A `tf.DType` from: `tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `type`.\n",
      "    \n",
      "    boolean_mask(tensor, mask, name='boolean_mask', axis=None)\n",
      "        Apply boolean mask to tensor.\n",
      "        \n",
      "        Numpy equivalent is `tensor[mask]`.\n",
      "        \n",
      "        In general, `0 < dim(mask) = K <= dim(tensor)`, and `mask`'s shape must match\n",
      "        the first K dimensions of `tensor`'s shape.  We then have:\n",
      "          `boolean_mask(tensor, mask)[i, j1,...,jd] = tensor[i1,...,iK,j1,...,jd]`\n",
      "        where `(i1,...,iK)` is the ith `True` entry of `mask` (row-major order).\n",
      "        The `axis` could be used with `mask` to indicate the axis to mask from.\n",
      "        In that case, `axis + dim(mask) <= dim(tensor)` and `mask`'s shape must match\n",
      "        the first `axis + dim(mask)` dimensions of `tensor`'s shape.\n",
      "        \n",
      "        See also: `tf.ragged.boolean_mask`, which can be applied to both dense and\n",
      "        ragged tensors, and can be used if you need to preserve the masked dimensions\n",
      "        of `tensor` (rather than flattening them, as `tf.boolean_mask` does).\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        # 1-D example\n",
      "        tensor = [0, 1, 2, 3]\n",
      "        mask = np.array([True, False, True, False])\n",
      "        tf.boolean_mask(tensor, mask)  # [0, 2]\n",
      "        \n",
      "        # 2-D example\n",
      "        tensor = [[1, 2], [3, 4], [5, 6]]\n",
      "        mask = np.array([True, False, True])\n",
      "        tf.boolean_mask(tensor, mask)  # [[1, 2], [5, 6]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor:  N-D Tensor.\n",
      "          mask:  K-D boolean Tensor, K <= N and K must be known statically.\n",
      "          name:  A name for this operation (optional).\n",
      "          axis:  A 0-D int Tensor representing the axis in `tensor` to mask from. By\n",
      "            default, axis is 0 which will mask from the first dimension. Otherwise K +\n",
      "            axis <= N.\n",
      "        \n",
      "        Returns:\n",
      "          (N-K+1)-dimensional tensor populated by entries in `tensor` corresponding\n",
      "          to `True` values in `mask`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If shapes do not conform.\n",
      "    \n",
      "    broadcast_dynamic_shape(shape_x, shape_y)\n",
      "        Computes the shape of a broadcast given symbolic shapes.\n",
      "        \n",
      "        When `shape_x` and `shape_y` are Tensors representing shapes (i.e. the result\n",
      "        of calling tf.shape on another Tensor) this computes a Tensor which is the\n",
      "        shape of the result of a broadcasting op applied in tensors of shapes\n",
      "        `shape_x` and `shape_y`.\n",
      "        \n",
      "        This is useful when validating the result of a broadcasting operation when the\n",
      "        tensors do not have statically known shapes.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> shape_x = (1, 2, 3)\n",
      "        >>> shape_y = (5, 1, 3)\n",
      "        >>> tf.broadcast_dynamic_shape(shape_x, shape_y)\n",
      "        <tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 2, 3], ...>\n",
      "        \n",
      "        Args:\n",
      "          shape_x: A rank 1 integer `Tensor`, representing the shape of x.\n",
      "          shape_y: A rank 1 integer `Tensor`, representing the shape of y.\n",
      "        \n",
      "        Returns:\n",
      "          A rank 1 integer `Tensor` representing the broadcasted shape.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: If the two shapes are incompatible for\n",
      "          broadcasting.\n",
      "    \n",
      "    broadcast_static_shape(shape_x, shape_y)\n",
      "        Computes the shape of a broadcast given known shapes.\n",
      "        \n",
      "        When `shape_x` and `shape_y` are fully known `TensorShape`s this computes a\n",
      "        `TensorShape` which is the shape of the result of a broadcasting op applied in\n",
      "        tensors of shapes `shape_x` and `shape_y`.\n",
      "        \n",
      "        For example, if shape_x is `TensorShape([1, 2, 3])` and shape_y is\n",
      "        `TensorShape([5, 1, 3])`, the result is a TensorShape whose value is\n",
      "        `TensorShape([5, 2, 3])`.\n",
      "        \n",
      "        This is useful when validating the result of a broadcasting operation when the\n",
      "        tensors have statically known shapes.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> shape_x = tf.TensorShape([1, 2, 3])\n",
      "        >>> shape_y = tf.TensorShape([5, 1 ,3])\n",
      "        >>> tf.broadcast_static_shape(shape_x, shape_y)\n",
      "        TensorShape([5, 2, 3])\n",
      "        \n",
      "        Args:\n",
      "          shape_x: A `TensorShape`\n",
      "          shape_y: A `TensorShape`\n",
      "        \n",
      "        Returns:\n",
      "          A `TensorShape` representing the broadcasted shape.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the two shapes can not be broadcasted.\n",
      "    \n",
      "    broadcast_to(input: Annotated[Any, ~TV_BroadcastTo_T], shape: Annotated[Any, ~TV_BroadcastTo_Tidx], name=None) -> Annotated[Any, ~TV_BroadcastTo_T]\n",
      "        Broadcast an array for a compatible shape.\n",
      "        \n",
      "        Broadcasting is the process of making arrays to have compatible shapes\n",
      "        for arithmetic operations. Two shapes are compatible if for each\n",
      "        dimension pair they are either equal or one of them is one.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([[1, 2, 3]])   # Shape (1, 3,)\n",
      "        >>> y = tf.broadcast_to(x, [2, 3])\n",
      "        >>> print(y)\n",
      "        tf.Tensor(\n",
      "            [[1 2 3]\n",
      "             [1 2 3]], shape=(2, 3), dtype=int32)\n",
      "        \n",
      "        In the above example, the input Tensor with the shape of `[1, 3]`\n",
      "        is broadcasted to output Tensor with shape of `[2, 3]`.\n",
      "        \n",
      "        When broadcasting, if a tensor has fewer axes than necessary its shape is\n",
      "        padded on the left with ones. So this gives the same result as the previous\n",
      "        example:\n",
      "        \n",
      "        >>> x = tf.constant([1, 2, 3])   # Shape (3,)\n",
      "        >>> y = tf.broadcast_to(x, [2, 3])\n",
      "        \n",
      "        \n",
      "        When doing broadcasted operations such as multiplying a tensor\n",
      "        by a scalar, broadcasting (usually) confers some time or space\n",
      "        benefit, as the broadcasted tensor is never materialized.\n",
      "        \n",
      "        However, `broadcast_to` does not carry with it any such benefits.\n",
      "        The newly-created tensor takes the full memory of the broadcasted\n",
      "        shape. (In a graph context, `broadcast_to` might be fused to\n",
      "        subsequent operation and then be optimized away, however.)\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. A Tensor to broadcast.\n",
      "          shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            An 1-D `int` Tensor. The shape of the desired output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    case(pred_fn_pairs, default=None, exclusive=False, strict=False, name='case')\n",
      "        Create a case operation.\n",
      "        \n",
      "        See also `tf.switch_case`.\n",
      "        \n",
      "        The `pred_fn_pairs` parameter is a dict or list of pairs of size N.\n",
      "        Each pair contains a boolean scalar tensor and a python callable that\n",
      "        creates the tensors to be returned if the boolean evaluates to True.\n",
      "        `default` is a callable generating a list of tensors. All the callables\n",
      "        in `pred_fn_pairs` as well as `default` (if provided) should return the same\n",
      "        number and types of tensors.\n",
      "        \n",
      "        If `exclusive==True`, all predicates are evaluated, and an exception is\n",
      "        thrown if more than one of the predicates evaluates to `True`.\n",
      "        If `exclusive==False`, execution stops at the first predicate which\n",
      "        evaluates to True, and the tensors generated by the corresponding function\n",
      "        are returned immediately. If none of the predicates evaluate to True, this\n",
      "        operation returns the tensors generated by `default`.\n",
      "        \n",
      "        `tf.case` supports nested structures as implemented in\n",
      "        `tf.nest`. All of the callables must return the same (possibly nested) value\n",
      "        structure of lists, tuples, and/or named tuples. Singleton lists and tuples\n",
      "        form the only exceptions to this: when returned by a callable, they are\n",
      "        implicitly unpacked to single values. This behavior is disabled by passing\n",
      "        `strict=True`.\n",
      "        \n",
      "        If an unordered dictionary is used for `pred_fn_pairs`, the order of the\n",
      "        conditional tests is not guaranteed. However, the order is guaranteed to be\n",
      "        deterministic, so that variables created in conditional branches are created\n",
      "        in fixed order across runs.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Unordered dictionaries are not supported in eager mode when `exclusive=False`.\n",
      "        Use a list of tuples instead.\n",
      "        @end_compatibility\n",
      "        \n",
      "        \n",
      "        **Example 1:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```\n",
      "        if (x < y) return 17;\n",
      "        else return 23;\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        f1 = lambda: tf.constant(17)\n",
      "        f2 = lambda: tf.constant(23)\n",
      "        r = tf.case([(tf.less(x, y), f1)], default=f2)\n",
      "        ```\n",
      "        \n",
      "        **Example 2:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```\n",
      "        if (x < y && x > z) raise OpError(\"Only one predicate may evaluate to True\");\n",
      "        if (x < y) return 17;\n",
      "        else if (x > z) return 23;\n",
      "        else return -1;\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        def f1(): return tf.constant(17)\n",
      "        def f2(): return tf.constant(23)\n",
      "        def f3(): return tf.constant(-1)\n",
      "        r = tf.case({tf.less(x, y): f1, tf.greater(x, z): f2},\n",
      "                 default=f3, exclusive=True)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          pred_fn_pairs: Dict or list of pairs of a boolean scalar tensor and a\n",
      "            callable which returns a list of tensors.\n",
      "          default: Optional callable that returns a list of tensors.\n",
      "          exclusive: True iff at most one predicate is allowed to evaluate to `True`.\n",
      "          strict: A boolean that enables/disables 'strict' mode; see above.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The tensors returned by the first pair whose predicate evaluated to True, or\n",
      "          those returned by `default` if none does.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `pred_fn_pairs` is not a list/dictionary.\n",
      "          TypeError: If `pred_fn_pairs` is a list but does not contain 2-tuples.\n",
      "          TypeError: If `fns[i]` is not callable for any i, or `default` is not\n",
      "                     callable.\n",
      "    \n",
      "    cast(x, dtype, name=None)\n",
      "        Casts a tensor to a new type.\n",
      "        \n",
      "        The operation casts `x` (in case of `Tensor`) or `x.values`\n",
      "        (in case of `SparseTensor` or `IndexedSlices`) to `dtype`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
      "        >>> tf.cast(x, tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
      "        \n",
      "        Notice `tf.cast` has an alias `tf.dtypes.cast`:\n",
      "        \n",
      "        >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
      "        >>> tf.dtypes.cast(x, tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
      "        \n",
      "        The operation supports data types (for `x` and `dtype`) of\n",
      "        `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`, `int64`,\n",
      "        `float16`, `float32`, `float64`, `complex64`, `complex128`, `bfloat16`.\n",
      "        In case of casting from complex types (`complex64`, `complex128`) to real\n",
      "        types, only the real part of `x` is returned. In case of casting from real\n",
      "        types to complex types (`complex64`, `complex128`), the imaginary part of the\n",
      "        returned value is set to `0`. The handling of complex types here matches the\n",
      "        behavior of numpy.\n",
      "        \n",
      "        Note casting nan and inf values to integral types has undefined behavior.\n",
      "        \n",
      "        Note this operation can lead to a loss of precision when converting native\n",
      "        Python `float` and `complex` variables to `tf.float64` or `tf.complex128`\n",
      "        tensors, since the input is first converted to the `float32` data type and\n",
      "        then widened. It is recommended to use `tf.convert_to_tensor` instead of\n",
      "        `tf.cast` for any non-tensor inputs.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could\n",
      "            be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,\n",
      "            `int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,\n",
      "            `bfloat16`.\n",
      "          dtype: The destination type. The list of supported dtypes is the same as\n",
      "            `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` and\n",
      "            same type as `dtype`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `dtype`.\n",
      "    \n",
      "    ceil(x, name=None)\n",
      "        Return the ceiling of the input, element-wise.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.math.ceil([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])\n",
      "        <tf.Tensor: shape=(7,), dtype=float32,\n",
      "        numpy=array([-1., -1., -0.,  1.,  2.,  2.,  2.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`. `int32`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor`. Has the same type as `x`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.ceil\n",
      "        @end_compatibility\n",
      "    \n",
      "    check_numerics(tensor: Annotated[Any, ~TV_CheckNumerics_T], message: str, name=None) -> Annotated[Any, ~TV_CheckNumerics_T]\n",
      "        Checks a tensor for NaN and Inf values.\n",
      "        \n",
      "        When run, reports an `InvalidArgument` error if `tensor` has any values\n",
      "        that are not a number (NaN) or infinity (Inf). Otherwise, returns the input\n",
      "        tensor.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        ``` python\n",
      "        a = tf.Variable(1.0)\n",
      "        tf.debugging.check_numerics(a, message='')\n",
      "        \n",
      "        b = tf.Variable(np.nan)\n",
      "        try:\n",
      "          tf.debugging.check_numerics(b, message='Checking b')\n",
      "        except Exception as e:\n",
      "          assert \"Checking b : Tensor had NaN values\" in e.message\n",
      "        \n",
      "        c = tf.Variable(np.inf)\n",
      "        try:\n",
      "          tf.debugging.check_numerics(c, message='Checking c')\n",
      "        except Exception as e:\n",
      "          assert \"Checking c : Tensor had Inf values\" in e.message\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          message: A `string`. Prefix of the error message.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    cholesky(input: Annotated[Any, ~TV_Cholesky_T], name=None) -> Annotated[Any, ~TV_Cholesky_T]\n",
      "        Computes the Cholesky decomposition of one or more square matrices.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices.\n",
      "        \n",
      "        The input has to be symmetric and positive definite. Only the lower-triangular\n",
      "        part of the input will be used for this operation. The upper-triangular part\n",
      "        will not be read.\n",
      "        \n",
      "        The output is a tensor of the same shape as the input\n",
      "        containing the Cholesky decompositions for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        **Note**: The gradient computation on GPU is faster for large matrices but\n",
      "        not for large batch dimensions when the submatrices are small. In this\n",
      "        case it might be faster to use the CPU.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    cholesky_solve(chol, rhs, name=None)\n",
      "        Solves systems of linear eqns `A X = RHS`, given Cholesky factorizations.\n",
      "        \n",
      "        Specifically, returns `X` from `A X = RHS`, where `A = L L^T`, `L` is the\n",
      "        `chol` arg and `RHS` is the `rhs` arg.\n",
      "        \n",
      "        ```python\n",
      "        # Solve 10 separate 2x2 linear systems:\n",
      "        A = ... # shape 10 x 2 x 2\n",
      "        RHS = ... # shape 10 x 2 x 1\n",
      "        chol = tf.linalg.cholesky(A)  # shape 10 x 2 x 2\n",
      "        X = tf.linalg.cholesky_solve(chol, RHS)  # shape 10 x 2 x 1\n",
      "        # tf.matmul(A, X) ~ RHS\n",
      "        X[3, :, 0]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 0]\n",
      "        \n",
      "        # Solve five linear systems (K = 5) for every member of the length 10 batch.\n",
      "        A = ... # shape 10 x 2 x 2\n",
      "        RHS = ... # shape 10 x 2 x 5\n",
      "        ...\n",
      "        X[3, :, 2]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 2]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          chol:  A `Tensor`.  Must be `float32` or `float64`, shape is `[..., M, M]`.\n",
      "            Cholesky factorization of `A`, e.g. `chol = tf.linalg.cholesky(A)`.\n",
      "            For that reason, only the lower triangular parts (including the diagonal)\n",
      "            of the last two dimensions of `chol` are used.  The strictly upper part is\n",
      "            assumed to be zero and not accessed.\n",
      "          rhs:  A `Tensor`, same type as `chol`, shape is `[..., M, K]`.\n",
      "          name:  A name to give this `Op`.  Defaults to `cholesky_solve`.\n",
      "        \n",
      "        Returns:\n",
      "          Solution to `A x = rhs`, shape `[..., M, K]`.\n",
      "    \n",
      "    clip_by_average_norm(t, clip_norm, name=None)\n",
      "        Clips tensor values to a maximum average L2-norm. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        clip_by_average_norm is deprecated in TensorFlow 2.0. Please use clip_by_norm(t, clip_norm * tf.cast(tf.size(t), tf.float32), name) instead.\n",
      "        \n",
      "        Given a tensor `t`, and a maximum clip value `clip_norm`, this operation\n",
      "        normalizes `t` so that its average L2-norm is less than or equal to\n",
      "        `clip_norm`. Specifically, if the average L2-norm is already less than or\n",
      "        equal to `clip_norm`, then `t` is not modified. If the average L2-norm is\n",
      "        greater than `clip_norm`, then this operation returns a tensor of the same\n",
      "        type and shape as `t` with its values set to:\n",
      "        \n",
      "        `t * clip_norm / l2norm_avg(t)`\n",
      "        \n",
      "        In this case, the average L2-norm of the output tensor is `clip_norm`.\n",
      "        \n",
      "        This operation is typically used to clip gradients before applying them with\n",
      "        an optimizer.\n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor`.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor`.\n",
      "    \n",
      "    clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None)\n",
      "        Clips values of multiple tensors by the ratio of the sum of their norms.\n",
      "        \n",
      "        Given a tuple or list of tensors `t_list`, and a clipping ratio `clip_norm`,\n",
      "        this operation returns a list of clipped tensors `list_clipped`\n",
      "        and the global norm (`global_norm`) of all tensors in `t_list`. Optionally,\n",
      "        if you've already computed the global norm for `t_list`, you can specify\n",
      "        the global norm with `use_norm`.\n",
      "        \n",
      "        To perform the clipping, the values `t_list[i]` are set to:\n",
      "        \n",
      "            t_list[i] * clip_norm / max(global_norm, clip_norm)\n",
      "        \n",
      "        where:\n",
      "        \n",
      "            global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))\n",
      "        \n",
      "        If `clip_norm > global_norm` then the entries in `t_list` remain as they are,\n",
      "        otherwise they're all shrunk by the global ratio.\n",
      "        \n",
      "        If `global_norm == infinity` then the entries in `t_list` are all set to `NaN`\n",
      "        to signal that an error occurred.\n",
      "        \n",
      "        Any of the entries of `t_list` that are of type `None` are ignored.\n",
      "        \n",
      "        This is the correct way to perform gradient clipping (Pascanu et al., 2012).\n",
      "        \n",
      "        However, it is slower than `clip_by_norm()` because all the parameters must be\n",
      "        ready before the clipping operation can be performed.\n",
      "        \n",
      "        Args:\n",
      "          t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. The clipping ratio.\n",
      "          use_norm: A 0-D (scalar) `Tensor` of type `float` (optional). The global\n",
      "            norm to use. If not provided, `global_norm()` is used to compute the norm.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          list_clipped: A list of `Tensors` of the same type as `list_t`.\n",
      "          global_norm: A 0-D (scalar) `Tensor` representing the global norm.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `t_list` is not a sequence.\n",
      "        \n",
      "        References:\n",
      "          On the difficulty of training Recurrent Neural Networks:\n",
      "            [Pascanu et al., 2012](http://proceedings.mlr.press/v28/pascanu13.html)\n",
      "            ([pdf](http://proceedings.mlr.press/v28/pascanu13.pdf))\n",
      "    \n",
      "    clip_by_norm(t, clip_norm, axes=None, name=None)\n",
      "        Clips tensor values to a maximum L2-norm.\n",
      "        \n",
      "        Given a tensor `t`, and a maximum clip value `clip_norm`, this operation\n",
      "        normalizes `t` so that its L2-norm is less than or equal to `clip_norm`,\n",
      "        along the dimensions given in `axes`. Specifically, in the default case\n",
      "        where all dimensions are used for calculation, if the L2-norm of `t` is\n",
      "        already less than or equal to `clip_norm`, then `t` is not modified. If\n",
      "        the L2-norm is greater than `clip_norm`, then this operation returns a\n",
      "        tensor of the same type and shape as `t` with its values set to:\n",
      "        \n",
      "        `t * clip_norm / l2norm(t)`\n",
      "        \n",
      "        In this case, the L2-norm of the output tensor is `clip_norm`.\n",
      "        \n",
      "        As another example, if `t` is a matrix and `axes == [1]`, then each row\n",
      "        of the output will have L2-norm less than or equal to `clip_norm`. If\n",
      "        `axes == [0]` instead, each column of the output will be clipped.\n",
      "        \n",
      "        Code example:\n",
      "        \n",
      "        >>> some_nums = tf.constant([[1, 2, 3, 4, 5]], dtype=tf.float32)\n",
      "        >>> tf.clip_by_norm(some_nums, 2.0).numpy()\n",
      "        array([[0.26967996, 0.5393599 , 0.80903983, 1.0787199 , 1.3483998 ]],\n",
      "              dtype=float32)\n",
      "        \n",
      "        This operation is typically used to clip gradients before applying them with\n",
      "        an optimizer.  Most gradient data is a collection of different shaped tensors\n",
      "        for different parts of the model.  Thus, this is a common usage:\n",
      "        \n",
      "        ```\n",
      "        # Get your gradients after training\n",
      "        loss_value, grads = grad(model, features, labels)\n",
      "        \n",
      "        # Apply some clipping\n",
      "        grads = [tf.clip_by_norm(g, norm)\n",
      "                     for g in grads]\n",
      "        \n",
      "        # Continue on with training\n",
      "        optimizer.apply_gradients(grads)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor` or `IndexedSlices`.  This must be a floating point type.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value, also\n",
      "            floating point.\n",
      "            Note: If a negative clip_norm is provided, it will be treated as zero.\n",
      "          axes: A 1-D (vector) `Tensor` of type int32 containing the dimensions to use\n",
      "            for computing the L2-norm. If `None` (the default), uses all dimensions.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor` or `IndexedSlices`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the clip_norm tensor is not a 0-D scalar tensor.\n",
      "          TypeError: If dtype of the input is not a floating point or\n",
      "            complex type.\n",
      "    \n",
      "    clip_by_value(t, clip_value_min, clip_value_max, name=None)\n",
      "        Clips tensor values to a specified min and max.\n",
      "        \n",
      "        Given a tensor `t`, this operation returns a tensor of the same type and\n",
      "        shape as `t` with its values clipped to `clip_value_min` and `clip_value_max`.\n",
      "        Any values less than `clip_value_min` are set to `clip_value_min`. Any values\n",
      "        greater than `clip_value_max` are set to `clip_value_max`.\n",
      "        \n",
      "        Note: `clip_value_min` needs to be smaller or equal to `clip_value_max` for\n",
      "        correct results.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        Basic usage passes a scalar as the min and max value.\n",
      "        \n",
      "        >>> t = tf.constant([[-10., -1., 0.], [0., 2., 10.]])\n",
      "        >>> t2 = tf.clip_by_value(t, clip_value_min=-1, clip_value_max=1)\n",
      "        >>> t2.numpy()\n",
      "        array([[-1., -1.,  0.],\n",
      "               [ 0.,  1.,  1.]], dtype=float32)\n",
      "        \n",
      "        The min and max can be the same size as `t`, or broadcastable to that size.\n",
      "        \n",
      "        >>> t = tf.constant([[-1, 0., 10.], [-1, 0, 10]])\n",
      "        >>> clip_min = [[2],[1]]\n",
      "        >>> t3 = tf.clip_by_value(t, clip_value_min=clip_min, clip_value_max=100)\n",
      "        >>> t3.numpy()\n",
      "        array([[ 2.,  2., 10.],\n",
      "               [ 1.,  1., 10.]], dtype=float32)\n",
      "        \n",
      "        Broadcasting fails, intentionally, if you would expand the dimensions of `t`\n",
      "        \n",
      "        >>> t = tf.constant([[-1, 0., 10.], [-1, 0, 10]])\n",
      "        >>> clip_min = [[[2, 1]]] # Has a third axis\n",
      "        >>> t4 = tf.clip_by_value(t, clip_value_min=clip_min, clip_value_max=100)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError: Incompatible shapes: [2,3] vs. [1,1,2]\n",
      "        \n",
      "        It throws a `TypeError` if you try to clip an `int` to a `float` value\n",
      "        (`tf.cast` the input to `float` first).\n",
      "        \n",
      "        >>> t = tf.constant([[1, 2], [3, 4]], dtype=tf.int32)\n",
      "        >>> t5 = tf.clip_by_value(t, clip_value_min=-3.1, clip_value_max=3.1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        TypeError: Cannot convert ...\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor` or `IndexedSlices`.\n",
      "          clip_value_min: The minimum value to clip to. A scalar `Tensor` or one that\n",
      "            is broadcastable to the shape of `t`.\n",
      "          clip_value_max: The maximum value to clip to. A scalar `Tensor` or one that\n",
      "            is broadcastable to the shape of `t`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor` or `IndexedSlices`.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If the clip tensors would trigger array\n",
      "            broadcasting that would make the returned tensor larger than the input.\n",
      "          TypeError: If dtype of the input is `int32` and dtype of\n",
      "            the `clip_value_min` or `clip_value_max` is `float32`\n",
      "    \n",
      "    colocate_with = _colocate_with(op, ignore_existing=False) -> ContextManager[NoneType]\n",
      "        DEPRECATED FUNCTION\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Colocations handled automatically by placer.\n",
      "    \n",
      "    complex(real, imag, name=None)\n",
      "        Converts two real numbers to a complex number.\n",
      "        \n",
      "        Given a tensor `real` representing the real part of a complex number, and a\n",
      "        tensor `imag` representing the imaginary part of a complex number, this\n",
      "        operation returns complex numbers elementwise of the form \\\\(a + bj\\\\), where\n",
      "        *a* represents the `real` part and *b* represents the `imag` part.\n",
      "        \n",
      "        The input tensors `real` and `imag` must have the same shape.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        real = tf.constant([2.25, 3.25])\n",
      "        imag = tf.constant([4.75, 5.75])\n",
      "        tf.complex(real, imag)  # [[2.25 + 4.75j], [3.25 + 5.75j]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          real: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          imag: A `Tensor`. Must have the same type as `real`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `complex64` or `complex128`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: Real and imag must be correct types\n",
      "    \n",
      "    concat(values, axis, name='concat')\n",
      "        Concatenates tensors along one dimension.\n",
      "        \n",
      "        See also `tf.tile`, `tf.stack`, `tf.repeat`.\n",
      "        \n",
      "        Concatenates the list of tensors `values` along dimension `axis`.  If\n",
      "        `values[i].shape = [D0, D1, ... Daxis(i), ...Dn]`, the concatenated\n",
      "        result has shape\n",
      "        \n",
      "            [D0, D1, ... Raxis, ...Dn]\n",
      "        \n",
      "        where\n",
      "        \n",
      "            Raxis = sum(Daxis(i))\n",
      "        \n",
      "        That is, the data from the input tensors is joined along the `axis`\n",
      "        dimension.\n",
      "        \n",
      "        The number of dimensions of the input tensors must match, and all dimensions\n",
      "        except `axis` must be equal.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> t1 = [[1, 2, 3], [4, 5, 6]]\n",
      "        >>> t2 = [[7, 8, 9], [10, 11, 12]]\n",
      "        >>> tf.concat([t1, t2], 0)\n",
      "        <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
      "        array([[ 1,  2,  3],\n",
      "               [ 4,  5,  6],\n",
      "               [ 7,  8,  9],\n",
      "               [10, 11, 12]], dtype=int32)>\n",
      "        \n",
      "        >>> tf.concat([t1, t2], 1)\n",
      "        <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
      "        array([[ 1,  2,  3,  7,  8,  9],\n",
      "               [ 4,  5,  6, 10, 11, 12]], dtype=int32)>\n",
      "        \n",
      "        As in Python, the `axis` could also be negative numbers. Negative `axis`\n",
      "        are interpreted as counting from the end of the rank, i.e.,\n",
      "         `axis + rank(values)`-th dimension.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> t1 = [[[1, 2], [2, 3]], [[4, 4], [5, 3]]]\n",
      "        >>> t2 = [[[7, 4], [8, 4]], [[2, 10], [15, 11]]]\n",
      "        >>> tf.concat([t1, t2], -1)\n",
      "        <tf.Tensor: shape=(2, 2, 4), dtype=int32, numpy=\n",
      "          array([[[ 1,  2,  7,  4],\n",
      "                  [ 2,  3,  8,  4]],\n",
      "                 [[ 4,  4,  2, 10],\n",
      "                  [ 5,  3, 15, 11]]], dtype=int32)>\n",
      "        \n",
      "        Note: If you are concatenating along a new axis consider using stack.\n",
      "        E.g.\n",
      "        \n",
      "        ```python\n",
      "        tf.concat([tf.expand_dims(t, axis) for t in tensors], axis)\n",
      "        ```\n",
      "        \n",
      "        can be rewritten as\n",
      "        \n",
      "        ```python\n",
      "        tf.stack(tensors, axis=axis)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects or a single `Tensor`.\n",
      "          axis: 0-D `int32` `Tensor`.  Dimension along which to concatenate. Must be\n",
      "            in the range `[-rank(values), rank(values))`. As in Python, indexing for\n",
      "            axis is 0-based. Positive axis in the rage of `[0, rank(values))` refers\n",
      "            to `axis`-th dimension. And negative axis refers to `axis +\n",
      "            rank(values)`-th dimension.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` resulting from concatenation of the input tensors.\n",
      "    \n",
      "    cond(pred, true_fn=None, false_fn=None, strict=False, name=None, fn1=None, fn2=None)\n",
      "        Return `true_fn()` if the predicate `pred` is true else `false_fn()`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(fn1, fn2)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "        \n",
      "        `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and\n",
      "        `false_fn` must have the same non-zero number and type of outputs.\n",
      "        \n",
      "        **WARNING**: Any Tensors or Operations created outside of `true_fn` and\n",
      "        `false_fn` will be executed regardless of which branch is selected at runtime.\n",
      "        \n",
      "        Although this behavior is consistent with the dataflow model of TensorFlow,\n",
      "        it has frequently surprised users who expected a lazier semantics.\n",
      "        Consider the following simple program:\n",
      "        \n",
      "        ```python\n",
      "        z = tf.multiply(a, b)\n",
      "        result = tf.cond(x < y, lambda: tf.add(x, z), lambda: tf.square(y))\n",
      "        ```\n",
      "        \n",
      "        If `x < y`, the `tf.add` operation will be executed and `tf.square`\n",
      "        operation will not be executed. Since `z` is needed for at least one\n",
      "        branch of the `cond`, the `tf.multiply` operation is always executed,\n",
      "        unconditionally.\n",
      "        \n",
      "        Note that `cond` calls `true_fn` and `false_fn` *exactly once* (inside the\n",
      "        call to `cond`, and not at all during `Session.run()`). `cond`\n",
      "        stitches together the graph fragments created during the `true_fn` and\n",
      "        `false_fn` calls with some additional graph nodes to ensure that the right\n",
      "        branch gets executed depending on the value of `pred`.\n",
      "        \n",
      "        `tf.cond` supports nested structures as implemented in\n",
      "        `tensorflow.python.util.nest`. Both `true_fn` and `false_fn` must return the\n",
      "        same (possibly nested) value structure of lists, tuples, and/or named tuples.\n",
      "        Singleton lists and tuples form the only exceptions to this: when returned by\n",
      "        `true_fn` and/or `false_fn`, they are implicitly unpacked to single values.\n",
      "        This behavior is disabled by passing `strict=True`.\n",
      "        \n",
      "        Args:\n",
      "          pred: A scalar determining whether to return the result of `true_fn` or\n",
      "            `false_fn`.\n",
      "          true_fn: The callable to be performed if pred is true.\n",
      "          false_fn: The callable to be performed if pred is false.\n",
      "          strict: A boolean that enables/disables 'strict' mode; see above.\n",
      "          name: Optional name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          Tensors returned by the call to either `true_fn` or `false_fn`. If the\n",
      "          callables return a singleton list, the element is extracted from the list.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `true_fn` or `false_fn` is not callable.\n",
      "          ValueError: if `true_fn` and `false_fn` do not return the same number of\n",
      "            tensors, or return tensors of different types.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant(2)\n",
      "        y = tf.constant(5)\n",
      "        def f1(): return tf.multiply(x, 17)\n",
      "        def f2(): return tf.add(y, 23)\n",
      "        r = tf.cond(tf.less(x, y), f1, f2)\n",
      "        # r is set to f1().\n",
      "        # Operations in f2 (e.g., tf.add) are not executed.\n",
      "        ```\n",
      "    \n",
      "    confusion_matrix = confusion_matrix_v1(labels, predictions, num_classes=None, dtype=tf.int32, name=None, weights=None)\n",
      "        Computes the confusion matrix from predictions and labels.\n",
      "        \n",
      "        The matrix columns represent the prediction labels and the rows represent the\n",
      "        real labels. The confusion matrix is always a 2-D array of shape `[n, n]`,\n",
      "        where `n` is the number of valid labels for a given classification task. Both\n",
      "        prediction and labels must be 1-D arrays of the same shape in order for this\n",
      "        function to work.\n",
      "        \n",
      "        If `num_classes` is `None`, then `num_classes` will be set to one plus the\n",
      "        maximum value in either predictions or labels. Class labels are expected to\n",
      "        start at 0. For example, if `num_classes` is 3, then the possible labels\n",
      "        would be `[0, 1, 2]`.\n",
      "        \n",
      "        If `weights` is not `None`, then each prediction contributes its\n",
      "        corresponding weight to the total value of the confusion matrix cell.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "          tf.math.confusion_matrix([1, 2, 4], [2, 2, 4]) ==>\n",
      "              [[0 0 0 0 0]\n",
      "               [0 0 1 0 0]\n",
      "               [0 0 1 0 0]\n",
      "               [0 0 0 0 0]\n",
      "               [0 0 0 0 1]]\n",
      "        ```\n",
      "        \n",
      "        Note that the possible labels are assumed to be `[0, 1, 2, 3, 4]`,\n",
      "        resulting in a 5x5 confusion matrix.\n",
      "        \n",
      "        Args:\n",
      "          labels: 1-D `Tensor` of real labels for the classification task.\n",
      "          predictions: 1-D `Tensor` of predictions for a given classification.\n",
      "          num_classes: The possible number of labels the classification task can have.\n",
      "            If this value is not provided, it will be calculated using both\n",
      "            predictions and labels array.\n",
      "          dtype: Data type of the confusion matrix.\n",
      "          name: Scope name.\n",
      "          weights: An optional `Tensor` whose shape matches `predictions`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `dtype` with shape `[n, n]` representing the confusion\n",
      "          matrix, where `n` is the number of possible labels in the classification\n",
      "          task.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If both predictions and labels are not 1-D vectors and have\n",
      "            mismatched shapes, or if `weights` is not `None` and its shape doesn't\n",
      "            match `predictions`.\n",
      "    \n",
      "    conj(x, name=None)\n",
      "        Returns the complex conjugate of a complex number.\n",
      "        \n",
      "        Given a tensor `x` of complex numbers, this operation returns a tensor of\n",
      "        complex numbers that are the complex conjugate of each element in `x`. The\n",
      "        complex numbers in `x` must be of the form \\\\(a + bj\\\\), where `a` is the\n",
      "        real part and `b` is the imaginary part.\n",
      "        \n",
      "        The complex conjugate returned by this operation is of the form \\\\(a - bj\\\\).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n",
      "        >>> tf.math.conj(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=complex128,\n",
      "        numpy=array([-2.25-4.75j,  3.25-5.75j])>\n",
      "        \n",
      "        If `x` is real, it is returned unchanged.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([-2.25, 3.25])\n",
      "        >>> tf.math.conj(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32,\n",
      "        numpy=array([-2.25,  3.25], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` to conjugate.  Must have numeric or variant type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that is the conjugate of `x` (with the same type).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` is not a numeric tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to numpy.conj.\n",
      "        @end_compatibility\n",
      "    \n",
      "    constant = constant_v1(value, dtype=None, shape=None, name='Const', verify_shape=False) -> Union[tensorflow.python.framework.ops.Operation, tensorflow.python.framework.ops._EagerTensorBase]\n",
      "        Creates a constant tensor.\n",
      "        \n",
      "        The resulting tensor is populated with values of type `dtype`, as\n",
      "        specified by arguments `value` and (optionally) `shape` (see examples\n",
      "        below).\n",
      "        \n",
      "        The argument `value` can be a constant value, or a list of values of type\n",
      "        `dtype`. If `value` is a list, then the length of the list must be less\n",
      "        than or equal to the number of elements implied by the `shape` argument (if\n",
      "        specified). In the case where the list length is less than the number of\n",
      "        elements specified by `shape`, the last element in the list will be used\n",
      "        to fill the remaining entries.\n",
      "        \n",
      "        The argument `shape` is optional. If present, it specifies the dimensions of\n",
      "        the resulting tensor. If not present, the shape of `value` is used.\n",
      "        \n",
      "        If the argument `dtype` is not specified, then the type is inferred from\n",
      "        the type of `value`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Constant 1-D Tensor populated with value list.\n",
      "        tensor = tf.constant([1, 2, 3, 4, 5, 6, 7]) => [1 2 3 4 5 6 7]\n",
      "        \n",
      "        # Constant 2-D tensor populated with scalar value -1.\n",
      "        tensor = tf.constant(-1.0, shape=[2, 3]) => [[-1. -1. -1.]\n",
      "                                                     [-1. -1. -1.]]\n",
      "        ```\n",
      "        \n",
      "        `tf.constant` differs from `tf.fill` in a few ways:\n",
      "        \n",
      "        *   `tf.constant` supports arbitrary constants, not just uniform scalar\n",
      "            Tensors like `tf.fill`.\n",
      "        *   `tf.constant` creates a `Const` node in the computation graph with the\n",
      "            exact value at graph construction time. On the other hand, `tf.fill`\n",
      "            creates an Op in the graph that is expanded at runtime.\n",
      "        *   Because `tf.constant` only embeds constant values in the graph, it does\n",
      "            not support dynamic shapes based on other runtime Tensors, whereas\n",
      "            `tf.fill` does.\n",
      "        \n",
      "        Args:\n",
      "          value:          A constant value (or list) of output type `dtype`.\n",
      "        \n",
      "          dtype:          The type of the elements of the resulting tensor.\n",
      "        \n",
      "          shape:          Optional dimensions of resulting tensor.\n",
      "        \n",
      "          name:           Optional name for the tensor.\n",
      "        \n",
      "          verify_shape:   Boolean that enables verification of a shape of values.\n",
      "        \n",
      "        Returns:\n",
      "          A Constant Tensor.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if shape is incorrectly specified or unsupported.\n",
      "    \n",
      "    container(container_name) -> ContextManager[str]\n",
      "        Wrapper for `Graph.container()` using the default graph.\n",
      "        \n",
      "        Args:\n",
      "          container_name: The container string to use in the context.\n",
      "        \n",
      "        Returns:\n",
      "          A context manager that specifies the default container to use for newly\n",
      "          created stateful ops.\n",
      "    \n",
      "    control_dependencies(control_inputs) -> tensorflow.python.framework.ops.Graph._ControlDependenciesController\n",
      "        Wrapper for `Graph.control_dependencies()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.control_dependencies` for more details.\n",
      "        \n",
      "        In TensorFlow 2 with eager and/or Autograph, you should not need this method\n",
      "        most of the times, as ops execute in the expected order thanks to automatic\n",
      "        control dependencies. Only use it to manually control ordering, for example as\n",
      "        a workaround to known issues such as `tf.function` with `tf.debugging.assert*`\n",
      "        and `tf.py_function`.\n",
      "        For example:\n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...   input_signature=[tf.TensorSpec([None, None], tf.float32),\n",
      "        ...                    tf.TensorSpec([None, None], tf.float32)])\n",
      "        ... def my_assert_func_1(x, bias):\n",
      "        ...   # `tf.function` attempts to execute `tf.math.add` in parallel to\n",
      "        ...   # `assert_equal`. As a result an error can get raised from `tf.math.add`\n",
      "        ...   # without triggering the assertion error.\n",
      "        ...   tf.assert_equal(tf.shape(x)[1],\n",
      "        ...                   tf.shape(bias)[1],\n",
      "        ...                   message='bad shape')\n",
      "        ...   return x + bias\n",
      "        \n",
      "        >>> # Error raised in either `add` or `assert`\n",
      "        >>> my_assert_func_1(tf.ones((2, 5)), tf.ones((2, 7)))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...   input_signature=[tf.TensorSpec([None, None], tf.float32),\n",
      "        ...                    tf.TensorSpec([None, None], tf.float32)])\n",
      "        ... def my_assert_func_2(x, bias):\n",
      "        ...   with tf.control_dependencies(\n",
      "        ...       [tf.assert_equal(tf.shape(x)[1],\n",
      "        ...                       tf.shape(bias)[1],\n",
      "        ...                       message='bad shape')]):\n",
      "        ...     return x + bias\n",
      "        \n",
      "        >>> # Error raised in `assert`\n",
      "        >>> my_assert_func_2(tf.ones((2, 5)), tf.ones((2, 7)))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        When eager execution is enabled, any callable object in the `control_inputs`\n",
      "        list will be called.\n",
      "        \n",
      "        Args:\n",
      "          control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      "            executed or computed before running the operations defined in the context.\n",
      "            Can also be `None` to clear the control dependencies. If eager execution\n",
      "            is enabled, any callable object in the `control_inputs` list will be\n",
      "            called.\n",
      "        \n",
      "        Returns:\n",
      "         A context manager that specifies control dependencies for all\n",
      "         operations constructed within the context.\n",
      "    \n",
      "    control_flow_v2_enabled()\n",
      "        Returns `True` if v2 control flow is enabled.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function.\n",
      "    \n",
      "    conv(input: Annotated[Any, ~TV_Conv_T], filter: Annotated[Any, ~TV_Conv_T], strides, padding: str, explicit_paddings=[], data_format: str = 'CHANNELS_LAST', dilations=[], batch_dims: int = 1, groups: int = 1, name=None) -> Annotated[Any, ~TV_Conv_T]\n",
      "        Computes a N-D convolution given (N+1+batch_dims)-D `input` and (N+2)-D `filter` tensors.\n",
      "        \n",
      "        General function for computing a N-D convolution. It is required that\n",
      "        `1 <= N <= 3`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`.\n",
      "            Tensor of type T and shape `batch_shape + spatial_shape + [in_channels]` in the\n",
      "            case that `channels_last_format = true` or shape\n",
      "            `batch_shape + [in_channels] + spatial_shape` if `channels_last_format = false`.\n",
      "            spatial_shape is N-dimensional with `N=2` or `N=3`.\n",
      "            Also note that `batch_shape` is dictated by the parameter `batch_dims`\n",
      "            and defaults to 1.\n",
      "          filter: A `Tensor`. Must have the same type as `input`.\n",
      "            An `(N+2)-D` Tensor with the same type as `input` and shape\n",
      "            `spatial_filter_shape + [in_channels, out_channels]`, where spatial_filter_shape\n",
      "            is N-dimensional with `N=2` or `N=3`.\n",
      "          strides: A list of `ints`.\n",
      "            1-D tensor of length `N+2`. The stride of the sliding window for each\n",
      "            dimension of `input`. Must have `strides[0] = strides[N+1] = 1`.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\", \"EXPLICIT\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          explicit_paddings: An optional list of `ints`. Defaults to `[]`.\n",
      "            If `padding` is `\"EXPLICIT\"`, the list of explicit padding amounts. For the ith\n",
      "            dimension, the amount of padding inserted before and after the dimension is\n",
      "            `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If\n",
      "            `padding` is not `\"EXPLICIT\"`, `explicit_paddings` must be empty.\n",
      "          data_format: An optional `string` from: `\"CHANNELS_FIRST\", \"CHANNELS_LAST\"`. Defaults to `\"CHANNELS_LAST\"`.\n",
      "            Used to set the data format. By default `CHANNELS_FIRST`, uses \n",
      "            `NHWC (2D) / NDHWC (3D)` or if `CHANNELS_LAST`, uses `NCHW (2D) / NCDHW (3D)`.\n",
      "          dilations: An optional list of `ints`. Defaults to `[]`.\n",
      "            1-D tensor of length `N+2`. The dilation factor for each dimension of\n",
      "            `input`. If set to `k > 1`, there will be `k-1` skipped cells between each\n",
      "            filter element on that dimension. The dimension order is determined by the\n",
      "            value of `channels_last_format`, see above for details. Dilations in the batch\n",
      "            and depth dimensions must be 1.\n",
      "          batch_dims: An optional `int`. Defaults to `1`.\n",
      "            A positive integer specifying the number of batch dimensions for the input\n",
      "            tensor. Should be less than the rank of the input tensor.\n",
      "          groups: An optional `int`. Defaults to `1`.\n",
      "            A positive integer specifying the number of groups in which the input is split\n",
      "            along the channel axis. Each group is convolved separately with\n",
      "            `filters / groups` filters. The output is the concatenation of all the groups\n",
      "            results along the channel axis. Input channels and filters must both be\n",
      "            divisible by groups.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    conv2d_backprop_filter_v2(input: Annotated[Any, ~TV_Conv2DBackpropFilterV2_T], filter: Annotated[Any, ~TV_Conv2DBackpropFilterV2_T], out_backprop: Annotated[Any, ~TV_Conv2DBackpropFilterV2_T], strides, padding: str, use_cudnn_on_gpu: bool = True, explicit_paddings=[], data_format: str = 'NHWC', dilations=[1, 1, 1, 1], name=None) -> Annotated[Any, ~TV_Conv2DBackpropFilterV2_T]\n",
      "        Computes the gradients of convolution with respect to the filter.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.\n",
      "            4-D with shape `[batch, in_height, in_width, in_channels]`.\n",
      "          filter: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[filter_height, filter_width, in_channels, out_channels]`.\n",
      "            Only shape of tensor is used.\n",
      "          out_backprop: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[batch, out_height, out_width, out_channels]`.\n",
      "            Gradients w.r.t. the output of the convolution.\n",
      "          strides: A list of `ints`.\n",
      "            The stride of the sliding window for each dimension of the input\n",
      "            of the convolution. Must be in the same order as the dimension specified with\n",
      "            format.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\", \"EXPLICIT\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "          explicit_paddings: An optional list of `ints`. Defaults to `[]`.\n",
      "            If `padding` is `\"EXPLICIT\"`, the list of explicit padding amounts. For the ith\n",
      "            dimension, the amount of padding inserted before and after the dimension is\n",
      "            `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If\n",
      "            `padding` is not `\"EXPLICIT\"`, `explicit_paddings` must be empty.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`. Defaults to `\"NHWC\"`.\n",
      "            Specify the data format of the input and output data. With the\n",
      "            default format \"NHWC\", the data is stored in the order of:\n",
      "                [batch, in_height, in_width, in_channels].\n",
      "            Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "                [batch, in_channels, in_height, in_width].\n",
      "          dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.\n",
      "            1-D tensor of length 4.  The dilation factor for each dimension of\n",
      "            `input`. If set to k > 1, there will be k-1 skipped cells between each filter\n",
      "            element on that dimension. The dimension order is determined by the value of\n",
      "            `data_format`, see above for details. Dilations in the batch and depth\n",
      "            dimensions must be 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    conv2d_backprop_input_v2(input: Annotated[Any, ~TV_Conv2DBackpropInputV2_T], filter: Annotated[Any, ~TV_Conv2DBackpropInputV2_T], out_backprop: Annotated[Any, ~TV_Conv2DBackpropInputV2_T], strides, padding: str, use_cudnn_on_gpu: bool = True, explicit_paddings=[], data_format: str = 'NHWC', dilations=[1, 1, 1, 1], name=None) -> Annotated[Any, ~TV_Conv2DBackpropInputV2_T]\n",
      "        Computes the gradients of convolution with respect to the input.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`.\n",
      "            4-D with shape `[batch, in_height, in_width, in_channels]`.\n",
      "            Only shape of tensor is used.\n",
      "          filter: A `Tensor`. Must have the same type as `input`. 4-D with shape\n",
      "            `[filter_height, filter_width, in_channels, out_channels]`.\n",
      "          out_backprop: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[batch, out_height, out_width, out_channels]`.\n",
      "            Gradients w.r.t. the output of the convolution.\n",
      "          strides: A list of `ints`.\n",
      "            The stride of the sliding window for each dimension of the input\n",
      "            of the convolution. Must be in the same order as the dimension specified with\n",
      "            format.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\", \"EXPLICIT\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "          explicit_paddings: An optional list of `ints`. Defaults to `[]`.\n",
      "            If `padding` is `\"EXPLICIT\"`, the list of explicit padding amounts. For the ith\n",
      "            dimension, the amount of padding inserted before and after the dimension is\n",
      "            `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If\n",
      "            `padding` is not `\"EXPLICIT\"`, `explicit_paddings` must be empty.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`. Defaults to `\"NHWC\"`.\n",
      "            Specify the data format of the input and output data. With the\n",
      "            default format \"NHWC\", the data is stored in the order of:\n",
      "                [batch, in_height, in_width, in_channels].\n",
      "            Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "                [batch, in_channels, in_height, in_width].\n",
      "          dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.\n",
      "            1-D tensor of length 4.  The dilation factor for each dimension of\n",
      "            `input`. If set to k > 1, there will be k-1 skipped cells between each filter\n",
      "            element on that dimension. The dimension order is determined by the value of\n",
      "            `data_format`, see above for details. Dilations in the batch and depth\n",
      "            dimensions must be 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    convert_to_tensor = convert_to_tensor_v1_with_dispatch(value, dtype=None, name=None, preferred_dtype=None, dtype_hint=None) -> tensorflow.python.framework.tensor.Tensor\n",
      "        Converts the given `value` to a `Tensor`.\n",
      "        \n",
      "        This function converts Python objects of various types to `Tensor`\n",
      "        objects. It accepts `Tensor` objects, numpy arrays, Python lists,\n",
      "        and Python scalars. For example:\n",
      "        \n",
      "        ```python\n",
      "        import numpy as np\n",
      "        \n",
      "        def my_func(arg):\n",
      "          arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
      "          return tf.matmul(arg, arg) + arg\n",
      "        \n",
      "        # The following calls are equivalent.\n",
      "        value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\n",
      "        value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\n",
      "        value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n",
      "        ```\n",
      "        \n",
      "        This function can be useful when composing a new operation in Python\n",
      "        (such as `my_func` in the example above). All standard Python op\n",
      "        constructors apply this function to each of their Tensor-valued\n",
      "        inputs, which allows those ops to accept numpy arrays, Python lists,\n",
      "        and scalars in addition to `Tensor` objects.\n",
      "        \n",
      "        Note: This function diverges from default Numpy behavior for `float` and\n",
      "          `string` types when `None` is present in a Python list or scalar. Rather\n",
      "          than silently converting `None` values, an error will be thrown.\n",
      "        \n",
      "        Args:\n",
      "          value: An object whose type has a registered `Tensor` conversion function.\n",
      "          dtype: Optional element type for the returned tensor. If missing, the type\n",
      "            is inferred from the type of `value`.\n",
      "          name: Optional name to use if a new `Tensor` is created.\n",
      "          preferred_dtype: Optional element type for the returned tensor, used when\n",
      "            dtype is None. In some cases, a caller may not have a dtype in mind when\n",
      "            converting to a tensor, so preferred_dtype can be used as a soft\n",
      "            preference.  If the conversion to `preferred_dtype` is not possible, this\n",
      "            argument has no effect.\n",
      "          dtype_hint: same meaning as preferred_dtype, and overrides it.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If no conversion function is registered for `value` to `dtype`.\n",
      "          RuntimeError: If a registered conversion function returns an invalid value.\n",
      "          ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\n",
      "    \n",
      "    convert_to_tensor_or_indexed_slices(value, dtype=None, name=None)\n",
      "        Converts the given object to a `Tensor` or an `IndexedSlices`.\n",
      "        \n",
      "        If `value` is an `IndexedSlices` or `SparseTensor` it is returned\n",
      "        unmodified. Otherwise, it is converted to a `Tensor` using\n",
      "        `convert_to_tensor()`.\n",
      "        \n",
      "        Args:\n",
      "          value: An `IndexedSlices`, `SparseTensor`, or an object that can be consumed\n",
      "            by `convert_to_tensor()`.\n",
      "          dtype: (Optional.) The required `DType` of the returned `Tensor` or\n",
      "            `IndexedSlices`.\n",
      "          name: (Optional.) A name to use if a new `Tensor` is created.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`, `IndexedSlices`, or `SparseTensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `dtype` does not match the element type of `value`.\n",
      "    \n",
      "    convert_to_tensor_or_sparse_tensor(value, dtype=None, name=None)\n",
      "        Converts value to a `SparseTensor` or `Tensor`.\n",
      "        \n",
      "        Args:\n",
      "          value: A `SparseTensor`, `SparseTensorValue`, or an object whose type has a\n",
      "            registered `Tensor` conversion function.\n",
      "          dtype: Optional element type for the returned tensor. If missing, the type\n",
      "            is inferred from the type of `value`.\n",
      "          name: Optional name to use if a new `Tensor` is created.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or `Tensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If result type is incompatible with `dtype`.\n",
      "    \n",
      "    cos(x: typing.Annotated[_any, ~TV_Cos_T], name=None) -> typing.Annotated[_any, ~TV_Cos_T]\n",
      "        Computes cos of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes cosine of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `[-1,1]`. If input lies outside the boundary, `nan`\n",
      "          is returned.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.cos(x) ==> [nan -0.91113025 0.87758255 0.5403023 0.36235774 0.48718765 -0.95215535 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    cosh(x: typing.Annotated[_any, ~TV_Cosh_T], name=None) -> typing.Annotated[_any, ~TV_Cosh_T]\n",
      "        Computes hyperbolic cosine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic cosine of every\n",
      "          element in the tensor. Input range is `[-inf, inf]` and output range\n",
      "          is `[1, inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 2, 10, float(\"inf\")])\n",
      "          tf.math.cosh(x) ==> [inf 4.0515420e+03 1.1276259e+00 1.5430807e+00 1.8106556e+00 3.7621956e+00 1.1013233e+04 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    count_nonzero(input_tensor=None, axis=None, keepdims=None, dtype=tf.int64, name=None, reduction_indices=None, keep_dims=None, input=None)\n",
      "        Computes number of nonzero elements across dimensions of a tensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(reduction_indices)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_indices is deprecated, use axis instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` has no entries, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        **NOTE** Floating point comparison to zero is done by exact floating point\n",
      "        equality check.  Small values are **not** rounded to zero for purposes of\n",
      "        the nonzero check.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[0, 1, 0], [1, 1, 0]])\n",
      "        tf.math.count_nonzero(x)  # 3\n",
      "        tf.math.count_nonzero(x, 0)  # [1, 2, 0]\n",
      "        tf.math.count_nonzero(x, 1)  # [1, 2]\n",
      "        tf.math.count_nonzero(x, 1, keepdims=True)  # [[1], [2]]\n",
      "        tf.math.count_nonzero(x, [0, 1])  # 3\n",
      "        ```\n",
      "        \n",
      "        **NOTE** Strings are compared against zero-length empty string `\"\"`. Any\n",
      "        string with a size greater than zero is already considered as nonzero.\n",
      "        \n",
      "        For example:\n",
      "        ```python\n",
      "        x = tf.constant([\"\", \"a\", \"  \", \"b\", \"\"])\n",
      "        tf.math.count_nonzero(x) # 3, with \"a\", \"  \", and \"b\" as nonzero strings.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should be of numeric type, `bool`, or\n",
      "            `string`.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          dtype: The output dtype; defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "          input: Overrides input_tensor. For compatibility.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor (number of nonzero values).\n",
      "    \n",
      "    count_up_to(ref, limit, name=None)\n",
      "        Increments 'ref' until it reaches 'limit'. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Prefer Dataset.range instead.\n",
      "        \n",
      "        Args:\n",
      "          ref: A Variable. Must be one of the following types: `int32`, `int64`.\n",
      "            Should be from a scalar `Variable` node.\n",
      "          limit: An `int`.\n",
      "            If incrementing ref would bring it above limit, instead generates an\n",
      "            'OutOfRange' error.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `ref`.\n",
      "          A copy of the input before increment. If nothing else modifies the\n",
      "          input, the values produced will all be distinct.\n",
      "    \n",
      "    create_partitioned_variables(shape, slicing, initializer, dtype=tf.float32, trainable=True, collections=None, name=None, reuse=None)\n",
      "        Create a list of partitioned variables according to the given `slicing`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.get_variable` with a partitioner set.\n",
      "        \n",
      "        Currently only one dimension of the full variable can be sliced, and the\n",
      "        full variable can be reconstructed by the concatenation of the returned\n",
      "        list along that dimension.\n",
      "        \n",
      "        Args:\n",
      "          shape: List of integers.  The shape of the full variable.\n",
      "          slicing: List of integers.  How to partition the variable.\n",
      "            Must be of the same length as `shape`.  Each value\n",
      "            indicate how many slices to create in the corresponding\n",
      "            dimension.  Presently only one of the values can be more than 1;\n",
      "            that is, the variable can only be sliced along one dimension.\n",
      "        \n",
      "            For convenience, The requested number of partitions does not have to\n",
      "            divide the corresponding dimension evenly.  If it does not, the\n",
      "            shapes of the partitions are incremented by 1 starting from partition\n",
      "            0 until all slack is absorbed.  The adjustment rules may change in the\n",
      "            future, but as you can save/restore these variables with different\n",
      "            slicing specifications this should not be a problem.\n",
      "          initializer: A `Tensor` of shape `shape` or a variable initializer\n",
      "            function.  If a function, it will be called once for each slice,\n",
      "            passing the shape and data type of the slice as parameters.  The\n",
      "            function must return a tensor with the same shape as the slice.\n",
      "          dtype: Type of the variables. Ignored if `initializer` is a `Tensor`.\n",
      "          trainable: If True also add all the variables to the graph collection\n",
      "            `GraphKeys.TRAINABLE_VARIABLES`.\n",
      "          collections: List of graph collections keys to add the variables to.\n",
      "            Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "          name: Optional name for the full variable.  Defaults to\n",
      "            `\"PartitionedVariable\"` and gets uniquified automatically.\n",
      "          reuse: Boolean or `None`; if `True` and name is set, it would reuse\n",
      "            previously created variables. if `False` it will create new variables.\n",
      "            if `None`, it would inherit the parent scope reuse.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variables corresponding to the slicing.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the arguments is malformed.\n",
      "    \n",
      "    cross(a: typing.Annotated[_any, ~TV_Cross_T], b: typing.Annotated[_any, ~TV_Cross_T], name=None) -> typing.Annotated[_any, ~TV_Cross_T]\n",
      "        Compute the pairwise cross product.\n",
      "        \n",
      "        `a` and `b` must be the same shape; they can either be simple 3-element vectors,\n",
      "        or any shape where the innermost dimension is 3. In the latter case, each pair\n",
      "        of corresponding 3-element vectors is cross-multiplied independently.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "            A tensor containing 3-element vectors.\n",
      "          b: A `Tensor`. Must have the same type as `a`.\n",
      "            Another tensor, of same type and shape as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    cumprod(x, axis=0, exclusive=False, reverse=False, name=None)\n",
      "        Compute the cumulative product of the tensor `x` along `axis`.\n",
      "        \n",
      "        By default, this op performs an inclusive cumprod, which means that the\n",
      "        first element of the input is identical to the first element of the output:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c])  # [a, a * b, a * b * c]\n",
      "        ```\n",
      "        \n",
      "        By setting the `exclusive` kwarg to `True`, an exclusive cumprod is\n",
      "        performed\n",
      "        instead:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], exclusive=True)  # [1, a, a * b]\n",
      "        ```\n",
      "        \n",
      "        By setting the `reverse` kwarg to `True`, the cumprod is performed in the\n",
      "        opposite direction:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], reverse=True)  # [a * b * c, b * c, c]\n",
      "        ```\n",
      "        \n",
      "        This is more efficient than using separate `tf.reverse` ops.\n",
      "        The `reverse` and `exclusive` kwargs can also be combined:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], exclusive=True, reverse=True)  # [b * c, c, 1]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`,\n",
      "            `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,\n",
      "            `complex128`, `qint8`, `quint8`, `qint32`, `half`.\n",
      "          axis: A `Tensor` of type `int32` (default: 0). Must be in the range\n",
      "            `[-rank(x), rank(x))`.\n",
      "          exclusive: If `True`, perform exclusive cumprod.\n",
      "          reverse: A `bool` (default: False).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    cumsum(x, axis=0, exclusive=False, reverse=False, name=None)\n",
      "        Compute the cumulative sum of the tensor `x` along `axis`.\n",
      "        \n",
      "        By default, this op performs an inclusive cumsum, which means that the first\n",
      "        element of the input is identical to the first element of the output:\n",
      "        For example:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c])   # [a, a + b, a + b + c]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([ 2,  6, 12, 20], dtype=int32)>\n",
      "        \n",
      "        >>> # using varying `axis` values\n",
      "        >>> y = tf.constant([[2, 4, 6, 8], [1,3,5,7]])\n",
      "        >>> tf.cumsum(y, axis=0)\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "        array([[ 2,  4,  6,  8],\n",
      "               [ 3,  7, 11, 15]], dtype=int32)>\n",
      "        >>> tf.cumsum(y, axis=1)\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "        array([[ 2,  6, 12, 20],\n",
      "               [ 1,  4,  9, 16]], dtype=int32)>\n",
      "        \n",
      "        By setting the `exclusive` kwarg to `True`, an exclusive cumsum is performed\n",
      "        instead:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], exclusive=True)  => [0, a, a + b]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, exclusive=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([ 0,  2,  6, 12], dtype=int32)>\n",
      "        \n",
      "        By setting the `reverse` kwarg to `True`, the cumsum is performed in the\n",
      "        opposite direction:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], reverse=True)  # [a + b + c, b + c, c]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, reverse=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([20, 18, 14,  8], dtype=int32)>\n",
      "        \n",
      "        This is more efficient than using separate `tf.reverse` ops.\n",
      "        The `reverse` and `exclusive` kwargs can also be combined:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], exclusive=True, reverse=True)  # [b + c, c, 0]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, exclusive=True, reverse=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([18, 14,  8,  0], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`,\n",
      "            `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,\n",
      "            `complex128`, `qint8`, `quint8`, `qint32`, `half`.\n",
      "          axis: A `Tensor` of type `int32` (default: 0). Must be in the range\n",
      "            `[-rank(x), rank(x))`.\n",
      "          exclusive: If `True`, perform exclusive cumsum.\n",
      "          reverse: A `bool` (default: False).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    custom_gradient(f=None)\n",
      "        Decorator to define a function with a custom gradient.\n",
      "        \n",
      "        This decorator allows fine grained control over the gradients of a sequence\n",
      "        for operations.  This may be useful for multiple reasons, including providing\n",
      "        a more efficient or numerically stable gradient for a sequence of operations.\n",
      "        \n",
      "        For example, consider the following function that commonly occurs in the\n",
      "        computation of cross entropy and log likelihoods:\n",
      "        \n",
      "        ```python\n",
      "        def log1pexp(x):\n",
      "          return tf.math.log(1 + tf.exp(x))\n",
      "        ```\n",
      "        \n",
      "        Due to numerical instability, the gradient of this function evaluated at x=100\n",
      "        is NaN.  For example:\n",
      "        \n",
      "        ```python\n",
      "        with tf.GradientTape() as tape:\n",
      "          tape.watch(x)\n",
      "          y=log1pexp(x)\n",
      "        dy_dx = tape.gradient(y, x) # Will be NaN when evaluated.\n",
      "        ```\n",
      "        \n",
      "        The gradient expression can be analytically simplified to provide numerical\n",
      "        stability:\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def log1pexp(x):\n",
      "          e = tf.exp(x)\n",
      "          def grad(upstream):\n",
      "            return upstream * (1 - 1 / (1 + e))\n",
      "          return tf.math.log(1 + e), grad\n",
      "        ```\n",
      "        \n",
      "        With this definition, the gradient `dy_dx` at `x = 100` will be correctly\n",
      "        evaluated as 1.0.\n",
      "        \n",
      "        The variable `upstream` is defined as the upstream gradient. i.e. the gradient\n",
      "        from all the layers or functions originating from this layer. The above\n",
      "        example has no upstream functions, therefore `upstream = dy/dy = 1.0`.\n",
      "        \n",
      "        Assume that `x_i` is `log1pexp` in the forward pass `x_1 = x_1(x_0)`,\n",
      "        `x_2 = x_2(x_1)`, ..., `x_i = x_i(x_i-1)`, ..., `x_n = x_n(x_n-1)`. By\n",
      "        chain rule we know that `dx_n/dx_0 = dx_n/dx_n-1 * dx_n-1/dx_n-2 * ... *\n",
      "        dx_i/dx_i-1 * ... * dx_1/dx_0`.\n",
      "        \n",
      "        In this case the gradient of our current function defined as\n",
      "        `dx_i/dx_i-1 = (exp(x_i) / (1 + exp(x_i))) = (1 - 1 / (1 + exp(x_i)))`. The\n",
      "        upstream gradient `upstream` would be `dx_n/dx_n-1 * dx_n-1/dx_n-2 * ... *\n",
      "        dx_i+1/dx_i`. The upstream gradient multiplied by the current gradient is\n",
      "        then passed downstream.\n",
      "        \n",
      "        In case the function takes multiple variables as input, the `grad`\n",
      "        function must also return  the same number of variables.\n",
      "        We take the function `z = x * y` as an example.\n",
      "        \n",
      "        >>> @tf.custom_gradient\n",
      "        ... def bar(x, y):\n",
      "        ...   def grad(upstream):\n",
      "        ...     dz_dx = y\n",
      "        ...     dz_dy = x\n",
      "        ...     return upstream * dz_dx, upstream * dz_dy\n",
      "        ...   z = x * y\n",
      "        ...   return z, grad\n",
      "        >>> x = tf.constant(2.0, dtype=tf.float32)\n",
      "        >>> y = tf.constant(3.0, dtype=tf.float32)\n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   tape.watch(y)\n",
      "        ...   z = bar(x, y)\n",
      "        >>> z\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
      "        >>> tape.gradient(z, x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=3.0>\n",
      "        >>> tape.gradient(z, y)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=2.0>\n",
      "        \n",
      "        Nesting custom gradients can lead to unintuitive results. The default\n",
      "        behavior does not correspond to n-th order derivatives. For example\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def op(x):\n",
      "          y = op1(x)\n",
      "          @tf.custom_gradient\n",
      "          def grad_fn(dy):\n",
      "            gdy = op2(x, y, dy)\n",
      "            def grad_grad_fn(ddy):  # Not the 2nd order gradient of op w.r.t. x.\n",
      "              return op3(x, y, dy, ddy)\n",
      "            return gdy, grad_grad_fn\n",
      "          return y, grad_fn\n",
      "        ```\n",
      "        \n",
      "        The function `grad_grad_fn` will be calculating the first order gradient\n",
      "        of `grad_fn` with respect to `dy`, which is used to generate forward-mode\n",
      "        gradient graphs from backward-mode gradient graphs, but is not the same as\n",
      "        the second order gradient of `op` with respect to `x`.\n",
      "        \n",
      "        Instead, wrap nested `@tf.custom_gradients` in another function:\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def op_with_fused_backprop(x):\n",
      "          y, x_grad = fused_op(x)\n",
      "          def first_order_gradient(dy):\n",
      "            @tf.custom_gradient\n",
      "            def first_order_custom(unused_x):\n",
      "              def second_order_and_transpose(ddy):\n",
      "                return second_order_for_x(...), gradient_wrt_dy(...)\n",
      "              return x_grad, second_order_and_transpose\n",
      "            return dy * first_order_custom(x)\n",
      "          return y, first_order_gradient\n",
      "        ```\n",
      "        \n",
      "        Additional arguments to the inner `@tf.custom_gradient`-decorated function\n",
      "        control the expected return values of the innermost function.\n",
      "        \n",
      "        The examples above illustrate how to specify custom gradients for functions\n",
      "        which do not read from variables. The following example uses variables, which\n",
      "        require special handling because they are effectively inputs of the forward\n",
      "        function.\n",
      "        \n",
      "        >>> weights = tf.Variable(tf.ones([2]))  # Trainable variable weights\n",
      "        >>> @tf.custom_gradient\n",
      "        ... def linear_poly(x):\n",
      "        ...   # Creating polynomial\n",
      "        ...   poly = weights[1] * x + weights[0]\n",
      "        ...\n",
      "        ...   def grad_fn(dpoly, variables):\n",
      "        ...     # dy/dx = weights[1] and we need to left multiply dpoly\n",
      "        ...     grad_xs = dpoly * weights[1]  # Scalar gradient\n",
      "        ...\n",
      "        ...     grad_vars = []  # To store gradients of passed variables\n",
      "        ...     assert variables is not None\n",
      "        ...     assert len(variables) == 1\n",
      "        ...     assert variables[0] is weights\n",
      "        ...     # Manually computing dy/dweights\n",
      "        ...     dy_dw = dpoly * tf.stack([x ** 1, x ** 0])\n",
      "        ...     grad_vars.append(\n",
      "        ...         tf.reduce_sum(tf.reshape(dy_dw, [2, -1]), axis=1)\n",
      "        ...     )\n",
      "        ...     return grad_xs, grad_vars\n",
      "        ...   return poly, grad_fn\n",
      "        >>> x = tf.constant([1., 2., 3.])\n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   poly = linear_poly(x)\n",
      "        >>> poly # poly = x + 1\n",
      "        <tf.Tensor: shape=(3,),\n",
      "          dtype=float32,\n",
      "          numpy=array([2., 3., 4.], dtype=float32)>\n",
      "        >>> tape.gradient(poly, x)  # conventional scalar gradient dy/dx\n",
      "        <tf.Tensor: shape=(3,),\n",
      "          dtype=float32,\n",
      "          numpy=array([1., 1., 1.], dtype=float32)>\n",
      "        >>> tape.gradient(poly, weights)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([6., 3.], dtype=float32)>\n",
      "        \n",
      "        Above example illustrates usage of trainable variable `weights`.\n",
      "        In the example, the inner `grad_fn` accepts an extra `variables` input\n",
      "        parameter and also returns an extra `grad_vars` output. That extra argument\n",
      "        is passed if the forward function reads any variables. You need to\n",
      "        compute the gradient w.r.t. each of those `variables` and output it as a list\n",
      "        of `grad_vars`. Note here that default value of `variables` is set to `None`\n",
      "        when no variables are used in the forward function.\n",
      "        \n",
      "        It should be noted `tf.GradientTape` is still watching the forward pass of a\n",
      "        `tf.custom_gradient`, and will use the ops it watches. As a consequence,\n",
      "        calling `tf.function` while the tape is still watching leads\n",
      "        to a gradient graph being built. If an op is used in `tf.function` without\n",
      "        registered gradient, a `LookupError` will be raised.\n",
      "        \n",
      "        Users can insert `tf.stop_gradient` to customize this behavior. This\n",
      "        is demonstrated in the example below. `tf.random.shuffle` does not have a\n",
      "        registered gradient. As a result `tf.stop_gradient` is used to avoid the\n",
      "        `LookupError`.\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0.3, 0.5], dtype=tf.float32)\n",
      "        \n",
      "        @tf.custom_gradient\n",
      "        def test_func_with_stop_grad(x):\n",
      "          @tf.function\n",
      "          def _inner_func():\n",
      "            # Avoid exception during the forward pass\n",
      "            return tf.stop_gradient(tf.random.shuffle(x))\n",
      "            # return tf.random.shuffle(x)  # This will raise\n",
      "        \n",
      "          res = _inner_func()\n",
      "          def grad(upstream):\n",
      "            return upstream  # Arbitrarily defined custom gradient\n",
      "          return res, grad\n",
      "        \n",
      "        with tf.GradientTape() as g:\n",
      "          g.watch(x)\n",
      "          res = test_func_with_stop_grad(x)\n",
      "        \n",
      "        g.gradient(res, x)\n",
      "        ```\n",
      "        \n",
      "        See also `tf.RegisterGradient` which registers a gradient function for a\n",
      "        primitive TensorFlow operation. `tf.custom_gradient` on the other hand allows\n",
      "        for fine grained control over the gradient computation of a sequence of\n",
      "        operations.\n",
      "        \n",
      "        Note that if the decorated function uses `Variable`s, the enclosing variable\n",
      "        scope must be using\n",
      "        [ResourceVariables](https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables).\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a tuple `(y, grad_fn)` where: - `x` is a\n",
      "            sequence of (nested structures of) `Tensor` inputs to the function. - `y`\n",
      "            is a (nested structure of) `Tensor` outputs of applying TensorFlow\n",
      "            operations in `f` to `x`. - `grad_fn` is a function with the signature\n",
      "            `g(*grad_ys)` which returns a list of `Tensor`s the same size as\n",
      "            (flattened) `x` - the derivatives of `Tensor`s in `y` with respect to the\n",
      "            `Tensor`s in `x`.  `grad_ys` is a sequence of `Tensor`s the same size as\n",
      "            (flattened) `y` holding the initial value gradients for each `Tensor` in\n",
      "            `y`.  In a pure mathematical sense, a vector-argument vector-valued\n",
      "            function `f`'s derivatives should be its Jacobian matrix `J`. Here we are\n",
      "            expressing the Jacobian `J` as a function `grad_fn` which defines how `J`\n",
      "            will transform a vector `grad_ys` when left-multiplied with it (`grad_ys *\n",
      "            J`, the vector-Jacobian product, or VJP). This functional representation\n",
      "            of a matrix is convenient to use for chain-rule calculation (in e.g. the\n",
      "            back-propagation algorithm).  If `f` uses `Variable`s (that are not part\n",
      "            of the inputs), i.e. through `get_variable`, then `grad_fn` should have\n",
      "            signature `g(*grad_ys, variables=None)`, where `variables` is a list of\n",
      "            the `Variable`s, and return a 2-tuple `(grad_xs, grad_vars)`, where\n",
      "            `grad_xs` is the same as above, and `grad_vars` is a `list<Tensor>` with\n",
      "            the derivatives of `Tensor`s in `y` with respect to the variables (that\n",
      "            is, grad_vars has one Tensor per variable in variables).\n",
      "        \n",
      "        Returns:\n",
      "          A function `h(x)` which returns the same value as `f(x)[0]` and whose\n",
      "          gradient (as calculated by `tf.gradients`) is determined by `f(x)[1]`.\n",
      "    \n",
      "    decode_base64(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Decode web-safe base64-encoded strings.\n",
      "        \n",
      "        Input may or may not have padding at the end. See\n",
      "        [EncodeBase64](https://www.tensorflow.org/api_docs/python/tf/io/encode_base64)\n",
      "        for padding. Web-safe means that input must use - and _ instead of + and /.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Base64 strings to decode.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    decode_compressed(bytes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], compression_type: str = '', name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Decompress strings.\n",
      "        \n",
      "        This op decompresses each element of the `bytes` input `Tensor`, which\n",
      "        is assumed to be compressed using the given `compression_type`.\n",
      "        \n",
      "        The `output` is a string `Tensor` of the same shape as `bytes`,\n",
      "        each element containing the decompressed data from the corresponding\n",
      "        element in `bytes`.\n",
      "        \n",
      "        Args:\n",
      "          bytes: A `Tensor` of type `string`.\n",
      "            A Tensor of string which is compressed.\n",
      "          compression_type: An optional `string`. Defaults to `\"\"`.\n",
      "            A scalar containing either (i) the empty string (no\n",
      "            compression), (ii) \"ZLIB\", or (iii) \"GZIP\".\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    decode_csv(records, record_defaults, field_delim=',', use_quote_delim=True, name=None, na_value='', select_cols=None)\n",
      "        Convert CSV records to tensors. Each column maps to one tensor.\n",
      "        \n",
      "        RFC 4180 format is expected for the CSV records.\n",
      "        (https://tools.ietf.org/html/rfc4180)\n",
      "        Note that we allow leading and trailing spaces with int or float field.\n",
      "        \n",
      "        Args:\n",
      "          records: A `Tensor` of type `string`.\n",
      "            Each string is a record/row in the csv and all records should have\n",
      "            the same format.\n",
      "          record_defaults: A list of `Tensor` objects with specific types.\n",
      "            Acceptable types are `float32`, `float64`, `int32`, `int64`, `string`.\n",
      "            One tensor per column of the input record, with either a\n",
      "            scalar default value for that column or an empty vector if the column is\n",
      "            required.\n",
      "          field_delim: An optional `string`. Defaults to `\",\"`.\n",
      "            char delimiter to separate fields in a record.\n",
      "          use_quote_delim: An optional `bool`. Defaults to `True`.\n",
      "            If false, treats double quotation marks as regular\n",
      "            characters inside of the string fields (ignoring RFC 4180, Section 2,\n",
      "            Bullet 5).\n",
      "          name: A name for the operation (optional).\n",
      "          na_value: Additional string to recognize as NA/NaN.\n",
      "          select_cols: Optional sorted list of column indices to select. If specified,\n",
      "            only this subset of columns will be parsed and returned.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` objects. Has the same type as `record_defaults`.\n",
      "          Each tensor will have the same shape as records.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the arguments is malformed.\n",
      "    \n",
      "    decode_json_example(json_examples, name=None)\n",
      "        Convert JSON-encoded Example records to binary protocol buffer strings.\n",
      "        \n",
      "        Note: This is **not** a general purpose JSON parsing op.\n",
      "        \n",
      "        This op converts JSON-serialized `tf.train.Example` (maybe created with\n",
      "        `json_format.MessageToJson`, following the\n",
      "        [standard JSON mapping](\n",
      "        https://developers.google.com/protocol-buffers/docs/proto3#json))\n",
      "        to a binary-serialized `tf.train.Example` (equivalent to\n",
      "        `Example.SerializeToString()`) suitable for conversion to tensors with\n",
      "        `tf.io.parse_example`.\n",
      "        \n",
      "        Here is a `tf.train.Example` proto:\n",
      "        \n",
      "        >>> example = tf.train.Example(\n",
      "        ...   features=tf.train.Features(\n",
      "        ...       feature={\n",
      "        ...           \"a\": tf.train.Feature(\n",
      "        ...               int64_list=tf.train.Int64List(\n",
      "        ...                   value=[1, 1, 3]))}))\n",
      "        \n",
      "        Here it is converted to JSON:\n",
      "        \n",
      "        >>> from google.protobuf import json_format\n",
      "        >>> example_json = json_format.MessageToJson(example)\n",
      "        >>> print(example_json)\n",
      "        {\n",
      "          \"features\": {\n",
      "            \"feature\": {\n",
      "              \"a\": {\n",
      "                \"int64List\": {\n",
      "                  \"value\": [\n",
      "                    \"1\",\n",
      "                    \"1\",\n",
      "                    \"3\"\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        \n",
      "        This op converts the above json string to a binary proto:\n",
      "        \n",
      "        >>> example_binary = tf.io.decode_json_example(example_json)\n",
      "        >>> example_binary.numpy()\n",
      "        b'\\n\\x0f\\n\\r\\n\\x01a\\x12\\x08\\x1a\\x06\\x08\\x01\\x08\\x01\\x08\\x03'\n",
      "        \n",
      "        The OP works on string tensors of andy shape:\n",
      "        \n",
      "        >>> tf.io.decode_json_example([\n",
      "        ...     [example_json, example_json],\n",
      "        ...     [example_json, example_json]]).shape.as_list()\n",
      "        [2, 2]\n",
      "        \n",
      "        This resulting binary-string is equivalent to `Example.SerializeToString()`,\n",
      "        and can be converted to Tensors using `tf.io.parse_example` and related\n",
      "        functions:\n",
      "        \n",
      "        >>> tf.io.parse_example(\n",
      "        ...   serialized=[example_binary.numpy(),\n",
      "        ...              example.SerializeToString()],\n",
      "        ...   features = {'a': tf.io.FixedLenFeature(shape=[3], dtype=tf.int64)})\n",
      "        {'a': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
      "         array([[1, 1, 3],\n",
      "                [1, 1, 3]])>}\n",
      "        \n",
      "        Args:\n",
      "          json_examples: A string tensor containing json-serialized `tf.Example`\n",
      "            protos.\n",
      "          name: A name for the op.\n",
      "        \n",
      "        Returns:\n",
      "          A string Tensor containing the binary-serialized `tf.Example` protos.\n",
      "        \n",
      "        Raises:\n",
      "           `tf.errors.InvalidArgumentError`: If the JSON could not be converted to a\n",
      "           `tf.Example`\n",
      "    \n",
      "    decode_raw = decode_raw_v1(input_bytes=None, out_type=None, little_endian=True, name=None, bytes=None)\n",
      "        Convert raw byte strings into tensors. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(bytes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        bytes is deprecated, use input_bytes instead\n",
      "        \n",
      "        Args:\n",
      "          input_bytes:\n",
      "            Each element of the input Tensor is converted to an array of bytes.\n",
      "          out_type:\n",
      "            `DType` of the output. Acceptable types are `half`, `float`, `double`,\n",
      "            `int32`, `uint16`, `uint8`, `int16`, `int8`, `int64`.\n",
      "          little_endian:\n",
      "            Whether the `input_bytes` data is in little-endian format. Data will be\n",
      "            converted into host byte order if necessary.\n",
      "          name: A name for the operation (optional).\n",
      "          bytes: Deprecated parameter. Use `input_bytes` instead.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` object storing the decoded bytes.\n",
      "    \n",
      "    delete_session_tensor(handle, name=None)\n",
      "        Delete the tensor for the given tensor handle.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Delete the tensor of a given tensor handle. The tensor is produced\n",
      "        in a previous run() and stored in the state of the session.\n",
      "        \n",
      "        Args:\n",
      "          handle: The string representation of a persistent tensor handle.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A pair of graph elements. The first is a placeholder for feeding a\n",
      "          tensor handle and the second is a deletion operation.\n",
      "    \n",
      "    depth_to_space(input, block_size, name=None, data_format='NHWC')\n",
      "        DepthToSpace for tensors of type T.\n",
      "        \n",
      "        Rearranges data from depth into blocks of spatial data.\n",
      "        This is the reverse transformation of SpaceToDepth. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `depth`\n",
      "        dimension are moved in spatial blocks to the `height` and `width` dimensions.\n",
      "        The attr `block_size` indicates the input block size and how the data is moved.\n",
      "        \n",
      "          * Chunks of data of size `block_size * block_size` from depth are rearranged\n",
      "            into non-overlapping blocks of size `block_size x block_size`\n",
      "          * The width of the output tensor is `input_depth * block_size`, whereas the\n",
      "            height is `input_height * block_size`.\n",
      "          * The Y, X coordinates within each block of the output image are determined\n",
      "            by the high order component of the input channel index.\n",
      "          * The depth of the input tensor must be divisible by\n",
      "            `block_size * block_size`.\n",
      "        \n",
      "        The `data_format` attr specifies the layout of the input and output tensors\n",
      "        with the following options:\n",
      "          \"NHWC\": `[ batch, height, width, channels ]`\n",
      "          \"NCHW\": `[ batch, channels, height, width ]`\n",
      "          \"NCHW_VECT_C\":\n",
      "              `qint8 [ batch, channels / 4, height, width, 4 ]`\n",
      "        \n",
      "        It is useful to consider the operation as transforming a 6-D Tensor.\n",
      "        e.g. for data_format = NHWC,\n",
      "             Each element in the input tensor can be specified via 6 coordinates,\n",
      "             ordered by decreasing memory layout significance as:\n",
      "             n,iY,iX,bY,bX,oC  (where n=batch index, iX, iY means X or Y coordinates\n",
      "                                within the input image, bX, bY means coordinates\n",
      "                                within the output block, oC means output channels).\n",
      "             The output would be the input transposed to the following layout:\n",
      "             n,iY,bY,iX,bX,oC\n",
      "        \n",
      "        This operation is useful for resizing the activations between convolutions\n",
      "        (but keeping all data), e.g. instead of pooling. It is also useful for training\n",
      "        purely convolutional models.\n",
      "        \n",
      "        For example, given an input of shape `[1, 1, 1, 4]`, data_format = \"NHWC\" and\n",
      "        block_size = 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        This operation will output a tensor of shape `[1, 2, 2, 1]`:\n",
      "        \n",
      "        ```\n",
      "           [[[[1], [2]],\n",
      "             [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,\n",
      "        the corresponding output will have 2x2 elements and will have a depth of\n",
      "        1 channel (1 = `4 / (block_size * block_size)`).\n",
      "        The output element shape is `[2, 2, 1]`.\n",
      "        \n",
      "        For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation, for block size of 2, will return the following tensor of shape\n",
      "        `[1, 2, 2, 3]`\n",
      "        \n",
      "        ```\n",
      "           [[[[1, 2, 3], [4, 5, 6]],\n",
      "             [[7, 8, 9], [10, 11, 12]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:\n",
      "        \n",
      "        ```\n",
      "        x =  [[[[1, 2, 3, 4],\n",
      "               [5, 6, 7, 8]],\n",
      "              [[9, 10, 11, 12],\n",
      "               [13, 14, 15, 16]]]]\n",
      "        ```\n",
      "        \n",
      "        the operator will return the following tensor of shape `[1 4 4 1]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[ [1],   [2],  [5],  [6]],\n",
      "              [ [3],   [4],  [7],  [8]],\n",
      "              [ [9],  [10], [13],  [14]],\n",
      "              [ [11], [12], [15],  [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "            The size of the spatial block, same as in Space2Depth.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\", \"NCHW_VECT_C\"`. Defaults to `\"NHWC\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    dequantize(input, min_range, max_range, mode='MIN_COMBINED', name=None, axis=None, narrow_range=False, dtype=tf.float32)\n",
      "        Dequantize the 'input' tensor into a float or bfloat16 Tensor.\n",
      "        \n",
      "        [min_range, max_range] are scalar floats that specify the range for\n",
      "        the output. The 'mode' attribute controls exactly which calculations are\n",
      "        used to convert the float values to their quantized equivalents.\n",
      "        \n",
      "        In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:\n",
      "        \n",
      "        ```\n",
      "        if T == qint8: in[i] += (range(T) + 1)/ 2.0\n",
      "        out[i] = min_range + (in[i]* (max_range - min_range) / range(T))\n",
      "        ```\n",
      "        here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`\n",
      "        \n",
      "        *MIN_COMBINED Mode Example*\n",
      "        \n",
      "        If the input comes from a QuantizedRelu6, the output type is\n",
      "        quint8 (range of 0-255) but the possible range of QuantizedRelu6 is\n",
      "        0-6.  The min_range and max_range values are therefore 0.0 and 6.0.\n",
      "        Dequantize on quint8 will take each value, cast to float, and multiply\n",
      "        by 6 / 255.\n",
      "        Note that if quantizedtype is qint8, the operation will additionally add\n",
      "        each value by 128 prior to casting.\n",
      "        \n",
      "        If the mode is 'MIN_FIRST', then this approach is used:\n",
      "        \n",
      "        ```c++\n",
      "        num_discrete_values = 1 << (# of bits in T)\n",
      "        range_adjust = num_discrete_values / (num_discrete_values - 1)\n",
      "        range = (range_max - range_min) * range_adjust\n",
      "        range_scale = range / num_discrete_values\n",
      "        const double offset_input = static_cast<double>(input) - lowest_quantized;\n",
      "        result = range_min + ((input - numeric_limits<T>::min()) * range_scale)\n",
      "        ```\n",
      "        \n",
      "        If the mode is `SCALED`, dequantization is performed by multiplying each\n",
      "        input value by a scaling_factor. (Thus an input of 0 always maps to 0.0).\n",
      "        \n",
      "        The scaling_factor is determined from `min_range`, `max_range`, and\n",
      "        `narrow_range` in a way that is compatible with `QuantizeAndDequantize{V2|V3}`\n",
      "        and `QuantizeV2`, using the following algorithm:\n",
      "        \n",
      "        ```c++\n",
      "        \n",
      "          const int min_expected_T = std::numeric_limits<T>::min() +\n",
      "            (narrow_range ? 1 : 0);\n",
      "          const int max_expected_T = std::numeric_limits<T>::max();\n",
      "          const float max_expected_T = std::numeric_limits<float>::max();\n",
      "        \n",
      "          const float scale_factor =\n",
      "            (std::numeric_limits<T>::min() == 0) ? (max_range / max_expected_T)\n",
      "                                                 : std::max(min_range / min_expected_T,\n",
      "                                                            max_range / max_expected_T);\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.\n",
      "          min_range: A `Tensor` of type `float32`.\n",
      "            The minimum scalar value possibly produced for the input.\n",
      "          max_range: A `Tensor` of type `float32`.\n",
      "            The maximum scalar value possibly produced for the input.\n",
      "          mode: An optional `string` from: `\"MIN_COMBINED\", \"MIN_FIRST\", \"SCALED\"`. Defaults to `\"MIN_COMBINED\"`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          axis: An optional `int`. Defaults to `-1`.\n",
      "          dtype: An optional `tf.DType` from: `tf.bfloat16, tf.float32`. Defaults to `tf.float32`.\n",
      "            Type of the output tensor. Currently Dequantize supports float and bfloat16.\n",
      "            If 'dtype' is 'bfloat16', it only supports 'MIN_COMBINED' mode.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `dtype`.\n",
      "    \n",
      "    deserialize_many_sparse(serialized_sparse, dtype, rank=None, name=None)\n",
      "        Deserialize and concatenate `SparseTensors` from a serialized minibatch.\n",
      "        \n",
      "        The input `serialized_sparse` must be a string matrix of shape `[N x 3]` where\n",
      "        `N` is the minibatch size and the rows correspond to packed outputs of\n",
      "        `serialize_sparse`.  The ranks of the original `SparseTensor` objects\n",
      "        must all match.  When the final `SparseTensor` is created, it has rank one\n",
      "        higher than the ranks of the incoming `SparseTensor` objects (they have been\n",
      "        concatenated along a new row dimension).\n",
      "        \n",
      "        The output `SparseTensor` object's shape values for all dimensions but the\n",
      "        first are the max across the input `SparseTensor` objects' shape values\n",
      "        for the corresponding dimensions.  Its first shape value is `N`, the minibatch\n",
      "        size.\n",
      "        \n",
      "        The input `SparseTensor` objects' indices are assumed ordered in\n",
      "        standard lexicographic order.  If this is not the case, after this\n",
      "        step run `sparse.reorder` to restore index ordering.\n",
      "        \n",
      "        For example, if the serialized input is a `[2, 3]` matrix representing two\n",
      "        original `SparseTensor` objects:\n",
      "        \n",
      "            index = [ 0]\n",
      "                    [10]\n",
      "                    [20]\n",
      "            values = [1, 2, 3]\n",
      "            shape = [50]\n",
      "        \n",
      "        and\n",
      "        \n",
      "            index = [ 2]\n",
      "                    [10]\n",
      "            values = [4, 5]\n",
      "            shape = [30]\n",
      "        \n",
      "        then the final deserialized `SparseTensor` will be:\n",
      "        \n",
      "            index = [0  0]\n",
      "                    [0 10]\n",
      "                    [0 20]\n",
      "                    [1  2]\n",
      "                    [1 10]\n",
      "            values = [1, 2, 3, 4, 5]\n",
      "            shape = [2 50]\n",
      "        \n",
      "        Args:\n",
      "          serialized_sparse: 2-D `Tensor` of type `string` of shape `[N, 3]`.\n",
      "            The serialized and packed `SparseTensor` objects.\n",
      "          dtype: The `dtype` of the serialized `SparseTensor` objects.\n",
      "          rank: (optional) Python int, the rank of the `SparseTensor` objects.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` representing the deserialized `SparseTensor`s,\n",
      "          concatenated along the `SparseTensor`s' first dimension.\n",
      "        \n",
      "          All of the serialized `SparseTensor`s must have had the same rank and type.\n",
      "    \n",
      "    device(device_name_or_function) -> ContextManager[NoneType]\n",
      "        Wrapper for `Graph.device()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.device` for more details.\n",
      "        \n",
      "        Args:\n",
      "          device_name_or_function: The device name or function to use in the context.\n",
      "        \n",
      "        Returns:\n",
      "          A context manager that specifies the default device to use for newly\n",
      "          created ops.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If eager execution is enabled and a function is passed in.\n",
      "    \n",
      "    diag(diagonal: Annotated[Any, ~TV_Diag_T], name=None) -> Annotated[Any, ~TV_Diag_T]\n",
      "        Returns a diagonal tensor with a given diagonal values.\n",
      "        \n",
      "        Given a `diagonal`, this operation returns a tensor with the `diagonal` and\n",
      "        everything else padded with zeros. The diagonal is computed as follows:\n",
      "        \n",
      "        Assume `diagonal` has dimensions [D1,..., Dk], then the output is a tensor of\n",
      "        rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:\n",
      "        \n",
      "        `output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]` and 0 everywhere else.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # 'diagonal' is [1, 2, 3, 4]\n",
      "        tf.diag(diagonal) ==> [[1, 0, 0, 0]\n",
      "                               [0, 2, 0, 0]\n",
      "                               [0, 0, 3, 0]\n",
      "                               [0, 0, 0, 4]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          diagonal: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "            Rank k tensor where k is at most 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `diagonal`.\n",
      "    \n",
      "    diag_part = tensor_diag_part(input, name=None)\n",
      "        Returns the diagonal part of the tensor.\n",
      "        \n",
      "        This operation returns a tensor with the `diagonal` part\n",
      "        of the `input`. The `diagonal` part is computed as follows:\n",
      "        \n",
      "        Assume `input` has dimensions `[D1,..., Dk, D1,..., Dk]`, then the output is a\n",
      "        tensor of rank `k` with dimensions `[D1,..., Dk]` where:\n",
      "        \n",
      "        `diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]`.\n",
      "        \n",
      "        For a rank 2 tensor, `linalg.diag_part` and `linalg.tensor_diag_part`\n",
      "        produce the same result. For rank 3 and higher, linalg.diag_part extracts\n",
      "        the diagonal of each inner-most matrix in the tensor. An example where\n",
      "        they differ is given below.\n",
      "        \n",
      "        >>> x = [[[[1111,1112],[1121,1122]],\n",
      "        ...       [[1211,1212],[1221,1222]]],\n",
      "        ...      [[[2111, 2112], [2121, 2122]],\n",
      "        ...       [[2211, 2212], [2221, 2222]]]\n",
      "        ...      ]\n",
      "        >>> tf.linalg.tensor_diag_part(x)\n",
      "        <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "        array([[1111, 1212],\n",
      "               [2121, 2222]], dtype=int32)>\n",
      "        >>> tf.linalg.diag_part(x).shape\n",
      "        TensorShape([2, 2, 2])\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` with rank `2k`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor containing diagonals of `input`. Has the same type as `input`, and\n",
      "          rank `k`.\n",
      "    \n",
      "    digamma(x: typing.Annotated[_any, ~TV_Digamma_T], name=None) -> typing.Annotated[_any, ~TV_Digamma_T]\n",
      "        Computes Psi, the derivative of Lgamma (the log of the absolute value of\n",
      "        \n",
      "        `Gamma(x)`), element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    dimension_at_index(shape, index) -> 'Dimension'\n",
      "        Compatibility utility required to allow for both V1 and V2 behavior in TF.\n",
      "        \n",
      "        Until the release of TF 2.0, we need the legacy behavior of `TensorShape` to\n",
      "        coexist with the new behavior. This utility is a bridge between the two.\n",
      "        \n",
      "        If you want to retrieve the Dimension instance corresponding to a certain\n",
      "        index in a TensorShape instance, use this utility, like this:\n",
      "        \n",
      "        ```\n",
      "        # If you had this in your V1 code:\n",
      "        dim = tensor_shape[i]\n",
      "        \n",
      "        # Use `dimension_at_index` as direct replacement compatible with both V1 & V2:\n",
      "        dim = dimension_at_index(tensor_shape, i)\n",
      "        \n",
      "        # Another possibility would be this, but WARNING: it only works if the\n",
      "        # tensor_shape instance has a defined rank.\n",
      "        dim = tensor_shape.dims[i]  # `dims` may be None if the rank is undefined!\n",
      "        \n",
      "        # In native V2 code, we recommend instead being more explicit:\n",
      "        if tensor_shape.rank is None:\n",
      "          dim = Dimension(None)\n",
      "        else:\n",
      "          dim = tensor_shape.dims[i]\n",
      "        \n",
      "        # Being more explicit will save you from the following trap (present in V1):\n",
      "        # you might do in-place modifications to `dim` and expect them to be reflected\n",
      "        # in `tensor_shape[i]`, but they would not be (as the Dimension object was\n",
      "        # instantiated on the fly.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          shape: A TensorShape instance.\n",
      "          index: An integer index.\n",
      "        \n",
      "        Returns:\n",
      "          A dimension object.\n",
      "    \n",
      "    dimension_value(dimension: Union[ForwardRef('Dimension'), int, NoneType]) -> Optional[int]\n",
      "        Compatibility utility required to allow for both V1 and V2 behavior in TF.\n",
      "        \n",
      "        Until the release of TF 2.0, we need the legacy behavior of `TensorShape` to\n",
      "        coexist with the new behavior. This utility is a bridge between the two.\n",
      "        \n",
      "        When accessing the value of a TensorShape dimension,\n",
      "        use this utility, like this:\n",
      "        \n",
      "        ```\n",
      "        # If you had this in your V1 code:\n",
      "        value = tensor_shape[i].value\n",
      "        \n",
      "        # Use `dimension_value` as direct replacement compatible with both V1 & V2:\n",
      "        value = dimension_value(tensor_shape[i])\n",
      "        \n",
      "        # This would be the V2 equivalent:\n",
      "        value = tensor_shape[i]  # Warning: this will return the dim value in V2!\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          dimension: Either a `Dimension` instance, an integer, or None.\n",
      "        \n",
      "        Returns:\n",
      "          A plain value, i.e. an integer or None.\n",
      "    \n",
      "    disable_control_flow_v2()\n",
      "        Opts out of control flow v2.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function. Calling this\n",
      "        function has no effect in that case.\n",
      "        \n",
      "        If your code needs tf.disable_control_flow_v2() to be called to work\n",
      "        properly please file a bug.\n",
      "    \n",
      "    disable_eager_execution() -> None\n",
      "        Disables eager execution.\n",
      "        \n",
      "        This function can only be called before any Graphs, Ops, or Tensors have been\n",
      "        created.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This function is not necessary if you are using TF2. Eager execution is\n",
      "        enabled by default. If you want to use Graph mode please consider\n",
      "        [tf.function](https://www.tensorflow.org/api_docs/python/tf/function).\n",
      "        @end_compatibility\n",
      "    \n",
      "    disable_resource_variables() -> None\n",
      "        Opts out of resource variables. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        non-resource variables are not supported in the long term\n",
      "        \n",
      "        If your code needs tf.disable_resource_variables() to be called to work\n",
      "        properly please file a bug.\n",
      "    \n",
      "    disable_tensor_equality()\n",
      "        Compare Tensors by their id and be hashable.\n",
      "        \n",
      "        This is a legacy behaviour of TensorFlow and is highly discouraged.\n",
      "    \n",
      "    disable_v2_behavior()\n",
      "        Disables TensorFlow 2.x behaviors.\n",
      "        \n",
      "        This function can be called at the beginning of the program (before `Tensors`,\n",
      "        `Graphs` or other structures have been created, and before devices have been\n",
      "        initialized. It switches all global behaviors that are different between\n",
      "        TensorFlow 1.x and 2.x to behave as intended for 1.x.\n",
      "        \n",
      "        User can call this function to disable 2.x behavior during complex migrations.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Using this function indicates that your software is not compatible\n",
      "        with eager execution and `tf.function` in TF2.\n",
      "        \n",
      "        To migrate to TF2, rewrite your code to be compatible with eager execution.\n",
      "        Please refer to the [migration guide]\n",
      "        (https://www.tensorflow.org/guide/migrate) for additional resource on the\n",
      "        topic.\n",
      "        @end_compatibility\n",
      "    \n",
      "    disable_v2_tensorshape()\n",
      "        Disables the V2 TensorShape behavior and reverts to V1 behavior.\n",
      "        \n",
      "        See docstring for `enable_v2_tensorshape` for details about the new behavior.\n",
      "    \n",
      "    div(x, y, name=None)\n",
      "        Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Deprecated in favor of operator or tf.math.divide.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "        `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "        semantics.\n",
      "        @end_compatibility\n",
      "        \n",
      "        \n",
      "        This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "        and `y` are both integers then the result will be an integer. This is in\n",
      "        contrast to Python 3, where division with `/` is always a float while division\n",
      "        with `//` is always an integer.\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of real numeric type.\n",
      "          y: `Tensor` denominator of real numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` returns the quotient of x and y.\n",
      "    \n",
      "    div_no_nan(x, y, name=None)\n",
      "        Computes a safe divide which returns 0 if `y` (denominator) is zero.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.constant(3.0) / 0.0\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=inf>\n",
      "        >>> tf.math.divide_no_nan(3.0, 0.0)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=0.0>\n",
      "        \n",
      "        Note that 0 is returned if `y` is 0 even if `x` is nonfinite:\n",
      "        \n",
      "        >>> tf.math.divide_no_nan(np.nan, 0.0)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=0.0>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of a floating or integer dtype.\n",
      "          y: A `Tensor` with the same dtype as `x` and a compatible shape.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The element-wise quotient as in `tf.math.divide(x, y)`,\n",
      "          except that division by zero produces `0.0`, not `nan`.\n",
      "    \n",
      "    divide(x, y, name=None)\n",
      "        Computes Python style division of `x` by `y`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([16, 12, 11])\n",
      "        >>> y = tf.constant([4, 6, 2])\n",
      "        >>> tf.divide(x,y)\n",
      "        <tf.Tensor: shape=(3,), dtype=float64,\n",
      "        numpy=array([4. , 2. , 5.5])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`\n",
      "          y: A `Tensor`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with same shape as input\n",
      "    \n",
      "    dynamic_partition(data: Annotated[Any, ~TV_DynamicPartition_T], partitions: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], num_partitions: int, name=None)\n",
      "        Partitions `data` into `num_partitions` tensors using indices from `partitions`.\n",
      "        \n",
      "        For each index tuple `js` of size `partitions.ndim`, the slice `data[js, ...]`\n",
      "        becomes part of `outputs[partitions[js]]`.  The slices with `partitions[js] = i`\n",
      "        are placed in `outputs[i]` in lexicographic order of `js`, and the first\n",
      "        dimension of `outputs[i]` is the number of entries in `partitions` equal to `i`.\n",
      "        In detail,\n",
      "        \n",
      "        ```python\n",
      "            outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]\n",
      "        \n",
      "            outputs[i] = pack([data[js, ...] for js if partitions[js] == i])\n",
      "        ```\n",
      "        \n",
      "        `data.shape` must start with `partitions.shape`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "            # Scalar partitions.\n",
      "            partitions = 1\n",
      "            num_partitions = 2\n",
      "            data = [10, 20]\n",
      "            outputs[0] = []  # Empty with shape [0, 2]\n",
      "            outputs[1] = [[10, 20]]\n",
      "        \n",
      "            # Vector partitions.\n",
      "            partitions = [0, 0, 1, 1, 0]\n",
      "            num_partitions = 2\n",
      "            data = [10, 20, 30, 40, 50]\n",
      "            outputs[0] = [10, 20, 50]\n",
      "            outputs[1] = [30, 40]\n",
      "        ```\n",
      "        \n",
      "        See `dynamic_stitch` for an example on how to merge partitions back.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/DynamicPartition.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        \n",
      "        Raises:\n",
      "          * `InvalidArgumentError` in following cases:\n",
      "            - If partitions is not in range `[0, num_partiions)`\n",
      "            - If `partitions.shape` does not match prefix of `data.shape` argument.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`.\n",
      "          partitions: A `Tensor` of type `int32`.\n",
      "            Any shape.  Indices in the range `[0, num_partitions)`.\n",
      "          num_partitions: An `int` that is `>= 1`.\n",
      "            The number of partitions to output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `num_partitions` `Tensor` objects with the same type as `data`.\n",
      "    \n",
      "    dynamic_stitch(indices: Annotated[List[Any], <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], data: Annotated[List[Any], ~TV_DynamicStitch_T], name=None) -> Annotated[Any, ~TV_DynamicStitch_T]\n",
      "        Interleave the values from the `data` tensors into a single tensor.\n",
      "        \n",
      "        Builds a merged tensor such that\n",
      "        \n",
      "        ```python\n",
      "            merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        For example, if each `indices[m]` is scalar or vector, we have\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices:\n",
      "            merged[indices[m], ...] = data[m][...]\n",
      "        \n",
      "            # Vector indices:\n",
      "            merged[indices[m][i], ...] = data[m][i, ...]\n",
      "        ```\n",
      "        \n",
      "        Each `data[i].shape` must start with the corresponding `indices[i].shape`,\n",
      "        and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we\n",
      "        must have `data[i].shape = indices[i].shape + constant`.  In terms of this\n",
      "        `constant`, the output shape is\n",
      "        \n",
      "            merged.shape = [max(indices) + 1] + constant\n",
      "        \n",
      "        Values are merged in order, so if an index appears in both `indices[m][i]` and\n",
      "        `indices[n][j]` for `(m,i) < (n,j)` the slice `data[n][j]` will appear in the\n",
      "        merged result. If you do not need this guarantee, ParallelDynamicStitch might\n",
      "        perform better on some devices.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "            indices[0] = 6\n",
      "            indices[1] = [4, 1]\n",
      "            indices[2] = [[5, 2], [0, 3]]\n",
      "            data[0] = [61, 62]\n",
      "            data[1] = [[41, 42], [11, 12]]\n",
      "            data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]\n",
      "            merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],\n",
      "                      [51, 52], [61, 62]]\n",
      "        ```\n",
      "        \n",
      "        This method can be used to merge partitions created by `dynamic_partition`\n",
      "        as illustrated on the following example:\n",
      "        \n",
      "        ```python\n",
      "            # Apply function (increments x_i) on elements for which a certain condition\n",
      "            # apply (x_i != -1 in this example).\n",
      "            x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])\n",
      "            condition_mask=tf.not_equal(x,tf.constant(-1.))\n",
      "            partitioned_data = tf.dynamic_partition(\n",
      "                x, tf.cast(condition_mask, tf.int32) , 2)\n",
      "            partitioned_data[1] = partitioned_data[1] + 1.0\n",
      "            condition_indices = tf.dynamic_partition(\n",
      "                tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)\n",
      "            x = tf.dynamic_stitch(condition_indices, partitioned_data)\n",
      "            # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain\n",
      "            # unchanged.\n",
      "        ```\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/DynamicStitch.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          indices: A list of at least 1 `Tensor` objects with type `int32`.\n",
      "          data: A list with the same length as `indices` of `Tensor` objects with the same type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    edit_distance(hypothesis, truth, normalize=True, name='edit_distance')\n",
      "        Computes the Levenshtein distance between sequences.\n",
      "        \n",
      "        This operation takes variable-length sequences (`hypothesis` and `truth`),\n",
      "        each provided as a `SparseTensor`, and computes the Levenshtein distance.\n",
      "        You can normalize the edit distance by length of `truth` by setting\n",
      "        `normalize` to true.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        Given the following input,\n",
      "        * `hypothesis` is a `tf.SparseTensor` of shape `[2, 1, 1]`\n",
      "        * `truth` is a `tf.SparseTensor` of shape `[2, 2, 2]`\n",
      "        \n",
      "        >>> hypothesis = tf.SparseTensor(\n",
      "        ...   [[0, 0, 0],\n",
      "        ...    [1, 0, 0]],\n",
      "        ...   [\"a\", \"b\"],\n",
      "        ...   (2, 1, 1))\n",
      "        >>> truth = tf.SparseTensor(\n",
      "        ...   [[0, 1, 0],\n",
      "        ...    [1, 0, 0],\n",
      "        ...    [1, 0, 1],\n",
      "        ...    [1, 1, 0]],\n",
      "        ...    [\"a\", \"b\", \"c\", \"a\"],\n",
      "        ...    (2, 2, 2))\n",
      "        >>> tf.edit_distance(hypothesis, truth, normalize=True)\n",
      "        <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "        array([[inf, 1. ],\n",
      "               [0.5, 1. ]], dtype=float32)>\n",
      "        \n",
      "        The operation returns a dense Tensor of shape `[2, 2]` with\n",
      "        edit distances normalized by `truth` lengths.\n",
      "        \n",
      "        **Note**: It is possible to calculate edit distance between two\n",
      "        sparse tensors with variable-length values. However, attempting to create\n",
      "        them while eager execution is enabled will result in a `ValueError`.\n",
      "        \n",
      "        For the following  inputs,\n",
      "        \n",
      "        ```python\n",
      "        # 'hypothesis' is a tensor of shape `[2, 1]` with variable-length values:\n",
      "        #   (0,0) = [\"a\"]\n",
      "        #   (1,0) = [\"b\"]\n",
      "        hypothesis = tf.sparse.SparseTensor(\n",
      "            [[0, 0, 0],\n",
      "             [1, 0, 0]],\n",
      "            [\"a\", \"b\"],\n",
      "            (2, 1, 1))\n",
      "        \n",
      "        # 'truth' is a tensor of shape `[2, 2]` with variable-length values:\n",
      "        #   (0,0) = []\n",
      "        #   (0,1) = [\"a\"]\n",
      "        #   (1,0) = [\"b\", \"c\"]\n",
      "        #   (1,1) = [\"a\"]\n",
      "        truth = tf.sparse.SparseTensor(\n",
      "            [[0, 1, 0],\n",
      "             [1, 0, 0],\n",
      "             [1, 0, 1],\n",
      "             [1, 1, 0]],\n",
      "            [\"a\", \"b\", \"c\", \"a\"],\n",
      "            (2, 2, 2))\n",
      "        \n",
      "        normalize = True\n",
      "        \n",
      "        # The output would be a dense Tensor of shape `(2,)`, with edit distances\n",
      "        normalized by 'truth' lengths.\n",
      "        # output => array([0., 0.5], dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          hypothesis: A `SparseTensor` containing hypothesis sequences.\n",
      "          truth: A `SparseTensor` containing truth sequences.\n",
      "          normalize: A `bool`. If `True`, normalizes the Levenshtein distance by\n",
      "            length of `truth.`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A dense `Tensor` with rank `R - 1`, where R is the rank of the\n",
      "          `SparseTensor` inputs `hypothesis` and `truth`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If either `hypothesis` or `truth` are not a `SparseTensor`.\n",
      "    \n",
      "    einsum(equation, *inputs, **kwargs)\n",
      "        Tensor contraction over specified indices and outer product.\n",
      "        \n",
      "        Einsum allows defining Tensors by defining their element-wise computation.\n",
      "        This computation is defined by `equation`, a shorthand form based on Einstein\n",
      "        summation. As an example, consider multiplying two matrices A and B to form a\n",
      "        matrix C.  The elements of C are given by:\n",
      "        \n",
      "        $$ C_{i,k} = \\sum_j A_{i,j} B_{j,k} $$\n",
      "        \n",
      "        or\n",
      "        \n",
      "        ```\n",
      "        C[i,k] = sum_j A[i,j] * B[j,k]\n",
      "        ```\n",
      "        \n",
      "        The corresponding einsum `equation` is:\n",
      "        \n",
      "        ```\n",
      "        ij,jk->ik\n",
      "        ```\n",
      "        \n",
      "        In general, to convert the element-wise equation into the `equation` string,\n",
      "        use the following procedure (intermediate strings for matrix multiplication\n",
      "        example provided in parentheses):\n",
      "        \n",
      "        1. remove variable names, brackets, and commas, (`ik = sum_j ij * jk`)\n",
      "        2. replace \"*\" with \",\", (`ik = sum_j ij , jk`)\n",
      "        3. drop summation signs, and (`ik = ij, jk`)\n",
      "        4. move the output to the right, while replacing \"=\" with \"->\". (`ij,jk->ik`)\n",
      "        \n",
      "        Note: If the output indices are not specified repeated indices are summed.\n",
      "        So `ij,jk->ik` can be simplified to `ij,jk`.\n",
      "        \n",
      "        Many common operations can be expressed in this way.  For example:\n",
      "        \n",
      "        **Matrix multiplication**\n",
      "        \n",
      "        >>> m0 = tf.random.normal(shape=[2, 3])\n",
      "        >>> m1 = tf.random.normal(shape=[3, 5])\n",
      "        >>> e = tf.einsum('ij,jk->ik', m0, m1)\n",
      "        >>> # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
      "        >>> print(e.shape)\n",
      "        (2, 5)\n",
      "        \n",
      "        Repeated indices are summed if the output indices are not specified.\n",
      "        \n",
      "        >>> e = tf.einsum('ij,jk', m0, m1)  # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
      "        >>> print(e.shape)\n",
      "        (2, 5)\n",
      "        \n",
      "        \n",
      "        **Dot product**\n",
      "        \n",
      "        >>> u = tf.random.normal(shape=[5])\n",
      "        >>> v = tf.random.normal(shape=[5])\n",
      "        >>> e = tf.einsum('i,i->', u, v)  # output = sum_i u[i]*v[i]\n",
      "        >>> print(e.shape)\n",
      "        ()\n",
      "        \n",
      "        **Outer product**\n",
      "        \n",
      "        >>> u = tf.random.normal(shape=[3])\n",
      "        >>> v = tf.random.normal(shape=[5])\n",
      "        >>> e = tf.einsum('i,j->ij', u, v)  # output[i,j] = u[i]*v[j]\n",
      "        >>> print(e.shape)\n",
      "        (3, 5)\n",
      "        \n",
      "        **Transpose**\n",
      "        \n",
      "        >>> m = tf.ones(2,3)\n",
      "        >>> e = tf.einsum('ij->ji', m0)  # output[j,i] = m0[i,j]\n",
      "        >>> print(e.shape)\n",
      "        (3, 2)\n",
      "        \n",
      "        **Diag**\n",
      "        \n",
      "        >>> m = tf.reshape(tf.range(9), [3,3])\n",
      "        >>> diag = tf.einsum('ii->i', m)\n",
      "        >>> print(diag.shape)\n",
      "        (3,)\n",
      "        \n",
      "        **Trace**\n",
      "        \n",
      "        >>> # Repeated indices are summed.\n",
      "        >>> trace = tf.einsum('ii', m)  # output[j,i] = trace(m) = sum_i m[i, i]\n",
      "        >>> assert trace == sum(diag)\n",
      "        >>> print(trace.shape)\n",
      "        ()\n",
      "        \n",
      "        **Batch matrix multiplication**\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[7,5,3])\n",
      "        >>> t = tf.random.normal(shape=[7,3,2])\n",
      "        >>> e = tf.einsum('bij,bjk->bik', s, t)\n",
      "        >>> # output[a,i,k] = sum_j s[a,i,j] * t[a, j, k]\n",
      "        >>> print(e.shape)\n",
      "        (7, 5, 2)\n",
      "        \n",
      "        This method does not support broadcasting on named-axes. All axes with\n",
      "        matching labels should have the same length. If you have length-1 axes,\n",
      "        use `tf.squeeze` or `tf.reshape` to eliminate them.\n",
      "        \n",
      "        To write code that is agnostic to the number of indices in the input\n",
      "        use an ellipsis. The ellipsis is a placeholder for \"whatever other indices\n",
      "        fit here\".\n",
      "        \n",
      "        For example, to perform a NumPy-style broadcasting-batch-matrix multiplication\n",
      "        where the matrix multiply acts on the last two axes of the input, use:\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[11, 7, 5, 3])\n",
      "        >>> t = tf.random.normal(shape=[11, 7, 3, 2])\n",
      "        >>> e =  tf.einsum('...ij,...jk->...ik', s, t)\n",
      "        >>> print(e.shape)\n",
      "        (11, 7, 5, 2)\n",
      "        \n",
      "        Einsum **will** broadcast over axes covered by the ellipsis.\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[11, 1, 5, 3])\n",
      "        >>> t = tf.random.normal(shape=[1, 7, 3, 2])\n",
      "        >>> e =  tf.einsum('...ij,...jk->...ik', s, t)\n",
      "        >>> print(e.shape)\n",
      "        (11, 7, 5, 2)\n",
      "        \n",
      "        Args:\n",
      "          equation: a `str` describing the contraction, in the same format as\n",
      "            `numpy.einsum`.\n",
      "          *inputs: the inputs to contract (each one a `Tensor`), whose shapes should\n",
      "            be consistent with `equation`.\n",
      "          **kwargs:\n",
      "            - optimize: Optimization strategy to use to find contraction path using\n",
      "              opt_einsum. Must be 'greedy', 'optimal', 'branch-2', 'branch-all' or\n",
      "                'auto'. (optional, default: 'greedy').\n",
      "            - name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The contracted `Tensor`, with shape determined by `equation`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If\n",
      "            - the format of `equation` is incorrect,\n",
      "            - number of inputs or their shapes are inconsistent with `equation`.\n",
      "    \n",
      "    enable_control_flow_v2()\n",
      "        Use control flow v2.\n",
      "        \n",
      "        control flow v2 (cfv2) is an improved version of control flow in TensorFlow\n",
      "        with support for higher order derivatives. Enabling cfv2 will change the\n",
      "        graph/function representation of control flow, e.g., `tf.while_loop` and\n",
      "        `tf.cond` will generate functional `While` and `If` ops instead of low-level\n",
      "        `Switch`, `Merge` etc. ops. Note: Importing and running graphs exported\n",
      "        with old control flow will still be supported.\n",
      "        \n",
      "        Calling tf.enable_control_flow_v2() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function. Calling this\n",
      "        function is not required.\n",
      "    \n",
      "    enable_eager_execution(config=None, device_policy=None, execution_mode=None) -> None\n",
      "        Enables eager execution for the lifetime of this program.\n",
      "        \n",
      "        Eager execution provides an imperative interface to TensorFlow. With eager\n",
      "        execution enabled, TensorFlow functions execute operations immediately (as\n",
      "        opposed to adding to a graph to be executed later in a `tf.compat.v1.Session`)\n",
      "        and\n",
      "        return concrete values (as opposed to symbolic references to a node in a\n",
      "        computational graph).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        # After eager execution is enabled, operations are executed as they are\n",
      "        # defined and Tensor objects hold concrete values, which can be accessed as\n",
      "        # numpy.ndarray`s through the numpy() method.\n",
      "        assert tf.multiply(6, 7).numpy() == 42\n",
      "        ```\n",
      "        \n",
      "        Eager execution cannot be enabled after TensorFlow APIs have been used to\n",
      "        create or execute graphs. It is typically recommended to invoke this function\n",
      "        at program startup and not in a library (as most libraries should be usable\n",
      "        both with and without eager execution).\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This function is not necessary if you are using TF2. Eager execution is\n",
      "        enabled by default.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          config: (Optional.) A `tf.compat.v1.ConfigProto` to use to configure the\n",
      "            environment in which operations are executed. Note that\n",
      "            `tf.compat.v1.ConfigProto` is also used to configure graph execution (via\n",
      "            `tf.compat.v1.Session`) and many options within `tf.compat.v1.ConfigProto`\n",
      "            are not implemented (or are irrelevant) when eager execution is enabled.\n",
      "          device_policy: (Optional.) Policy controlling how operations requiring\n",
      "            inputs on a specific device (e.g., a GPU 0) handle inputs on a different\n",
      "            device  (e.g. GPU 1 or CPU). When set to None, an appropriate value will\n",
      "            be picked automatically. The value picked may change between TensorFlow\n",
      "            releases.\n",
      "            Valid values:\n",
      "            - DEVICE_PLACEMENT_EXPLICIT: raises an error if the\n",
      "              placement is not correct.\n",
      "            - DEVICE_PLACEMENT_WARN: copies the tensors which are not\n",
      "              on the right device but logs a warning.\n",
      "            - DEVICE_PLACEMENT_SILENT: silently copies the tensors.\n",
      "              Note that this may hide performance problems as there is no notification\n",
      "              provided when operations are blocked on the tensor being copied between\n",
      "              devices.\n",
      "            - DEVICE_PLACEMENT_SILENT_FOR_INT32: silently copies\n",
      "              int32 tensors, raising errors on the other ones.\n",
      "          execution_mode: (Optional.) Policy controlling how operations dispatched are\n",
      "            actually executed. When set to None, an appropriate value will be picked\n",
      "            automatically. The value picked may change between TensorFlow releases.\n",
      "            Valid values:\n",
      "            - SYNC: executes each operation synchronously.\n",
      "            - ASYNC: executes each operation asynchronously. These\n",
      "              operations may return \"non-ready\" handles.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If eager execution is enabled after creating/executing a\n",
      "           TensorFlow graph, or if options provided conflict with a previous call\n",
      "           to this function.\n",
      "    \n",
      "    enable_resource_variables() -> None\n",
      "        Creates resource variables by default.\n",
      "        \n",
      "        Resource variables are improved versions of TensorFlow variables with a\n",
      "        well-defined memory model. Accessing a resource variable reads its value, and\n",
      "        all ops which access a specific read value of the variable are guaranteed to\n",
      "        see the same value for that tensor. Writes which happen after a read (by\n",
      "        having a control or data dependency on the read) are guaranteed not to affect\n",
      "        the value of the read tensor, and similarly writes which happen before a read\n",
      "        are guaranteed to affect the value. No guarantees are made about unordered\n",
      "        read/write pairs.\n",
      "        \n",
      "        Calling tf.enable_resource_variables() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "    \n",
      "    enable_tensor_equality()\n",
      "        Compare Tensors with element-wise comparison and thus be unhashable.\n",
      "        \n",
      "        Comparing tensors with element-wise allows comparisons such as\n",
      "        tf.Variable(1.0) == 1.0. Element-wise equality implies that tensors are\n",
      "        unhashable. Thus tensors can no longer be directly used in sets or as a key in\n",
      "        a dictionary.\n",
      "    \n",
      "    enable_v2_behavior()\n",
      "        Enables TensorFlow 2.x behaviors.\n",
      "        \n",
      "        This function can be called at the beginning of the program (before `Tensors`,\n",
      "        `Graphs` or other structures have been created, and before devices have been\n",
      "        initialized. It switches all global behaviors that are different between\n",
      "        TensorFlow 1.x and 2.x to behave as intended for 2.x.\n",
      "        \n",
      "        This function is called in the main TensorFlow `__init__.py` file, user should\n",
      "        not need to call it, except during complex migrations.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This function is not necessary if you are using TF2. V2 behavior is enabled by\n",
      "        default.\n",
      "        @end_compatibility\n",
      "    \n",
      "    enable_v2_tensorshape()\n",
      "        In TensorFlow 2.0, iterating over a TensorShape instance returns values.\n",
      "        \n",
      "        This enables the new behavior.\n",
      "        \n",
      "        Concretely, `tensor_shape[i]` returned a Dimension instance in V1, but\n",
      "        it V2 it returns either an integer, or None.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```\n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        value = tensor_shape[i].value\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        value = tensor_shape[i]\n",
      "        \n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        for dim in tensor_shape:\n",
      "          value = dim.value\n",
      "          print(value)\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        for value in tensor_shape:\n",
      "          print(value)\n",
      "        \n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        dim = tensor_shape[i]\n",
      "        dim.assert_is_compatible_with(other_shape)  # or using any other shape method\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        if tensor_shape.rank is None:\n",
      "          dim = Dimension(None)\n",
      "        else:\n",
      "          dim = tensor_shape.dims[i]\n",
      "        dim.assert_is_compatible_with(other_shape)  # or using any other shape method\n",
      "        \n",
      "        # The V2 suggestion above is more explicit, which will save you from\n",
      "        # the following trap (present in V1):\n",
      "        # you might do in-place modifications to `dim` and expect them to be reflected\n",
      "        # in `tensor_shape[i]`, but they would not be.\n",
      "        ```\n",
      "    \n",
      "    encode_base64(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], pad: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Encode strings into web-safe base64 format.\n",
      "        \n",
      "        Refer to [this article](https://en.wikipedia.org/wiki/Base64) for more information on\n",
      "        base64 format. Base64 strings may have padding with '=' at the\n",
      "        end so that the encoded has length multiple of 4. See Padding section of the\n",
      "        link above.\n",
      "        \n",
      "        Web-safe means that the encoder uses - and _ instead of + and /.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Strings to be encoded.\n",
      "          pad: An optional `bool`. Defaults to `False`.\n",
      "            Bool whether padding is applied at the ends.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    ensure_shape(x, shape, name=None)\n",
      "        Updates the shape of a tensor and checks at runtime that the shape holds.\n",
      "        \n",
      "        When executed, this operation asserts that the input tensor `x`'s shape\n",
      "        is compatible with the `shape` argument.\n",
      "        See `tf.TensorShape.is_compatible_with` for details.\n",
      "        \n",
      "        >>> x = tf.constant([[1, 2, 3],\n",
      "        ...                  [4, 5, 6]])\n",
      "        >>> x = tf.ensure_shape(x, [2, 3])\n",
      "        \n",
      "        Use `None` for unknown dimensions:\n",
      "        \n",
      "        >>> x = tf.ensure_shape(x, [None, 3])\n",
      "        >>> x = tf.ensure_shape(x, [2, None])\n",
      "        \n",
      "        If the tensor's shape is not compatible with the `shape` argument, an error\n",
      "        is raised:\n",
      "        \n",
      "        >>> x = tf.ensure_shape(x, [5])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        tf.errors.InvalidArgumentError: Shape of tensor dummy_input [3] is not\n",
      "          compatible with expected shape [5]. [Op:EnsureShape]\n",
      "        \n",
      "        During graph construction (typically tracing a `tf.function`),\n",
      "        `tf.ensure_shape` updates the static-shape of the **result** tensor by\n",
      "        merging the two shapes. See `tf.TensorShape.merge_with` for details.\n",
      "        \n",
      "        This is most useful when **you** know a shape that can't be determined\n",
      "        statically by TensorFlow.\n",
      "        \n",
      "        The following trivial `tf.function` prints the input tensor's\n",
      "        static-shape before and after `ensure_shape` is applied.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(tensor):\n",
      "        ...   print(\"Static-shape before:\", tensor.shape)\n",
      "        ...   tensor = tf.ensure_shape(tensor, [None, 3])\n",
      "        ...   print(\"Static-shape after:\", tensor.shape)\n",
      "        ...   return tensor\n",
      "        \n",
      "        This lets you see the effect of `tf.ensure_shape` when the function is traced:\n",
      "        >>> cf = f.get_concrete_function(tf.TensorSpec([None, None]))\n",
      "        Static-shape before: (None, None)\n",
      "        Static-shape after: (None, 3)\n",
      "        \n",
      "        >>> cf(tf.zeros([3, 3])) # Passes\n",
      "        >>> cf(tf.constant([1, 2, 3])) # fails\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError:  Shape of tensor x [3] is not compatible with expected shape [3,3].\n",
      "        \n",
      "        The above example raises `tf.errors.InvalidArgumentError`, because `x`'s\n",
      "        shape, `(3,)`, is not compatible with the `shape` argument, `(None, 3)`\n",
      "        \n",
      "        Inside a `tf.function` or `v1.Graph` context it checks both the buildtime and\n",
      "        runtime shapes. This is stricter than `tf.Tensor.set_shape` which only\n",
      "        checks the buildtime shape.\n",
      "        \n",
      "        Note: This differs from `tf.Tensor.set_shape` in that it sets the static shape\n",
      "        of the resulting tensor and enforces it at runtime, raising an error if the\n",
      "        tensor's runtime shape is incompatible with the specified shape.\n",
      "        `tf.Tensor.set_shape` sets the static shape of the tensor without enforcing it\n",
      "        at runtime, which may result in inconsistencies between the statically-known\n",
      "        shape of tensors and the runtime value of tensors.\n",
      "        \n",
      "        For example, of loading images of a known size:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def decode_image(png):\n",
      "        ...   image = tf.image.decode_png(png, channels=3)\n",
      "        ...   # the `print` executes during tracing.\n",
      "        ...   print(\"Initial shape: \", image.shape)\n",
      "        ...   image = tf.ensure_shape(image,[28, 28, 3])\n",
      "        ...   print(\"Final shape: \", image.shape)\n",
      "        ...   return image\n",
      "        \n",
      "        When tracing a function, no ops are being executed, shapes may be unknown.\n",
      "        See the [Concrete Functions Guide](https://www.tensorflow.org/guide/concrete_function)\n",
      "        for details.\n",
      "        \n",
      "        >>> concrete_decode = decode_image.get_concrete_function(\n",
      "        ...     tf.TensorSpec([], dtype=tf.string))\n",
      "        Initial shape:  (None, None, 3)\n",
      "        Final shape:  (28, 28, 3)\n",
      "        \n",
      "        >>> image = tf.random.uniform(maxval=255, shape=[28, 28, 3], dtype=tf.int32)\n",
      "        >>> image = tf.cast(image,tf.uint8)\n",
      "        >>> png = tf.image.encode_png(image)\n",
      "        >>> image2 = concrete_decode(png)\n",
      "        >>> print(image2.shape)\n",
      "        (28, 28, 3)\n",
      "        \n",
      "        >>> image = tf.concat([image,image], axis=0)\n",
      "        >>> print(image.shape)\n",
      "        (56, 28, 3)\n",
      "        >>> png = tf.image.encode_png(image)\n",
      "        >>> image2 = concrete_decode(png)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        tf.errors.InvalidArgumentError:  Shape of tensor DecodePng [56,28,3] is not\n",
      "          compatible with expected shape [28,28,3].\n",
      "        \n",
      "        Caution: if you don't use the result of `tf.ensure_shape` the check may not\n",
      "        run.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def bad_decode_image(png):\n",
      "        ...   image = tf.image.decode_png(png, channels=3)\n",
      "        ...   # the `print` executes during tracing.\n",
      "        ...   print(\"Initial shape: \", image.shape)\n",
      "        ...   # BAD: forgot to use the returned tensor.\n",
      "        ...   tf.ensure_shape(image,[28, 28, 3])\n",
      "        ...   print(\"Final shape: \", image.shape)\n",
      "        ...   return image\n",
      "        \n",
      "        >>> image = bad_decode_image(png)\n",
      "        Initial shape:  (None, None, 3)\n",
      "        Final shape:  (None, None, 3)\n",
      "        >>> print(image.shape)\n",
      "        (56, 28, 3)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`.\n",
      "          shape: A `TensorShape` representing the shape of this tensor, a\n",
      "            `TensorShapeProto`, a list, a tuple, or None.\n",
      "          name: A name for this operation (optional). Defaults to \"EnsureShape\".\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type and contents as `x`.\n",
      "        \n",
      "        Raises:\n",
      "          tf.errors.InvalidArgumentError: If `shape` is incompatible with the shape\n",
      "          of `x`.\n",
      "    \n",
      "    equal(x, y, name=None)\n",
      "        Returns the truth value of (x == y) element-wise.\n",
      "        \n",
      "        Performs a [broadcast](\n",
      "        https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) with the\n",
      "        arguments and then an element-wise equality comparison, returning a Tensor of\n",
      "        boolean values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant(2)\n",
      "        >>> tf.math.equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  False])>\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant([2, 4])\n",
      "        >>> tf.math.equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`.\n",
      "          y: A `tf.Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If shapes of arguments are incompatible\n",
      "    \n",
      "    erf(x: typing.Annotated[_any, ~TV_Erf_T], name=None) -> typing.Annotated[_any, ~TV_Erf_T]\n",
      "        Computes the [Gauss error function](https://en.wikipedia.org/wiki/Error_function) of `x` element-wise. In statistics, for non-negative values of $x$, the error function has the following interpretation: for a random variable $Y$ that is normally distributed with mean 0 and variance $1/\\sqrt{2}$, $erf(x)$ is the probability that $Y$ falls in the range $[−x, x]$.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.math.erf([[1.0, 2.0, 3.0], [0.0, -1.0, -2.0]])\n",
      "        <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
      "        array([[ 0.8427007,  0.9953223,  0.999978 ],\n",
      "               [ 0.       , -0.8427007, -0.9953223]], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.erf(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    erfc(x: typing.Annotated[_any, ~TV_Erfc_T], name=None) -> typing.Annotated[_any, ~TV_Erfc_T]\n",
      "        Computes the complementary error function of `x` element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    executing_eagerly = executing_eagerly_v1()\n",
      "        Checks whether the current thread has eager execution enabled.\n",
      "        \n",
      "        Eager execution is typically enabled via\n",
      "        `tf.compat.v1.enable_eager_execution`, but may also be enabled within the\n",
      "        context of a Python function via tf.contrib.eager.py_func.\n",
      "        \n",
      "        When eager execution is enabled, returns `True` in most cases. However,\n",
      "        this API might return `False` in the following use cases.\n",
      "        \n",
      "        *  Executing inside `tf.function`, unless under `tf.init_scope` or\n",
      "           `tf.config.run_functions_eagerly(True)` is previously called.\n",
      "        *  Executing inside a transformation function for `tf.dataset`.\n",
      "        *  `tf.compat.v1.disable_eager_execution()` is called.\n",
      "        \n",
      "        >>> tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        General case:\n",
      "        \n",
      "        >>> print(tf.executing_eagerly())\n",
      "        True\n",
      "        \n",
      "        Inside `tf.function`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def fn():\n",
      "        ...   with tf.init_scope():\n",
      "        ...     print(tf.executing_eagerly())\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        >>> fn()\n",
      "        True\n",
      "        False\n",
      "        \n",
      "        Inside `tf.function`\n",
      "        after  `tf.config.run_functions_eagerly(True)` is called:\n",
      "        \n",
      "        >>> tf.config.run_functions_eagerly(True)\n",
      "        >>> @tf.function\n",
      "        ... def fn():\n",
      "        ...   with tf.init_scope():\n",
      "        ...     print(tf.executing_eagerly())\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        >>> fn()\n",
      "        True\n",
      "        True\n",
      "        >>> tf.config.run_functions_eagerly(False)\n",
      "        \n",
      "        Inside a transformation function for `tf.dataset`:\n",
      "        \n",
      "        >>> def data_fn(x):\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        ...   return x\n",
      "        >>> dataset = tf.data.Dataset.range(100)\n",
      "        >>> dataset = dataset.map(data_fn)\n",
      "        False\n",
      "        \n",
      "        Returns:\n",
      "          `True` if the current thread has eager execution enabled.\n",
      "    \n",
      "    executing_eagerly_outside_functions() -> bool\n",
      "        Returns True if executing eagerly, even if inside a graph function.\n",
      "        \n",
      "        This function will check the outermost context for the program and see if\n",
      "        it is in eager mode. It is useful comparing to `tf.executing_eagerly()`,\n",
      "        which checks the current context and will return `False` within a\n",
      "        `tf.function` body. It can be used to build library that behave differently\n",
      "        in eager runtime and v1 session runtime (deprecated).\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> tf.compat.v1.enable_eager_execution()\n",
      "        >>> @tf.function\n",
      "        ... def func():\n",
      "        ...   # A function constructs TensorFlow graphs, it does not execute eagerly,\n",
      "        ...   # but the outer most context is still eager.\n",
      "        ...   assert not tf.executing_eagerly()\n",
      "        ...   return tf.compat.v1.executing_eagerly_outside_functions()\n",
      "        >>> func()\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "        \n",
      "        Returns:\n",
      "          boolean, whether the outermost context is in eager mode.\n",
      "    \n",
      "    exp(x, name=None)\n",
      "        Computes exponential of x element-wise.  \\\\(y = e^x\\\\).\n",
      "        \n",
      "        This function computes the exponential of the input tensor element-wise.\n",
      "        i.e. `math.exp(x)` or \\\\(e^x\\\\), where `x` is the input tensor.\n",
      "        \\\\(e\\\\) denotes Euler's number and is approximately equal to 2.718281.\n",
      "        Output is positive for any real input.\n",
      "        \n",
      "        >>> x = tf.constant(2.0)\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=7.389056>\n",
      "        \n",
      "        >>> x = tf.constant([2.0, 8.0])\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32,\n",
      "        numpy=array([   7.389056, 2980.958   ], dtype=float32)>\n",
      "        \n",
      "        For complex numbers, the exponential value is calculated as\n",
      "        $$\n",
      "        e^{x+iy} = {e^x} {e^{iy}} = {e^x} ({\\cos (y) + i \\sin (y)})\n",
      "        $$\n",
      "        \n",
      "        For `1+1j` the value would be computed as:\n",
      "        $$\n",
      "        e^1 (\\cos (1) + i \\sin (1)) = 2.7182817 \\times (0.5403023+0.84147096j)\n",
      "        $$\n",
      "        \n",
      "        >>> x = tf.constant(1 + 1j)\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(), dtype=complex128,\n",
      "        numpy=(1.4686939399158851+2.2873552871788423j)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor`. Has the same type as `x`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.exp\n",
      "        @end_compatibility\n",
      "    \n",
      "    expand_dims(input, axis=None, name=None, dim=None)\n",
      "        Returns a tensor with a length 1 axis inserted at index `axis`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Given a tensor `input`, this operation inserts a dimension of length 1 at the\n",
      "        dimension index `axis` of `input`'s shape. The dimension index follows Python\n",
      "        indexing rules: It's zero-based, a negative index it is counted backward\n",
      "        from the end.\n",
      "        \n",
      "        This operation is useful to:\n",
      "        \n",
      "        * Add an outer \"batch\" dimension to a single element.\n",
      "        * Align axes for broadcasting.\n",
      "        * To add an inner vector length axis to a tensor of scalars.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        If you have a single image of shape `[height, width, channels]`:\n",
      "        \n",
      "        >>> image = tf.zeros([10,10,3])\n",
      "        \n",
      "        You can add an outer `batch` axis by passing `axis=0`:\n",
      "        \n",
      "        >>> tf.expand_dims(image, axis=0).shape.as_list()\n",
      "        [1, 10, 10, 3]\n",
      "        \n",
      "        The new axis location matches Python `list.insert(axis, 1)`:\n",
      "        \n",
      "        >>> tf.expand_dims(image, axis=1).shape.as_list()\n",
      "        [10, 1, 10, 3]\n",
      "        \n",
      "        Following standard Python indexing rules, a negative `axis` counts from the\n",
      "        end so `axis=-1` adds an inner most dimension:\n",
      "        \n",
      "        >>> tf.expand_dims(image, -1).shape.as_list()\n",
      "        [10, 10, 3, 1]\n",
      "        \n",
      "        This operation requires that `axis` is a valid index for `input.shape`,\n",
      "        following Python indexing rules:\n",
      "        \n",
      "        ```\n",
      "        -1-tf.rank(input) <= axis <= tf.rank(input)\n",
      "        ```\n",
      "        \n",
      "        This operation is related to:\n",
      "        \n",
      "        * `tf.squeeze`, which removes dimensions of size 1.\n",
      "        * `tf.reshape`, which provides more flexible reshaping capability.\n",
      "        * `tf.sparse.expand_dims`, which provides this functionality for\n",
      "          `tf.SparseTensor`\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          axis: 0-D (scalar). Specifies the dimension index at which to expand the\n",
      "            shape of `input`. Must be in the range `[-rank(input) - 1, rank(input)]`.\n",
      "          name: The name of the output `Tensor` (optional).\n",
      "          dim: 0-D (scalar). Equivalent to `axis`, to be deprecated.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same data as `input`, but its shape has an additional\n",
      "          dimension of size 1 added.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if either both or neither of `dim` and `axis` are specified.\n",
      "    \n",
      "    expm1(x: typing.Annotated[_any, ~TV_Expm1_T], name=None) -> typing.Annotated[_any, ~TV_Expm1_T]\n",
      "        Computes `exp(x) - 1` element-wise.\n",
      "        \n",
      "          i.e. `exp(x) - 1` or `e^(x) - 1`, where `x` is the input tensor.\n",
      "          `e` denotes Euler's number and is approximately equal to 2.718281.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant(2.0)\n",
      "          tf.math.expm1(x) ==> 6.389056\n",
      "        \n",
      "          x = tf.constant([2.0, 8.0])\n",
      "          tf.math.expm1(x) ==> array([6.389056, 2979.958], dtype=float32)\n",
      "        \n",
      "          x = tf.constant(1 + 1j)\n",
      "          tf.math.expm1(x) ==> (0.46869393991588515+2.2873552871788423j)\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    extract_image_patches(images, ksizes=None, strides=None, rates=None, padding=None, name=None, sizes=None)\n",
      "        Extract `patches` from `images` and put them in the \"depth\" output dimension.\n",
      "        \n",
      "        Args:\n",
      "          images: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `complex64`, `complex128`, `bool`.\n",
      "            4-D Tensor with shape `[batch, in_rows, in_cols, depth]`.\n",
      "          ksizes: A list of `ints` that has length `>= 4`.\n",
      "            The size of the sliding window for each dimension of `images`.\n",
      "          strides: A list of `ints` that has length `>= 4`.\n",
      "            How far the centers of two consecutive patches are in\n",
      "            the images. Must be: `[1, stride_rows, stride_cols, 1]`.\n",
      "          rates: A list of `ints` that has length `>= 4`.\n",
      "            Must be: `[1, rate_rows, rate_cols, 1]`. This is the\n",
      "            input stride, specifying how far two consecutive patch samples are in the\n",
      "            input. Equivalent to extracting patches with\n",
      "            `patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by\n",
      "            subsampling them spatially by a factor of `rates`. This is equivalent to\n",
      "            `rate` in dilated (a.k.a. Atrous) convolutions.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `images`.\n",
      "    \n",
      "    extract_volume_patches(input: Annotated[Any, ~TV_ExtractVolumePatches_T], ksizes, strides, padding: str, name=None) -> Annotated[Any, ~TV_ExtractVolumePatches_T]\n",
      "        Extract `patches` from `input` and put them in the `\"depth\"` output dimension. 3D extension of `extract_image_patches`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "            5-D Tensor with shape `[batch, in_planes, in_rows, in_cols, depth]`.\n",
      "          ksizes: A list of `ints` that has length `>= 5`.\n",
      "            The size of the sliding window for each dimension of `input`.\n",
      "          strides: A list of `ints` that has length `>= 5`.\n",
      "            1-D of length 5. How far the centers of two consecutive patches are in\n",
      "            `input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "            The type of padding algorithm to use.\n",
      "        \n",
      "            The size-related attributes are specified as follows:\n",
      "        \n",
      "            ```python\n",
      "            ksizes = [1, ksize_planes, ksize_rows, ksize_cols, 1]\n",
      "            strides = [1, stride_planes, strides_rows, strides_cols, 1]\n",
      "            ```\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    eye(num_rows, num_columns=None, batch_shape=None, dtype=tf.float32, name=None)\n",
      "        Construct an identity matrix, or a batch of matrices.\n",
      "        \n",
      "        See also `tf.ones`, `tf.zeros`, `tf.fill`, `tf.one_hot`.\n",
      "        \n",
      "        ```python\n",
      "        # Construct one identity matrix.\n",
      "        tf.eye(2)\n",
      "        ==> [[1., 0.],\n",
      "             [0., 1.]]\n",
      "        \n",
      "        # Construct a batch of 3 identity matrices, each 2 x 2.\n",
      "        # batch_identity[i, :, :] is a 2 x 2 identity matrix, i = 0, 1, 2.\n",
      "        batch_identity = tf.eye(2, batch_shape=[3])\n",
      "        \n",
      "        # Construct one 2 x 3 \"identity\" matrix\n",
      "        tf.eye(2, num_columns=3)\n",
      "        ==> [[ 1.,  0.,  0.],\n",
      "             [ 0.,  1.,  0.]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          num_rows: Non-negative `int32` scalar `Tensor` giving the number of rows\n",
      "            in each batch matrix.\n",
      "          num_columns: Optional non-negative `int32` scalar `Tensor` giving the number\n",
      "            of columns in each batch matrix.  Defaults to `num_rows`.\n",
      "          batch_shape:  A list or tuple of Python integers or a 1-D `int32` `Tensor`.\n",
      "            If provided, the returned `Tensor` will have leading batch dimensions of\n",
      "            this shape.\n",
      "          dtype:  The type of an element in the resulting `Tensor`\n",
      "          name:  A name for this `Op`.  Defaults to \"eye\".\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of shape `batch_shape + [num_rows, num_columns]`\n",
      "    \n",
      "    fake_quant_with_min_max_args(inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: float = -6, max: float = 6, num_bits: int = 8, narrow_range: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same shape and type.\n",
      "        \n",
      "        \n",
      "          Quantization is called fake since the output is still in floating point.\n",
      "          The API converts inputs into values within the range [min and max] and returns\n",
      "          as output.\n",
      "        \n",
      "        Attributes\n",
      "        \n",
      "        *   `[min; max]` define the clamping range for the `inputs` data.\n",
      "        *   `inputs` values are quantized into the quantization range (\n",
      "        `[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`\n",
      "        when it is true) and then de-quantized and output as floats in `[min; max]`\n",
      "        interval.\n",
      "        *   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        \n",
      "        *   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        *   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        *   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        \n",
      "        Examples\n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        inp = tf.constant ([10.03, -10.23, 3])\n",
      "        out = tf.quantization.fake_quant_with_min_max_args(inp, min=-5, max=5,\n",
      "                                                           num_bits=16)\n",
      "        print(out)\n",
      "        \n",
      "        #  Output:\n",
      "        #  tf.Tensor([ 4.9999237 -5.0000763  3.0000763], shape=(3,), dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "          * InvalidArgumentError:\n",
      "            - If num_bits are outside of range [2, 16].\n",
      "            - If min >= max.\n",
      "          * ValueError: If `inputs` are of any other type than float32.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: An optional `float`. Defaults to `-6`.\n",
      "          max: An optional `float`. Defaults to `6`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_args_gradient(gradients: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: float = -6, max: float = 6, num_bits: int = 8, narrow_range: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Compute gradients for a FakeQuantWithMinMaxArgs operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxArgs operation.\n",
      "          min: An optional `float`. Defaults to `-6`.\n",
      "          max: An optional `float`. Defaults to `6`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars(inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], max: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], num_bits: int = 8, narrow_range: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Fake-quantize the 'inputs' tensor of type float via global float scalars\n",
      "        \n",
      "        Fake-quantize the `inputs` tensor of type float via global float scalars\n",
      "        `min` and `max` to `outputs` tensor of same shape as `inputs`.\n",
      "        \n",
      "        Attributes\n",
      "        \n",
      "        *   `[min; max]` define the clamping range for the `inputs` data.\n",
      "        *   `inputs` values are quantized into the quantization range (\n",
      "        `[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`\n",
      "        when it is true) and then de-quantized and output as floats in `[min; max]`\n",
      "        interval.\n",
      "        *   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        \n",
      "        *   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        *   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        *   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        This operation has a gradient and thus allows for training `min` and `max`\n",
      "        values.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_gradient(gradients: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], max: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], num_bits: int = 8, narrow_range: bool = False, name=None)\n",
      "        Compute gradients for a FakeQuantWithMinMaxVars operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxVars operation.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxVars operation.\n",
      "            min, max: Quantization interval, scalar floats.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "            The bitwidth of the quantization; between 2 and 8, inclusive.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "            Whether to quantize into 2^num_bits - 1 distinct values.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).\n",
      "        \n",
      "          backprops_wrt_input: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_min: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_per_channel(inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], max: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], num_bits: int = 8, narrow_range: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Fake-quantize the 'inputs' tensor of type float via per-channel floats\n",
      "        \n",
      "        Fake-quantize the `inputs` tensor of type float per-channel and one of the\n",
      "        shapes: `[d]`, `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max`\n",
      "        of shape `[d]` to `outputs` tensor of same shape as `inputs`.\n",
      "        \n",
      "        Attributes\n",
      "        \n",
      "        *   `[min; max]` define the clamping range for the `inputs` data.\n",
      "        *   `inputs` values are quantized into the quantization range (\n",
      "        `[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`\n",
      "        when it is true) and then de-quantized and output as floats in `[min; max]`\n",
      "        interval.\n",
      "        *   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        \n",
      "        *   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        *   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        *   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        This operation has a gradient and thus allows for training `min` and `max`\n",
      "        values.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_per_channel_gradient(gradients: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], max: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], num_bits: int = 8, narrow_range: bool = False, name=None)\n",
      "        Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxVars operation,\n",
      "            shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape\n",
      "              same as `gradients`.\n",
      "            min, max: Quantization interval, floats of shape `[d]`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "            The bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "            Whether to quantize into 2^num_bits - 1 distinct values.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).\n",
      "        \n",
      "          backprops_wrt_input: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_min: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    fft(input: Annotated[Any, ~TV_FFT_Tcomplex], name=None) -> Annotated[Any, ~TV_FFT_Tcomplex]\n",
      "        Fast Fourier transform.\n",
      "        \n",
      "        Computes the 1-dimensional discrete Fourier transform over the inner-most\n",
      "        dimension of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fft2d(input: Annotated[Any, ~TV_FFT2D_Tcomplex], name=None) -> Annotated[Any, ~TV_FFT2D_Tcomplex]\n",
      "        2D fast Fourier transform.\n",
      "        \n",
      "        Computes the 2-dimensional discrete Fourier transform over the inner-most\n",
      "        2 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fft3d(input: Annotated[Any, ~TV_FFT3D_Tcomplex], name=None) -> Annotated[Any, ~TV_FFT3D_Tcomplex]\n",
      "        3D fast Fourier transform.\n",
      "        \n",
      "        Computes the 3-dimensional discrete Fourier transform over the inner-most 3\n",
      "        dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fftnd(input: Annotated[Any, ~TV_FFTND_Tcomplex], fft_length: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], axes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], name=None) -> Annotated[Any, ~TV_FFTND_Tcomplex]\n",
      "        ND fast Fourier transform.\n",
      "        \n",
      "        Computes the n-dimensional discrete Fourier transform over\n",
      "        designated dimensions of `input`. The designated dimensions of\n",
      "        `input` are assumed to be the result of `FFTND`.\n",
      "        \n",
      "        If fft_length[i]<shape(input)[i], the input is cropped. If\n",
      "        fft_length[i]>shape(input)[i], the input is padded with zeros. If fft_length\n",
      "        is not given, the default shape(input) is used.\n",
      "        \n",
      "        Axes mean the dimensions to perform the transform on. Default is to perform on\n",
      "        all axes.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          fft_length: A `Tensor` of type `int32`.\n",
      "            An int32 tensor. The FFT length for each dimension.\n",
      "          axes: A `Tensor` of type `int32`.\n",
      "            An int32 tensor with a same shape as fft_length. Axes to perform the transform.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fill(dims, value, name=None, layout=None)\n",
      "        Creates a tensor filled with a scalar value.\n",
      "        \n",
      "        See also `tf.ones`, `tf.zeros`, `tf.one_hot`, `tf.eye`.\n",
      "        \n",
      "        This operation creates a tensor of shape `dims` and fills it with `value`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.fill([2, 3], 9)\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[9, 9, 9],\n",
      "               [9, 9, 9]], dtype=int32)>\n",
      "        \n",
      "        `tf.fill` evaluates at graph runtime and supports dynamic shapes based on\n",
      "        other runtime `tf.Tensors`, unlike `tf.constant(value, shape=dims)`, which\n",
      "        embeds the value as a `Const` node.\n",
      "        \n",
      "        Args:\n",
      "          dims: A 1-D sequence of non-negative numbers. Represents the shape of the\n",
      "            output `tf.Tensor`. Entries should be of type: `int32`, `int64`.\n",
      "          value: A value to fill the returned `tf.Tensor`.\n",
      "          name: Optional string. The name of the output `tf.Tensor`.\n",
      "          layout: Optional, `tf.experimental.dtensor.Layout`. If provided, the result\n",
      "            is a [DTensor](https://www.tensorflow.org/guide/dtensor_overview) with the\n",
      "            provided layout.\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` with shape `dims` and the same dtype as `value`.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: `dims` contains negative entries.\n",
      "          NotFoundError: `dims` contains non-integer entries.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Similar to `np.full`. In `numpy`, more parameters are supported. Passing a\n",
      "        number argument as the shape (`np.full(5, value)`) is valid in `numpy` for\n",
      "        specifying a 1-D shaped result, while TensorFlow does not support this syntax.\n",
      "        @end_compatibility\n",
      "    \n",
      "    fingerprint(data, method='farmhash64', name=None)\n",
      "        Generates fingerprint values.\n",
      "        \n",
      "        Generates fingerprint values of `data`.\n",
      "        \n",
      "        Fingerprint op considers the first dimension of `data` as the batch dimension,\n",
      "        and `output[i]` contains the fingerprint value generated from contents in\n",
      "        `data[i, ...]` for all `i`.\n",
      "        \n",
      "        Fingerprint op writes fingerprint values as byte arrays. For example, the\n",
      "        default method `farmhash64` generates a 64-bit fingerprint value at a time.\n",
      "        This 8-byte value is written out as an `tf.uint8` array of size 8, in\n",
      "        little-endian order.\n",
      "        \n",
      "        For example, suppose that `data` has data type `tf.int32` and shape (2, 3, 4),\n",
      "        and that the fingerprint method is `farmhash64`. In this case, the output\n",
      "        shape is (2, 8), where 2 is the batch dimension size of `data`, and 8 is the\n",
      "        size of each fingerprint value in bytes. `output[0, :]` is generated from\n",
      "        12 integers in `data[0, :, :]` and similarly `output[1, :]` is generated from\n",
      "        other 12 integers in `data[1, :, :]`.\n",
      "        \n",
      "        Note that this op fingerprints the raw underlying buffer, and it does not\n",
      "        fingerprint Tensor's metadata such as data type and/or shape. For example, the\n",
      "        fingerprint values are invariant under reshapes and bitcasts as long as the\n",
      "        batch dimension remain the same:\n",
      "        \n",
      "        ```python\n",
      "        tf.fingerprint(data) == tf.fingerprint(tf.reshape(data, ...))\n",
      "        tf.fingerprint(data) == tf.fingerprint(tf.bitcast(data, ...))\n",
      "        ```\n",
      "        \n",
      "        For string data, one should expect `tf.fingerprint(data) !=\n",
      "        tf.fingerprint(tf.string.reduce_join(data))` in general.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must have rank 1 or higher.\n",
      "          method: A `Tensor` of type `tf.string`. Fingerprint method used by this op.\n",
      "            Currently, available method is `farmhash64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A two-dimensional `Tensor` of type `tf.uint8`. The first dimension equals to\n",
      "          `data`'s first dimension, and the second dimension size depends on the\n",
      "          fingerprint algorithm.\n",
      "    \n",
      "    fixed_size_partitioner(num_shards, axis=0)\n",
      "        Partitioner to specify a fixed number of shards along given axis.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is deprecated in TF2. In TF2, partitioner is no longer part of\n",
      "        the variable declaration via `tf.Variable`.\n",
      "        [ParameterServer Training]\n",
      "        (https://www.tensorflow.org/tutorials/distribute/parameter_server_training)\n",
      "        handles partitioning of variables. The corresponding TF2 partitioner class of\n",
      "        `fixed_size_partitioner` is\n",
      "        `tf.distribute.experimental.partitioners.FixedShardsPartitioner`.\n",
      "        \n",
      "        Check the [migration guide]\n",
      "        (https://www.tensorflow.org/guide/migrate#2_use_python_objects_to_track_variables_and_losses)\n",
      "        on the differences in treatment of variables and losses between TF1 and TF2.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "          ```\n",
      "          x = tf.compat.v1.get_variable(\n",
      "            \"x\", shape=(2,), partitioner=tf.compat.v1.fixed_size_partitioner(2)\n",
      "          )\n",
      "          ```\n",
      "        After:\n",
      "        \n",
      "          ```\n",
      "          partitioner = (\n",
      "              tf.distribute.experimental.partitioners.FixedShardsPartitioner(\n",
      "                  num_shards=2)\n",
      "          )\n",
      "          strategy = tf.distribute.experimental.ParameterServerStrategy(\n",
      "                         cluster_resolver=cluster_resolver,\n",
      "                         variable_partitioner=partitioner)\n",
      "        \n",
      "          with strategy.scope():\n",
      "            x = tf.Variable([1.0, 2.0])\n",
      "          ```\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          num_shards: `int`, number of shards to partition variable.\n",
      "          axis: `int`, axis to partition on.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "    \n",
      "    floor(x, name=None)\n",
      "        Returns element-wise largest integer not greater than x.\n",
      "        \n",
      "        Both input range is `(-inf, inf)` and the\n",
      "        output range consists of all integer values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.3324, -1.5, 5.555, -2.532, 0.99, float(\"inf\")])\n",
      "        >>> tf.floor(x).numpy()\n",
      "        array([ 1., -2.,  5., -3.,  0., inf], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          x:  A `Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as x.\n",
      "    \n",
      "    floor_div(x: typing.Annotated[_any, ~TV_FloorDiv_T], y: typing.Annotated[_any, ~TV_FloorDiv_T], name=None) -> typing.Annotated[_any, ~TV_FloorDiv_T]\n",
      "        Returns x // y element-wise.\n",
      "        \n",
      "        *NOTE*: `floor_div` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    floordiv(x, y, name=None)\n",
      "        Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "        \n",
      "        Mathematically, this is equivalent to floor(x / y). For example:\n",
      "          floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "          floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "        This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "        \n",
      "        Note: `x` and `y` must have the same type, and the result will have the same\n",
      "        type as well.\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of real numeric type.\n",
      "          y: `Tensor` denominator of real numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` rounded toward -infinity.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the inputs are complex.\n",
      "    \n",
      "    floormod = floor_mod(x: typing.Annotated[_any, ~TV_FloorMod_T], y: typing.Annotated[_any, ~TV_FloorMod_T], name=None) -> typing.Annotated[_any, ~TV_FloorMod_T]\n",
      "        Returns element-wise remainder of division.\n",
      "        \n",
      "        This follows Python semantics in that the\n",
      "        result here is consistent with a flooring divide. E.g.\n",
      "        `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "        \n",
      "        *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    foldl(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)\n",
      "        foldl on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This foldl operator repeatedly applies the callable `fn` to a sequence\n",
      "        of elements from first to last. The elements are made of the tensors\n",
      "        unpacked from `elems` on dimension 0. The callable fn takes two tensors as\n",
      "        arguments. The first argument is the accumulated value computed from the\n",
      "        preceding invocation of fn, and the second is the value at the current\n",
      "        position of `elems`. If `initializer` is None, `elems` must contain at least\n",
      "        one element, and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is fn(initializer, values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            as the initial value for the accumulator.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors, resulting from applying\n",
      "          `fn` consecutively to the list of tensors unpacked from `elems`, from first\n",
      "          to last.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable.\n",
      "        \n",
      "        Example:\n",
      "          ```python\n",
      "          elems = tf.constant([1, 2, 3, 4, 5, 6])\n",
      "          sum = foldl(lambda a, x: a + x, elems)\n",
      "          # sum == 21\n",
      "          ```\n",
      "    \n",
      "    foldr(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)\n",
      "        foldr on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This foldr operator repeatedly applies the callable `fn` to a sequence\n",
      "        of elements from last to first. The elements are made of the tensors\n",
      "        unpacked from `elems`. The callable fn takes two tensors as arguments.\n",
      "        The first argument is the accumulated value computed from the preceding\n",
      "        invocation of fn, and the second is the value at the current position of\n",
      "        `elems`. If `initializer` is None, `elems` must contain at least one element,\n",
      "        and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `fn(initializer, values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            as the initial value for the accumulator.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors, resulting from applying\n",
      "          `fn` consecutively to the list of tensors unpacked from `elems`, from last\n",
      "          to first.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable.\n",
      "        \n",
      "        Example:\n",
      "          ```python\n",
      "          elems = [1, 2, 3, 4, 5, 6]\n",
      "          sum = foldr(lambda a, x: a + x, elems)\n",
      "          # sum == 21\n",
      "          ```\n",
      "    \n",
      "    function(func=None, input_signature=None, autograph=True, jit_compile=None, reduce_retracing=False, experimental_implements=None, experimental_autograph_options=None, experimental_attributes=None, experimental_relax_shapes=None, experimental_compile=None, experimental_follow_type_hints=None) -> tensorflow.python.types.core.PolymorphicFunction\n",
      "        Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_compile)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_compile is deprecated, use jit_compile instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_relax_shapes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_follow_type_hints)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_follow_type_hints is deprecated\n",
      "        \n",
      "        `tf.function` constructs a `tf.types.experimental.PolymorphicFunction` that\n",
      "        executes a TensorFlow graph (`tf.Graph`) created by trace-compiling the\n",
      "        TensorFlow operations in `func`. More information on the topic can be found\n",
      "        in [Introduction to Graphs and tf.function]\n",
      "        (https://www.tensorflow.org/guide/intro_to_graphs).\n",
      "        \n",
      "        See [Better Performance with tf.function]\n",
      "        (https://www.tensorflow.org/guide/function) for tips on performance and\n",
      "        known limitations.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x, y):\n",
      "        ...   return x ** 2 + y\n",
      "        >>> x = tf.constant([2, 3])\n",
      "        >>> y = tf.constant([3, -2])\n",
      "        >>> f(x, y)\n",
      "        <tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "        \n",
      "        The trace-compilation allows non-TensorFlow operations to execute, but under\n",
      "        special conditions. In general, only TensorFlow operations are guaranteed to\n",
      "        run and create fresh results whenever the `PolymorphicFunction` is called.\n",
      "        \n",
      "        ## Features\n",
      "        \n",
      "        `func` may use data-dependent Python control flow statements, including `if`,\n",
      "        `for`, `while` `break`, `continue` and `return`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   if tf.reduce_sum(x) > 0:\n",
      "        ...     return x * x\n",
      "        ...   else:\n",
      "        ...     return -x // 2\n",
      "        >>> f(tf.constant(-2))\n",
      "        <tf.Tensor: ... numpy=1>\n",
      "        \n",
      "        `func`'s closure may include `tf.Tensor` and `tf.Variable` objects:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f():\n",
      "        ...   return x ** 2 + y\n",
      "        >>> x = tf.constant([-2, -3])\n",
      "        >>> y = tf.Variable([3, -2])\n",
      "        >>> f()\n",
      "        <tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "        \n",
      "        `func` may also use ops with side effects, such as `tf.print`, `tf.Variable`\n",
      "        and others:\n",
      "        \n",
      "        >>> v = tf.Variable(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   for i in tf.range(x):\n",
      "        ...     v.assign_add(i)\n",
      "        >>> f(3)\n",
      "        >>> v\n",
      "        <tf.Variable ... numpy=4>\n",
      "        \n",
      "        Important: Any Python side-effects (appending to a list, printing with\n",
      "        `print`, etc) will only happen once, when `func` is traced. To have\n",
      "        side-effects executed into your `tf.function` they need to be written\n",
      "        as TF ops:\n",
      "        \n",
      "        >>> l = []\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   for i in x:\n",
      "        ...     l.append(i + 1)    # Caution! Will only happen once when tracing\n",
      "        >>> f(tf.constant([1, 2, 3]))\n",
      "        >>> l\n",
      "        [<tf.Tensor ...>]\n",
      "        \n",
      "        Instead, use TensorFlow collections like `tf.TensorArray`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
      "        ...   for i in range(len(x)):\n",
      "        ...     ta = ta.write(i, x[i] + 1)\n",
      "        ...   return ta.stack()\n",
      "        >>> f(tf.constant([1, 2, 3]))\n",
      "        <tf.Tensor: ..., numpy=array([2, 3, 4], ...)>\n",
      "        \n",
      "        ## `tf.function` creates polymorphic callables\n",
      "        \n",
      "        Internally, `tf.types.experimental.PolymorphicFunction` may contain multiple\n",
      "        `tf.types.experimental.ConcreteFunction`s, each specialized to arguments with\n",
      "        different data types or shapes, since TensorFlow can perform more\n",
      "        optimizations on graphs of specific shapes, dtypes and values of constant\n",
      "        arguments. `tf.function` treats any pure Python values as opaque objects (best\n",
      "        thought of as compile-time constants), and builds a separate `tf.Graph` for\n",
      "        each set of Python arguments that it encounters.\n",
      "        For more information, see the\n",
      "        [tf.function guide](https://www.tensorflow.org/guide/function#rules_of_tracing)\n",
      "        \n",
      "        Executing a `PolymorphicFunction` will select and execute the appropriate\n",
      "        `ConcreteFunction` based on the argument types and values.\n",
      "        \n",
      "        To obtain an individual `ConcreteFunction`, use the\n",
      "        `PolymorphicFunction.get_concrete_function` method. It can be called with the\n",
      "        same arguments as `func` and returns a\n",
      "        `tf.types.experimental.ConcreteFunction`. `ConcreteFunction`s are backed by a\n",
      "        single `tf.Graph`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> isinstance(f.get_concrete_function(1).graph, tf.Graph)\n",
      "        True\n",
      "        \n",
      "        `ConcreteFunction`s can be executed just like `PolymorphicFunction`s, but their\n",
      "        input is resticted to the types to which they're specialized.\n",
      "        \n",
      "        ## Retracing\n",
      "        \n",
      "        `ConcreteFunctions` are built (traced) on the fly, as the `PolymorphicFunction` is\n",
      "        called with new TensorFlow types or shapes, or with new Python values as\n",
      "        arguments. When `PolymorphicFunction` builds a new trace, it is said that `func`\n",
      "        is retraced. Retracing is a frequent performance concern for `tf.function` as\n",
      "        it can be considerably slower than executing a graph that's already been\n",
      "        traced. It is ideal to minimize the amount of retracing in your code.\n",
      "        \n",
      "        Caution: Passing python scalars or lists as arguments to `tf.function` will\n",
      "        usually retrace. To avoid this, pass numeric arguments as Tensors whenever\n",
      "        possible:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return tf.abs(x)\n",
      "        >>> f1 = f.get_concrete_function(1)\n",
      "        >>> f2 = f.get_concrete_function(2)  # Slow - compiles new graph\n",
      "        >>> f1 is f2\n",
      "        False\n",
      "        >>> f1 = f.get_concrete_function(tf.constant(1))\n",
      "        >>> f2 = f.get_concrete_function(tf.constant(2))  # Fast - reuses f1\n",
      "        >>> f1 is f2\n",
      "        True\n",
      "        \n",
      "        Python numerical arguments should only be used when they take few distinct\n",
      "        values, such as hyperparameters like the number of layers in a neural network.\n",
      "        \n",
      "        ## Input signatures\n",
      "        \n",
      "        For Tensor arguments, `PolymorphicFunction`creates a new `ConcreteFunction` for\n",
      "        every unique set of input shapes and datatypes. The example below creates two\n",
      "        separate `ConcreteFunction`s, each specialized to a different shape:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> vector = tf.constant([1.0, 1.0])\n",
      "        >>> matrix = tf.constant([[3.0]])\n",
      "        >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "        False\n",
      "        \n",
      "        An \"input signature\" can be optionally provided to `tf.function` to control\n",
      "        this process. The input signature specifies the shape and type of each\n",
      "        Tensor argument to the function using a `tf.TensorSpec` object. More general\n",
      "        shapes can be used. This ensures only one `ConcreteFunction` is created, and\n",
      "        restricts the `PolymorphicFunction` to the specified shapes and types. It is\n",
      "        an effective way to limit retracing when Tensors have dynamic shapes.\n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...     input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> vector = tf.constant([1.0, 1.0])\n",
      "        >>> matrix = tf.constant([[3.0]])\n",
      "        >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "        True\n",
      "        \n",
      "        ## Variables may only be created once\n",
      "        \n",
      "        `tf.function` only allows creating new `tf.Variable` objects when it is called\n",
      "        for the first time:\n",
      "        \n",
      "        >>> class MyModule(tf.Module):\n",
      "        ...   def __init__(self):\n",
      "        ...     self.v = None\n",
      "        ...\n",
      "        ...   @tf.function\n",
      "        ...   def __call__(self, x):\n",
      "        ...     if self.v is None:\n",
      "        ...       self.v = tf.Variable(tf.ones_like(x))\n",
      "        ...     return self.v * x\n",
      "        \n",
      "        In general, it is recommended to create `tf.Variable`s outside of\n",
      "        `tf.function`.\n",
      "        In simple cases, persisting state across `tf.function` boundaries may be\n",
      "        implemented using a pure functional style in which state is represented by\n",
      "        `tf.Tensor`s passed as arguments and returned as return values.\n",
      "        \n",
      "        Contrast the two styles below:\n",
      "        \n",
      "        >>> state = tf.Variable(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   state.assign_add(x)\n",
      "        >>> f(tf.constant(2))  # Non-pure functional style\n",
      "        >>> state\n",
      "        <tf.Variable ... numpy=3>\n",
      "        \n",
      "        >>> state = tf.constant(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(state, x):\n",
      "        ...   state += x\n",
      "        ...   return state\n",
      "        >>> state = f(state, tf.constant(2))  # Pure functional style\n",
      "        >>> state\n",
      "        <tf.Tensor: ... numpy=3>\n",
      "        \n",
      "        ## Python operations execute only once per trace\n",
      "        \n",
      "        `func` may contain TensorFlow operations mixed with pure Python operations.\n",
      "        However, when the function is executed, only the TensorFlow operations will\n",
      "        run. The Python operations run only once, at trace time. If TensorFlow\n",
      "        operations depend on results from Python operations, those results will be\n",
      "        frozen into the graph.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(a, b):\n",
      "        ...   print('this runs at trace time; a is', a, 'and b is', b)\n",
      "        ...   return b\n",
      "        >>> f(1, tf.constant(1))\n",
      "        this runs at trace time; a is 1 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        >>> f(1, tf.constant(2))\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        \n",
      "        >>> f(2, tf.constant(1))\n",
      "        this runs at trace time; a is 2 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        >>> f(2, tf.constant(2))\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        \n",
      "        Args:\n",
      "          func: The function to be compiled. If `func` is None, `tf.function` returns\n",
      "            a decorator that can be invoked with a single argument - `func`. In other\n",
      "            words, `tf.function(input_signature=...)(func)` is equivalent to\n",
      "            `tf.function(func, input_signature=...)`. The former can be used as\n",
      "            decorator.\n",
      "          input_signature: A possibly nested sequence of `tf.TensorSpec` objects\n",
      "            specifying the shapes and dtypes of the Tensors that will be supplied to\n",
      "            this function. If `None`, a separate function is instantiated for each\n",
      "            inferred input signature.  If input_signature is specified, every input to\n",
      "            `func` must be a `Tensor`, and `func` cannot accept `**kwargs`.\n",
      "          autograph: Whether autograph should be applied on `func` before tracing a\n",
      "            graph. Data-dependent Python control flow statements require\n",
      "            `autograph=True`. For more information, see the\n",
      "            [tf.function and AutoGraph guide](\n",
      "            https://www.tensorflow.org/guide/function#autograph_transformations).\n",
      "          jit_compile: If `True`, compiles the function using\n",
      "            [XLA](https://tensorflow.org/xla). XLA performs compiler optimizations,\n",
      "            such as fusion, and attempts to emit more efficient code. This may\n",
      "            drastically improve the performance. If set to `True`,\n",
      "            the whole function needs to be compilable by XLA, or an\n",
      "            `errors.InvalidArgumentError` is thrown.\n",
      "            If `None` (default), compiles the function with XLA when running on TPU\n",
      "            and goes through the regular function execution path when running on\n",
      "            other devices.\n",
      "            If `False`, executes the function without XLA compilation.  Set this value\n",
      "            to `False` when directly running a multi-device function on TPUs (e.g. two\n",
      "            TPU cores, one TPU core and its host CPU).\n",
      "            Not all functions are compilable, see a list of\n",
      "            [sharp corners](https://tensorflow.org/xla/known_issues).\n",
      "          reduce_retracing: When True, `tf.function` attempts to reduce the\n",
      "            amount of retracing, for example by using more generic shapes. This\n",
      "            can be controlled for user objects by customizing their associated\n",
      "            `tf.types.experimental.TraceType`.\n",
      "          experimental_implements: If provided, contains a name of a \"known\" function\n",
      "            this implements. For example \"mycompany.my_recurrent_cell\".\n",
      "            This is stored as an attribute in inference function,\n",
      "            which can then be detected when processing serialized function.\n",
      "            See [standardizing composite ops](https://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.md)  # pylint: disable=line-too-long\n",
      "            for details.  For an example of utilizing this attribute see this\n",
      "            [example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.cc)\n",
      "            The code above automatically detects and substitutes function that\n",
      "            implements \"embedded_matmul\" and allows TFLite to substitute its own\n",
      "            implementations. For instance, a tensorflow user can use this\n",
      "             attribute to mark that their function also implements\n",
      "            `embedded_matmul` (perhaps more efficiently!)\n",
      "            by specifying it using this parameter:\n",
      "            `@tf.function(experimental_implements=\"embedded_matmul\")`\n",
      "            This can either be specified as just the string name of the function or\n",
      "            a NameAttrList corresponding to a list of key-value attributes associated\n",
      "            with the function name. The name of the function will be in the 'name'\n",
      "            field of the NameAttrList. To define a formal TF op for this function\n",
      "            implements, try the experimental [composite TF](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tfr)\n",
      "            project.\n",
      "          experimental_autograph_options: Optional tuple of\n",
      "            `tf.autograph.experimental.Feature` values.\n",
      "          experimental_attributes: Optional dictionary of attributes to include in the\n",
      "            generated FunctionDefs.\n",
      "          experimental_relax_shapes: Deprecated. Use `reduce_retracing`\n",
      "            instead.\n",
      "          experimental_compile: Deprecated alias to 'jit_compile'.\n",
      "          experimental_follow_type_hints: Deprecated. Please use input_signature or\n",
      "            reduce_retracing instead.\n",
      "        \n",
      "        Returns:\n",
      "           If `func` is not None, returns a `tf.types.experimental.PolymorphicFunction`.\n",
      "           If `func` is None, returns a decorator that, when invoked with a single\n",
      "           `func` argument, returns a `tf.types.experimental.PolymorphicFunction`.\n",
      "        \n",
      "        Raises:\n",
      "           `ValueError` when attempting to use `jit_compile=True`, but XLA support is\n",
      "           not available.\n",
      "    \n",
      "    gather(params, indices, validate_indices=None, name=None, axis=None, batch_dims=0)\n",
      "        Gather slices from params axis `axis` according to indices. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(validate_indices)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "        \n",
      "        Gather slices from `params` axis `axis` according to `indices`.  `indices`\n",
      "        must be an integer tensor of any dimension (often 1-D).\n",
      "        \n",
      "        `Tensor.__getitem__` works for scalars, `tf.newaxis`, and\n",
      "        [python slices](https://numpy.org/doc/stable/reference/arrays.indexing.html#basic-slicing-and-indexing)\n",
      "        \n",
      "        `tf.gather` extends indexing to handle tensors of indices.\n",
      "        \n",
      "        In the simplest case it's identical to scalar indexing:\n",
      "        \n",
      "        >>> params = tf.constant(['p0', 'p1', 'p2', 'p3', 'p4', 'p5'])\n",
      "        >>> params[3].numpy()\n",
      "        b'p3'\n",
      "        >>> tf.gather(params, 3).numpy()\n",
      "        b'p3'\n",
      "        \n",
      "        The most common case is to pass a single axis tensor of indices (this\n",
      "        can't be expressed as a python slice because the indices are not sequential):\n",
      "        \n",
      "        >>> indices = [2, 0, 2, 5]\n",
      "        >>> tf.gather(params, indices).numpy()\n",
      "        array([b'p2', b'p0', b'p2', b'p5'], dtype=object)\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/Gather.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        The indices can have any shape. When the `params` has 1 axis, the\n",
      "        output shape is equal to the input shape:\n",
      "        \n",
      "        >>> tf.gather(params, [[2, 0], [2, 5]]).numpy()\n",
      "        array([[b'p2', b'p0'],\n",
      "               [b'p2', b'p5']], dtype=object)\n",
      "        \n",
      "        The `params` may also have any shape. `gather` can select slices\n",
      "        across any axis depending on the `axis` argument (which defaults to 0).\n",
      "        Below it is used to gather first rows, then columns from a matrix:\n",
      "        \n",
      "        >>> params = tf.constant([[0, 1.0, 2.0],\n",
      "        ...                       [10.0, 11.0, 12.0],\n",
      "        ...                       [20.0, 21.0, 22.0],\n",
      "        ...                       [30.0, 31.0, 32.0]])\n",
      "        >>> tf.gather(params, indices=[3,1]).numpy()\n",
      "        array([[30., 31., 32.],\n",
      "               [10., 11., 12.]], dtype=float32)\n",
      "        >>> tf.gather(params, indices=[2,1], axis=1).numpy()\n",
      "        array([[ 2.,  1.],\n",
      "               [12., 11.],\n",
      "               [22., 21.],\n",
      "               [32., 31.]], dtype=float32)\n",
      "        \n",
      "        More generally: The output shape has the same shape as the input, with the\n",
      "        indexed-axis replaced by the shape of the indices.\n",
      "        \n",
      "        >>> def result_shape(p_shape, i_shape, axis=0):\n",
      "        ...   return p_shape[:axis] + i_shape + p_shape[axis+1:]\n",
      "        >>>\n",
      "        >>> result_shape([1, 2, 3], [], axis=1)\n",
      "        [1, 3]\n",
      "        >>> result_shape([1, 2, 3], [7], axis=1)\n",
      "        [1, 7, 3]\n",
      "        >>> result_shape([1, 2, 3], [7, 5], axis=1)\n",
      "        [1, 7, 5, 3]\n",
      "        \n",
      "        Here are some examples:\n",
      "        \n",
      "        >>> params.shape.as_list()\n",
      "        [4, 3]\n",
      "        >>> indices = tf.constant([[0, 2]])\n",
      "        >>> tf.gather(params, indices=indices, axis=0).shape.as_list()\n",
      "        [1, 2, 3]\n",
      "        >>> tf.gather(params, indices=indices, axis=1).shape.as_list()\n",
      "        [4, 1, 2]\n",
      "        \n",
      "        >>> params = tf.random.normal(shape=(5, 6, 7, 8))\n",
      "        >>> indices = tf.random.uniform(shape=(10, 11), maxval=7, dtype=tf.int32)\n",
      "        >>> result = tf.gather(params, indices, axis=2)\n",
      "        >>> result.shape.as_list()\n",
      "        [5, 6, 10, 11, 8]\n",
      "        \n",
      "        This is because each index takes a slice from `params`, and\n",
      "        places it at the corresponding location in the output. For the above example\n",
      "        \n",
      "        >>> # For any location in indices\n",
      "        >>> a, b = 0, 1\n",
      "        >>> tf.reduce_all(\n",
      "        ...     # the corresponding slice of the result\n",
      "        ...     result[:, :, a, b, :] ==\n",
      "        ...     # is equal to the slice of `params` along `axis` at the index.\n",
      "        ...     params[:, :, indices[a, b], :]\n",
      "        ... ).numpy()\n",
      "        True\n",
      "        \n",
      "        ### Batching:\n",
      "        \n",
      "        The `batch_dims` argument lets you gather different items from each element\n",
      "        of a batch.\n",
      "        \n",
      "        Using `batch_dims=1` is equivalent to having an outer loop over the first\n",
      "        axis of `params` and `indices`:\n",
      "        \n",
      "        >>> params = tf.constant([\n",
      "        ...     [0, 0, 1, 0, 2],\n",
      "        ...     [3, 0, 0, 0, 4],\n",
      "        ...     [0, 5, 0, 6, 0]])\n",
      "        >>> indices = tf.constant([\n",
      "        ...     [2, 4],\n",
      "        ...     [0, 4],\n",
      "        ...     [1, 3]])\n",
      "        \n",
      "        >>> tf.gather(params, indices, axis=1, batch_dims=1).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        \n",
      "        This is equivalent to:\n",
      "        \n",
      "        >>> def manually_batched_gather(params, indices, axis):\n",
      "        ...   batch_dims=1\n",
      "        ...   result = []\n",
      "        ...   for p,i in zip(params, indices):\n",
      "        ...     r = tf.gather(p, i, axis=axis-batch_dims)\n",
      "        ...     result.append(r)\n",
      "        ...   return tf.stack(result)\n",
      "        >>> manually_batched_gather(params, indices, axis=1).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        \n",
      "        Higher values of `batch_dims` are equivalent to multiple nested loops over\n",
      "        the outer axes of `params` and `indices`. So the overall shape function is\n",
      "        \n",
      "        >>> def batched_result_shape(p_shape, i_shape, axis=0, batch_dims=0):\n",
      "        ...   return p_shape[:axis] + i_shape[batch_dims:] + p_shape[axis+1:]\n",
      "        >>>\n",
      "        >>> batched_result_shape(\n",
      "        ...     p_shape=params.shape.as_list(),\n",
      "        ...     i_shape=indices.shape.as_list(),\n",
      "        ...     axis=1,\n",
      "        ...     batch_dims=1)\n",
      "        [3, 2]\n",
      "        \n",
      "        >>> tf.gather(params, indices, axis=1, batch_dims=1).shape.as_list()\n",
      "        [3, 2]\n",
      "        \n",
      "        This comes up naturally if you need to use the indices of an operation like\n",
      "        `tf.argsort`, or `tf.math.top_k` where the last dimension of the indices\n",
      "        indexes into the last dimension of input, at the corresponding location.\n",
      "        In this case you can use `tf.gather(values, indices, batch_dims=-1)`.\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "        * `tf.Tensor.__getitem__`: The direct tensor index operation (`t[]`), handles\n",
      "          scalars and python-slices `tensor[..., 7, 1:-1]`\n",
      "        * `tf.scatter`: A collection of operations similar to `__setitem__`\n",
      "          (`t[i] = x`)\n",
      "        * `tf.gather_nd`: An operation similar to `tf.gather` but gathers across\n",
      "          multiple axis at once (it can gather elements of a matrix instead of rows\n",
      "          or columns)\n",
      "        * `tf.boolean_mask`, `tf.where`: Binary indexing.\n",
      "        * `tf.slice` and `tf.strided_slice`: For lower level access to the\n",
      "          implementation of `__getitem__`'s python-slice handling (`t[1:-1:2]`)\n",
      "        \n",
      "        Args:\n",
      "          params: The `Tensor` from which to gather values. Must be at least rank\n",
      "            `axis + 1`.\n",
      "          indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
      "            `int64`. The values must be in range `[0, params.shape[axis])`.\n",
      "          validate_indices: Deprecated, does nothing. Indices are always validated on\n",
      "            CPU, never validated on GPU.\n",
      "        \n",
      "            Caution: On CPU, if an out of bound index is found, an error is raised.\n",
      "            On GPU, if an out of bound index is found, a 0 is stored in the\n",
      "            corresponding output value.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`. The\n",
      "            `axis` in `params` to gather `indices` from. Must be greater than or equal\n",
      "            to `batch_dims`.  Defaults to the first non-batch dimension. Supports\n",
      "            negative indexes.\n",
      "          batch_dims: An `integer`.  The number of batch dimensions.  Must be less\n",
      "            than or equal to `rank(indices)`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `params`.\n",
      "    \n",
      "    gather_nd(params, indices, name=None, batch_dims=0)\n",
      "        Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
      "        \n",
      "        `indices` is a `Tensor` of indices into `params`. The index vectors are\n",
      "        arranged along the last axis of `indices`.\n",
      "        \n",
      "        This is similar to `tf.gather`, in which `indices` defines slices into the\n",
      "        first dimension of `params`. In `tf.gather_nd`, `indices` defines slices into\n",
      "        the first `N` dimensions of `params`, where `N = indices.shape[-1]`.\n",
      "        \n",
      "        Caution: On CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, a 0 is stored in the\n",
      "        corresponding output value.\n",
      "        \n",
      "        ## Gathering scalars\n",
      "        \n",
      "        In the simplest case the vectors in `indices` index the full rank of `params`:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices=[[0, 0],\n",
      "        ...              [1, 1]],\n",
      "        ...     params = [['a', 'b'],\n",
      "        ...               ['c', 'd']]).numpy()\n",
      "        array([b'a', b'd'], dtype=object)\n",
      "        \n",
      "        In this case the result has 1-axis fewer than `indices`, and each index vector\n",
      "        is replaced by the scalar indexed from `params`.\n",
      "        \n",
      "        In this case the shape relationship is:\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        assert index_depth == params.shape.rank\n",
      "        result_shape = indices.shape[:-1]\n",
      "        ```\n",
      "        \n",
      "        If `indices` has a rank of `K`, it is helpful to think `indices` as a\n",
      "        (K-1)-dimensional tensor of indices into `params`.\n",
      "        \n",
      "        ## Gathering slices\n",
      "        \n",
      "        If the index vectors do not index the full rank of `params` then each location\n",
      "        in the result contains a slice of params. This example collects rows from a\n",
      "        matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[1],\n",
      "        ...                [0]],\n",
      "        ...     params = [['a', 'b', 'c'],\n",
      "        ...               ['d', 'e', 'f']]).numpy()\n",
      "        array([[b'd', b'e', b'f'],\n",
      "               [b'a', b'b', b'c']], dtype=object)\n",
      "        \n",
      "        Here `indices` contains `[2]` index vectors, each with a length of `1`.\n",
      "        The index vectors each refer to rows of the `params` matrix. Each\n",
      "        row has a shape of `[3]` so the output shape is `[2, 3]`.\n",
      "        \n",
      "        In this case, the relationship between the shapes is:\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        outer_shape = indices.shape[:-1]\n",
      "        assert index_depth <= params.shape.rank\n",
      "        inner_shape = params.shape[index_depth:]\n",
      "        output_shape = outer_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        It is helpful to think of the results in this case as tensors-of-tensors.\n",
      "        The shape of the outer tensor is set by the leading dimensions of `indices`.\n",
      "        While the shape of the inner tensors is the shape of a single slice.\n",
      "        \n",
      "        ## Batches\n",
      "        \n",
      "        Additionally, both `params` and `indices` can have `M` leading batch\n",
      "        dimensions that exactly match. In this case `batch_dims` must be set to `M`.\n",
      "        \n",
      "        For example, to collect one row from each of a batch of matrices you could\n",
      "        set the leading elements of the index vectors to be their location in the\n",
      "        batch:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 1],\n",
      "        ...                [1, 0],\n",
      "        ...                [2, 4],\n",
      "        ...                [3, 2],\n",
      "        ...                [4, 1]],\n",
      "        ...     params=tf.zeros([5, 7, 3])).shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        The `batch_dims` argument lets you omit those leading location dimensions\n",
      "        from the index:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims=1,\n",
      "        ...     indices = [[1],\n",
      "        ...                [0],\n",
      "        ...                [4],\n",
      "        ...                [2],\n",
      "        ...                [1]],\n",
      "        ...     params=tf.zeros([5, 7, 3])).shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        This is equivalent to caling a separate `gather_nd` for each location in the\n",
      "        batch dimensions.\n",
      "        \n",
      "        \n",
      "        >>> params=tf.zeros([5, 7, 3])\n",
      "        >>> indices=tf.zeros([5, 1])\n",
      "        >>> batch_dims = 1\n",
      "        >>>\n",
      "        >>> index_depth = indices.shape[-1]\n",
      "        >>> batch_shape = indices.shape[:batch_dims]\n",
      "        >>> assert params.shape[:batch_dims] == batch_shape\n",
      "        >>> outer_shape = indices.shape[batch_dims:-1]\n",
      "        >>> assert index_depth <= params.shape.rank\n",
      "        >>> inner_shape = params.shape[batch_dims + index_depth:]\n",
      "        >>> output_shape = batch_shape + outer_shape + inner_shape\n",
      "        >>> output_shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        ### More examples\n",
      "        \n",
      "        Indexing into a 3-tensor:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[1]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'a1', b'b1'],\n",
      "                [b'c1', b'd1']]], dtype=object)\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 1], [1, 0]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0', b'd0'],\n",
      "               [b'a1', b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 0, 1], [1, 0, 1]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([b'b0', b'b1'], dtype=object)\n",
      "        \n",
      "        The examples below are for the case when only indices have leading extra\n",
      "        dimensions. If both 'params' and 'indices' have leading batch dimensions, use\n",
      "        the 'batch_dims' parameter to run gather_nd in batch mode.\n",
      "        \n",
      "        Batched indexing into a matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 0]], [[0, 1]]],\n",
      "        ...     params = [['a', 'b'], ['c', 'd']]).numpy()\n",
      "        array([[b'a'],\n",
      "               [b'b']], dtype=object)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Batched slice indexing into a matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [['a', 'b'], ['c', 'd']]).numpy()\n",
      "        array([[[b'c', b'd']],\n",
      "               [[b'a', b'b']]], dtype=object)\n",
      "        \n",
      "        \n",
      "        Batched indexing into a 3-tensor:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[[b'a1', b'b1'],\n",
      "                 [b'c1', b'd1']]],\n",
      "               [[[b'a0', b'b0'],\n",
      "                 [b'c0', b'd0']]]], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'c0', b'd0'],\n",
      "                [b'a1', b'b1']],\n",
      "               [[b'a0', b'b0'],\n",
      "                [b'c1', b'd1']]], dtype=object)\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'b0', b'b1'],\n",
      "               [b'd0', b'c1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        Examples with batched 'params' and 'indices':\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[1],\n",
      "        ...                [0]],\n",
      "        ...     params = [[['a0', 'b0'],\n",
      "        ...                ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'],\n",
      "        ...                ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0', b'd0'],\n",
      "               [b'a1', b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'c0', b'd0']],\n",
      "               [[b'a1', b'b1']]], dtype=object)\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[[1, 0]], [[0, 1]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0'],\n",
      "               [b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        See also `tf.gather`.\n",
      "        \n",
      "        Args:\n",
      "          params: A `Tensor`. The tensor from which to gather values.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          name: A name for the operation (optional).\n",
      "          batch_dims: An integer or a scalar 'Tensor'. The number of batch dimensions.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `params`.\n",
      "    \n",
      "    get_collection(key, scope=None) -> list[typing.Any]\n",
      "        Wrapper for `Graph.get_collection()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.get_collection`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          key: The key for the collection. For example, the `GraphKeys` class contains\n",
      "            many standard names for collections.\n",
      "          scope: (Optional.) If supplied, the resulting list is filtered to include\n",
      "            only items whose `name` attribute matches using `re.match`. Items without\n",
      "            a `name` attribute are never returned if a scope is supplied and the\n",
      "            choice or `re.match` means that a `scope` without special tokens filters\n",
      "            by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          The list of values in the collection with the given `name`, or\n",
      "          an empty list if no value has been added to that collection. The\n",
      "          list contains the values in the order under which they were\n",
      "          collected.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are not supported when eager execution is enabled.\n",
      "        @end_compatibility\n",
      "    \n",
      "    get_collection_ref(key) -> list[typing.Any]\n",
      "        Wrapper for `Graph.get_collection_ref()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.get_collection_ref`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          key: The key for the collection. For example, the `GraphKeys` class contains\n",
      "            many standard names for collections.\n",
      "        \n",
      "        Returns:\n",
      "          The list of values in the collection with the given `name`, or an empty\n",
      "          list if no value has been added to that collection.  Note that this returns\n",
      "          the collection list itself, which can be modified in place to change the\n",
      "          collection.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are not supported when eager execution is enabled.\n",
      "        @end_compatibility\n",
      "    \n",
      "    get_default_graph() -> tensorflow.python.framework.ops.Graph\n",
      "        Returns the default graph for the current thread.\n",
      "        \n",
      "        The returned graph will be the innermost graph on which a\n",
      "        `Graph.as_default()` context has been entered, or a global default\n",
      "        graph if none has been explicitly created.\n",
      "        \n",
      "        NOTE: The default graph is a property of the current thread. If you\n",
      "        create a new thread, and wish to use the default graph in that\n",
      "        thread, you must explicitly add a `with g.as_default():` in that\n",
      "        thread's function.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `get_default_graph` does not work with either eager execution or\n",
      "        `tf.function`, and you should not invoke it directly. To migrate code that\n",
      "        uses Graph-related functions to TF2, rewrite the code without them. See the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate) for more\n",
      "        description about the behavior and semantic changes between Tensorflow 1 and\n",
      "        Tensorflow 2.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Returns:\n",
      "          The default `Graph` being used in the current thread.\n",
      "    \n",
      "    get_default_session()\n",
      "        Returns the default session for the current thread.\n",
      "        \n",
      "        The returned `Session` will be the innermost session on which a\n",
      "        `Session` or `Session.as_default()` context has been entered.\n",
      "        \n",
      "        NOTE: The default session is a property of the current thread. If you\n",
      "        create a new thread, and wish to use the default session in that\n",
      "        thread, you must explicitly add a `with sess.as_default():` in that\n",
      "        thread's function.\n",
      "        \n",
      "        Returns:\n",
      "          The default `Session` being used in the current thread.\n",
      "    \n",
      "    get_local_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=False, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "        Gets an existing *local* variable or creates a new one.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Although it is a legacy `compat.v1` api,\n",
      "        `tf.compat.v1.get_variable` is mostly compatible with eager\n",
      "        execution and `tf.function` but only if you combine it with the\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables` decorator. (Though\n",
      "        it will behave as if reuse is always set to `AUTO_REUSE`.)\n",
      "        \n",
      "        See the\n",
      "        [model migration guide](https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "        for more info.\n",
      "        \n",
      "        If you do not combine it with\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables`, `get_variable` will create\n",
      "        a brand new variable every single time it is called and will never reuse\n",
      "        variables, regardless of variable names or `reuse` arguments.\n",
      "        \n",
      "        The TF2 equivalent of this symbol would be `tf.Variable`, but note\n",
      "        that when using `tf.Variable` you must make sure you track your variables\n",
      "        (and regularizer arguments) either manually or via `tf.Module` or\n",
      "        `tf.keras.layers.Layer` mechanisms.\n",
      "        \n",
      "        A section of the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate/model_mapping#incremental_migration_to_native_tf2)\n",
      "        provides more details on incrementally migrating these usages to `tf.Variable`\n",
      "        as well.\n",
      "        \n",
      "        Note: The `partitioner` arg is not compatible with TF2 behaviors even when\n",
      "        using `tf.compat.v1.keras.utils.track_tf1_style_variables`. It can be replaced\n",
      "        by using `ParameterServerStrategy` and its partitioners. See the\n",
      "        [multi-gpu migration guide](https://www.tensorflow.org/guide/migrate/multi_worker_cpu_gpu_training)\n",
      "        and the ParameterServerStrategy guides it references for more info.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Behavior is the same as in `get_variable`, except that variables are\n",
      "        added to the `LOCAL_VARIABLES` collection and `trainable` is set to\n",
      "        `False`.\n",
      "        This function prefixes the name with the current variable scope\n",
      "        and performs reuse checks. See the\n",
      "        [Variable Scope How To](https://tensorflow.org/guide/variables)\n",
      "        for an extensive description of how reusing works. Here is a basic example:\n",
      "        \n",
      "        ```python\n",
      "        def foo():\n",
      "          with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
      "            v = tf.get_variable(\"v\", [1])\n",
      "          return v\n",
      "        \n",
      "        v1 = foo()  # Creates v.\n",
      "        v2 = foo()  # Gets the same, existing v.\n",
      "        assert v1 == v2\n",
      "        ```\n",
      "        \n",
      "        If initializer is `None` (the default), the default initializer passed in\n",
      "        the variable scope will be used. If that one is `None` too, a\n",
      "        `glorot_uniform_initializer` will be used. The initializer can also be\n",
      "        a Tensor, in which case the variable is initialized to this value and shape.\n",
      "        \n",
      "        Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "        passed in the variable scope will be used (if that is `None` too,\n",
      "        then by default no regularization is performed).\n",
      "        \n",
      "        If a partitioner is provided, a `PartitionedVariable` is returned.\n",
      "        Accessing this object as a `Tensor` returns the shards concatenated along\n",
      "        the partition axis.\n",
      "        \n",
      "        Some useful partitioners are available.  See, e.g.,\n",
      "        `variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "        \n",
      "        Args:\n",
      "          name: The name of the new or existing variable.\n",
      "          shape: Shape of the new or existing variable.\n",
      "          dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "          initializer: Initializer for the variable if one is created. Can either be\n",
      "            an initializer object or a Tensor. If it's a Tensor, its shape must be known\n",
      "            unless validate_shape is False.\n",
      "          regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "            applying it on a newly created variable will be added to the collection\n",
      "            `tf.GraphKeys.REGULARIZATION_LOSSES` and can be used for regularization.\n",
      "          collections: List of graph collections keys to add the Variable to.\n",
      "            Defaults to `[GraphKeys.LOCAL_VARIABLES]` (see `tf.Variable`).\n",
      "          caching_device: Optional device string or function describing where the\n",
      "            Variable should be cached for reading.  Defaults to the Variable's\n",
      "            device.  If not `None`, caches on another device.  Typical use is to\n",
      "            cache on the device where the Ops using the Variable reside, to\n",
      "            deduplicate copying through `Switch` and other conditional statements.\n",
      "          partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "            and `dtype` of the Variable to be created, and returns a list of\n",
      "            partitions for each axis (currently only one axis can be partitioned).\n",
      "          validate_shape: If False, allows the variable to be initialized with a\n",
      "              value of unknown shape. If True, the default, the shape of initial_value\n",
      "              must be known. For this to be used the initializer must be a Tensor and\n",
      "              not an initializer object.\n",
      "          use_resource: If False, creates a regular Variable. If true, creates an\n",
      "            experimental ResourceVariable instead with well-defined semantics.\n",
      "            Defaults to False (will later change to True). When eager execution is\n",
      "            enabled this argument is always forced to be True.\n",
      "          custom_getter: Callable that takes as a first argument the true getter, and\n",
      "            allows overwriting the internal get_variable method.\n",
      "            The signature of `custom_getter` should match that of this method,\n",
      "            but the most future-proof version will allow for changes:\n",
      "            `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "            all `get_variable` parameters is also allowed:\n",
      "            `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "            custom getter that simply creates variables with modified names is:\n",
      "            ```python\n",
      "            def custom_getter(getter, name, *args, **kwargs):\n",
      "              return getter(name + '_suffix', *args, **kwargs)\n",
      "            ```\n",
      "          constraint: An optional projection function to be applied to the variable\n",
      "            after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "            constraints or value constraints for layer weights). The function must\n",
      "            take as input the unprojected Tensor representing the value of the\n",
      "            variable and return the Tensor for the projected value\n",
      "            (which must have the same shape). Constraints are not safe to\n",
      "            use when doing asynchronous distributed training.\n",
      "          synchronization: Indicates when a distributed a variable will be\n",
      "            aggregated. Accepted values are constants defined in the class\n",
      "            `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "            `AUTO` and the current `DistributionStrategy` chooses\n",
      "            when to synchronize.\n",
      "          aggregation: Indicates how a distributed variable will be aggregated.\n",
      "            Accepted values are constants defined in the class\n",
      "            `tf.VariableAggregation`.\n",
      "        \n",
      "        Returns:\n",
      "          The created or existing `Variable` (or `PartitionedVariable`, if a\n",
      "          partitioner was used).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: when creating a new variable and shape is not declared,\n",
      "            when violating reuse during variable creation, or when `initializer` dtype\n",
      "            and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "    \n",
      "    get_logger()\n",
      "        Return TF logger instance.\n",
      "        \n",
      "        Returns:\n",
      "          An instance of the Python logging library Logger.\n",
      "        \n",
      "        See Python documentation (https://docs.python.org/3/library/logging.html)\n",
      "        for detailed API. Below is only a summary.\n",
      "        \n",
      "        The logger has 5 levels of logging from the most serious to the least:\n",
      "        \n",
      "        1. FATAL\n",
      "        2. ERROR\n",
      "        3. WARN\n",
      "        4. INFO\n",
      "        5. DEBUG\n",
      "        \n",
      "        The logger has the following methods, based on these logging levels:\n",
      "        \n",
      "        1. fatal(msg, *args, **kwargs)\n",
      "        2. error(msg, *args, **kwargs)\n",
      "        3. warn(msg, *args, **kwargs)\n",
      "        4. info(msg, *args, **kwargs)\n",
      "        5. debug(msg, *args, **kwargs)\n",
      "        \n",
      "        The `msg` can contain string formatting.  An example of logging at the `ERROR`\n",
      "        level\n",
      "        using string formating is:\n",
      "        \n",
      "        >>> tf.get_logger().error(\"The value %d is invalid.\", 3)\n",
      "        \n",
      "        You can also specify the logging verbosity.  In this case, the\n",
      "        WARN level log will not be emitted:\n",
      "        \n",
      "        >>> tf.get_logger().setLevel(ERROR)\n",
      "        >>> tf.get_logger().warn(\"This is a warning.\")\n",
      "    \n",
      "    get_seed(op_seed)\n",
      "        Returns the local seeds an operation should use given an op-specific seed.\n",
      "        \n",
      "        Given operation-specific seed, `op_seed`, this helper function returns two\n",
      "        seeds derived from graph-level and op-level seeds. Many random operations\n",
      "        internally use the two seeds to allow user to change the seed globally for a\n",
      "        graph, or for only specific operations.\n",
      "        \n",
      "        For details on how the graph-level seed interacts with op seeds, see\n",
      "        `tf.compat.v1.random.set_random_seed`.\n",
      "        \n",
      "        Args:\n",
      "          op_seed: integer.\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of two integers that should be used for the local seed of this\n",
      "          operation.\n",
      "    \n",
      "    get_session_handle(data, name=None)\n",
      "        Return the handle of `data`.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Keep `data` \"in-place\" in the runtime and create a handle that can be\n",
      "        used to retrieve `data` in a subsequent run().\n",
      "        \n",
      "        Combined with `get_session_tensor`, we can keep a tensor produced in\n",
      "        one run call in place, and use it as the input in a future run call.\n",
      "        \n",
      "        Args:\n",
      "          data: A tensor to be stored in the session.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A scalar string tensor representing a unique handle for `data`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `data` is not a Tensor.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.multiply(a, b)\n",
      "        h = tf.compat.v1.get_session_handle(c)\n",
      "        h = sess.run(h)\n",
      "        \n",
      "        p, a = tf.compat.v1.get_session_tensor(h.handle, tf.float32)\n",
      "        b = tf.multiply(a, 10)\n",
      "        c = sess.run(b, feed_dict={p: h.handle})\n",
      "        ```\n",
      "    \n",
      "    get_session_tensor(handle, dtype, name=None)\n",
      "        Get the tensor of type `dtype` by feeding a tensor handle.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Get the value of the tensor from a tensor handle. The tensor\n",
      "        is produced in a previous run() and stored in the state of the\n",
      "        session.\n",
      "        \n",
      "        Args:\n",
      "          handle: The string representation of a persistent tensor handle.\n",
      "          dtype: The type of the output tensor.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A pair of tensors. The first is a placeholder for feeding a\n",
      "          tensor handle and the second is the tensor in the session state\n",
      "          keyed by the tensor handle.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.multiply(a, b)\n",
      "        h = tf.compat.v1.get_session_handle(c)\n",
      "        h = sess.run(h)\n",
      "        \n",
      "        p, a = tf.compat.v1.get_session_tensor(h.handle, tf.float32)\n",
      "        b = tf.multiply(a, 10)\n",
      "        c = sess.run(b, feed_dict={p: h.handle})\n",
      "        ```\n",
      "    \n",
      "    get_static_value = constant_value(tensor, partial=False)\n",
      "        Returns the constant value of the given tensor, if efficiently calculable.\n",
      "        \n",
      "        This function attempts to partially evaluate the given tensor, and\n",
      "        returns its value as a numpy ndarray if this succeeds.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> a = tf.constant(10)\n",
      "        >>> tf.get_static_value(a)\n",
      "        10\n",
      "        >>> b = tf.constant(20)\n",
      "        >>> tf.get_static_value(tf.add(a, b))\n",
      "        30\n",
      "        \n",
      "        >>> # `tf.Variable` is not supported.\n",
      "        >>> c = tf.Variable(30)\n",
      "        >>> print(tf.get_static_value(c))\n",
      "        None\n",
      "        \n",
      "        Using `partial` option is most relevant when calling `get_static_value` inside\n",
      "        a `tf.function`. Setting it to `True` will return the results but for the\n",
      "        values that cannot be evaluated will be `None`. For example:\n",
      "        \n",
      "        ```python\n",
      "        class Foo:\n",
      "          def __init__(self):\n",
      "            self.a = tf.Variable(1)\n",
      "            self.b = tf.constant(2)\n",
      "        \n",
      "          @tf.function\n",
      "          def bar(self, partial):\n",
      "            packed = tf.raw_ops.Pack(values=[self.a, self.b])\n",
      "            static_val = tf.get_static_value(packed, partial=partial)\n",
      "            tf.print(static_val)\n",
      "        \n",
      "        f = Foo()\n",
      "        f.bar(partial=True)  # `array([None, array(2, dtype=int32)], dtype=object)`\n",
      "        f.bar(partial=False)  # `None`\n",
      "        ```\n",
      "        \n",
      "        Compatibility(V1): If `constant_value(tensor)` returns a non-`None` result, it\n",
      "        will no longer be possible to feed a different value for `tensor`. This allows\n",
      "        the result of this function to influence the graph that is constructed, and\n",
      "        permits static shape optimizations.\n",
      "        \n",
      "        Args:\n",
      "          tensor: The Tensor to be evaluated.\n",
      "          partial: If True, the returned numpy array is allowed to have partially\n",
      "            evaluated values. Values that can't be evaluated will be None.\n",
      "        \n",
      "        Returns:\n",
      "          A numpy ndarray containing the constant value of the given `tensor`,\n",
      "          or None if it cannot be calculated.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if tensor is not an tensor.Tensor.\n",
      "    \n",
      "    get_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "        Gets an existing variable with these parameters or create a new one.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Although it is a legacy `compat.v1` api,\n",
      "        `tf.compat.v1.get_variable` is mostly compatible with eager\n",
      "        execution and `tf.function` but only if you combine it with the\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables` decorator. (Though\n",
      "        it will behave as if reuse is always set to `AUTO_REUSE`.)\n",
      "        \n",
      "        See the\n",
      "        [model migration guide](https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "        for more info.\n",
      "        \n",
      "        If you do not combine it with\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables`, `get_variable` will create\n",
      "        a brand new variable every single time it is called and will never reuse\n",
      "        variables, regardless of variable names or `reuse` arguments.\n",
      "        \n",
      "        The TF2 equivalent of this symbol would be `tf.Variable`, but note\n",
      "        that when using `tf.Variable` you must make sure you track your variables\n",
      "        (and regularizer arguments) either manually or via `tf.Module` or\n",
      "        `tf.keras.layers.Layer` mechanisms.\n",
      "        \n",
      "        A section of the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate/model_mapping#incremental_migration_to_native_tf2)\n",
      "        provides more details on incrementally migrating these usages to `tf.Variable`\n",
      "        as well.\n",
      "        \n",
      "        Note: The `partitioner` arg is not compatible with TF2 behaviors even when\n",
      "        using `tf.compat.v1.keras.utils.track_tf1_style_variables`. It can be replaced\n",
      "        by using `ParameterServerStrategy` and its partitioners. See the\n",
      "        [multi-gpu migration guide](https://www.tensorflow.org/guide/migrate/multi_worker_cpu_gpu_training)\n",
      "        and the ParameterServerStrategy guides it references for more info.\n",
      "        @end_compatibility\n",
      "        \n",
      "        This function prefixes the name with the current variable scope\n",
      "        and performs reuse checks. See the\n",
      "        [Variable Scope How To](https://tensorflow.org/guide/variables)\n",
      "        for an extensive description of how reusing works. Here is a basic example:\n",
      "        \n",
      "        ```python\n",
      "        def foo():\n",
      "          with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
      "            v = tf.get_variable(\"v\", [1])\n",
      "          return v\n",
      "        \n",
      "        v1 = foo()  # Creates v.\n",
      "        v2 = foo()  # Gets the same, existing v.\n",
      "        assert v1 == v2\n",
      "        ```\n",
      "        \n",
      "        If initializer is `None` (the default), the default initializer passed in\n",
      "        the variable scope will be used. If that one is `None` too, a\n",
      "        `glorot_uniform_initializer` will be used. The initializer can also be\n",
      "        a Tensor, in which case the variable is initialized to this value and shape.\n",
      "        \n",
      "        Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "        passed in the variable scope will be used (if that is `None` too,\n",
      "        then by default no regularization is performed).\n",
      "        \n",
      "        If a partitioner is provided, a `PartitionedVariable` is returned.\n",
      "        Accessing this object as a `Tensor` returns the shards concatenated along\n",
      "        the partition axis.\n",
      "        \n",
      "        Some useful partitioners are available.  See, e.g.,\n",
      "        `variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "        \n",
      "        Args:\n",
      "          name: The name of the new or existing variable.\n",
      "          shape: Shape of the new or existing variable.\n",
      "          dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "          initializer: Initializer for the variable if one is created. Can either be\n",
      "            an initializer object or a Tensor. If it's a Tensor, its shape must be known\n",
      "            unless validate_shape is False.\n",
      "          regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "            applying it on a newly created variable will be added to the collection\n",
      "            `tf.GraphKeys.REGULARIZATION_LOSSES` and can be used for regularization.\n",
      "          trainable: If `True` also add the variable to the graph collection\n",
      "            `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).\n",
      "          collections: List of graph collections keys to add the Variable to.\n",
      "            Defaults to `[GraphKeys.GLOBAL_VARIABLES]` (see `tf.Variable`).\n",
      "          caching_device: Optional device string or function describing where the\n",
      "            Variable should be cached for reading.  Defaults to the Variable's\n",
      "            device.  If not `None`, caches on another device.  Typical use is to\n",
      "            cache on the device where the Ops using the Variable reside, to\n",
      "            deduplicate copying through `Switch` and other conditional statements.\n",
      "          partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "            and `dtype` of the Variable to be created, and returns a list of\n",
      "            partitions for each axis (currently only one axis can be partitioned).\n",
      "          validate_shape: If False, allows the variable to be initialized with a\n",
      "              value of unknown shape. If True, the default, the shape of initial_value\n",
      "              must be known. For this to be used the initializer must be a Tensor and\n",
      "              not an initializer object.\n",
      "          use_resource: If False, creates a regular Variable. If true, creates an\n",
      "            experimental ResourceVariable instead with well-defined semantics.\n",
      "            Defaults to False (will later change to True). When eager execution is\n",
      "            enabled this argument is always forced to be True.\n",
      "          custom_getter: Callable that takes as a first argument the true getter, and\n",
      "            allows overwriting the internal get_variable method.\n",
      "            The signature of `custom_getter` should match that of this method,\n",
      "            but the most future-proof version will allow for changes:\n",
      "            `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "            all `get_variable` parameters is also allowed:\n",
      "            `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "            custom getter that simply creates variables with modified names is:\n",
      "            ```python\n",
      "            def custom_getter(getter, name, *args, **kwargs):\n",
      "              return getter(name + '_suffix', *args, **kwargs)\n",
      "            ```\n",
      "          constraint: An optional projection function to be applied to the variable\n",
      "            after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "            constraints or value constraints for layer weights). The function must\n",
      "            take as input the unprojected Tensor representing the value of the\n",
      "            variable and return the Tensor for the projected value\n",
      "            (which must have the same shape). Constraints are not safe to\n",
      "            use when doing asynchronous distributed training.\n",
      "          synchronization: Indicates when a distributed a variable will be\n",
      "            aggregated. Accepted values are constants defined in the class\n",
      "            `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "            `AUTO` and the current `DistributionStrategy` chooses\n",
      "            when to synchronize.\n",
      "          aggregation: Indicates how a distributed variable will be aggregated.\n",
      "            Accepted values are constants defined in the class\n",
      "            `tf.VariableAggregation`.\n",
      "        \n",
      "        Returns:\n",
      "          The created or existing `Variable` (or `PartitionedVariable`, if a\n",
      "          partitioner was used).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: when creating a new variable and shape is not declared,\n",
      "            when violating reuse during variable creation, or when `initializer` dtype\n",
      "            and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "    \n",
      "    get_variable_scope()\n",
      "        Returns the current variable scope.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Although it is a legacy `compat.v1` api,\n",
      "        `tf.compat.v1.get_variable` is compatible with eager\n",
      "        execution and `tf.function`\n",
      "        \n",
      "        However, to maintain variable-scope based variable reuse\n",
      "        you will need to combine it with\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables`. (Though\n",
      "        it will behave as if reuse is always set to `tf.compat.v1.AUTO_REUSE`.)\n",
      "        \n",
      "        See the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "        for more info.\n",
      "        \n",
      "        The TF2 equivalent, if you are just trying to track\n",
      "        variable name prefixes and not control `get_variable`-based variable reuse,\n",
      "        would be to use `tf.name_scope` and capture the output of opening the\n",
      "        scope (which represents the current name prefix).\n",
      "        \n",
      "        For example:\n",
      "        ```python\n",
      "        x = tf.name_scope('foo') as current_scope:\n",
      "          ...\n",
      "        ```\n",
      "        @end_compatibility\n",
      "    \n",
      "    global_norm(t_list, name=None)\n",
      "        Computes the global norm of multiple tensors.\n",
      "        \n",
      "        Given a tuple or list of tensors `t_list`, this operation returns the\n",
      "        global norm of the elements in all tensors in `t_list`. The global norm is\n",
      "        computed as:\n",
      "        \n",
      "        `global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))`\n",
      "        \n",
      "        Any entries in `t_list` that are of type None are ignored.\n",
      "        \n",
      "        Args:\n",
      "          t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A 0-D (scalar) `Tensor` of type `float`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `t_list` is not a sequence.\n",
      "    \n",
      "    global_variables(scope=None)\n",
      "        Returns global variables.\n",
      "        \n",
      "        Global variables are variables that are shared across machines in a\n",
      "        distributed environment. The `Variable()` constructor or `get_variable()`\n",
      "        automatically adds new variables to the graph collection\n",
      "        `GraphKeys.GLOBAL_VARIABLES`.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        An alternative to global variables are local variables. See\n",
      "        `tf.compat.v1.local_variables`\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Not compatible with eager execution and `tf.function`. In particular, Graph\n",
      "        collections are deprecated in TF2. Instead please create a\n",
      "        [tf.Module](https://www.tensorflow.org/guide/intro_to_modules)\n",
      "        container for all your model state, including variables.\n",
      "        You can then list all the variables in your `tf.Module` through the\n",
      "        `variables` attribute.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Variable` objects.\n",
      "    \n",
      "    global_variables_initializer()\n",
      "        Returns an Op that initializes global variables.\n",
      "        \n",
      "        This is just a shortcut for `variables_initializer(global_variables())`\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        In TF2, variables are initialized immediately when they are created. There is\n",
      "        no longer a need to run variable initializers before using them.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes global variables in the graph.\n",
      "    \n",
      "    grad_pass_through(f)\n",
      "        Creates a grad-pass-through op with the forward behavior provided in f.\n",
      "        \n",
      "        Use this function to wrap any op, maintaining its behavior in the forward\n",
      "        pass, but replacing the original op in the backward graph with an identity.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.Variable(1.0, name=\"x\")\n",
      "        z = tf.Variable(3.0, name=\"z\")\n",
      "        \n",
      "        with tf.GradientTape() as tape:\n",
      "          # y will evaluate to 9.0\n",
      "          y = tf.grad_pass_through(x.assign)(z**2)\n",
      "        # grads will evaluate to 6.0\n",
      "        grads = tape.gradient(y, z)\n",
      "        ```\n",
      "        \n",
      "        Another example is a 'differentiable' moving average approximation, where\n",
      "        gradients are allowed to flow into the last value fed to the moving average,\n",
      "        but the moving average is still used for the forward pass:\n",
      "        \n",
      "        ```python\n",
      "        x = ... # Some scalar value\n",
      "        # A moving average object, we don't need to know how this is implemented\n",
      "        moving_average = MovingAverage()\n",
      "        with backprop.GradientTape() as tape:\n",
      "          # mavg_x will evaluate to the current running average value\n",
      "          mavg_x = tf.grad_pass_through(moving_average)(x)\n",
      "        grads = tape.gradient(mavg_x, x) # grads will evaluate to 1.0\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a `Tensor` or nested structure of `Tensor`\n",
      "            outputs.\n",
      "        \n",
      "        Returns:\n",
      "          A function `h(x)` which returns the same values as `f(x)` and whose\n",
      "          gradients are the same as those of an identity function.\n",
      "    \n",
      "    gradients(ys, xs, grad_ys=None, name='gradients', colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None, stop_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      "        Constructs symbolic derivatives of sum of `ys` w.r.t. x in `xs`.\n",
      "        \n",
      "        `ys` and `xs` are each a `Tensor` or a list of tensors.  `grad_ys`\n",
      "        is a list of `Tensor`, holding the gradients received by the\n",
      "        `ys`. The list must be the same length as `ys`.\n",
      "        \n",
      "        `gradients()` adds ops to the graph to output the derivatives of `ys` with\n",
      "        respect to `xs`.  It returns a list of `Tensor` of length `len(xs)` where\n",
      "        each tensor is the `sum(dy/dx)` for y in `ys` and for x in `xs`.\n",
      "        \n",
      "        `grad_ys` is a list of tensors of the same length as `ys` that holds\n",
      "        the initial gradients for each y in `ys`.  When `grad_ys` is None,\n",
      "        we fill in a tensor of '1's of the shape of y for each y in `ys`.  A\n",
      "        user can provide their own initial `grad_ys` to compute the\n",
      "        derivatives using a different initial gradient for each y (e.g., if\n",
      "        one wanted to weight the gradient differently for each value in\n",
      "        each y).\n",
      "        \n",
      "        `stop_gradients` is a `Tensor` or a list of tensors to be considered constant\n",
      "        with respect to all `xs`. These tensors will not be backpropagated through,\n",
      "        as though they had been explicitly disconnected using `stop_gradient`.  Among\n",
      "        other things, this allows computation of partial derivatives as opposed to\n",
      "        total derivatives. For example:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.constant(0.)\n",
      "        b = 2 * a\n",
      "        g = tf.gradients(a + b, [a, b], stop_gradients=[a, b])\n",
      "        ```\n",
      "        \n",
      "        Here the partial derivatives `g` evaluate to `[1.0, 1.0]`, compared to the\n",
      "        total derivatives `tf.gradients(a + b, [a, b])`, which take into account the\n",
      "        influence of `a` on `b` and evaluate to `[3.0, 1.0]`.  Note that the above is\n",
      "        equivalent to:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.stop_gradient(tf.constant(0.))\n",
      "        b = tf.stop_gradient(2 * a)\n",
      "        g = tf.gradients(a + b, [a, b])\n",
      "        ```\n",
      "        \n",
      "        `stop_gradients` provides a way of stopping gradient after the graph has\n",
      "        already been constructed, as compared to `tf.stop_gradient` which is used\n",
      "        during graph construction.  When the two approaches are combined,\n",
      "        backpropagation stops at both `tf.stop_gradient` nodes and nodes in\n",
      "        `stop_gradients`, whichever is encountered first.\n",
      "        \n",
      "        All integer tensors are considered constant with respect to all `xs`, as if\n",
      "        they were included in `stop_gradients`.\n",
      "        \n",
      "        `unconnected_gradients` determines the value returned for each x in xs if it\n",
      "        is unconnected in the graph to ys. By default this is None to safeguard\n",
      "        against errors. Mathematically these gradients are zero which can be requested\n",
      "        using the `'zero'` option. `tf.UnconnectedGradients` provides the\n",
      "        following options and behaviors:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.ones([1, 2])\n",
      "        b = tf.ones([3, 1])\n",
      "        g1 = tf.gradients([b], [a], unconnected_gradients='none')\n",
      "        sess.run(g1)  # [None]\n",
      "        \n",
      "        g2 = tf.gradients([b], [a], unconnected_gradients='zero')\n",
      "        sess.run(g2)  # [array([[0., 0.]], dtype=float32)]\n",
      "        ```\n",
      "        \n",
      "        Let us take one practical example which comes during the back propogation\n",
      "        phase. This function is used to evaluate the derivatives of the cost function\n",
      "        with respect to Weights `Ws` and Biases `bs`. Below sample implementation\n",
      "        provides the exaplantion of what it is actually used for :\n",
      "        \n",
      "        ```python\n",
      "        Ws = tf.constant(0.)\n",
      "        bs = 2 * Ws\n",
      "        cost = Ws + bs  # This is just an example. So, please ignore the formulas.\n",
      "        g = tf.gradients(cost, [Ws, bs])\n",
      "        dCost_dW, dCost_db = g\n",
      "        ```\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          ys: A `Tensor` or list of tensors to be differentiated.\n",
      "          xs: A `Tensor` or list of tensors to be used for differentiation.\n",
      "          grad_ys: Optional. A `Tensor` or list of tensors the same size as\n",
      "            `ys` and holding the gradients computed for each y in `ys`.\n",
      "          name: Optional name to use for grouping all the gradient ops together.\n",
      "            defaults to 'gradients'.\n",
      "          colocate_gradients_with_ops: If True, try colocating gradients with\n",
      "            the corresponding op.\n",
      "          gate_gradients: If True, add a tuple around the gradients returned\n",
      "            for an operations.  This avoids some race conditions.\n",
      "          aggregation_method: Specifies the method used to combine gradient terms.\n",
      "            Accepted values are constants defined in the class `AggregationMethod`.\n",
      "          stop_gradients: Optional. A `Tensor` or list of tensors not to differentiate\n",
      "            through.\n",
      "          unconnected_gradients: Optional. Specifies the gradient value returned when\n",
      "            the given input tensors are unconnected. Accepted values are constants\n",
      "            defined in the class `tf.UnconnectedGradients` and the default value is\n",
      "            `none`.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` of length `len(xs)` where each tensor is the `sum(dy/dx)`\n",
      "          for y in `ys` and for x in `xs`.\n",
      "        \n",
      "        Raises:\n",
      "          LookupError: if one of the operations between `x` and `y` does not\n",
      "            have a registered gradient function.\n",
      "          ValueError: if the arguments are invalid.\n",
      "          RuntimeError: if called in Eager mode.\n",
      "    \n",
      "    greater(x: typing.Annotated[_any, ~TV_Greater_T], y: typing.Annotated[_any, ~TV_Greater_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of (x > y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5, 2, 5])\n",
      "        tf.math.greater(x, y) ==> [False, True, True]\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5])\n",
      "        tf.math.greater(x, y) ==> [False, False, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    greater_equal(x: typing.Annotated[_any, ~TV_GreaterEqual_T], y: typing.Annotated[_any, ~TV_GreaterEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of (x >= y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5, 4, 6, 7])\n",
      "        y = tf.constant([5, 2, 5, 10])\n",
      "        tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "        \n",
      "        x = tf.constant([5, 4, 6, 7])\n",
      "        y = tf.constant([5])\n",
      "        tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    group(*inputs, **kwargs)\n",
      "        Create an op that groups multiple operations.\n",
      "        \n",
      "        When this op finishes, all ops in `inputs` have finished. This op has no\n",
      "        output.\n",
      "        \n",
      "        Note: *In TensorFlow 2 with eager and/or Autograph, you should not require\n",
      "        this method, as ops execute in the expected order thanks to automatic control\n",
      "        dependencies.* Only use `tf.group` when working with v1\n",
      "        `tf.Graph` code.\n",
      "        \n",
      "        When operating in a v1-style graph context, ops are not executed in the same\n",
      "        order as specified in the code; TensorFlow will attempt to execute ops in\n",
      "        parallel or in an order convenient to the result it is computing.  `tf.group`\n",
      "        allows you to request that one or more results finish before execution\n",
      "        continues.\n",
      "        \n",
      "        `tf.group` creates a single op (of type `NoOp`), and then adds appropriate\n",
      "        control dependencies.  Thus, `c = tf.group(a, b)` will compute the same graph\n",
      "        as this:\n",
      "        \n",
      "            with tf.control_dependencies([a, b]):\n",
      "                c = tf.no_op()\n",
      "        \n",
      "        See also `tf.tuple` and\n",
      "        `tf.control_dependencies`.\n",
      "        \n",
      "        Args:\n",
      "          *inputs: Zero or more tensors to group.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          An Operation that executes all its inputs.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If an unknown keyword argument is provided.\n",
      "    \n",
      "    guarantee_const(input, name=None)\n",
      "        Promise to the TF runtime that the input tensor is a constant. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Not for public use.\n",
      "        \n",
      "        The runtime is then free to make optimizations based on this.\n",
      "        \n",
      "        Returns the input tensor without modification.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for this operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same dtype as `input`.\n",
      "    \n",
      "    hessians(ys, xs, name='hessians', colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None)\n",
      "        Constructs the Hessian of sum of `ys` with respect to `x` in `xs`.\n",
      "        \n",
      "        `hessians()` adds ops to the graph to output the Hessian matrix of `ys`\n",
      "        with respect to `xs`.  It returns a list of `Tensor` of length `len(xs)`\n",
      "        where each tensor is the Hessian of `sum(ys)`.\n",
      "        \n",
      "        The Hessian is a matrix of second-order partial derivatives of a scalar\n",
      "        tensor (see https://en.wikipedia.org/wiki/Hessian_matrix for more details).\n",
      "        \n",
      "        Args:\n",
      "          ys: A `Tensor` or list of tensors to be differentiated.\n",
      "          xs: A `Tensor` or list of tensors to be used for differentiation.\n",
      "          name: Optional name to use for grouping all the gradient ops together.\n",
      "            defaults to 'hessians'.\n",
      "          colocate_gradients_with_ops: See `gradients()` documentation for details.\n",
      "          gate_gradients: See `gradients()` documentation for details.\n",
      "          aggregation_method: See `gradients()` documentation for details.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Hessian matrices of `sum(ys)` for each `x` in `xs`.\n",
      "        \n",
      "        Raises:\n",
      "          LookupError: if one of the operations between `xs` and `ys` does not\n",
      "            have a registered gradient function.\n",
      "    \n",
      "    histogram_fixed_width(values, value_range, nbins=100, dtype=tf.int32, name=None)\n",
      "        Return histogram of values.\n",
      "        \n",
      "        Given the tensor `values`, this operation returns a rank 1 histogram counting\n",
      "        the number of entries in `values` that fell into every bin.  The bins are\n",
      "        equal width and determined by the arguments `value_range` and `nbins`.\n",
      "        \n",
      "        Args:\n",
      "          values:  Numeric `Tensor`.\n",
      "          value_range:  Shape [2] `Tensor` of same `dtype` as `values`.\n",
      "            values <= value_range[0] will be mapped to hist[0],\n",
      "            values >= value_range[1] will be mapped to hist[-1].\n",
      "          nbins:  Scalar `int32 Tensor`.  Number of histogram bins.\n",
      "          dtype:  dtype for returned histogram.\n",
      "          name:  A name for this operation (defaults to 'histogram_fixed_width').\n",
      "        \n",
      "        Returns:\n",
      "          A 1-D `Tensor` holding histogram of values.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If any unsupported dtype is provided.\n",
      "          tf.errors.InvalidArgumentError: If value_range does not\n",
      "              satisfy value_range[0] < value_range[1].\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)\n",
      "        ...\n",
      "        >>> nbins = 5\n",
      "        >>> value_range = [0.0, 5.0]\n",
      "        >>> new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\n",
      "        >>> hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)\n",
      "        >>> hist.numpy()\n",
      "        array([2, 1, 1, 0, 2], dtype=int32)\n",
      "    \n",
      "    histogram_fixed_width_bins(values, value_range, nbins=100, dtype=tf.int32, name=None)\n",
      "        Bins the given values for use in a histogram.\n",
      "        \n",
      "        Given the tensor `values`, this operation returns a rank 1 `Tensor`\n",
      "        representing the indices of a histogram into which each element\n",
      "        of `values` would be binned. The bins are equal width and\n",
      "        determined by the arguments `value_range` and `nbins`.\n",
      "        \n",
      "        Args:\n",
      "          values:  Numeric `Tensor`.\n",
      "          value_range:  Shape [2] `Tensor` of same `dtype` as `values`.\n",
      "            values <= value_range[0] will be mapped to hist[0],\n",
      "            values >= value_range[1] will be mapped to hist[-1].\n",
      "          nbins:  Scalar `int32 Tensor`.  Number of histogram bins.\n",
      "          dtype:  dtype for returned histogram.\n",
      "          name:  A name for this operation (defaults to 'histogram_fixed_width').\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` holding the indices of the binned values whose shape matches\n",
      "          `values`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If any unsupported dtype is provided.\n",
      "          tf.errors.InvalidArgumentError: If value_range does not\n",
      "              satisfy value_range[0] < value_range[1].\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)\n",
      "        ...\n",
      "        >>> nbins = 5\n",
      "        >>> value_range = [0.0, 5.0]\n",
      "        >>> new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\n",
      "        >>> indices = tf.histogram_fixed_width_bins(new_values, value_range, nbins=5)\n",
      "        >>> indices.numpy()\n",
      "        array([0, 0, 1, 2, 4, 4], dtype=int32)\n",
      "    \n",
      "    identity(input, name=None)\n",
      "        Return a Tensor with the same shape and contents as input.\n",
      "        \n",
      "        The return value is not the same Tensor as the original, but contains the same\n",
      "        values.  This operation is fast when used on the same device.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([0.78])\n",
      "        >>> a_identity = tf.identity(a)\n",
      "        >>> a.numpy()\n",
      "        array([0.78], dtype=float32)\n",
      "        >>> a_identity.numpy()\n",
      "        array([0.78], dtype=float32)\n",
      "        \n",
      "        Calling `tf.identity` on a variable will make a Tensor that represents the\n",
      "        value of that variable at the time it is called. This is equivalent to calling\n",
      "        `<variable>.read_value()`.\n",
      "        \n",
      "        >>> a = tf.Variable(5)\n",
      "        >>> a_identity = tf.identity(a)\n",
      "        >>> a.assign_add(1)\n",
      "        <tf.Variable ... shape=() dtype=int32, numpy=6>\n",
      "        >>> a.numpy()\n",
      "        6\n",
      "        >>> a_identity.numpy()\n",
      "        5\n",
      "        \n",
      "        This function can also be used to explicitly transfer tensors between devices.\n",
      "        For example, to transfer a tensor in GPU memory back to host memory, one can\n",
      "        use:\n",
      "        \n",
      "        >>> with tf.device(\"/gpu:0\"):\n",
      "        ...   x_on_gpu = tf.constant(1)\n",
      "        >>> with tf.device(\"/cpu:0\"):\n",
      "        ...   x_on_cpu = tf.identity(x_on_gpu)\n",
      "        >>> x_on_cpu.device\n",
      "        '/job:localhost/replica:0/task:0/device:CPU:0'\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`, a `Variable`, a `CompositeTensor` or anything that can be\n",
      "          converted to a tensor using `tf.convert_to_tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or CompositeTensor. Has the same type and contents as `input`.\n",
      "    \n",
      "    identity_n(input, name=None)\n",
      "        Returns a list of tensors with the same shapes and contents as the input\n",
      "        \n",
      "        tensors.\n",
      "        \n",
      "        This op can be used to override the gradient for complicated functions. For\n",
      "        example, suppose y = f(x) and we wish to apply a custom function g for backprop\n",
      "        such that dx = g(dy). In Python,\n",
      "        \n",
      "        ```python\n",
      "        with tf.get_default_graph().gradient_override_map(\n",
      "            {'IdentityN': 'OverrideGradientWithG'}):\n",
      "          y, _ = identity_n([f(x), x])\n",
      "        \n",
      "        @tf.RegisterGradient('OverrideGradientWithG')\n",
      "        def ApplyG(op, dy, _):\n",
      "          return [None, g(dy)]  # Do not backprop to f(x).\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A list of `Tensor` objects.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` objects. Has the same type as `input`.\n",
      "    \n",
      "    ifft(input: Annotated[Any, ~TV_IFFT_Tcomplex], name=None) -> Annotated[Any, ~TV_IFFT_Tcomplex]\n",
      "        Inverse fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 1-dimensional discrete Fourier transform over the\n",
      "        inner-most dimension of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    ifft2d(input: Annotated[Any, ~TV_IFFT2D_Tcomplex], name=None) -> Annotated[Any, ~TV_IFFT2D_Tcomplex]\n",
      "        Inverse 2D fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 2-dimensional discrete Fourier transform over the\n",
      "        inner-most 2 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    ifft3d(input: Annotated[Any, ~TV_IFFT3D_Tcomplex], name=None) -> Annotated[Any, ~TV_IFFT3D_Tcomplex]\n",
      "        Inverse 3D fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 3-dimensional discrete Fourier transform over the\n",
      "        inner-most 3 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    ifftnd(input: Annotated[Any, ~TV_IFFTND_Tcomplex], fft_length: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], axes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], name=None) -> Annotated[Any, ~TV_IFFTND_Tcomplex]\n",
      "        ND inverse fast Fourier transform.\n",
      "        \n",
      "        Computes the n-dimensional inverse discrete Fourier transform over designated\n",
      "        dimensions of `input`. The designated dimensions of `input` are assumed to be\n",
      "        the result of `IFFTND`.\n",
      "        \n",
      "        If fft_length[i]<shape(input)[i], the input is cropped. If\n",
      "        fft_length[i]>shape(input)[i], the input is padded with zeros. If fft_length\n",
      "        is not given, the default shape(input) is used.\n",
      "        \n",
      "        Axes mean the dimensions to perform the transform on. Default is to perform on\n",
      "        all axes.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          fft_length: A `Tensor` of type `int32`.\n",
      "            An int32 tensor. The FFT length for each dimension.\n",
      "          axes: A `Tensor` of type `int32`.\n",
      "            An int32 tensor with a same shape as fft_length. Axes to perform the transform.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    igamma(a: typing.Annotated[_any, ~TV_Igamma_T], x: typing.Annotated[_any, ~TV_Igamma_T], name=None) -> typing.Annotated[_any, ~TV_Igamma_T]\n",
      "        Compute the lower regularized incomplete Gamma function `P(a, x)`.\n",
      "        \n",
      "        The lower regularized incomplete Gamma function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \\\\(gamma(a, x) = \\\\int_{0}^{x} t^{a-1} exp(-t) dt\\\\)\n",
      "        \n",
      "        is the lower incomplete Gamma function.\n",
      "        \n",
      "        Note, above `Q(a, x)` (`Igammac`) is the upper regularized complete\n",
      "        Gamma function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    igammac(a: typing.Annotated[_any, ~TV_Igammac_T], x: typing.Annotated[_any, ~TV_Igammac_T], name=None) -> typing.Annotated[_any, ~TV_Igammac_T]\n",
      "        Compute the upper regularized incomplete Gamma function `Q(a, x)`.\n",
      "        \n",
      "        The upper regularized incomplete Gamma function is defined as:\n",
      "        \n",
      "        \\\\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \\\\(Gamma(a, x) = \\int_{x}^{\\infty} t^{a-1} exp(-t) dt\\\\)\n",
      "        \n",
      "        is the upper incomplete Gamma function.\n",
      "        \n",
      "        Note, above `P(a, x)` (`Igamma`) is the lower regularized complete\n",
      "        Gamma function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    imag(input, name=None)\n",
      "        Returns the imaginary part of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the imaginary part of each element in `input` considered as a complex\n",
      "        number. If `input` is real, a tensor of all zeros is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n",
      "        tf.math.imag(x)  # [4.75, 5.75]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float`, `double`,\n",
      "            `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None, producer_op_list=None)\n",
      "        Imports the graph from `graph_def` into the current default `Graph`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(op_dict)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please file an issue at https://github.com/tensorflow/tensorflow/issues if you depend on this feature.\n",
      "        \n",
      "        This function provides a way to import a serialized TensorFlow\n",
      "        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      "        protocol buffer, and extract individual objects in the `GraphDef` as\n",
      "        `tf.Tensor` and `tf.Operation` objects. Once extracted,\n",
      "        these objects are placed into the current default `Graph`. See\n",
      "        `tf.Graph.as_graph_def` for a way to create a `GraphDef`\n",
      "        proto.\n",
      "        \n",
      "        Args:\n",
      "          graph_def: A `GraphDef` proto containing operations to be imported into\n",
      "            the default graph.\n",
      "          input_map: A dictionary mapping input names (as strings) in `graph_def`\n",
      "            to `Tensor` objects. The values of the named input tensors in the\n",
      "            imported graph will be re-mapped to the respective `Tensor` values.\n",
      "          return_elements: A list of strings containing operation names in\n",
      "            `graph_def` that will be returned as `Operation` objects; and/or\n",
      "            tensor names in `graph_def` that will be returned as `Tensor` objects.\n",
      "          name: (Optional.) A prefix that will be prepended to the names in\n",
      "            `graph_def`. Note that this does not apply to imported function names.\n",
      "            Defaults to `\"import\"`.\n",
      "          op_dict: (Optional.) Deprecated, do not use.\n",
      "          producer_op_list: (Optional.) An `OpList` proto with the (possibly stripped)\n",
      "            list of `OpDef`s used by the producer of the graph. If provided,\n",
      "            unrecognized attrs for ops in `graph_def` that have their default value\n",
      "            according to `producer_op_list` will be removed. This will allow some more\n",
      "            `GraphDef`s produced by later binaries to be accepted by earlier binaries.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Operation` and/or `Tensor` objects from the imported graph,\n",
      "          corresponding to the names in `return_elements`,\n",
      "          and None if `returns_elements` is None.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `graph_def` is not a `GraphDef` proto,\n",
      "            `input_map` is not a dictionary mapping strings to `Tensor` objects,\n",
      "            or `return_elements` is not a list of strings.\n",
      "          ValueError: If `input_map`, or `return_elements` contains names that\n",
      "            do not appear in `graph_def`, or `graph_def` is not well-formed (e.g.\n",
      "            it refers to an unknown tensor).\n",
      "    \n",
      "    init_scope() -> collections.abc.Iterator[None]\n",
      "        A context manager that lifts ops out of control-flow scopes and function-building graphs.\n",
      "        \n",
      "        There is often a need to lift variable initialization ops out of control-flow\n",
      "        scopes, function-building graphs, and gradient tapes. Entering an\n",
      "        `init_scope` is a mechanism for satisfying these desiderata. In particular,\n",
      "        entering an `init_scope` has three effects:\n",
      "        \n",
      "          (1) All control dependencies are cleared the moment the scope is entered;\n",
      "              this is equivalent to entering the context manager returned from\n",
      "              `control_dependencies(None)`, which has the side-effect of exiting\n",
      "              control-flow scopes like `tf.cond` and `tf.while_loop`.\n",
      "        \n",
      "          (2) All operations that are created while the scope is active are lifted\n",
      "              into the lowest context on the `context_stack` that is not building a\n",
      "              graph function. Here, a context is defined as either a graph or an eager\n",
      "              context. Every context switch, i.e., every installation of a graph as\n",
      "              the default graph and every switch into eager mode, is logged in a\n",
      "              thread-local stack called `context_switches`; the log entry for a\n",
      "              context switch is popped from the stack when the context is exited.\n",
      "              Entering an `init_scope` is equivalent to crawling up\n",
      "              `context_switches`, finding the first context that is not building a\n",
      "              graph function, and entering it. A caveat is that if graph mode is\n",
      "              enabled but the default graph stack is empty, then entering an\n",
      "              `init_scope` will simply install a fresh graph as the default one.\n",
      "        \n",
      "          (3) The gradient tape is paused while the scope is active.\n",
      "        \n",
      "        When eager execution is enabled, code inside an init_scope block runs with\n",
      "        eager execution enabled even when tracing a `tf.function`. For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        @tf.function\n",
      "        def func():\n",
      "          # A function constructs TensorFlow graphs,\n",
      "          # it does not execute eagerly.\n",
      "          assert not tf.executing_eagerly()\n",
      "          with tf.init_scope():\n",
      "            # Initialization runs with eager execution enabled\n",
      "            assert tf.executing_eagerly()\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if graph state is incompatible with this initialization.\n",
      "    \n",
      "    initialize_all_tables(name='init_all_tables')\n",
      "        Returns an Op that initializes all tables of the default graph. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.tables_initializer` instead.\n",
      "        \n",
      "        Args:\n",
      "          name: Optional name for the initialization op.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all tables.  Note that if there are\n",
      "          not tables the returned Op is a NoOp.\n",
      "    \n",
      "    initialize_all_variables()\n",
      "        See `tf.compat.v1.global_variables_initializer`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.global_variables_initializer` instead.\n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    initialize_local_variables()\n",
      "        See `tf.compat.v1.local_variables_initializer`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.local_variables_initializer` instead.\n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    initialize_variables(var_list, name='init')\n",
      "        See `tf.compat.v1.variables_initializer`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.variables_initializer` instead.\n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    invert_permutation(x: Annotated[Any, ~TV_InvertPermutation_T], name=None) -> Annotated[Any, ~TV_InvertPermutation_T]\n",
      "        Computes the inverse permutation of a tensor.\n",
      "        \n",
      "        This operation computes the inverse of an index permutation. It takes a 1-D\n",
      "        integer tensor `x`, which represents the indices of a zero-based array, and\n",
      "        swaps each value with its index position. In other words, for an output tensor\n",
      "        `y` and an input tensor `x`, this operation computes the following:\n",
      "        \n",
      "        `y[x[i]] = i for i in [0, 1, ..., len(x) - 1]`\n",
      "        \n",
      "        The values must include 0. There can be no duplicate values or negative values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor `x` is [3, 4, 0, 2, 1]\n",
      "        invert_permutation(x) ==> [2, 4, 3, 0, 1]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    irfftnd(input: Annotated[Any, ~TV_IRFFTND_Tcomplex], fft_length: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], axes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], Treal: ~TV_IRFFTND_Treal = tf.float32, name=None) -> Annotated[Any, ~TV_IRFFTND_Treal]\n",
      "        ND inverse real fast Fourier transform.\n",
      "        \n",
      "        Computes the n-dimensional inverse real discrete Fourier transform over\n",
      "        designated dimensions of `input`. The designated dimensions of `input` are\n",
      "        assumed to be the result of `IRFFTND`. The inner-most dimension contains the\n",
      "        `fft_length / 2 + 1` unique components of the DFT of a real-valued signal. \n",
      "        \n",
      "        If fft_length[i]<shape(input)[i], the input is cropped. If\n",
      "        fft_length[i]>shape(input)[i], the input is padded with zeros. If fft_length\n",
      "        is not given, the default shape(input) is used.\n",
      "        \n",
      "        Axes mean the dimensions to perform the transform on. Default is to perform on\n",
      "        all axes.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          fft_length: A `Tensor` of type `int32`.\n",
      "            An int32 tensor. The FFT length for each dimension.\n",
      "          axes: A `Tensor` of type `int32`.\n",
      "            An int32 tensor with a same shape as fft_length. Axes to perform the transform.\n",
      "          Treal: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `Treal`.\n",
      "    \n",
      "    is_finite(x: typing.Annotated[_any, ~TV_IsFinite_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns which elements of x are finite.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isfinite\n",
      "        @end_compatibility\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5.0, 4.8, 6.8, np.inf, np.nan])\n",
      "        tf.math.is_finite(x) ==> [True, True, True, False, False]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_inf(x: typing.Annotated[_any, ~TV_IsInf_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns which elements of x are Inf.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isinf\n",
      "        @end_compatibility\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5.0, np.inf, 6.8, np.inf])\n",
      "        tf.math.is_inf(x) ==> [False, True, False, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_nan(x: typing.Annotated[_any, ~TV_IsNan_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns which elements of x are NaN.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isnan\n",
      "        @end_compatibility\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5.0, np.nan, 6.8, np.nan, np.inf])\n",
      "        tf.math.is_nan(x) ==> [False, True, False, True, False]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_non_decreasing(x, name=None)\n",
      "        Returns `True` if `x` is non-decreasing.\n",
      "        \n",
      "        Elements of `x` are compared in row-major order.  The tensor `[x[0],...]`\n",
      "        is non-decreasing if for every adjacent pair we have `x[i] <= x[i+1]`.\n",
      "        If `x` has less than two elements, it is trivially non-decreasing.\n",
      "        \n",
      "        See also:  `is_strictly_increasing`\n",
      "        \n",
      "        >>> x1 = tf.constant([1.0, 1.0, 3.0])\n",
      "        >>> tf.math.is_non_decreasing(x1)\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "        >>> x2 = tf.constant([3.0, 1.0, 2.0])\n",
      "        >>> tf.math.is_non_decreasing(x2)\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "        \n",
      "        Args:\n",
      "          x: Numeric `Tensor`.\n",
      "          name: A name for this operation (optional).  Defaults to \"is_non_decreasing\"\n",
      "        \n",
      "        Returns:\n",
      "          Boolean `Tensor`, equal to `True` iff `x` is non-decreasing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `x` is not a numeric tensor.\n",
      "    \n",
      "    is_numeric_tensor(tensor)\n",
      "        Returns `True` if the elements of `tensor` are numbers.\n",
      "        \n",
      "        Specifically, returns `True` if the dtype of `tensor` is one of the following:\n",
      "        \n",
      "        * `tf.float16`\n",
      "        * `tf.float32`\n",
      "        * `tf.float64`\n",
      "        * `tf.int8`\n",
      "        * `tf.int16`\n",
      "        * `tf.int32`\n",
      "        * `tf.int64`\n",
      "        * `tf.uint8`\n",
      "        * `tf.uint16`\n",
      "        * `tf.uint32`\n",
      "        * `tf.uint64`\n",
      "        * `tf.qint8`\n",
      "        * `tf.qint16`\n",
      "        * `tf.qint32`\n",
      "        * `tf.quint8`\n",
      "        * `tf.quint16`\n",
      "        * `tf.complex64`\n",
      "        * `tf.complex128`\n",
      "        * `tf.bfloat16`\n",
      "        \n",
      "        Returns `False` if `tensor` is of a non-numeric type or if `tensor` is not\n",
      "        a `tf.Tensor` object.\n",
      "    \n",
      "    is_strictly_increasing(x, name=None)\n",
      "        Returns `True` if `x` is strictly increasing.\n",
      "        \n",
      "        Elements of `x` are compared in row-major order.  The tensor `[x[0],...]`\n",
      "        is strictly increasing if for every adjacent pair we have `x[i] < x[i+1]`.\n",
      "        If `x` has less than two elements, it is trivially strictly increasing.\n",
      "        \n",
      "        See also:  `is_non_decreasing`\n",
      "        \n",
      "        >>> x1 = tf.constant([1.0, 2.0, 3.0])\n",
      "        >>> tf.math.is_strictly_increasing(x1)\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "        >>> x2 = tf.constant([3.0, 1.0, 2.0])\n",
      "        >>> tf.math.is_strictly_increasing(x2)\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "        \n",
      "        Args:\n",
      "          x: Numeric `Tensor`.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"is_strictly_increasing\"\n",
      "        \n",
      "        Returns:\n",
      "          Boolean `Tensor`, equal to `True` iff `x` is strictly increasing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `x` is not a numeric tensor.\n",
      "    \n",
      "    is_symbolic_tensor(tensor) -> bool\n",
      "        Test if `tensor` is a symbolic Tensor.\n",
      "        \n",
      "        Args:\n",
      "          tensor: a tensor-like object\n",
      "        \n",
      "        Returns:\n",
      "          True if `tensor` is a symbolic tensor (not an eager tensor).\n",
      "    \n",
      "    is_tensor = is_tf_type(x)\n",
      "        Checks whether `x` is a TF-native type that can be passed to many TF ops.\n",
      "        \n",
      "        Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\n",
      "        without any conversion (e.g., `tf.Tensor`, `tf.SparseTensor`, and\n",
      "        `tf.RaggedTensor`) from types that need to be converted into tensors before\n",
      "        they are ingested (e.g., numpy `ndarray` and Python scalars).\n",
      "        \n",
      "        For example, in the following code block:\n",
      "        \n",
      "        ```python\n",
      "        if not tf.is_tensor(t):\n",
      "          t = tf.convert_to_tensor(t)\n",
      "        return t.shape, t.dtype\n",
      "        ```\n",
      "        \n",
      "        we check to make sure that `t` is a tensor (and convert it if not) before\n",
      "        accessing its `shape` and `dtype`.  (But note that not all TensorFlow native\n",
      "        types have shapes or dtypes; `tf.data.Dataset` is an example of a TensorFlow\n",
      "        native type that has neither shape nor dtype.)\n",
      "        \n",
      "        Args:\n",
      "          x: A python object to check.\n",
      "        \n",
      "        Returns:\n",
      "          `True` if `x` is a TensorFlow-native type.\n",
      "    \n",
      "    is_variable_initialized(variable)\n",
      "        Tests if a variable has been initialized.\n",
      "        \n",
      "        Args:\n",
      "          variable: A `Variable`.\n",
      "        \n",
      "        Returns:\n",
      "          Returns a scalar boolean Tensor, `True` if the variable has been\n",
      "          initialized, `False` otherwise.\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    lbeta(x, name=None)\n",
      "        Computes \\\\(ln(|Beta(x)|)\\\\), reducing along the last dimension.\n",
      "        \n",
      "        Given one-dimensional $z = [z_1,...,z_K]$, we define\n",
      "        \n",
      "        $$Beta(z) = \\frac{\\prod_j \\Gamma(z_j)}{\\Gamma(\\sum_j z_j)},$$\n",
      "        \n",
      "        where $\\Gamma$ is the gamma function.\n",
      "        \n",
      "        And for $n + 1$ dimensional $x$ with shape $[N_1, ..., N_n, K]$, we define\n",
      "        \n",
      "        $$lbeta(x)[i_1, ..., i_n] = \\log{|Beta(x[i_1, ..., i_n, :])|}.$$\n",
      "        \n",
      "        In other words, the last dimension is treated as the $z$ vector.\n",
      "        \n",
      "        Note that if $z = [u, v]$, then\n",
      "        \n",
      "        $$Beta(z) = \\frac{\\Gamma(u)\\Gamma(v)}{\\Gamma(u + v)}\n",
      "          = \\int_0^1 t^{u-1} (1 - t)^{v-1} \\mathrm{d}t,$$\n",
      "        \n",
      "        which defines the traditional bivariate beta function.\n",
      "        \n",
      "        If the last dimension is empty, we follow the convention that the sum over\n",
      "        the empty set is zero, and the product is one.\n",
      "        \n",
      "        Args:\n",
      "          x: A rank `n + 1` `Tensor`, `n >= 0` with type `float`, or `double`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The logarithm of \\\\(|Beta(x)|\\\\) reducing along the last dimension.\n",
      "    \n",
      "    less(x: typing.Annotated[_any, ~TV_Less_T], y: typing.Annotated[_any, ~TV_Less_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of (x < y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5])\n",
      "        tf.math.less(x, y) ==> [False, True, False]\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5, 6, 7])\n",
      "        tf.math.less(x, y) ==> [False, True, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    less_equal(x: typing.Annotated[_any, ~TV_LessEqual_T], y: typing.Annotated[_any, ~TV_LessEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of (x <= y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5])\n",
      "        tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5, 6, 6])\n",
      "        tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    lgamma(x: typing.Annotated[_any, ~TV_Lgamma_T], name=None) -> typing.Annotated[_any, ~TV_Lgamma_T]\n",
      "        Computes the log of the absolute value of `Gamma(x)` element-wise.\n",
      "        \n",
      "          For positive numbers, this function computes log((input - 1)!) for every element in the tensor.\n",
      "          `lgamma(5) = log((5-1)!) = log(4!) = log(24) = 3.1780539`\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0, 0.5, 1, 4.5, -4, -5.6])\n",
      "        tf.math.lgamma(x) ==> [inf, 0.5723649, 0., 2.4537368, inf, -4.6477685]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    lin_space = linspace_nd(start, stop, num, name=None, axis=0)\n",
      "        Generates evenly-spaced values in an interval along a given axis.\n",
      "        \n",
      "        A sequence of `num` evenly-spaced values are generated beginning at `start`\n",
      "        along a given `axis`.\n",
      "        If `num > 1`, the values in the sequence increase by\n",
      "        `(stop - start) / (num - 1)`, so that the last one is exactly `stop`.\n",
      "        If `num <= 0`, `ValueError` is raised.\n",
      "        \n",
      "        Matches\n",
      "        [np.linspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)'s\n",
      "        behaviour\n",
      "        except when `num == 0`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        tf.linspace(10.0, 12.0, 3, name=\"linspace\") => [ 10.0  11.0  12.0]\n",
      "        ```\n",
      "        \n",
      "        `Start` and `stop` can be tensors of arbitrary size:\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=0)\n",
      "        <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  5.  ],\n",
      "               [ 2.5 , 13.75],\n",
      "               [ 5.  , 22.5 ],\n",
      "               [ 7.5 , 31.25],\n",
      "               [10.  , 40.  ]], dtype=float32)>\n",
      "        \n",
      "        `Axis` is where the values will be generated (the dimension in the\n",
      "        returned tensor which corresponds to the axis will be equal to `num`)\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=-1)\n",
      "        <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  2.5 ,  5.  ,  7.5 , 10.  ],\n",
      "               [ 5.  , 13.75, 22.5 , 31.25, 40.  ]], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          start: A `Tensor`. Must be one of the following types: `bfloat16`,\n",
      "            `float32`, `float64`. N-D tensor. First entry in the range.\n",
      "          stop: A `Tensor`. Must have the same type and shape as `start`. N-D tensor.\n",
      "            Last entry in the range.\n",
      "          num: A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D\n",
      "            tensor. Number of values to generate.\n",
      "          name: A name for the operation (optional).\n",
      "          axis: Axis along which the operation is performed (used only when N-D\n",
      "            tensors are provided).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `start`.\n",
      "    \n",
      "    linspace = linspace_nd(start, stop, num, name=None, axis=0)\n",
      "        Generates evenly-spaced values in an interval along a given axis.\n",
      "        \n",
      "        A sequence of `num` evenly-spaced values are generated beginning at `start`\n",
      "        along a given `axis`.\n",
      "        If `num > 1`, the values in the sequence increase by\n",
      "        `(stop - start) / (num - 1)`, so that the last one is exactly `stop`.\n",
      "        If `num <= 0`, `ValueError` is raised.\n",
      "        \n",
      "        Matches\n",
      "        [np.linspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)'s\n",
      "        behaviour\n",
      "        except when `num == 0`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        tf.linspace(10.0, 12.0, 3, name=\"linspace\") => [ 10.0  11.0  12.0]\n",
      "        ```\n",
      "        \n",
      "        `Start` and `stop` can be tensors of arbitrary size:\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=0)\n",
      "        <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  5.  ],\n",
      "               [ 2.5 , 13.75],\n",
      "               [ 5.  , 22.5 ],\n",
      "               [ 7.5 , 31.25],\n",
      "               [10.  , 40.  ]], dtype=float32)>\n",
      "        \n",
      "        `Axis` is where the values will be generated (the dimension in the\n",
      "        returned tensor which corresponds to the axis will be equal to `num`)\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=-1)\n",
      "        <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  2.5 ,  5.  ,  7.5 , 10.  ],\n",
      "               [ 5.  , 13.75, 22.5 , 31.25, 40.  ]], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          start: A `Tensor`. Must be one of the following types: `bfloat16`,\n",
      "            `float32`, `float64`. N-D tensor. First entry in the range.\n",
      "          stop: A `Tensor`. Must have the same type and shape as `start`. N-D tensor.\n",
      "            Last entry in the range.\n",
      "          num: A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D\n",
      "            tensor. Number of values to generate.\n",
      "          name: A name for the operation (optional).\n",
      "          axis: Axis along which the operation is performed (used only when N-D\n",
      "            tensors are provided).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `start`.\n",
      "    \n",
      "    load_file_system_library(library_filename)\n",
      "        Loads a TensorFlow plugin, containing file system implementation. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.load_library` instead.\n",
      "        \n",
      "        Pass `library_filename` to a platform-specific mechanism for dynamically\n",
      "        loading a library. The rules for determining the exact location of the\n",
      "        library are platform-specific and are not documented here.\n",
      "        \n",
      "        Args:\n",
      "          library_filename: Path to the plugin.\n",
      "            Relative or absolute filesystem path to a dynamic library file.\n",
      "        \n",
      "        Returns:\n",
      "          None.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: when unable to load the library.\n",
      "    \n",
      "    load_library(library_location)\n",
      "        Loads a TensorFlow plugin.\n",
      "        \n",
      "        \"library_location\" can be a path to a specific shared object, or a folder.\n",
      "        If it is a folder, all shared objects that are named \"libtfkernel*\" will be\n",
      "        loaded. When the library is loaded, kernels registered in the library via the\n",
      "        `REGISTER_*` macros are made available in the TensorFlow process.\n",
      "        \n",
      "        Args:\n",
      "          library_location: Path to the plugin or the folder of plugins.\n",
      "            Relative or absolute filesystem path to a dynamic library file or folder.\n",
      "        \n",
      "        Returns:\n",
      "          None\n",
      "        \n",
      "        Raises:\n",
      "          OSError: When the file to be loaded is not found.\n",
      "          RuntimeError: when unable to load the library.\n",
      "    \n",
      "    load_op_library(library_filename)\n",
      "        Loads a TensorFlow plugin, containing custom ops and kernels.\n",
      "        \n",
      "        Pass \"library_filename\" to a platform-specific mechanism for dynamically\n",
      "        loading a library. The rules for determining the exact location of the\n",
      "        library are platform-specific and are not documented here. When the\n",
      "        library is loaded, ops and kernels registered in the library via the\n",
      "        `REGISTER_*` macros are made available in the TensorFlow process. Note\n",
      "        that ops with the same name as an existing op are rejected and not\n",
      "        registered with the process.\n",
      "        \n",
      "        Args:\n",
      "          library_filename: Path to the plugin.\n",
      "            Relative or absolute filesystem path to a dynamic library file.\n",
      "        \n",
      "        Returns:\n",
      "          A python module containing the Python wrappers for Ops defined in\n",
      "          the plugin.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: when unable to load the library or get the python wrappers.\n",
      "    \n",
      "    local_variables(scope=None)\n",
      "        Returns local variables.\n",
      "        \n",
      "        Local variables - per process variables, usually not saved/restored to\n",
      "        checkpoint and used for temporary or intermediate values.\n",
      "        For example, they can be used as counters for metrics computation or\n",
      "        number of epochs this machine has read data.\n",
      "        The `tf.contrib.framework.local_variable()` function automatically adds the\n",
      "        new variable to `GraphKeys.LOCAL_VARIABLES`.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        An alternative to local variables are global variables. See\n",
      "        `tf.compat.v1.global_variables`\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of local `Variable` objects.\n",
      "    \n",
      "    local_variables_initializer()\n",
      "        Returns an Op that initializes all local variables.\n",
      "        \n",
      "        This is just a shortcut for `variables_initializer(local_variables())`\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        In TF2, variables are initialized immediately when they are created. There is\n",
      "        no longer a need to run variable initializers before using them.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all local variables in the graph.\n",
      "    \n",
      "    log(x: typing.Annotated[_any, ~TV_Log_T], name=None) -> typing.Annotated[_any, ~TV_Log_T]\n",
      "        Computes natural logarithm of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = \\log_e x\\\\).\n",
      "        \n",
      "        Example:\n",
      "        >>> x = tf.constant([0, 0.5, 1, 5])\n",
      "        >>> tf.math.log(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([      -inf, -0.6931472,  0.       ,  1.609438 ], dtype=float32)>\n",
      "        \n",
      "        See: https://en.wikipedia.org/wiki/Logarithm\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    log1p(x: typing.Annotated[_any, ~TV_Log1p_T], name=None) -> typing.Annotated[_any, ~TV_Log1p_T]\n",
      "        Computes natural logarithm of (1 + x) element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = \\log_e (1 + x)\\\\).\n",
      "        \n",
      "        Example:\n",
      "        >>> x = tf.constant([0, 0.5, 1, 5])\n",
      "        >>> tf.math.log1p(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.       , 0.4054651, 0.6931472, 1.7917595], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    log_sigmoid(x, name=None)\n",
      "        Computes log sigmoid of `x` element-wise.\n",
      "        \n",
      "        Specifically, `y = log(1 / (1 + exp(-x)))`.  For numerical stability,\n",
      "        we use `y = -tf.nn.softplus(-x)`.\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor with type `float32` or `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor with the same type as `x`.\n",
      "        \n",
      "        Usage Example:\n",
      "        \n",
      "        If a positive number is large, then its log_sigmoid will approach to 0 since\n",
      "        the formula will be `y = log( <large_num> / (1 + <large_num>) )` which\n",
      "        approximates to `log (1)` which is 0.\n",
      "        \n",
      "        >>> x = tf.constant([0.0, 1.0, 50.0, 100.0])\n",
      "        >>> tf.math.log_sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
      "        array([-6.9314718e-01, -3.1326169e-01, -1.9287499e-22, -0.0000000e+00],\n",
      "              dtype=float32)>\n",
      "        \n",
      "        If a negative number is large, its log_sigmoid will approach to the number\n",
      "        itself since the formula will be `y = log( 1 / (1 + <large_num>) )` which is\n",
      "        `log (1) - log ( (1 + <large_num>) )` which approximates to `- <large_num>`\n",
      "        that is the number itself.\n",
      "        \n",
      "        >>> x = tf.constant([-100.0, -50.0, -1.0, 0.0])\n",
      "        >>> tf.math.log_sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
      "        array([-100.       ,  -50.       ,   -1.3132616,   -0.6931472],\n",
      "              dtype=float32)>\n",
      "    \n",
      "    logical_and(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], y: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of x AND y element-wise.\n",
      "        \n",
      "        Logical AND function.\n",
      "        \n",
      "        Requires that `x` and `y` have the same shape or have\n",
      "        [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        shapes. For example, `x` and `y` can be:\n",
      "        \n",
      "          - Two single elements of type `bool`.\n",
      "          - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "            be calculated by applying logical AND with the single element to each\n",
      "            element in the larger Tensor.\n",
      "          - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "            the result will be the element-wise logical AND of the two input tensors.\n",
      "        \n",
      "        You can also use the `&` operator instead.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "          >>> a = tf.constant([True])\n",
      "          >>> b = tf.constant([False])\n",
      "          >>> tf.math.logical_and(a, b)\n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>\n",
      "          >>> a & b\n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>\n",
      "        \n",
      "          >>> c = tf.constant([True])\n",
      "          >>> x = tf.constant([False, True, True, False])\n",
      "          >>> tf.math.logical_and(c, x)\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "          >>> c & x\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "        \n",
      "          >>> y = tf.constant([False, False, True, True])\n",
      "          >>> z = tf.constant([False, True, False, True])\n",
      "          >>> tf.math.logical_and(y, z)\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])>\n",
      "          >>> y & z\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])>\n",
      "        \n",
      "          This op also supports broadcasting\n",
      "        \n",
      "          >>> tf.logical_and([[True, False]], [[True], [False]])\n",
      "          <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "            array([[ True, False],\n",
      "                   [False, False]])>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_all`.\n",
      "        \n",
      "        Args:\n",
      "            x: A `tf.Tensor` of type bool.\n",
      "            y: A `tf.Tensor` of type bool.\n",
      "            name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          y: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_not(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of `NOT x` element-wise.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> tf.math.logical_not(tf.constant([True, False]))\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`. A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_or(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], y: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of x OR y element-wise.\n",
      "        \n",
      "        Logical OR function.\n",
      "        \n",
      "        Requires that `x` and `y` have the same shape or have\n",
      "        [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        shapes. For example, `x` and `y` can be:\n",
      "        \n",
      "        - Two single elements of type `bool`.\n",
      "        - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "          be calculated by applying logical OR with the single element to each\n",
      "          element in the larger Tensor.\n",
      "        - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "          the result will be the element-wise logical OR of the two input tensors.\n",
      "        \n",
      "        You can also use the `|` operator instead.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "          >>> a = tf.constant([True])\n",
      "          >>> b = tf.constant([False])\n",
      "          >>> tf.math.logical_or(a, b)\n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "          >>> a | b\n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "        \n",
      "          >>> c = tf.constant([False])\n",
      "          >>> x = tf.constant([False, True, True, False])\n",
      "          >>> tf.math.logical_or(c, x)\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "          >>> c | x\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "        \n",
      "          >>> y = tf.constant([False, False, True, True])\n",
      "          >>> z = tf.constant([False, True, False, True])\n",
      "          >>> tf.math.logical_or(y, z)\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "          >>> y | z\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "        \n",
      "          This op also supports broadcasting\n",
      "        \n",
      "          >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "          <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "          array([[ True,  True],\n",
      "               [ True, False]])>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "        \n",
      "        Args:\n",
      "            x: A `tf.Tensor` of type bool.\n",
      "            y: A `tf.Tensor` of type bool.\n",
      "            name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          y: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_xor(x, y, name='LogicalXor')\n",
      "        Logical XOR function.\n",
      "        \n",
      "        x ^ y = (x | y) & ~(x & y)\n",
      "        \n",
      "        Requires that `x` and `y` have the same shape or have\n",
      "        [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        shapes. For example, `x` and `y` can be:\n",
      "        \n",
      "        - Two single elements of type `bool`\n",
      "        - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "          be calculated by applying logical XOR with the single element to each\n",
      "          element in the larger Tensor.\n",
      "        - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "          the result will be the element-wise logical XOR of the two input tensors.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        >>> a = tf.constant([True])\n",
      "        >>> b = tf.constant([False])\n",
      "        >>> tf.math.logical_xor(a, b)\n",
      "        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "        \n",
      "        >>> c = tf.constant([True])\n",
      "        >>> x = tf.constant([False, True, True, False])\n",
      "        >>> tf.math.logical_xor(c, x)\n",
      "        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>\n",
      "        \n",
      "        >>> y = tf.constant([False, False, True, True])\n",
      "        >>> z = tf.constant([False, True, False, True])\n",
      "        >>> tf.math.logical_xor(y, z)\n",
      "        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "        \n",
      "        Args:\n",
      "            x: A `tf.Tensor` type bool.\n",
      "            y: A `tf.Tensor` of type bool.\n",
      "            name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "    \n",
      "    make_ndarray = MakeNdarray(tensor)\n",
      "        Create a numpy ndarray from a tensor.\n",
      "        \n",
      "        Create a numpy ndarray with the same shape and data as the tensor.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Tensor a has shape (2,3)\n",
      "        a = tf.constant([[1,2,3],[4,5,6]])\n",
      "        proto_tensor = tf.make_tensor_proto(a)  # convert `tensor a` to a proto tensor\n",
      "        tf.make_ndarray(proto_tensor) # output: array([[1, 2, 3],\n",
      "        #                                              [4, 5, 6]], dtype=int32)\n",
      "        # output has shape (2,3)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A TensorProto.\n",
      "        \n",
      "        Returns:\n",
      "          A numpy array with the tensor contents.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if tensor has unsupported type.\n",
      "    \n",
      "    make_template(name_, func_, create_scope_now_=False, unique_name_=None, custom_getter_=None, **kwargs)\n",
      "        Given an arbitrary function, wrap it so that it does variable sharing.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.make_template` is a legacy API that is only compatible\n",
      "        with eager execution enabled and `tf.function` if you combine it with\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables`. See the model mapping\n",
      "        migration guide section on `make_template` for more info:\n",
      "        \n",
      "        https://www.tensorflow.org/guide/migrate/model_mapping#using_tfcompatv1make_template_in_the_decorated_method\n",
      "        \n",
      "        Even if you use legacy apis for `variable_scope`-based variable reuse,\n",
      "        we recommend using\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables` directly and not using\n",
      "        `tf.compat.v1.make_template`, as it interoperates with eager execution in a\n",
      "        simpler and more predictable fashion than `make_template`.\n",
      "        \n",
      "        The TF2 API approach would be tracking your variables using\n",
      "        `tf.Module`s or Keras layers and models rather than relying on\n",
      "        `make_template`.\n",
      "        @end_compatibility\n",
      "        \n",
      "        This wraps `func_` in a Template and partially evaluates it. Templates are\n",
      "        functions that create variables the first time they are called and reuse them\n",
      "        thereafter. In order for `func_` to be compatible with a `Template` it must\n",
      "        have the following properties:\n",
      "        \n",
      "        * The function should create all trainable variables and any variables that\n",
      "           should be reused by calling `tf.compat.v1.get_variable`. If a trainable\n",
      "           variable is\n",
      "           created using `tf.Variable`, then a ValueError will be thrown. Variables\n",
      "           that are intended to be locals can be created by specifying\n",
      "           `tf.Variable(..., trainable=false)`.\n",
      "        * The function may use variable scopes and other templates internally to\n",
      "            create and reuse variables, but it shouldn't use\n",
      "            `tf.compat.v1.global_variables` to\n",
      "            capture variables that are defined outside of the scope of the function.\n",
      "        * Internal scopes and variable names should not depend on any arguments that\n",
      "            are not supplied to `make_template`. In general you will get a ValueError\n",
      "            telling you that you are trying to reuse a variable that doesn't exist\n",
      "            if you make a mistake.\n",
      "        \n",
      "        In the following example, both `z` and `w` will be scaled by the same `y`. It\n",
      "        is important to note that if we didn't assign `scalar_name` and used a\n",
      "        different name for z and w that a `ValueError` would be thrown because it\n",
      "        couldn't reuse the variable.\n",
      "        \n",
      "        ```python\n",
      "        def my_op(x, scalar_name):\n",
      "          var1 = tf.compat.v1.get_variable(scalar_name,\n",
      "                                 shape=[],\n",
      "                                 initializer=tf.compat.v1.constant_initializer(1))\n",
      "          return x * var1\n",
      "        \n",
      "        scale_by_y = tf.compat.v1.make_template('scale_by_y', my_op, scalar_name='y')\n",
      "        \n",
      "        z = scale_by_y(input1)\n",
      "        w = scale_by_y(input2)\n",
      "        ```\n",
      "        \n",
      "        As a safe-guard, the returned function will raise a `ValueError` after the\n",
      "        first call if trainable variables are created by calling `tf.Variable`.\n",
      "        \n",
      "        If all of these are true, then 2 properties are enforced by the template:\n",
      "        \n",
      "        1. Calling the same template multiple times will share all non-local\n",
      "            variables.\n",
      "        2. Two different templates are guaranteed to be unique, unless you reenter the\n",
      "            same variable scope as the initial definition of a template and redefine\n",
      "            it. An examples of this exception:\n",
      "        \n",
      "        ```python\n",
      "        def my_op(x, scalar_name):\n",
      "          var1 = tf.compat.v1.get_variable(scalar_name,\n",
      "                                 shape=[],\n",
      "                                 initializer=tf.compat.v1.constant_initializer(1))\n",
      "          return x * var1\n",
      "        \n",
      "        with tf.compat.v1.variable_scope('scope') as vs:\n",
      "          scale_by_y = tf.compat.v1.make_template('scale_by_y', my_op,\n",
      "          scalar_name='y')\n",
      "          z = scale_by_y(input1)\n",
      "          w = scale_by_y(input2)\n",
      "        \n",
      "        # Creates a template that reuses the variables above.\n",
      "        with tf.compat.v1.variable_scope(vs, reuse=True):\n",
      "          scale_by_y2 = tf.compat.v1.make_template('scale_by_y', my_op,\n",
      "          scalar_name='y')\n",
      "          z2 = scale_by_y2(input1)\n",
      "          w2 = scale_by_y2(input2)\n",
      "        ```\n",
      "        \n",
      "        Depending on the value of `create_scope_now_`, the full variable scope may be\n",
      "        captured either at the time of first call or at the time of construction. If\n",
      "        this option is set to True, then all Tensors created by repeated calls to the\n",
      "        template will have an extra trailing _N+1 to their name, as the first time the\n",
      "        scope is entered in the Template constructor no Tensors are created.\n",
      "        \n",
      "        Note: `name_`, `func_` and `create_scope_now_` have a trailing underscore to\n",
      "        reduce the likelihood of collisions with kwargs.\n",
      "        \n",
      "        Args:\n",
      "          name_: A name for the scope created by this template. If necessary, the name\n",
      "            will be made unique by appending `_N` to the name.\n",
      "          func_: The function to wrap.\n",
      "          create_scope_now_: Boolean controlling whether the scope should be created\n",
      "            when the template is constructed or when the template is called. Default\n",
      "            is False, meaning the scope is created when the template is called.\n",
      "          unique_name_: When used, it overrides name_ and is not made unique. If a\n",
      "            template of the same scope/unique_name already exists and reuse is false,\n",
      "            an error is raised. Defaults to None.\n",
      "          custom_getter_: Optional custom getter for variables used in `func_`. See\n",
      "            the `tf.compat.v1.get_variable` `custom_getter` documentation for more\n",
      "            information.\n",
      "          **kwargs: Keyword arguments to apply to `func_`.\n",
      "        \n",
      "        Returns:\n",
      "          A function to encapsulate a set of variables which should be created once\n",
      "          and reused. An enclosing scope will be created either when `make_template`\n",
      "          is called or when the result is called, depending on the value of\n",
      "          `create_scope_now_`. Regardless of the value, the first time the template\n",
      "          is called it will enter the scope with no reuse, and call `func_` to create\n",
      "          variables, which are guaranteed to be unique. All subsequent calls will\n",
      "          re-enter the scope and reuse those variables.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if `name_` is None.\n",
      "    \n",
      "    make_tensor_proto(values, dtype=None, shape=None, verify_shape=False, allow_broadcast=False)\n",
      "        Create a TensorProto.\n",
      "        \n",
      "        In TensorFlow 2.0, representing tensors as protos should no longer be a\n",
      "        common workflow. That said, this utility function is still useful for\n",
      "        generating TF Serving request protos:\n",
      "        \n",
      "        ```python\n",
      "          request = tensorflow_serving.apis.predict_pb2.PredictRequest()\n",
      "          request.model_spec.name = \"my_model\"\n",
      "          request.model_spec.signature_name = \"serving_default\"\n",
      "          request.inputs[\"images\"].CopyFrom(tf.make_tensor_proto(X_new))\n",
      "        ```\n",
      "        \n",
      "        `make_tensor_proto` accepts \"values\" of a python scalar, a python list, a\n",
      "        numpy ndarray, or a numpy scalar.\n",
      "        \n",
      "        If \"values\" is a python scalar or a python list, make_tensor_proto\n",
      "        first convert it to numpy ndarray. If dtype is None, the\n",
      "        conversion tries its best to infer the right numpy data\n",
      "        type. Otherwise, the resulting numpy array has a compatible data\n",
      "        type with the given dtype.\n",
      "        \n",
      "        In either case above, the numpy ndarray (either the caller provided\n",
      "        or the auto-converted) must have the compatible type with dtype.\n",
      "        \n",
      "        `make_tensor_proto` then converts the numpy array to a tensor proto.\n",
      "        \n",
      "        If \"shape\" is None, the resulting tensor proto represents the numpy\n",
      "        array precisely.\n",
      "        \n",
      "        Otherwise, \"shape\" specifies the tensor's shape and the numpy array\n",
      "        can not have more elements than what \"shape\" specifies.\n",
      "        \n",
      "        Args:\n",
      "          values:         Values to put in the TensorProto.\n",
      "          dtype:          Optional tensor_pb2 DataType value.\n",
      "          shape:          List of integers representing the dimensions of tensor.\n",
      "          verify_shape:   Boolean that enables verification of a shape of values.\n",
      "          allow_broadcast:  Boolean that enables allowing scalars and 1 length vector\n",
      "              broadcasting. Cannot be true when verify_shape is true.\n",
      "        \n",
      "        Returns:\n",
      "          A `TensorProto`. Depending on the type, it may contain data in the\n",
      "          \"tensor_content\" attribute, which is not directly useful to Python programs.\n",
      "          To access the values you should convert the proto back to a numpy ndarray\n",
      "          with `tf.make_ndarray(proto)`.\n",
      "        \n",
      "          If `values` is a `TensorProto`, it is immediately returned; `dtype` and\n",
      "          `shape` are ignored.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  if unsupported types are provided.\n",
      "          ValueError: if arguments have inappropriate values or if verify_shape is\n",
      "           True and shape of values is not equals to a shape from the argument.\n",
      "    \n",
      "    map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None, fn_output_signature=None)\n",
      "        Transforms `elems` by applying `fn` to each element unstacked on axis 0. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use fn_output_signature instead\n",
      "        \n",
      "        See also `tf.scan`.\n",
      "        \n",
      "        `map_fn` unstacks `elems` on axis 0 to obtain a sequence of elements;\n",
      "        calls `fn` to transform each element; and then stacks the transformed\n",
      "        values back together.\n",
      "        \n",
      "        #### Mapping functions with single-Tensor inputs and outputs\n",
      "        \n",
      "        If `elems` is a single tensor and `fn`'s signature is `tf.Tensor->tf.Tensor`,\n",
      "        then `map_fn(fn, elems)` is equivalent to\n",
      "        `tf.stack([fn(elem) for elem in tf.unstack(elems)])`.  E.g.:\n",
      "        \n",
      "        >>> tf.map_fn(fn=lambda t: tf.range(t, t + 3), elems=tf.constant([3, 5, 2]))\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        `map_fn(fn, elems).shape = [elems.shape[0]] + fn(elems[0]).shape`.\n",
      "        \n",
      "        #### Mapping functions with multi-arity inputs and outputs\n",
      "        \n",
      "        `map_fn` also supports functions with multi-arity inputs and outputs:\n",
      "        \n",
      "        * If `elems` is a tuple (or nested structure) of tensors, then those tensors\n",
      "          must all have the same outer-dimension size (`num_elems`); and `fn` is\n",
      "          used to transform each tuple (or structure) of corresponding slices from\n",
      "          `elems`.  E.g., if `elems` is a tuple `(t1, t2, t3)`, then `fn` is used to\n",
      "          transform each tuple of slices `(t1[i], t2[i], t3[i])`\n",
      "          (where `0 <= i < num_elems`).\n",
      "        \n",
      "        * If `fn` returns a tuple (or nested structure) of tensors, then the\n",
      "          result is formed by stacking corresponding elements from those structures.\n",
      "        \n",
      "        #### Specifying `fn`'s output signature\n",
      "        \n",
      "        If `fn`'s input and output signatures are different, then the output\n",
      "        signature must be specified using `fn_output_signature`.  (The input and\n",
      "        output signatures are differ if their structures, dtypes, or tensor types do\n",
      "        not match).  E.g.:\n",
      "        \n",
      "        >>> tf.map_fn(fn=tf.strings.length,  # input & output have different dtypes\n",
      "        ...           elems=tf.constant([\"hello\", \"moon\"]),\n",
      "        ...           fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 4], dtype=int32)>\n",
      "        >>> tf.map_fn(fn=tf.strings.join,  # input & output have different structures\n",
      "        ...           elems=[tf.constant(['The', 'A']), tf.constant(['Dog', 'Cat'])],\n",
      "        ...           fn_output_signature=tf.string)\n",
      "        <tf.Tensor: shape=(2,), dtype=string,\n",
      "         numpy=array([b'TheDog', b'ACat'], dtype=object)>\n",
      "        \n",
      "        `fn_output_signature` can be specified using any of the following:\n",
      "        \n",
      "        * A `tf.DType` or `tf.TensorSpec` (to describe a `tf.Tensor`)\n",
      "        * A `tf.RaggedTensorSpec` (to describe a `tf.RaggedTensor`)\n",
      "        * A `tf.SparseTensorSpec` (to describe a `tf.sparse.SparseTensor`)\n",
      "        * A (possibly nested) tuple, list, or dict containing the above types.\n",
      "        \n",
      "        #### RaggedTensors\n",
      "        \n",
      "        `map_fn` supports `tf.RaggedTensor` inputs and outputs.  In particular:\n",
      "        \n",
      "        * If `elems` is a `RaggedTensor`, then `fn` will be called with each\n",
      "          row of that ragged tensor.\n",
      "          * If `elems` has only one ragged dimension, then the values passed to\n",
      "            `fn` will be `tf.Tensor`s.\n",
      "          * If `elems` has multiple ragged dimensions, then the values passed to\n",
      "            `fn` will be `tf.RaggedTensor`s with one fewer ragged dimension.\n",
      "        \n",
      "        * If the result of `map_fn` should be a `RaggedTensor`, then use a\n",
      "          `tf.RaggedTensorSpec` to specify `fn_output_signature`.\n",
      "          * If `fn` returns `tf.Tensor`s with varying sizes, then use a\n",
      "            `tf.RaggedTensorSpec` with `ragged_rank=0` to combine them into a\n",
      "            single ragged tensor (which will have ragged_rank=1).\n",
      "          * If `fn` returns `tf.RaggedTensor`s, then use a `tf.RaggedTensorSpec`\n",
      "            with the same `ragged_rank`.\n",
      "        \n",
      "        >>> # Example: RaggedTensor input\n",
      "        >>> rt = tf.ragged.constant([[1, 2, 3], [], [4, 5], [6]])\n",
      "        >>> tf.map_fn(tf.reduce_sum, rt, fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([6, 0, 9, 6], dtype=int32)>\n",
      "        \n",
      "        >>> # Example: RaggedTensor output\n",
      "        >>> elems = tf.constant([3, 5, 0, 2])\n",
      "        >>> tf.map_fn(tf.range, elems,\n",
      "        ...           fn_output_signature=tf.RaggedTensorSpec(shape=[None],\n",
      "        ...                                                   dtype=tf.int32))\n",
      "        <tf.RaggedTensor [[0, 1, 2], [0, 1, 2, 3, 4], [], [0, 1]]>\n",
      "        \n",
      "        Note: `map_fn` should only be used if you need to map a function over the\n",
      "        *rows* of a `RaggedTensor`.  If you wish to map a function over the\n",
      "        individual values, then you should use:\n",
      "        \n",
      "        * `tf.ragged.map_flat_values(fn, rt)`\n",
      "          (if fn is expressible as TensorFlow ops)\n",
      "        * `rt.with_flat_values(map_fn(fn, rt.flat_values))`\n",
      "          (otherwise)\n",
      "        \n",
      "        E.g.:\n",
      "        \n",
      "        >>> rt = tf.ragged.constant([[1, 2, 3], [], [4, 5], [6]])\n",
      "        >>> tf.ragged.map_flat_values(lambda x: x + 2, rt)\n",
      "        <tf.RaggedTensor [[3, 4, 5], [], [6, 7], [8]]>\n",
      "        \n",
      "        #### SparseTensors\n",
      "        \n",
      "        `map_fn` supports `tf.sparse.SparseTensor` inputs and outputs.  In particular:\n",
      "        \n",
      "        * If `elems` is a `SparseTensor`, then `fn` will be called with each row\n",
      "          of that sparse tensor. In particular, the value passed to `fn` will be a\n",
      "          `tf.sparse.SparseTensor` with one fewer dimension than `elems`.\n",
      "        \n",
      "        * If the result of `map_fn` should be a `SparseTensor`, then use a\n",
      "          `tf.SparseTensorSpec` to specify `fn_output_signature`.  The individual\n",
      "          `SparseTensor`s returned by `fn` will be stacked into a single\n",
      "          `SparseTensor` with one more dimension.\n",
      "        \n",
      "        >>> # Example: SparseTensor input\n",
      "        >>> st = tf.sparse.SparseTensor([[0, 0], [2, 0], [2, 1]], [2, 3, 4], [4, 4])\n",
      "        >>> tf.map_fn(tf.sparse.reduce_sum, st, fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([2, 0, 7, 0], dtype=int32)>\n",
      "        \n",
      "        >>> # Example: SparseTensor output\n",
      "        >>> tf.sparse.to_dense(\n",
      "        ...     tf.map_fn(tf.sparse.eye, tf.constant([2, 3]),\n",
      "        ...               fn_output_signature=tf.SparseTensorSpec(None, tf.float32)))\n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
      "          array([[[1., 0., 0.],\n",
      "                  [0., 1., 0.],\n",
      "                  [0., 0., 0.]],\n",
      "                 [[1., 0., 0.],\n",
      "                  [0., 1., 0.],\n",
      "                  [0., 0., 1.]]], dtype=float32)>\n",
      "        \n",
      "        Note: `map_fn` should only be used if you need to map a function over the\n",
      "        *rows* of a `SparseTensor`.  If you wish to map a function over the nonzero\n",
      "        values, then you should use:\n",
      "        \n",
      "        * If the function is expressible as TensorFlow ops, use:\n",
      "          ```python\n",
      "          tf.sparse.SparseTensor(st.indices, fn(st.values), st.dense_shape)\n",
      "          ```\n",
      "        * Otherwise, use:\n",
      "          ```python\n",
      "          tf.sparse.SparseTensor(st.indices, tf.map_fn(fn, st.values),\n",
      "                                 st.dense_shape)\n",
      "          ```\n",
      "        \n",
      "        #### `map_fn` vs. vectorized operations\n",
      "        \n",
      "        `map_fn` will apply the operations used by `fn` to each element of `elems`,\n",
      "        resulting in `O(elems.shape[0])` total operations.  This is somewhat\n",
      "        mitigated by the fact that `map_fn` can process elements in parallel.\n",
      "        However, a transform expressed using `map_fn` is still typically less\n",
      "        efficient than an equivalent transform expressed using vectorized operations.\n",
      "        \n",
      "        `map_fn` should typically only be used if one of the following is true:\n",
      "        \n",
      "        * It is difficult or expensive to express the desired transform with\n",
      "          vectorized operations.\n",
      "        * `fn` creates large intermediate values, so an equivalent vectorized\n",
      "          transform would take too much memory.\n",
      "        * Processing elements in parallel is more efficient than an equivalent\n",
      "          vectorized transform.\n",
      "        * Efficiency of the transform is not critical, and using `map_fn` is\n",
      "          more readable.\n",
      "        \n",
      "        E.g., the example given above that maps `fn=lambda t: tf.range(t, t + 3)`\n",
      "        across `elems` could be rewritten more efficiently using vectorized ops:\n",
      "        \n",
      "        >>> elems = tf.constant([3, 5, 2])\n",
      "        >>> tf.range(3) + tf.expand_dims(elems, 1)\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        In some cases, `tf.vectorized_map` can be used to automatically convert a\n",
      "        function to a vectorized equivalent.\n",
      "        \n",
      "        #### Eager execution\n",
      "        \n",
      "        When executing eagerly, `map_fn` does not execute in parallel even if\n",
      "        `parallel_iterations` is set to a value > 1. You can still get the\n",
      "        performance benefits of running a function in parallel by using the\n",
      "        `tf.function` decorator:\n",
      "        \n",
      "        >>> fn=lambda t: tf.range(t, t + 3)\n",
      "        >>> @tf.function\n",
      "        ... def func(elems):\n",
      "        ...   return tf.map_fn(fn, elems, parallel_iterations=3)\n",
      "        >>> func(tf.constant([3, 5, 2]))\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        \n",
      "        Note: if you use the `tf.function` decorator, any non-TensorFlow Python\n",
      "        code that you may have written in your function won't get executed. See\n",
      "        `tf.function` for more  details. The recommendation would be to debug without\n",
      "        `tf.function` but switch to it to get performance benefits of running `map_fn`\n",
      "        in parallel.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.  It accepts one argument, which will have\n",
      "            the same (possibly nested) structure as `elems`.  Its output must have the\n",
      "            same structure as `fn_output_signature` if one is provided; otherwise it\n",
      "            must have the same structure as `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unstacked along their first dimension.  `fn` will be applied to the\n",
      "            nested sequence of the resulting slices.  `elems` may include ragged and\n",
      "            sparse tensors. `elems` must consist of at least one tensor.\n",
      "          dtype: Deprecated: Equivalent to `fn_output_signature`.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel. When graph building, the default value is 10. While executing\n",
      "            eagerly, the default value is set to 1.\n",
      "          back_prop: (optional) False disables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "          fn_output_signature: The output signature of `fn`. Must be specified if\n",
      "            `fn`'s input and output signatures are different (i.e., if their\n",
      "            structures, dtypes, or tensor types do not match).\n",
      "            `fn_output_signature` can be specified using any of the following:\n",
      "        \n",
      "            * A `tf.DType` or `tf.TensorSpec` (to describe a `tf.Tensor`)\n",
      "            * A `tf.RaggedTensorSpec` (to describe a `tf.RaggedTensor`)\n",
      "            * A `tf.SparseTensorSpec` (to describe a `tf.sparse.SparseTensor`)\n",
      "            * A (possibly nested) tuple, list, or dict containing the above types.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors.  Each tensor stacks the\n",
      "          results of applying `fn` to tensors unstacked from `elems` along the first\n",
      "          dimension, from first to last.  The result may include ragged and sparse\n",
      "          tensors.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable or the structure of the output of\n",
      "            `fn` and `fn_output_signature` do not match.\n",
      "          ValueError: if the lengths of the output of `fn` and `fn_output_signature`\n",
      "            do not match, or if the `elems` does not contain any tensor.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          >>> tf.map_fn(lambda x: x * x, elems)\n",
      "          <tf.Tensor: shape=(6,), dtype=int64, numpy=array([ 1,  4,  9, 16, 25, 36])>\n",
      "        \n",
      "          >>> elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\n",
      "          >>> tf.map_fn(lambda x: x[0] * x[1], elems, fn_output_signature=tf.int64)\n",
      "          <tf.Tensor: shape=(3,), dtype=int64, numpy=array([-1,  2, -3])>\n",
      "        \n",
      "          >>> elems = np.array([1, 2, 3])\n",
      "          >>> tf.map_fn(lambda x: (x, -x), elems,\n",
      "          ...          fn_output_signature=(tf.int64, tf.int64))\n",
      "          (<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])>,\n",
      "           <tf.Tensor: shape=(3,), dtype=int64, numpy=array([-1, -2, -3])>)\n",
      "    \n",
      "    matching_files(pattern: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Returns the set of files matching one or more glob patterns.\n",
      "        \n",
      "        Note that this routine only supports wildcard characters in the\n",
      "        basename portion of the pattern, not in the directory portion.\n",
      "        Note also that the order of filenames returned is deterministic.\n",
      "        \n",
      "        Args:\n",
      "          pattern: A `Tensor` of type `string`.\n",
      "            Shell wildcard pattern(s). Scalar or vector of type string.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    matmul(a, b, transpose_a=False, transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False, output_type=None, grad_a=False, grad_b=False, name=None)\n",
      "        Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "        \n",
      "        The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "        where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
      "        and any further outer dimensions specify matching batch size.\n",
      "        \n",
      "        Both matrices must be of the same type. The supported types are:\n",
      "        `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "        `complex64`, `complex128`.\n",
      "        \n",
      "        Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "        the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "        by default.\n",
      "        \n",
      "        If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "        multiplication algorithm can be used by setting the corresponding\n",
      "        `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "        This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "        datatypes `bfloat16` or `float32`.\n",
      "        \n",
      "        A simple 2-D tensor matrix multiplication:\n",
      "        \n",
      "        >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "        >>> a  # 2-D tensor\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[1, 2, 3],\n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "        >>> b  # 2-D tensor\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "        array([[ 7,  8],\n",
      "               [ 9, 10],\n",
      "               [11, 12]], dtype=int32)>\n",
      "        >>> c = tf.matmul(a, b)\n",
      "        >>> c  # `a` * `b`\n",
      "        <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "        array([[ 58,  64],\n",
      "               [139, 154]], dtype=int32)>\n",
      "        \n",
      "        A batch matrix multiplication with batch shape [2]:\n",
      "        \n",
      "        >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
      "        >>> a  # 3-D tensor\n",
      "        <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
      "        array([[[ 1,  2,  3],\n",
      "                [ 4,  5,  6]],\n",
      "               [[ 7,  8,  9],\n",
      "                [10, 11, 12]]], dtype=int32)>\n",
      "        >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
      "        >>> b  # 3-D tensor\n",
      "        <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "        array([[[13, 14],\n",
      "                [15, 16],\n",
      "                [17, 18]],\n",
      "               [[19, 20],\n",
      "                [21, 22],\n",
      "                [23, 24]]], dtype=int32)>\n",
      "        >>> c = tf.matmul(a, b)\n",
      "        >>> c  # `a` * `b`\n",
      "        <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "        array([[[ 94, 100],\n",
      "                [229, 244]],\n",
      "               [[508, 532],\n",
      "                [697, 730]]], dtype=int32)>\n",
      "        \n",
      "        Since python >= 3.5 the @ operator is supported\n",
      "        (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
      "        it simply calls the `tf.matmul()` function, so the following lines are\n",
      "        equivalent:\n",
      "        \n",
      "        >>> d = a @ b @ [[10], [11]]\n",
      "        >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
      "        \n",
      "        Args:\n",
      "          a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
      "            `complex64`, `complex128` and rank > 1.\n",
      "          b: `tf.Tensor` with same type and rank as `a`.\n",
      "          transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "          transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "          adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "            multiplication.\n",
      "          adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "            multiplication.\n",
      "          a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
      "            **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "            that assume most values in `a` are zero. See\n",
      "            `tf.sparse.sparse_dense_matmul` for some support for\n",
      "            `tf.sparse.SparseTensor` multiplication.\n",
      "          b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
      "            **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "            that assume most values in `b` are zero. See\n",
      "            `tf.sparse.sparse_dense_matmul` for some support for\n",
      "            `tf.sparse.SparseTensor` multiplication.\n",
      "          output_type: The output datatype if needed. Defaults to None in which case\n",
      "            the output_type is the same as input type. Currently only works when input\n",
      "            tensors are type (u)int8 and output_type can be int32.\n",
      "          grad_a: Set it to `True` to hint that Tensor `a` is for the backward pass.\n",
      "          grad_b: Set it to `True` to hint that Tensor `b` is for the backward pass.\n",
      "          name: Name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
      "          is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "          transpose or adjoint attributes are `False`:\n",
      "        \n",
      "          `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
      "          for all indices `i`, `j`.\n",
      "        \n",
      "          Note: This is matrix product, not element-wise product.\n",
      "        \n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
      "            `adjoint_b` are both set to `True`.\n",
      "          TypeError: If output_type is specified but the types of `a`, `b` and\n",
      "            `output_type` is not (u)int8, (u)int8 and int32.\n",
      "    \n",
      "    matrix_band_part(input: Annotated[Any, ~TV_MatrixBandPart_T], num_lower: Annotated[Any, ~TV_MatrixBandPart_Tindex], num_upper: Annotated[Any, ~TV_MatrixBandPart_Tindex], name=None) -> Annotated[Any, ~TV_MatrixBandPart_T]\n",
      "        Copy a tensor setting everything outside a central band in each innermost matrix to zero.\n",
      "        \n",
      "        The `band` part is computed as follows:\n",
      "        Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a\n",
      "        tensor with the same shape where\n",
      "        \n",
      "        `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.\n",
      "        \n",
      "        The indicator function\n",
      "        \n",
      "        `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)) &&\n",
      "                         (num_upper < 0 || (n-m) <= num_upper)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # if 'input' is [[ 0,  1,  2, 3]\n",
      "        #                [-1,  0,  1, 2]\n",
      "        #                [-2, -1,  0, 1]\n",
      "        #                [-3, -2, -1, 0]],\n",
      "        \n",
      "        tf.linalg.band_part(input, 1, -1) ==> [[ 0,  1,  2, 3]\n",
      "                                               [-1,  0,  1, 2]\n",
      "                                               [ 0, -1,  0, 1]\n",
      "                                               [ 0,  0, -1, 0]],\n",
      "        \n",
      "        tf.linalg.band_part(input, 2, 1) ==> [[ 0,  1,  0, 0]\n",
      "                                              [-1,  0,  1, 0]\n",
      "                                              [-2, -1,  0, 1]\n",
      "                                              [ 0, -2, -1, 0]]\n",
      "        ```\n",
      "        \n",
      "        Useful special cases:\n",
      "        \n",
      "        ```\n",
      "         tf.linalg.band_part(input, 0, -1) ==> Upper triangular part.\n",
      "         tf.linalg.band_part(input, -1, 0) ==> Lower triangular part.\n",
      "         tf.linalg.band_part(input, 0, 0) ==> Diagonal.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Rank `k` tensor.\n",
      "          num_lower: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            0-D tensor. Number of subdiagonals to keep. If negative, keep entire\n",
      "            lower triangle.\n",
      "          num_upper: A `Tensor`. Must have the same type as `num_lower`.\n",
      "            0-D tensor. Number of superdiagonals to keep. If negative, keep\n",
      "            entire upper triangle.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_determinant(input: Annotated[Any, ~TV_MatrixDeterminant_T], name=None) -> Annotated[Any, ~TV_MatrixDeterminant_T]\n",
      "        Computes the determinant of one or more square matrices.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor containing the determinants\n",
      "        for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_diag(diagonal, name='diag', k=0, num_rows=-1, num_cols=-1, padding_value=0, align='RIGHT_LEFT')\n",
      "        Returns a batched diagonal tensor with given batched diagonal values.\n",
      "        \n",
      "        Returns a tensor with the contents in `diagonal` as `k[0]`-th to `k[1]`-th\n",
      "        diagonals of a matrix, with everything else padded with `padding`. `num_rows`\n",
      "        and `num_cols` specify the dimension of the innermost matrix of the output. If\n",
      "        both are not specified, the op assumes the innermost matrix is square and\n",
      "        infers its size from `k` and the innermost dimension of `diagonal`. If only\n",
      "        one of them is specified, the op assumes the unspecified value is the smallest\n",
      "        possible based on other criteria.\n",
      "        \n",
      "        Let `diagonal` have `r` dimensions `[I, J, ..., L, M, N]`. The output tensor\n",
      "        has rank `r+1` with shape `[I, J, ..., L, M, num_rows, num_cols]` when only\n",
      "        one diagonal is given (`k` is an integer or `k[0] == k[1]`). Otherwise, it has\n",
      "        rank `r` with shape `[I, J, ..., L, num_rows, num_cols]`.\n",
      "        \n",
      "        The second innermost dimension of `diagonal` has double meaning. When `k` is\n",
      "        scalar or `k[0] == k[1]`, `M` is part of the batch size [I, J, ..., M], and\n",
      "        the output tensor is:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, n-max(d_upper, 0)] ; if n - m == d_upper\n",
      "            padding_value                             ; otherwise\n",
      "        ```\n",
      "        \n",
      "        Otherwise, `M` is treated as the number of diagonals for the matrix in the\n",
      "        same batch (`M = k[1]-k[0]+1`), and the output tensor is:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] <= d <= k[1]\n",
      "            padding_value                                     ; otherwise\n",
      "        ```\n",
      "        where `d = n - m`, `diag_index = k[1] - d`, and\n",
      "        `index_in_diag = n - max(d, 0) + offset`.\n",
      "        \n",
      "        `offset` is zero except when the alignment of the diagonal is to the right.\n",
      "        ```\n",
      "        offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}\n",
      "                                                   and `d >= 0`) or\n",
      "                                                 (`align` in {LEFT_RIGHT, RIGHT_RIGHT}\n",
      "                                                   and `d <= 0`)\n",
      "                 0                          ; otherwise\n",
      "        ```\n",
      "        where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # The main diagonal.\n",
      "        diagonal = np.array([[1, 2, 3, 4],            # Input shape: (2, 4)\n",
      "                             [5, 6, 7, 8]])\n",
      "        tf.matrix_diag(diagonal) ==> [[[1, 0, 0, 0],  # Output shape: (2, 4, 4)\n",
      "                                       [0, 2, 0, 0],\n",
      "                                       [0, 0, 3, 0],\n",
      "                                       [0, 0, 0, 4]],\n",
      "                                      [[5, 0, 0, 0],\n",
      "                                       [0, 6, 0, 0],\n",
      "                                       [0, 0, 7, 0],\n",
      "                                       [0, 0, 0, 8]]]\n",
      "        \n",
      "        # A superdiagonal (per batch).\n",
      "        diagonal = np.array([[1, 2, 3],  # Input shape: (2, 3)\n",
      "                             [4, 5, 6]])\n",
      "        tf.matrix_diag(diagonal, k = 1)\n",
      "          ==> [[[0, 1, 0, 0],  # Output shape: (2, 4, 4)\n",
      "                [0, 0, 2, 0],\n",
      "                [0, 0, 0, 3],\n",
      "                [0, 0, 0, 0]],\n",
      "               [[0, 4, 0, 0],\n",
      "                [0, 0, 5, 0],\n",
      "                [0, 0, 0, 6],\n",
      "                [0, 0, 0, 0]]]\n",
      "        \n",
      "        # A tridiagonal band (per batch).\n",
      "        diagonals = np.array([[[8, 9, 0],  # Input shape: (2, 2, 3)\n",
      "                               [1, 2, 3],\n",
      "                               [0, 4, 5]],\n",
      "                              [[2, 3, 0],\n",
      "                               [6, 7, 9],\n",
      "                               [0, 9, 1]]])\n",
      "        tf.matrix_diag(diagonals, k = (-1, 1))\n",
      "          ==> [[[1, 8, 0],  # Output shape: (2, 3, 3)\n",
      "                [4, 2, 9],\n",
      "                [0, 5, 3]],\n",
      "               [[6, 2, 0],\n",
      "                [9, 7, 3],\n",
      "                [0, 1, 9]]]\n",
      "        \n",
      "        # RIGHT_LEFT alignment.\n",
      "        diagonals = np.array([[[0, 8, 9],  # Input shape: (2, 2, 3)\n",
      "                               [1, 2, 3],\n",
      "                               [4, 5, 0]],\n",
      "                              [[0, 2, 3],\n",
      "                               [6, 7, 9],\n",
      "                               [9, 1, 0]]])\n",
      "        tf.matrix_diag(diagonals, k = (-1, 1), align=\"RIGHT_LEFT\")\n",
      "          ==> [[[1, 8, 0],  # Output shape: (2, 3, 3)\n",
      "                [4, 2, 9],\n",
      "                [0, 5, 3]],\n",
      "               [[6, 2, 0],\n",
      "                [9, 7, 3],\n",
      "                [0, 1, 9]]]\n",
      "        \n",
      "        # Rectangular matrix.\n",
      "        diagonal = np.array([1, 2])  # Input shape: (2)\n",
      "        tf.matrix_diag(diagonal, k = -1, num_rows = 3, num_cols = 4)\n",
      "          ==> [[0, 0, 0, 0],  # Output shape: (3, 4)\n",
      "               [1, 0, 0, 0],\n",
      "               [0, 2, 0, 0]]\n",
      "        \n",
      "        # Rectangular matrix with inferred num_cols and padding_value = 9.\n",
      "        tf.matrix_diag(diagonal, k = -1, num_rows = 3, padding_value = 9)\n",
      "          ==> [[9, 9],  # Output shape: (3, 2)\n",
      "               [1, 9],\n",
      "               [9, 2]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          diagonal: A `Tensor` with `rank k >= 1`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "          num_rows: The number of rows of the output matrix. If it is not provided,\n",
      "            the op assumes the output matrix is a square matrix and infers the matrix\n",
      "            size from `d_lower`, `d_upper`, and the innermost dimension of `diagonal`.\n",
      "          num_cols: The number of columns of the output matrix. If it is not provided,\n",
      "            the op assumes the output matrix is a square matrix and infers the matrix\n",
      "            size from `d_lower`, `d_upper`, and the innermost dimension of `diagonal`.\n",
      "          padding_value: The value to fill the area outside the specified diagonal\n",
      "            band with. Default is 0.\n",
      "          align: Some diagonals are shorter than `max_diag_len` and need to be padded.\n",
      "            `align` is a string specifying how superdiagonals and subdiagonals should\n",
      "            be aligned, respectively. There are four possible alignments: \"RIGHT_LEFT\"\n",
      "            (default), \"LEFT_RIGHT\", \"LEFT_LEFT\", and \"RIGHT_RIGHT\". \"RIGHT_LEFT\"\n",
      "            aligns superdiagonals to the right (left-pads the row) and subdiagonals to\n",
      "            the left (right-pads the row). It is the packing format LAPACK uses.\n",
      "            cuSPARSE uses \"LEFT_RIGHT\", which is the opposite alignment.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor. Has the same type as `diagonal`.\n",
      "    \n",
      "    matrix_diag_part(input, name='diag_part', k=0, padding_value=0, align='RIGHT_LEFT')\n",
      "        Returns the batched diagonal part of a batched tensor.\n",
      "        \n",
      "        Returns a tensor with the `k[0]`-th to `k[1]`-th diagonals of the batched\n",
      "        `input`.\n",
      "        \n",
      "        Assume `input` has `r` dimensions `[I, J, ..., L, M, N]`.\n",
      "        Let `max_diag_len` be the maximum length among all diagonals to be extracted,\n",
      "        `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`\n",
      "        Let `num_diags` be the number of diagonals to extract,\n",
      "        `num_diags = k[1] - k[0] + 1`.\n",
      "        \n",
      "        If `num_diags == 1`, the output tensor is of rank `r - 1` with shape\n",
      "        `[I, J, ..., L, max_diag_len]` and values:\n",
      "        \n",
      "        ```\n",
      "        diagonal[i, j, ..., l, n]\n",
      "          = input[i, j, ..., l, n+y, n+x] ; if 0 <= n+y < M and 0 <= n+x < N,\n",
      "            padding_value                 ; otherwise.\n",
      "        ```\n",
      "        where `y = max(-k[1], 0)`, `x = max(k[1], 0)`.\n",
      "        \n",
      "        Otherwise, the output tensor has rank `r` with dimensions\n",
      "        `[I, J, ..., L, num_diags, max_diag_len]` with values:\n",
      "        \n",
      "        ```\n",
      "        diagonal[i, j, ..., l, m, n]\n",
      "          = input[i, j, ..., l, n+y, n+x] ; if 0 <= n+y < M and 0 <= n+x < N,\n",
      "            padding_value                 ; otherwise.\n",
      "        ```\n",
      "        where `d = k[1] - m`, `y = max(-d, 0) - offset`, and `x = max(d, 0) - offset`.\n",
      "        \n",
      "        `offset` is zero except when the alignment of the diagonal is to the right.\n",
      "        ```\n",
      "        offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}\n",
      "                                                   and `d >= 0`) or\n",
      "                                                 (`align` in {LEFT_RIGHT, RIGHT_RIGHT}\n",
      "                                                   and `d <= 0`)\n",
      "                 0                          ; otherwise\n",
      "        ```\n",
      "        where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.\n",
      "        \n",
      "        The input must be at least a matrix.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        input = np.array([[[1, 2, 3, 4],  # Input shape: (2, 3, 4)\n",
      "                           [5, 6, 7, 8],\n",
      "                           [9, 8, 7, 6]],\n",
      "                          [[5, 4, 3, 2],\n",
      "                           [1, 2, 3, 4],\n",
      "                           [5, 6, 7, 8]]])\n",
      "        \n",
      "        # A main diagonal from each batch.\n",
      "        tf.linalg.diag_part(input) ==> [[1, 6, 7],  # Output shape: (2, 3)\n",
      "                                        [5, 2, 7]]\n",
      "        \n",
      "        # A superdiagonal from each batch.\n",
      "        tf.linalg.diag_part(input, k = 1)\n",
      "          ==> [[2, 7, 6],  # Output shape: (2, 3)\n",
      "               [4, 3, 8]]\n",
      "        \n",
      "        # A band from each batch.\n",
      "        tf.linalg.diag_part(input, k = (-1, 2))\n",
      "          ==> [[[3, 8, 0],  # Output shape: (2, 4, 3)\n",
      "                [2, 7, 6],\n",
      "                [1, 6, 7],\n",
      "                [0, 5, 8]],\n",
      "               [[3, 4, 0],\n",
      "                [4, 3, 8],\n",
      "                [5, 2, 7],\n",
      "                [0, 1, 6]]]\n",
      "        \n",
      "        # RIGHT_LEFT alignment.\n",
      "        tf.linalg.diag_part(input, k = (-1, 2), align=\"RIGHT_LEFT\")\n",
      "          ==> [[[0, 3, 8],  # Output shape: (2, 4, 3)\n",
      "                [2, 7, 6],\n",
      "                [1, 6, 7],\n",
      "                [5, 8, 0]],\n",
      "               [[0, 3, 4],\n",
      "                [4, 3, 8],\n",
      "                [5, 2, 7],\n",
      "                [1, 6, 0]]]\n",
      "        \n",
      "        # max_diag_len can be shorter than the main diagonal.\n",
      "        tf.linalg.diag_part(input, k = (-2, -1))\n",
      "          ==> [[[5, 8],\n",
      "                [0, 9]],\n",
      "               [[1, 6],\n",
      "                [0, 5]]]\n",
      "        \n",
      "        # padding_value = 9\n",
      "        tf.linalg.diag_part(input, k = (1, 3), padding_value = 9)\n",
      "          ==> [[[4, 9, 9],  # Output shape: (2, 3, 3)\n",
      "                [3, 8, 9],\n",
      "                [2, 7, 6]],\n",
      "               [[2, 9, 9],\n",
      "                [3, 4, 9],\n",
      "                [4, 3, 8]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` with `rank k >= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "          padding_value: The value to fill the area outside the specified diagonal\n",
      "            band with. Default is 0.\n",
      "          align: Some diagonals are shorter than `max_diag_len` and need to be padded.\n",
      "            `align` is a string specifying how superdiagonals and subdiagonals should\n",
      "            be aligned, respectively. There are four possible alignments: \"RIGHT_LEFT\"\n",
      "            (default), \"LEFT_RIGHT\", \"LEFT_LEFT\", and \"RIGHT_RIGHT\". \"RIGHT_LEFT\"\n",
      "            aligns superdiagonals to the right (left-pads the row) and subdiagonals to\n",
      "            the left (right-pads the row). It is the packing format LAPACK uses.\n",
      "            cuSPARSE uses \"LEFT_RIGHT\", which is the opposite alignment.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor containing diagonals of `input`. Has the same type as `input`.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: When `k` is out of bound or when `k[0]>k[1:]`.\n",
      "    \n",
      "    matrix_inverse(input: Annotated[Any, ~TV_MatrixInverse_T], adjoint: bool = False, name=None) -> Annotated[Any, ~TV_MatrixInverse_T]\n",
      "        Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).\n",
      "        \n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor of the same shape as the input\n",
      "        containing the inverse for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        The op uses LU decomposition with partial pivoting to compute the inverses.\n",
      "        \n",
      "        If a matrix is not invertible there is no guarantee what the op does. It\n",
      "        may detect the condition and raise an exception or it may simply return a\n",
      "        garbage result.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          adjoint: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_set_diag(input, diagonal, name='set_diag', k=0, align='RIGHT_LEFT')\n",
      "        Returns a batched matrix tensor with new batched diagonal values.\n",
      "        \n",
      "        Given `input` and `diagonal`, this operation returns a tensor with the\n",
      "        same shape and values as `input`, except for the specified diagonals of the\n",
      "        innermost matrices. These will be overwritten by the values in `diagonal`.\n",
      "        \n",
      "        `input` has `r+1` dimensions `[I, J, ..., L, M, N]`. When `k` is scalar or\n",
      "        `k[0] == k[1]`, `diagonal` has `r` dimensions `[I, J, ..., L, max_diag_len]`.\n",
      "        Otherwise, it has `r+1` dimensions `[I, J, ..., L, num_diags, max_diag_len]`.\n",
      "        `num_diags` is the number of diagonals, `num_diags = k[1] - k[0] + 1`.\n",
      "        `max_diag_len` is the longest diagonal in the range `[k[0], k[1]]`,\n",
      "        `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`\n",
      "        \n",
      "        The output is a tensor of rank `k+1` with dimensions `[I, J, ..., L, M, N]`.\n",
      "        If `k` is scalar or `k[0] == k[1]`:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, n-max(k[1], 0)] ; if n - m == k[1]\n",
      "            input[i, j, ..., l, m, n]              ; otherwise\n",
      "        ```\n",
      "        \n",
      "        Otherwise,\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] <= d <= k[1]\n",
      "            input[i, j, ..., l, m, n]                         ; otherwise\n",
      "        ```\n",
      "        where `d = n - m`, `diag_index = k[1] - d`, and\n",
      "        `index_in_diag = n - max(d, 0) + offset`.\n",
      "        \n",
      "        `offset` is zero except when the alignment of the diagonal is to the right.\n",
      "        ```\n",
      "        offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}\n",
      "                                                   and `d >= 0`) or\n",
      "                                                 (`align` in {LEFT_RIGHT, RIGHT_RIGHT}\n",
      "                                                   and `d <= 0`)\n",
      "                 0                          ; otherwise\n",
      "        ```\n",
      "        where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # The main diagonal.\n",
      "        input = np.array([[[7, 7, 7, 7],              # Input shape: (2, 3, 4)\n",
      "                           [7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7]],\n",
      "                          [[7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7]]])\n",
      "        diagonal = np.array([[1, 2, 3],               # Diagonal shape: (2, 3)\n",
      "                             [4, 5, 6]])\n",
      "        tf.matrix_set_diag(input, diagonal)\n",
      "          ==> [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)\n",
      "                [7, 2, 7, 7],\n",
      "                [7, 7, 3, 7]],\n",
      "               [[4, 7, 7, 7],\n",
      "                [7, 5, 7, 7],\n",
      "                [7, 7, 6, 7]]]\n",
      "        \n",
      "        # A superdiagonal (per batch).\n",
      "        tf.matrix_set_diag(input, diagonal, k = 1)\n",
      "          ==> [[[7, 1, 7, 7],  # Output shape: (2, 3, 4)\n",
      "                [7, 7, 2, 7],\n",
      "                [7, 7, 7, 3]],\n",
      "               [[7, 4, 7, 7],\n",
      "                [7, 7, 5, 7],\n",
      "                [7, 7, 7, 6]]]\n",
      "        \n",
      "        # A band of diagonals.\n",
      "        diagonals = np.array([[[9, 1, 0],  # Diagonal shape: (2, 4, 3)\n",
      "                               [6, 5, 8],\n",
      "                               [1, 2, 3],\n",
      "                               [0, 4, 5]],\n",
      "                              [[1, 2, 0],\n",
      "                               [5, 6, 4],\n",
      "                               [6, 1, 2],\n",
      "                               [0, 3, 4]]])\n",
      "        tf.matrix_set_diag(input, diagonals, k = (-1, 2))\n",
      "          ==> [[[1, 6, 9, 7],  # Output shape: (2, 3, 4)\n",
      "                [4, 2, 5, 1],\n",
      "                [7, 5, 3, 8]],\n",
      "               [[6, 5, 1, 7],\n",
      "                [3, 1, 6, 2],\n",
      "                [7, 4, 2, 4]]]\n",
      "        \n",
      "        # RIGHT_LEFT alignment.\n",
      "        diagonals = np.array([[[0, 9, 1],  # Diagonal shape: (2, 4, 3)\n",
      "                               [6, 5, 8],\n",
      "                               [1, 2, 3],\n",
      "                               [4, 5, 0]],\n",
      "                              [[0, 1, 2],\n",
      "                               [5, 6, 4],\n",
      "                               [6, 1, 2],\n",
      "                               [3, 4, 0]]])\n",
      "        tf.matrix_set_diag(input, diagonals, k = (-1, 2), align=\"RIGHT_LEFT\")\n",
      "          ==> [[[1, 6, 9, 7],  # Output shape: (2, 3, 4)\n",
      "                [4, 2, 5, 1],\n",
      "                [7, 5, 3, 8]],\n",
      "               [[6, 5, 1, 7],\n",
      "                [3, 1, 6, 2],\n",
      "                [7, 4, 2, 4]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` with rank `k + 1`, where `k >= 1`.\n",
      "          diagonal:  A `Tensor` with rank `k`, when `d_lower == d_upper`, or `k + 1`,\n",
      "            otherwise. `k >= 1`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "          align: Some diagonals are shorter than `max_diag_len` and need to be padded.\n",
      "            `align` is a string specifying how superdiagonals and subdiagonals should\n",
      "            be aligned, respectively. There are four possible alignments: \"RIGHT_LEFT\"\n",
      "            (default), \"LEFT_RIGHT\", \"LEFT_LEFT\", and \"RIGHT_RIGHT\". \"RIGHT_LEFT\"\n",
      "            aligns superdiagonals to the right (left-pads the row) and subdiagonals to\n",
      "            the left (right-pads the row). It is the packing format LAPACK uses.\n",
      "            cuSPARSE uses \"LEFT_RIGHT\", which is the opposite alignment.\n",
      "    \n",
      "    matrix_solve(matrix: Annotated[Any, ~TV_MatrixSolve_T], rhs: Annotated[Any, ~TV_MatrixSolve_T], adjoint: bool = False, name=None) -> Annotated[Any, ~TV_MatrixSolve_T]\n",
      "        Solves systems of linear equations.\n",
      "        \n",
      "        `Matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. `Rhs` is a tensor of shape `[..., M, K]`. The `output` is\n",
      "        a tensor shape `[..., M, K]`.  If `adjoint` is `False` then each output matrix\n",
      "        satisfies `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.\n",
      "        If `adjoint` is `True` then each output matrix satisfies\n",
      "        `adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          rhs: A `Tensor`. Must have the same type as `matrix`.\n",
      "            Shape is `[..., M, K]`.\n",
      "          adjoint: An optional `bool`. Defaults to `False`.\n",
      "            Boolean indicating whether to solve with `matrix` or its (block-wise)\n",
      "            adjoint.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `matrix`.\n",
      "    \n",
      "    matrix_solve_ls(matrix, rhs, l2_regularizer=0.0, fast=True, name=None)\n",
      "        Solves one or more linear least-squares problems.\n",
      "        \n",
      "        `matrix` is a tensor of shape `[..., M, N]` whose inner-most 2 dimensions\n",
      "        form `M`-by-`N` matrices. Rhs is a tensor of shape `[..., M, K]` whose\n",
      "        inner-most 2 dimensions form `M`-by-`K` matrices.  The computed output is a\n",
      "        `Tensor` of shape `[..., N, K]` whose inner-most 2 dimensions form `M`-by-`K`\n",
      "        matrices that solve the equations\n",
      "        `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]` in the least squares\n",
      "        sense.\n",
      "        \n",
      "        Below we will use the following notation for each pair of matrix and\n",
      "        right-hand sides in the batch:\n",
      "        \n",
      "        `matrix`=\\\\(A \\in \\Re^{m \\times n}\\\\),\n",
      "        `rhs`=\\\\(B  \\in \\Re^{m \\times k}\\\\),\n",
      "        `output`=\\\\(X  \\in \\Re^{n \\times k}\\\\),\n",
      "        `l2_regularizer`=\\\\(\\lambda\\\\).\n",
      "        \n",
      "        If `fast` is `True`, then the solution is computed by solving the normal\n",
      "        equations using Cholesky decomposition. Specifically, if \\\\(m \\ge n\\\\) then\n",
      "        \\\\(X = (A^T A + \\lambda I)^{-1} A^T B\\\\), which solves the least-squares\n",
      "        problem \\\\(X = \\mathrm{argmin}_{Z \\in \\Re^{n \\times k}} ||A Z - B||_F^2 +\n",
      "        \\lambda ||Z||_F^2\\\\). If \\\\(m \\lt n\\\\) then `output` is computed as\n",
      "        \\\\(X = A^T (A A^T + \\lambda I)^{-1} B\\\\), which (for \\\\(\\lambda = 0\\\\)) is\n",
      "        the minimum-norm solution to the under-determined linear system, i.e.\n",
      "        \\\\(X = \\mathrm{argmin}_{Z \\in \\Re^{n \\times k}} ||Z||_F^2 \\\\), subject to\n",
      "        \\\\(A Z = B\\\\). Notice that the fast path is only numerically stable when\n",
      "        \\\\(A\\\\) is numerically full rank and has a condition number\n",
      "        \\\\(\\mathrm{cond}(A) \\lt \\frac{1}{\\sqrt{\\epsilon_{mach}}}\\\\) or\\\\(\\lambda\\\\)\n",
      "        is sufficiently large.\n",
      "        \n",
      "        If `fast` is `False` an algorithm based on the numerically robust complete\n",
      "        orthogonal decomposition is used. This computes the minimum-norm\n",
      "        least-squares solution, even when \\\\(A\\\\) is rank deficient. This path is\n",
      "        typically 6-7 times slower than the fast path. If `fast` is `False` then\n",
      "        `l2_regularizer` is ignored.\n",
      "        \n",
      "        Args:\n",
      "          matrix: `Tensor` of shape `[..., M, N]`.\n",
      "          rhs: `Tensor` of shape `[..., M, K]`.\n",
      "          l2_regularizer: 0-D `double` `Tensor`. Ignored if `fast=False`.\n",
      "          fast: bool. Defaults to `True`.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          output: `Tensor` of shape `[..., N, K]` whose inner-most 2 dimensions form\n",
      "            `M`-by-`K` matrices that solve the equations\n",
      "            `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]` in the least\n",
      "            squares sense.\n",
      "        \n",
      "        Raises:\n",
      "          NotImplementedError: linalg.lstsq is currently disabled for complex128\n",
      "          and l2_regularizer != 0 due to poor accuracy.\n",
      "    \n",
      "    matrix_square_root(input: Annotated[Any, ~TV_MatrixSquareRoot_T], name=None) -> Annotated[Any, ~TV_MatrixSquareRoot_T]\n",
      "        Computes the matrix square root of one or more square matrices:\n",
      "        \n",
      "        matmul(sqrtm(A), sqrtm(A)) = A\n",
      "        \n",
      "        The input matrix should be invertible. If the input matrix is real, it should\n",
      "        have no eigenvalues which are real and negative (pairs of complex conjugate\n",
      "        eigenvalues are allowed).\n",
      "        \n",
      "        The matrix square root is computed by first reducing the matrix to\n",
      "        quasi-triangular form with the real Schur decomposition. The square root\n",
      "        of the quasi-triangular matrix is then computed directly. Details of\n",
      "        the algorithm can be found in: Nicholas J. Higham, \"Computing real\n",
      "        square roots of a real matrix\", Linear Algebra Appl., 1987.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor of the same shape as the input\n",
      "        containing the matrix square root for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_transpose(a, name='matrix_transpose', conjugate=False)\n",
      "        Transposes last two dimensions of tensor `a`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.linalg.matrix_transpose(x)  # [[1, 4],\n",
      "                                       #  [2, 5],\n",
      "                                       #  [3, 6]]\n",
      "        \n",
      "        x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "                         [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "        tf.linalg.matrix_transpose(x, conjugate=True)  # [[1 - 1j, 4 - 4j],\n",
      "                                                       #  [2 - 2j, 5 - 5j],\n",
      "                                                       #  [3 - 3j, 6 - 6j]]\n",
      "        \n",
      "        # Matrix with two batch dimensions.\n",
      "        # x.shape is [1, 2, 3, 4]\n",
      "        # tf.linalg.matrix_transpose(x) is shape [1, 2, 4, 3]\n",
      "        ```\n",
      "        \n",
      "        Note that `tf.matmul` provides kwargs allowing for transpose of arguments.\n",
      "        This is done with minimal cost, and is preferable to using this function. E.g.\n",
      "        \n",
      "        ```python\n",
      "        # Good!  Transpose is taken at minimal additional cost.\n",
      "        tf.matmul(matrix, b, transpose_b=True)\n",
      "        \n",
      "        # Inefficient!\n",
      "        tf.matmul(matrix, tf.linalg.matrix_transpose(b))\n",
      "        ```\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        In `numpy` transposes are memory-efficient constant time operations as they\n",
      "        simply return a new view of the same data with adjusted `strides`.\n",
      "        \n",
      "        TensorFlow does not support strides, `linalg.matrix_transpose` returns a new\n",
      "        tensor with the items permuted.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor` with `rank >= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "          conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "            to tf.math.conj(tf.linalg.matrix_transpose(input)).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed batch matrix `Tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If `a` is determined statically to have `rank < 2`.\n",
      "    \n",
      "    matrix_triangular_solve(matrix, rhs, lower=True, adjoint=False, name=None)\n",
      "        Solve systems of linear equations with upper or lower triangular matrices.\n",
      "        \n",
      "        `matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions form\n",
      "        square matrices. If `lower` is `True` then the strictly upper triangular part\n",
      "        of each inner-most matrix is assumed to be zero and not accessed. If `lower`\n",
      "        is `False` then the strictly lower triangular part of each inner-most matrix\n",
      "        is assumed to be zero and not accessed. `rhs` is a tensor of shape\n",
      "        `[..., M, N]`.\n",
      "        \n",
      "        The output is a tensor of shape `[..., M, N]`. If `adjoint` is `True` then the\n",
      "        innermost matrices in output satisfy matrix equations `\n",
      "        sum_k matrix[..., i, k] * output[..., k, j] = rhs[..., i, j]`.\n",
      "        If `adjoint` is `False` then the\n",
      "        innermost matrices in output satisfy matrix equations\n",
      "        `sum_k adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]`.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> a = tf.constant([[3,  0,  0,  0],\n",
      "        ...   [2,  1,  0,  0],\n",
      "        ...   [1,  0,  1,  0],\n",
      "        ...   [1,  1,  1,  1]], dtype=tf.float32)\n",
      "        \n",
      "        >>> b = tf.constant([[4], [2], [4], [2]], dtype=tf.float32)\n",
      "        >>> x = tf.linalg.triangular_solve(a, b, lower=True)\n",
      "        >>> x\n",
      "        <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
      "        array([[ 1.3333334 ],\n",
      "               [-0.66666675],\n",
      "               [ 2.6666665 ],\n",
      "               [-1.3333331 ]], dtype=float32)>\n",
      "        >>> tf.matmul(a, x)\n",
      "        <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
      "        array([[4.],\n",
      "               [2.],\n",
      "               [4.],\n",
      "               [2.]], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          matrix: A `Tensor`. Must be one of the following types: `float64`,\n",
      "            `float32`, `half`, `complex64`, `complex128`. Shape is `[..., M, M]`.\n",
      "          rhs: A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M,\n",
      "            N]`.\n",
      "          lower: An optional `bool`. Defaults to `True`. Boolean indicating whether\n",
      "            the innermost matrices in matrix are lower or upper triangular.\n",
      "          adjoint: An optional `bool`. Defaults to `False`. Boolean indicating whether\n",
      "            to solve with matrix or its (block-wise) adjoint.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as matrix, and shape is `[..., M, N]`.\n",
      "    \n",
      "    maximum(x: typing.Annotated[_any, ~TV_Maximum_T], y: typing.Annotated[_any, ~TV_Maximum_T], name=None) -> typing.Annotated[_any, ~TV_Maximum_T]\n",
      "        Returns the max of x and y (i.e. x > y ? x : y) element-wise.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> x = tf.constant([0., 0., 0., 0.])\n",
      "        >>> y = tf.constant([-2., 0., 2., 5.])\n",
      "        >>> tf.math.maximum(x, y)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 2., 5.], dtype=float32)>\n",
      "        \n",
      "        Note that `maximum` supports [broadcast semantics](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for `x` and `y`.\n",
      "        \n",
      "        >>> x = tf.constant([-5., 0., 0., 0.])\n",
      "        >>> y = tf.constant([-3.])\n",
      "        >>> tf.math.maximum(x, y)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-3., 0., 0., 0.], dtype=float32)>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_max`\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    meshgrid(*args, **kwargs)\n",
      "        Broadcasts parameters for evaluation on an N-D grid.\n",
      "        \n",
      "        Given N one-dimensional coordinate arrays `*args`, returns a list `outputs`\n",
      "        of N-D coordinate arrays for evaluating expressions on an N-D grid.\n",
      "        \n",
      "        Notes:\n",
      "        \n",
      "        `meshgrid` supports cartesian ('xy') and matrix ('ij') indexing conventions.\n",
      "        When the `indexing` argument is set to 'xy' (the default), the broadcasting\n",
      "        instructions for the first two dimensions are swapped.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        Calling `X, Y = meshgrid(x, y)` with the tensors\n",
      "        \n",
      "        ```python\n",
      "        x = [1, 2, 3]\n",
      "        y = [4, 5, 6]\n",
      "        X, Y = tf.meshgrid(x, y)\n",
      "        # X = [[1, 2, 3],\n",
      "        #      [1, 2, 3],\n",
      "        #      [1, 2, 3]]\n",
      "        # Y = [[4, 4, 4],\n",
      "        #      [5, 5, 5],\n",
      "        #      [6, 6, 6]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          *args: `Tensor`s with rank 1.\n",
      "          **kwargs:\n",
      "            - indexing: Either 'xy' or 'ij' (optional, default: 'xy').\n",
      "            - name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          outputs: A list of N `Tensor`s with rank N.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: When no keyword arguments (kwargs) are passed.\n",
      "          ValueError: When indexing keyword argument is not one of `xy` or `ij`.\n",
      "    \n",
      "    min_max_variable_partitioner(max_partitions=1, axis=0, min_slice_size=262144, bytes_per_string_element=16)\n",
      "        Partitioner to allocate minimum size per slice.\n",
      "        \n",
      "        Returns a partitioner that partitions the variable of given shape and dtype\n",
      "        such that each partition has a minimum of `min_slice_size` slice of the\n",
      "        variable. The maximum number of such partitions (upper bound) is given by\n",
      "        `max_partitions`.\n",
      "        \n",
      "        Args:\n",
      "          max_partitions: Upper bound on the number of partitions. Defaults to 1.\n",
      "          axis: Axis along which to partition the variable. Defaults to 0.\n",
      "          min_slice_size: Minimum size of the variable slice per partition. Defaults\n",
      "            to 256K.\n",
      "          bytes_per_string_element: If the `Variable` is of type string, this provides\n",
      "            an estimate of how large each scalar in the `Variable` is.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "    \n",
      "    minimum(x: typing.Annotated[_any, ~TV_Minimum_T], y: typing.Annotated[_any, ~TV_Minimum_T], name=None) -> typing.Annotated[_any, ~TV_Minimum_T]\n",
      "        Returns the min of x and y (i.e. x < y ? x : y) element-wise.\n",
      "        \n",
      "        Both inputs are number-type tensors (except complex).  `minimum` expects that\n",
      "        both tensors have the same `dtype`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> x = tf.constant([0., 0., 0., 0.])\n",
      "        >>> y = tf.constant([-5., -2., 0., 3.])\n",
      "        >>> tf.math.minimum(x, y)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -2., 0., 0.], dtype=float32)>\n",
      "        \n",
      "        Note that `minimum` supports [broadcast semantics](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for `x` and `y`.\n",
      "        \n",
      "        >>> x = tf.constant([-5., 0., 0., 0.])\n",
      "        >>> y = tf.constant([-3.])\n",
      "        >>> tf.math.minimum(x, y)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -3., -3., -3.], dtype=float32)>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_min`\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    mod = floor_mod(x: typing.Annotated[_any, ~TV_FloorMod_T], y: typing.Annotated[_any, ~TV_FloorMod_T], name=None) -> typing.Annotated[_any, ~TV_FloorMod_T]\n",
      "        Returns element-wise remainder of division.\n",
      "        \n",
      "        This follows Python semantics in that the\n",
      "        result here is consistent with a flooring divide. E.g.\n",
      "        `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "        \n",
      "        *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    model_variables(scope=None)\n",
      "        Returns all variables in the MODEL_VARIABLES collection.\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of local Variable objects.\n",
      "    \n",
      "    moving_average_variables(scope=None)\n",
      "        Returns all variables that maintain their moving averages.\n",
      "        \n",
      "        If an `ExponentialMovingAverage` object is created and the `apply()`\n",
      "        method is called on a list of variables, these variables will\n",
      "        be added to the `GraphKeys.MOVING_AVERAGE_VARIABLES` collection.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variable objects.\n",
      "    \n",
      "    multinomial(logits, num_samples, seed=None, name=None, output_dtype=None)\n",
      "        Draws samples from a multinomial distribution. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.random.categorical` instead.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        # samples has shape [1, 5], where each value is either 0 or 1 with equal\n",
      "        # probability.\n",
      "        samples = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 5)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          logits: 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice\n",
      "            `[i, :]` represents the unnormalized log-probabilities for all classes.\n",
      "          num_samples: 0-D.  Number of independent samples to draw for each row slice.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See `tf.random.set_seed` for behavior.\n",
      "          name: Optional name for the operation.\n",
      "          output_dtype: The integer type of the output: `int32` or `int64`. Defaults\n",
      "            to `int64`.\n",
      "        \n",
      "        Returns:\n",
      "          The drawn samples of shape `[batch_size, num_samples]`.\n",
      "    \n",
      "    multiply(x, y, name=None)\n",
      "        Returns an element-wise x * y.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "        >>> tf.math.multiply(x, x)\n",
      "        <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "        \n",
      "        Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "        pass in non-`Tensor` arguments:\n",
      "        \n",
      "        >>> tf.math.multiply(7,6)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "        \n",
      "        If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "        compatible shape. (More about broadcasting\n",
      "        [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.ones([1, 2]);\n",
      "        >>> y = tf.ones([2, 1]);\n",
      "        >>> x * y  # Taking advantage of operator overriding\n",
      "        <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "        array([[1., 1.],\n",
      "             [1., 1.]], dtype=float32)>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "            `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "            `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "        \n",
      "        A `Tensor`.  Has the same type as `x`.\n",
      "        \n",
      "        Raises:\n",
      "        \n",
      "         * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "    \n",
      "    negative = neg(x: typing.Annotated[_any, ~TV_Neg_T], name=None) -> typing.Annotated[_any, ~TV_Neg_T]\n",
      "        Computes numerical negative value element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = -x\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    no_gradient(op_type: str) -> None\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    no_op(name=None)\n",
      "        Does nothing. Only useful as a placeholder for control edges.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The created Operation.\n",
      "    \n",
      "    no_regularizer(_)\n",
      "        Use this function to prevent regularization of variables.\n",
      "    \n",
      "    nondifferentiable_batch_function = batch_function(num_batch_threads, max_batch_size, batch_timeout_micros, allowed_batch_sizes=None, max_enqueued_batches=10, autograph=True, enable_large_batch_splitting=True)\n",
      "        Batches the computation done by the decorated function.\n",
      "        \n",
      "        So, for example, in the following code\n",
      "        \n",
      "        ```python\n",
      "        @batch_function(1, 2, 3)\n",
      "        def layer(a):\n",
      "          return tf.matmul(a, a)\n",
      "        \n",
      "        b = layer(w)\n",
      "        ```\n",
      "        \n",
      "        if more than one session.run call is simultaneously trying to compute `b`\n",
      "        the values of `w` will be gathered, non-deterministically concatenated\n",
      "        along the first axis, and only one thread will run the computation. See the\n",
      "        documentation of the `Batch` op for more details.\n",
      "        \n",
      "        Assumes that all arguments of the decorated function are Tensors which will\n",
      "        be batched along their first dimension.\n",
      "        \n",
      "        SparseTensor is not supported. The return value of the decorated function\n",
      "        must be a Tensor or a list/tuple of Tensors.\n",
      "        \n",
      "        Args:\n",
      "          num_batch_threads: Number of scheduling threads for processing batches\n",
      "           of work. Determines the number of batches processed in parallel.\n",
      "          max_batch_size: Batch sizes will never be bigger than this.\n",
      "          batch_timeout_micros: Maximum number of microseconds to wait before\n",
      "           outputting an incomplete batch.\n",
      "          allowed_batch_sizes: Optional list of allowed batch sizes. If left empty,\n",
      "           does nothing. Otherwise, supplies a list of batch sizes, causing the op\n",
      "           to pad batches up to one of those sizes. The entries must increase\n",
      "           monotonically, and the final entry must equal max_batch_size.\n",
      "          max_enqueued_batches: The maximum depth of the batch queue. Defaults to 10.\n",
      "          autograph: Whether to use autograph to compile python and eager style code\n",
      "           for efficient graph-mode execution.\n",
      "          enable_large_batch_splitting: The value of this option doesn't affect\n",
      "           processing output given the same input; it affects implementation details\n",
      "           as stated below: 1. Improve batching efficiency by eliminating unnecessary\n",
      "           adding. 2.`max_batch_size` specifies the limit of input and\n",
      "           `allowed_batch_sizes` specifies the limit of a task to be processed. API\n",
      "           user can give an input of size 128 when 'max_execution_batch_size'\n",
      "           is 32 -> implementation can split input of 128 into 4 x 32, schedule\n",
      "           concurrent processing, and then return concatenated results corresponding\n",
      "           to 128.\n",
      "        \n",
      "        Returns:\n",
      "          The decorated function will return the unbatched computation output Tensors.\n",
      "    \n",
      "    norm(tensor, ord='euclidean', axis=None, keepdims=None, name=None, keep_dims=None)\n",
      "        Computes the norm of vectors, matrices, and tensors. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This function can compute several different vector norms (the 1-norm, the\n",
      "        Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0) and\n",
      "        matrix norms (Frobenius, 1-norm, 2-norm and inf-norm).\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of types `float32`, `float64`, `complex64`, `complex128`\n",
      "          ord: Order of the norm. Supported values are 'fro', 'euclidean',\n",
      "            `1`, `2`, `np.inf` and any positive real number yielding the corresponding\n",
      "            p-norm. Default is 'euclidean' which is equivalent to Frobenius norm if\n",
      "            `tensor` is a matrix and equivalent to 2-norm for vectors.\n",
      "            Some restrictions apply:\n",
      "              a) The Frobenius norm `fro` is not defined for vectors,\n",
      "              b) If axis is a 2-tuple (matrix norm), only 'euclidean', 'fro', `1`,\n",
      "                 `2`, `np.inf` are supported.\n",
      "            See the description of `axis` on how to compute norms for a batch of\n",
      "            vectors or matrices stored in a tensor.\n",
      "          axis: If `axis` is `None` (the default), the input is considered a vector\n",
      "            and a single vector norm is computed over the entire set of values in the\n",
      "            tensor, i.e. `norm(tensor, ord=ord)` is equivalent to\n",
      "            `norm(reshape(tensor, [-1]), ord=ord)`.\n",
      "            If `axis` is a Python integer, the input is considered a batch of vectors,\n",
      "            and `axis` determines the axis in `tensor` over which to compute vector\n",
      "            norms.\n",
      "            If `axis` is a 2-tuple of Python integers it is considered a batch of\n",
      "            matrices and `axis` determines the axes in `tensor` over which to compute\n",
      "            a matrix norm.\n",
      "            Negative indices are supported. Example: If you are passing a tensor that\n",
      "            can be either a matrix or a batch of matrices at runtime, pass\n",
      "            `axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are\n",
      "            computed.\n",
      "          keepdims: If True, the axis indicated in `axis` are kept with size 1.\n",
      "            Otherwise, the dimensions in `axis` are removed from the output shape.\n",
      "          name: The name of the op.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          output: A `Tensor` of the same type as tensor, containing the vector or\n",
      "            matrix norms. If `keepdims` is True then the rank of output is equal to\n",
      "            the rank of `tensor`. Otherwise, if `axis` is none the output is a scalar,\n",
      "            if `axis` is an integer, the rank of `output` is one less than the rank\n",
      "            of `tensor`, if `axis` is a 2-tuple the rank of `output` is two less\n",
      "            than the rank of `tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `ord` or `axis` is invalid.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Mostly equivalent to numpy.linalg.norm.\n",
      "        Not supported: ord <= 0, 2-norm for matrices, nuclear norm.\n",
      "        Other differences:\n",
      "          a) If axis is `None`, treats the flattened `tensor` as a vector\n",
      "           regardless of rank.\n",
      "          b) Explicitly supports 'euclidean' norm as the default, including for\n",
      "           higher order tensors.\n",
      "        @end_compatibility\n",
      "    \n",
      "    not_equal(x, y, name=None)\n",
      "        Returns the truth value of (x != y) element-wise.\n",
      "        \n",
      "        Performs a [broadcast](\n",
      "        https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) with the\n",
      "        arguments and then an element-wise inequality comparison, returning a Tensor\n",
      "        of boolean values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant(2)\n",
      "        >>> tf.math.not_equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant([2, 4])\n",
      "        >>> tf.math.not_equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  False])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`.\n",
      "          y: A `tf.Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If shapes of arguments are incompatible\n",
      "    \n",
      "    numpy_function(func=None, inp=None, Tout=None, stateful=True, name=None)\n",
      "        Wraps a python function and uses it as a TensorFlow op.\n",
      "        \n",
      "        Given a python function `func` wrap this function as an operation in a\n",
      "        `tf.function`. `func` must take numpy arrays as its arguments and\n",
      "        return numpy arrays as its outputs.\n",
      "        \n",
      "        There are two ways to use `tf.numpy_function`.\n",
      "        \n",
      "        ### As a decorator\n",
      "        \n",
      "        When using `tf.numpy_function` as a decorator:\n",
      "        \n",
      "        * you must set `Tout`\n",
      "        * you may set `name`\n",
      "        * you must not set `func` or `inp`\n",
      "        \n",
      "        >>> @tf.numpy_function(Tout=tf.float32)\n",
      "        ... def my_numpy_func(x):\n",
      "        ...   # x will be a numpy array with the contents of the input to the\n",
      "        ...   # tf.function\n",
      "        ...   print(f'executing eagerly, {x=}')\n",
      "        ...   return np.sinh(x)\n",
      "        \n",
      "        The function runs eagerly:\n",
      "        \n",
      "        >>> my_numpy_func(1.0).numpy()\n",
      "        executing eagerly, x=1.0\n",
      "        1.17520\n",
      "        \n",
      "        The behavior doesn't change inside a `tf.function`:\n",
      "        \n",
      "        >>> @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
      "        ... def tf_function(input):\n",
      "        ...   y = tf.numpy_function(my_numpy_func, [input], tf.float32)\n",
      "        ...   return y\n",
      "        >>> tf_function(tf.constant(1.)).numpy()\n",
      "        executing eagerly, x=array(1.)\n",
      "        1.17520\n",
      "        \n",
      "        ### Inplace\n",
      "        \n",
      "        This form can be useful if you don't control the function's source,\n",
      "        but it is harder to read.\n",
      "        \n",
      "        Here is the same function with no decorator:\n",
      "        \n",
      "        >>> def my_func(x):\n",
      "        ...   # x will be a numpy array with the contents of the input to the\n",
      "        ...   # tf.function\n",
      "        ...   print(f'executing eagerly, {x=}')\n",
      "        ...   return np.sinh(x)\n",
      "        \n",
      "        To run `tf.numpy_function` in-place, pass the function, its inputs, and the\n",
      "        output type in a single call to `tf.numpy_function`:\n",
      "        \n",
      "        >>> tf.numpy_function(my_func, [tf.constant(1.0)], tf.float32)\n",
      "        executing eagerly, x=array(1.)\n",
      "        1.17520\n",
      "        \n",
      "        ### More info\n",
      "        \n",
      "        Comparison to `tf.py_function`:\n",
      "        `tf.py_function` and `tf.numpy_function` are very similar, except that\n",
      "        `tf.numpy_function` takes numpy arrays, and not `tf.Tensor`s. If you want the\n",
      "        function to contain `tf.Tensors`, and have any TensorFlow operations executed\n",
      "        in the function be differentiable, please use `tf.py_function`.\n",
      "        \n",
      "        Note: We recommend to avoid using `tf.numpy_function` outside of\n",
      "        prototyping and experimentation due to the following known limitations:\n",
      "        \n",
      "        * Calling `tf.numpy_function` will acquire the Python Global Interpreter Lock\n",
      "          (GIL) that allows only one thread to run at any point in time. This will\n",
      "          preclude efficient parallelization and distribution of the execution of the\n",
      "          program. Therefore, you are discouraged to use `tf.numpy_function` outside\n",
      "          of prototyping and experimentation.\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `tf.SavedModel`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.numpy_function()`. If you are using distributed\n",
      "          TensorFlow, you must run a `tf.distribute.Server` in the same process as the\n",
      "          program that calls `tf.numpy_function`  you must pin the created\n",
      "          operation to a device in that server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        * Currently `tf.numpy_function` is not compatible with XLA. Calling\n",
      "          `tf.numpy_function` inside `tf.function(jit_compile=True)` will raise an\n",
      "          error.\n",
      "        \n",
      "        * Since the function takes numpy arrays, you cannot take gradients\n",
      "          through a numpy_function. If you require something that is differentiable,\n",
      "          please consider using tf.py_function.\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function, which accepts `numpy.ndarray` objects as arguments\n",
      "            and returns a list of `numpy.ndarray` objects (or a single\n",
      "            `numpy.ndarray`). This function must accept as many arguments as there are\n",
      "            tensors in `inp`, and these argument types will match the corresponding\n",
      "            `tf.Tensor` objects in `inp`. The returns `numpy.ndarray`s must match the\n",
      "            number and types defined `Tout`. Important Note: Input and output\n",
      "            `numpy.ndarray`s of `func` are not guaranteed to be copies. In some cases\n",
      "            their underlying memory will be shared with the corresponding TensorFlow\n",
      "            tensors. In-place modification or storing `func` input or return values in\n",
      "            python datastructures without explicit (np.)copy can have\n",
      "            non-deterministic consequences.\n",
      "          inp: A list of `tf.Tensor` objects.\n",
      "          Tout: A list or tuple of tensorflow data types or a single tensorflow data\n",
      "            type if there is only one, indicating what `func` returns.\n",
      "          stateful: (Boolean.) Setting this argument to False tells the runtime to\n",
      "            treat the function as stateless, which enables certain optimizations. A\n",
      "            function is stateless when given the same input it will return the same\n",
      "            output and have no side effects; its only purpose is to have a return\n",
      "            value. The behavior for a stateful function with the `stateful` argument\n",
      "            False is undefined. In particular, caution should be taken when mutating\n",
      "            the input arguments as this is a stateful operation.\n",
      "          name: (Optional) A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          * If `func` is `None` this returns a decorator that will ensure the\n",
      "            decorated function will always run with eager execution even if called\n",
      "            from a `tf.function`/`tf.Graph`.\n",
      "          * If used `func` is not `None` this executes `func` with eager execution\n",
      "            and returns the result: A single or list of `tf.Tensor` which `func`\n",
      "            computes.\n",
      "    \n",
      "    one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)\n",
      "        Returns a one-hot tensor.\n",
      "        \n",
      "        See also `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        The locations represented by indices in `indices` take value `on_value`,\n",
      "        while all other locations take value `off_value`.\n",
      "        \n",
      "        `on_value` and `off_value` must have matching data types. If `dtype` is also\n",
      "        provided, they must be the same data type as specified by `dtype`.\n",
      "        \n",
      "        If `on_value` is not provided, it will default to the value `1` with type\n",
      "        `dtype`\n",
      "        \n",
      "        If `off_value` is not provided, it will default to the value `0` with type\n",
      "        `dtype`\n",
      "        \n",
      "        If the input `indices` is rank `N`, the output will have rank `N+1`. The\n",
      "        new axis is created at dimension `axis` (default: the new axis is appended\n",
      "        at the end).\n",
      "        \n",
      "        If `indices` is a scalar the output shape will be a vector of length `depth`\n",
      "        \n",
      "        If `indices` is a vector of length `features`, the output shape will be:\n",
      "        \n",
      "        ```\n",
      "          features x depth if axis == -1\n",
      "          depth x features if axis == 0\n",
      "        ```\n",
      "        \n",
      "        If `indices` is a matrix (batch) with shape `[batch, features]`, the output\n",
      "        shape will be:\n",
      "        \n",
      "        ```\n",
      "          batch x features x depth if axis == -1\n",
      "          batch x depth x features if axis == 1\n",
      "          depth x batch x features if axis == 0\n",
      "        ```\n",
      "        \n",
      "        If `indices` is a RaggedTensor, the 'axis' argument must be positive and refer\n",
      "        to a non-ragged axis. The output will be equivalent to applying 'one_hot' on\n",
      "        the values of the RaggedTensor, and creating a new RaggedTensor from the\n",
      "        result.\n",
      "        \n",
      "        If `dtype` is not provided, it will attempt to assume the data type of\n",
      "        `on_value` or `off_value`, if one or both are passed in. If none of\n",
      "        `on_value`, `off_value`, or `dtype` are provided, `dtype` will default to the\n",
      "        value `tf.float32`.\n",
      "        \n",
      "        Note: If a non-numeric data type output is desired (`tf.string`, `tf.bool`,\n",
      "        etc.), both `on_value` and `off_value` _must_ be provided to `one_hot`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        indices = [0, 1, 2]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth)  # output: [3 x 3]\n",
      "        # [[1., 0., 0.],\n",
      "        #  [0., 1., 0.],\n",
      "        #  [0., 0., 1.]]\n",
      "        \n",
      "        indices = [0, 2, -1, 1]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth,\n",
      "                   on_value=5.0, off_value=0.0,\n",
      "                   axis=-1)  # output: [4 x 3]\n",
      "        # [[5.0, 0.0, 0.0],  # one_hot(0)\n",
      "        #  [0.0, 0.0, 5.0],  # one_hot(2)\n",
      "        #  [0.0, 0.0, 0.0],  # one_hot(-1)\n",
      "        #  [0.0, 5.0, 0.0]]  # one_hot(1)\n",
      "        \n",
      "        indices = [[0, 2], [1, -1]]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth,\n",
      "                   on_value=1.0, off_value=0.0,\n",
      "                   axis=-1)  # output: [2 x 2 x 3]\n",
      "        # [[[1.0, 0.0, 0.0],   # one_hot(0)\n",
      "        #   [0.0, 0.0, 1.0]],  # one_hot(2)\n",
      "        #  [[0.0, 1.0, 0.0],   # one_hot(1)\n",
      "        #   [0.0, 0.0, 0.0]]]  # one_hot(-1)\n",
      "        \n",
      "        indices = tf.ragged.constant([[0, 1], [2]])\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth)  # output: [2 x None x 3]\n",
      "        # [[[1., 0., 0.],\n",
      "        #   [0., 1., 0.]],\n",
      "        #  [[0., 0., 1.]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor` of indices.\n",
      "          depth: A scalar defining the depth of the one hot dimension.\n",
      "          on_value: A scalar defining the value to fill in output when `indices[j]\n",
      "            = i`. (default: 1)\n",
      "          off_value: A scalar defining the value to fill in output when `indices[j]\n",
      "            != i`. (default: 0)\n",
      "          axis: The axis to fill (default: -1, a new inner-most axis).\n",
      "          dtype: The data type of the output tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: The one-hot tensor.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If dtype of either `on_value` or `off_value` don't match `dtype`\n",
      "          TypeError: If dtype of `on_value` and `off_value` don't match one another\n",
      "    \n",
      "    ones(shape, dtype=tf.float32, name=None, layout=None)\n",
      "        Creates a tensor with all elements set to one (1).\n",
      "        \n",
      "        See also `tf.ones_like`, `tf.zeros`, `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        This operation returns a tensor of type `dtype` with shape `shape` and\n",
      "        all elements set to one.\n",
      "        \n",
      "        >>> tf.ones([3, 4], tf.int32)\n",
      "        <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
      "        array([[1, 1, 1, 1],\n",
      "               [1, 1, 1, 1],\n",
      "               [1, 1, 1, 1]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          shape: A `list` of integers, a `tuple` of integers, or a 1-D `Tensor` of\n",
      "            type `int32`.\n",
      "          dtype: Optional DType of an element in the resulting `Tensor`. Default is\n",
      "            `tf.float32`.\n",
      "          name: Optional string. A name for the operation.\n",
      "          layout: Optional, `tf.experimental.dtensor.Layout`. If provided, the result\n",
      "            is a [DTensor](https://www.tensorflow.org/guide/dtensor_overview) with the\n",
      "            provided layout.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to one (1).\n",
      "    \n",
      "    ones_like(tensor, dtype=None, name=None, optimize=True)\n",
      "        Creates a tensor with all elements set to 1.\n",
      "        \n",
      "        See also `tf.ones`.\n",
      "        \n",
      "        Given a single tensor (`tensor`), this operation returns a tensor of the same\n",
      "        type and shape as `tensor` with all elements set to 1. Optionally, you can\n",
      "        specify a new type (`dtype`) for the returned tensor.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.ones_like(tensor)  # [[1, 1, 1], [1, 1, 1]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          dtype: A type for the returned `Tensor`. Must be `float32`, `float64`,\n",
      "            `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `complex64`,\n",
      "            `complex128` or `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "          optimize: if true, attempt to statically determine the shape of 'tensor' and\n",
      "            encode it as a constant.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to 1.\n",
      "    \n",
      "    op_scope(values, name, default_name=None) -> collections.abc.Iterator[typing.Optional[str]]\n",
      "        DEPRECATED. Same as name_scope above, just different argument order.\n",
      "    \n",
      "    pad(tensor, paddings, mode='CONSTANT', name=None, constant_values=0)\n",
      "        Pads a tensor.\n",
      "        \n",
      "        This operation pads a `tensor` according to the `paddings` you specify.\n",
      "        `paddings` is an integer tensor with shape `[n, 2]`, where n is the rank of\n",
      "        `tensor`. For each dimension D of `input`, `paddings[D, 0]` indicates how\n",
      "        many values to add before the contents of `tensor` in that dimension, and\n",
      "        `paddings[D, 1]` indicates how many values to add after the contents of\n",
      "        `tensor` in that dimension. If `mode` is \"REFLECT\" then both `paddings[D, 0]`\n",
      "        and `paddings[D, 1]` must be no greater than `tensor.dim_size(D) - 1`. If\n",
      "        `mode` is \"SYMMETRIC\" then both `paddings[D, 0]` and `paddings[D, 1]` must be\n",
      "        no greater than `tensor.dim_size(D)`.\n",
      "        \n",
      "        The padded size of each dimension D of the output is:\n",
      "        \n",
      "        `paddings[D, 0] + tensor.dim_size(D) + paddings[D, 1]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        paddings = tf.constant([[1, 1,], [2, 2]])\n",
      "        # 'constant_values' is 0.\n",
      "        # rank of 't' is 2.\n",
      "        tf.pad(t, paddings, \"CONSTANT\")  # [[0, 0, 0, 0, 0, 0, 0],\n",
      "                                         #  [0, 0, 1, 2, 3, 0, 0],\n",
      "                                         #  [0, 0, 4, 5, 6, 0, 0],\n",
      "                                         #  [0, 0, 0, 0, 0, 0, 0]]\n",
      "        \n",
      "        tf.pad(t, paddings, \"REFLECT\")  # [[6, 5, 4, 5, 6, 5, 4],\n",
      "                                        #  [3, 2, 1, 2, 3, 2, 1],\n",
      "                                        #  [6, 5, 4, 5, 6, 5, 4],\n",
      "                                        #  [3, 2, 1, 2, 3, 2, 1]]\n",
      "        \n",
      "        tf.pad(t, paddings, \"SYMMETRIC\")  # [[2, 1, 1, 2, 3, 3, 2],\n",
      "                                          #  [2, 1, 1, 2, 3, 3, 2],\n",
      "                                          #  [5, 4, 4, 5, 6, 6, 5],\n",
      "                                          #  [5, 4, 4, 5, 6, 6, 5]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          paddings: A `Tensor` of type `int32`.\n",
      "          mode: One of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\" (case-insensitive)\n",
      "          name: A name for the operation (optional).\n",
      "          constant_values: In \"CONSTANT\" mode, the scalar pad value to use. Must be\n",
      "            same type as `tensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When mode is not one of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\".\n",
      "    \n",
      "    parallel_stack(values, name='parallel_stack')\n",
      "        Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor in parallel.\n",
      "        \n",
      "        Requires that the shape of inputs be known at graph construction time.\n",
      "        \n",
      "        Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "        each tensor in `values`, by packing them along the first dimension.\n",
      "        Given a list of length `N` of tensors of shape `(A, B, C)`; the `output`\n",
      "        tensor will have the shape `(N, A, B, C)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([1, 4])\n",
      "        y = tf.constant([2, 5])\n",
      "        z = tf.constant([3, 6])\n",
      "        tf.parallel_stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]]\n",
      "        ```\n",
      "        \n",
      "        The difference between `stack` and `parallel_stack` is that `stack` requires\n",
      "        all the inputs be computed before the operation will begin but doesn't require\n",
      "        that the input shapes be known during graph construction.\n",
      "        \n",
      "        `parallel_stack` will copy pieces of the input into the output as they become\n",
      "        available, in some situations this can provide a performance benefit.\n",
      "        \n",
      "        Unlike `stack`, `parallel_stack` does NOT support backpropagation.\n",
      "        \n",
      "        This is the opposite of unstack.  The numpy equivalent is\n",
      "        \n",
      "            tf.parallel_stack([x, y, z]) = np.asarray([x, y, z])\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        parallel_stack is not compatible with eager execution.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects with the same shape and type.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: A stacked `Tensor` with the same type as `values`.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if executed in eager mode.\n",
      "    \n",
      "    parse_example(serialized, features, name=None, example_names=None)\n",
      "        Parses `Example` protos into a `dict` of tensors.\n",
      "        \n",
      "        Parses a number of serialized [`Example`](https://www.tensorflow.org/code/tensorflow/core/example/example.proto)\n",
      "        protos given in `serialized`. We refer to `serialized` as a batch with\n",
      "        `batch_size` many entries of individual `Example` protos.\n",
      "        \n",
      "        `example_names` may contain descriptive names for the corresponding serialized\n",
      "        protos. These may be useful for debugging purposes, but they have no effect on\n",
      "        the output. If not `None`, `example_names` must be the same length as\n",
      "        `serialized`.\n",
      "        \n",
      "        This op parses serialized examples into a dictionary mapping keys to `Tensor`\n",
      "        `SparseTensor`, and `RaggedTensor` objects. `features` is a Mapping from keys\n",
      "        to `VarLenFeature`, `SparseFeature`, `RaggedFeature`, and `FixedLenFeature`\n",
      "        objects. Each `VarLenFeature` and `SparseFeature` is mapped to a\n",
      "        `SparseTensor`; each `FixedLenFeature` is mapped to a `Tensor`; and each\n",
      "        `RaggedFeature` is mapped to a `RaggedTensor`.\n",
      "        \n",
      "        Each `VarLenFeature` maps to a `SparseTensor` of the specified type\n",
      "        representing a ragged matrix. Its indices are `[batch, index]` where `batch`\n",
      "        identifies the example in `serialized`, and `index` is the value's index in\n",
      "        the list of values associated with that feature and example.\n",
      "        \n",
      "        Each `SparseFeature` maps to a `SparseTensor` of the specified type\n",
      "        representing a Tensor of `dense_shape` `[batch_size] + SparseFeature.size`.\n",
      "        Its `values` come from the feature in the examples with key `value_key`.\n",
      "        A `values[i]` comes from a position `k` in the feature of an example at batch\n",
      "        entry `batch`. This positional information is recorded in `indices[i]` as\n",
      "        `[batch, index_0, index_1, ...]` where `index_j` is the `k-th` value of\n",
      "        the feature in the example at with key `SparseFeature.index_key[j]`.\n",
      "        In other words, we split the indices (except the first index indicating the\n",
      "        batch entry) of a `SparseTensor` by dimension into different features of the\n",
      "        `Example`. Due to its complexity a `VarLenFeature` should be preferred over a\n",
      "        `SparseFeature` whenever possible.\n",
      "        \n",
      "        Each `FixedLenFeature` `df` maps to a `Tensor` of the specified type (or\n",
      "        `tf.float32` if not specified) and shape `(serialized.size(),) + df.shape`.\n",
      "        \n",
      "        `FixedLenFeature` entries with a `default_value` are optional. With no default\n",
      "        value, we will fail if that `Feature` is missing from any example in\n",
      "        `serialized`.\n",
      "        \n",
      "        Each `FixedLenSequenceFeature` `df` maps to a `Tensor` of the specified type\n",
      "        (or `tf.float32` if not specified) and shape\n",
      "        `(serialized.size(), None) + df.shape`.\n",
      "        All examples in `serialized` will be padded with `default_value` along the\n",
      "        second dimension.\n",
      "        \n",
      "        Each `RaggedFeature` maps to a `RaggedTensor` of the specified type.  It\n",
      "        is formed by stacking the `RaggedTensor` for each example, where the\n",
      "        `RaggedTensor` for each individual example is constructed using the tensors\n",
      "        specified by `RaggedTensor.values_key` and `RaggedTensor.partition`.  See\n",
      "        the `tf.io.RaggedFeature` documentation for details and examples.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        For example, if one expects a `tf.float32` `VarLenFeature` `ft` and three\n",
      "        serialized `Example`s are provided:\n",
      "        \n",
      "        ```\n",
      "        serialized = [\n",
      "          features\n",
      "            { feature { key: \"ft\" value { float_list { value: [1.0, 2.0] } } } },\n",
      "          features\n",
      "            { feature []},\n",
      "          features\n",
      "            { feature { key: \"ft\" value { float_list { value: [3.0] } } }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        then the output will look like:\n",
      "        \n",
      "        ```python\n",
      "        {\"ft\": SparseTensor(indices=[[0, 0], [0, 1], [2, 0]],\n",
      "                            values=[1.0, 2.0, 3.0],\n",
      "                            dense_shape=(3, 2)) }\n",
      "        ```\n",
      "        \n",
      "        If instead a `FixedLenSequenceFeature` with `default_value = -1.0` and\n",
      "        `shape=[]` is used then the output will look like:\n",
      "        \n",
      "        ```python\n",
      "        {\"ft\": [[1.0, 2.0], [3.0, -1.0]]}\n",
      "        ```\n",
      "        \n",
      "        Given two `Example` input protos in `serialized`:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"kw\" value { bytes_list { value: [ \"knit\", \"big\" ] } } }\n",
      "            feature { key: \"gps\" value { float_list { value: [] } } }\n",
      "          },\n",
      "          features {\n",
      "            feature { key: \"kw\" value { bytes_list { value: [ \"emmy\" ] } } }\n",
      "            feature { key: \"dank\" value { int64_list { value: [ 42 ] } } }\n",
      "            feature { key: \"gps\" value { } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        And arguments\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"kw\": VarLenFeature(tf.string),\n",
      "            \"dank\": VarLenFeature(tf.int64),\n",
      "            \"gps\": VarLenFeature(tf.float32),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        Then the output is a dictionary:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"kw\": SparseTensor(\n",
      "              indices=[[0, 0], [0, 1], [1, 0]],\n",
      "              values=[\"knit\", \"big\", \"emmy\"]\n",
      "              dense_shape=[2, 2]),\n",
      "          \"dank\": SparseTensor(\n",
      "              indices=[[1, 0]],\n",
      "              values=[42],\n",
      "              dense_shape=[2, 1]),\n",
      "          \"gps\": SparseTensor(\n",
      "              indices=[],\n",
      "              values=[],\n",
      "              dense_shape=[2, 0]),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        For dense results in two serialized `Example`s:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"age\" value { int64_list { value: [ 0 ] } } }\n",
      "            feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\n",
      "           },\n",
      "           features {\n",
      "            feature { key: \"age\" value { int64_list { value: [] } } }\n",
      "            feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        We can use arguments:\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"age\": FixedLenFeature([], dtype=tf.int64, default_value=-1),\n",
      "            \"gender\": FixedLenFeature([], dtype=tf.string),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        And the expected output is:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"age\": [[0], [-1]],\n",
      "          \"gender\": [[\"f\"], [\"f\"]],\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        An alternative to `VarLenFeature` to obtain a `SparseTensor` is\n",
      "        `SparseFeature`. For example, given two `Example` input protos in\n",
      "        `serialized`:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"val\" value { float_list { value: [ 0.5, -1.0 ] } } }\n",
      "            feature { key: \"ix\" value { int64_list { value: [ 3, 20 ] } } }\n",
      "          },\n",
      "          features {\n",
      "            feature { key: \"val\" value { float_list { value: [ 0.0 ] } } }\n",
      "            feature { key: \"ix\" value { int64_list { value: [ 42 ] } } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        And arguments\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"sparse\": SparseFeature(\n",
      "                index_key=\"ix\", value_key=\"val\", dtype=tf.float32, size=100),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        Then the output is a dictionary:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"sparse\": SparseTensor(\n",
      "              indices=[[0, 3], [0, 20], [1, 42]],\n",
      "              values=[0.5, -1.0, 0.0]\n",
      "              dense_shape=[2, 100]),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        See the `tf.io.RaggedFeature` documentation for examples showing how\n",
      "        `RaggedFeature` can be used to obtain `RaggedTensor`s.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A vector (1-D Tensor) of strings, a batch of binary\n",
      "            serialized `Example` protos.\n",
      "          features: A mapping of feature keys to `FixedLenFeature`,\n",
      "            `VarLenFeature`, `SparseFeature`, and `RaggedFeature` values.\n",
      "          example_names: A vector (1-D Tensor) of strings (optional), the names of\n",
      "            the serialized protos in the batch.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `dict` mapping feature keys to `Tensor`, `SparseTensor`, and\n",
      "          `RaggedTensor` values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_single_example(serialized, features, name=None, example_names=None)\n",
      "        Parses a single `Example` proto.\n",
      "        \n",
      "        Similar to `parse_example`, except:\n",
      "        \n",
      "        For dense tensors, the returned `Tensor` is identical to the output of\n",
      "        `parse_example`, except there is no batch dimension, the output shape is the\n",
      "        same as the shape given in `dense_shape`.\n",
      "        \n",
      "        For `SparseTensor`s, the first (batch) column of the indices matrix is removed\n",
      "        (the indices matrix is a column vector), the values vector is unchanged, and\n",
      "        the first (`batch_size`) entry of the shape vector is removed (it is now a\n",
      "        single element vector).\n",
      "        \n",
      "        One might see performance advantages by batching `Example` protos with\n",
      "        `parse_example` instead of using this function directly.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A scalar string Tensor, a single serialized Example.\n",
      "          features: A mapping of feature keys to `FixedLenFeature` or\n",
      "            `VarLenFeature` values.\n",
      "          name: A name for this operation (optional).\n",
      "          example_names: (Optional) A scalar string Tensor, the associated name.\n",
      "        \n",
      "        Returns:\n",
      "          A `dict` mapping feature keys to `Tensor` and `SparseTensor` values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_single_sequence_example(serialized, context_features=None, sequence_features=None, example_name=None, name=None)\n",
      "        Parses a single `SequenceExample` proto.\n",
      "        \n",
      "        Parses a single serialized [`SequenceExample`](https://www.tensorflow.org/code/tensorflow/core/example/example.proto)\n",
      "        proto given in `serialized`.\n",
      "        \n",
      "        This op parses a serialized sequence example into a tuple of dictionaries,\n",
      "        each mapping keys to `Tensor` and `SparseTensor` objects.\n",
      "        The first dictionary contains mappings for keys appearing in\n",
      "        `context_features`, and the second dictionary contains mappings for keys\n",
      "        appearing in `sequence_features`.\n",
      "        \n",
      "        At least one of `context_features` and `sequence_features` must be provided\n",
      "        and non-empty.\n",
      "        \n",
      "        The `context_features` keys are associated with a `SequenceExample` as a\n",
      "        whole, independent of time / frame.  In contrast, the `sequence_features` keys\n",
      "        provide a way to access variable-length data within the `FeatureList` section\n",
      "        of the `SequenceExample` proto.  While the shapes of `context_features` values\n",
      "        are fixed with respect to frame, the frame dimension (the first dimension)\n",
      "        of `sequence_features` values may vary between `SequenceExample` protos,\n",
      "        and even between `feature_list` keys within the same `SequenceExample`.\n",
      "        \n",
      "        `context_features` contains `VarLenFeature`, `RaggedFeature`, and\n",
      "        `FixedLenFeature` objects. Each `VarLenFeature` is mapped to a `SparseTensor`;\n",
      "        each `RaggedFeature` is mapped to a `RaggedTensor`; and each `FixedLenFeature`\n",
      "        is mapped to a `Tensor`, of the specified type, shape, and default value.\n",
      "        \n",
      "        `sequence_features` contains `VarLenFeature`, `RaggedFeature`, and\n",
      "        `FixedLenSequenceFeature` objects. Each `VarLenFeature` is mapped to a\n",
      "        `SparseTensor`; each `RaggedFeature` is mapped to a `RaggedTensor`; and each\n",
      "        `FixedLenSequenceFeature` is mapped to a `Tensor`, each of the specified type.\n",
      "        The shape will be `(T,) + df.dense_shape` for `FixedLenSequenceFeature` `df`,\n",
      "        where `T` is the length of the associated `FeatureList` in the\n",
      "        `SequenceExample`. For instance, `FixedLenSequenceFeature([])` yields a scalar\n",
      "        1-D `Tensor` of static shape `[None]` and dynamic shape `[T]`, while\n",
      "        `FixedLenSequenceFeature([k])` (for `int k >= 1`) yields a 2-D matrix `Tensor`\n",
      "        of static shape `[None, k]` and dynamic shape `[T, k]`.\n",
      "        \n",
      "        Each `SparseTensor` corresponding to `sequence_features` represents a ragged\n",
      "        vector.  Its indices are `[time, index]`, where `time` is the `FeatureList`\n",
      "        entry and `index` is the value's index in the list of values associated with\n",
      "        that time.\n",
      "        \n",
      "        `FixedLenFeature` entries with a `default_value` and `FixedLenSequenceFeature`\n",
      "        entries with `allow_missing=True` are optional; otherwise, we will fail if\n",
      "        that `Feature` or `FeatureList` is missing from any example in `serialized`.\n",
      "        \n",
      "        `example_name` may contain a descriptive name for the corresponding serialized\n",
      "        proto. This may be useful for debugging purposes, but it has no effect on the\n",
      "        output. If not `None`, `example_name` must be a scalar.\n",
      "        \n",
      "        Note that the batch version of this function, `tf.parse_sequence_example`,\n",
      "        is written for better memory efficiency and will be faster on large\n",
      "        `SequenceExample`s.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A scalar (0-D Tensor) of type string, a single binary\n",
      "            serialized `SequenceExample` proto.\n",
      "          context_features: A mapping of feature keys to `FixedLenFeature` or\n",
      "            `VarLenFeature` or `RaggedFeature` values. These features are associated\n",
      "            with a `SequenceExample` as a whole.\n",
      "          sequence_features: A mapping of feature keys to\n",
      "            `FixedLenSequenceFeature` or `VarLenFeature` or `RaggedFeature` values.\n",
      "            These features are associated with data within the `FeatureList` section\n",
      "            of the `SequenceExample` proto.\n",
      "          example_name: A scalar (0-D Tensor) of strings (optional), the name of\n",
      "            the serialized proto.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of two `dict`s, each mapping keys to `Tensor`s and `SparseTensor`s\n",
      "          and `RaggedTensor`s.\n",
      "        \n",
      "          * The first dict contains the context key/values.\n",
      "          * The second dict contains the feature_list key/values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_tensor(serialized: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], out_type: ~TV_ParseTensor_out_type, name=None) -> Annotated[Any, ~TV_ParseTensor_out_type]\n",
      "        Transforms a serialized tensorflow.TensorProto proto into a Tensor.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A `Tensor` of type `string`.\n",
      "            A scalar string containing a serialized TensorProto proto.\n",
      "          out_type: A `tf.DType`.\n",
      "            The type of the serialized tensor.  The provided type must match the\n",
      "            type of the serialized tensor and no implicit conversion will take place.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    placeholder(dtype, shape=None, name=None)\n",
      "        Inserts a placeholder for a tensor that will be always fed.\n",
      "        \n",
      "        **Important**: This tensor will produce an error if evaluated. Its value must\n",
      "        be fed using the `feed_dict` optional argument to `Session.run()`,\n",
      "        `Tensor.eval()`, or `Operation.run()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.compat.v1.placeholder(tf.float32, shape=(1024, 1024))\n",
      "        y = tf.matmul(x, x)\n",
      "        \n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "        \n",
      "          rand_array = np.random.rand(1024, 1024)\n",
      "          print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          dtype: The type of elements in the tensor to be fed.\n",
      "          shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "            specified, you can feed a tensor of any shape.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that may be used as a handle for feeding a value, but not\n",
      "          evaluated directly.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if eager execution is enabled\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is not compatible with eager execution and `tf.function`. To migrate\n",
      "        to TF2, rewrite the code to be compatible with eager execution. Check the\n",
      "        [migration\n",
      "        guide](https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls)\n",
      "        on replacing `Session.run` calls. In TF2, you can just pass tensors directly\n",
      "        into ops and layers. If you want to explicitly set up your inputs, also see\n",
      "        [Keras functional API](https://www.tensorflow.org/guide/keras/functional) on\n",
      "        how to use `tf.keras.Input` to replace `tf.compat.v1.placeholder`.\n",
      "        `tf.function` arguments also do the job of `tf.compat.v1.placeholder`.\n",
      "        For more details please read [Better\n",
      "        performance with tf.function](https://www.tensorflow.org/guide/function).\n",
      "        @end_compatibility\n",
      "    \n",
      "    placeholder_with_default(input, shape, name=None)\n",
      "        A placeholder op that passes through `input` when its output is not fed.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is strongly discouraged for use with eager execution and\n",
      "        `tf.function`. The primary use of this API is for testing computation wrapped\n",
      "        within a `tf.function` where the input tensors might not have statically known\n",
      "        fully-defined shapes. The same can be achieved by creating a\n",
      "        [concrete function](\n",
      "        https://www.tensorflow.org/guide/function#obtaining_concrete_functions)\n",
      "        from the `tf.function` with a `tf.TensorSpec` input which has partially\n",
      "        defined shapes. For example, the code\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f():\n",
      "        ...   x = tf.compat.v1.placeholder_with_default(\n",
      "        ...       tf.constant([[1., 2., 3.], [4., 5., 6.]]), [None, 3])\n",
      "        ...   y = tf.constant([[1.],[2.], [3.]])\n",
      "        ...   z = tf.matmul(x, y)\n",
      "        ...   assert z.shape[0] == None\n",
      "        ...   assert z.shape[1] == 1\n",
      "        \n",
      "        >>> f()\n",
      "        \n",
      "        can easily be replaced by\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   y = tf.constant([[1.],[2.], [3.]])\n",
      "        ...   z = tf.matmul(x, y)\n",
      "        ...   assert z.shape[0] == None\n",
      "        ...   assert z.shape[1] == 1\n",
      "        \n",
      "        >>> g = f.get_concrete_function(tf.TensorSpec([None, 3]))\n",
      "        \n",
      "        You can learn more about `tf.function` at [Better\n",
      "        performance with tf.function](https://www.tensorflow.org/guide/function).\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The default value to produce when output is not fed.\n",
      "          shape: A `tf.TensorShape` or list of `int`s. The (possibly partial) shape of\n",
      "            the tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    polygamma(a: typing.Annotated[_any, ~TV_Polygamma_T], x: typing.Annotated[_any, ~TV_Polygamma_T], name=None) -> typing.Annotated[_any, ~TV_Polygamma_T]\n",
      "        Compute the polygamma function \\\\(\\psi^{(n)}(x)\\\\).\n",
      "        \n",
      "        The polygamma function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(\\psi^{(a)}(x) = \\frac{d^a}{dx^a} \\psi(x)\\\\)\n",
      "        \n",
      "        where \\\\(\\psi(x)\\\\) is the digamma function.\n",
      "        The polygamma function is defined only for non-negative integer orders \\\\a\\\\.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    pow(x, y, name=None)\n",
      "        Computes the power of one value to another.\n",
      "        \n",
      "        Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "        corresponding elements in `x` and `y`. For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[2, 2], [3, 3]])\n",
      "        y = tf.constant([[8, 16], [2, 3]])\n",
      "        tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "            `complex64`, or `complex128`.\n",
      "          y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "            `complex64`, or `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.\n",
      "    \n",
      "    print = print_v2(*inputs, **kwargs)\n",
      "        Print the specified inputs.\n",
      "        \n",
      "        A TensorFlow operator that prints the specified inputs to a desired\n",
      "        output stream or logging level. The inputs may be dense or sparse Tensors,\n",
      "        primitive python objects, data structures that contain tensors, and printable\n",
      "        Python objects. Printed tensors will recursively show the first and last\n",
      "        elements of each dimension to summarize.\n",
      "        \n",
      "        Example:\n",
      "          Single-input usage:\n",
      "        \n",
      "          ```python\n",
      "          tensor = tf.range(10)\n",
      "          tf.print(tensor, output_stream=sys.stderr)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1 2 ... 7 8 9]\" to sys.stderr)\n",
      "        \n",
      "          Multi-input usage:\n",
      "        \n",
      "          ```python\n",
      "          tensor = tf.range(10)\n",
      "          tf.print(\"tensors:\", tensor, {2: tensor * 2}, output_stream=sys.stdout)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"tensors: [0 1 2 ... 7 8 9] {2: [0 2 4 ... 14 16 18]}\" to\n",
      "          sys.stdout)\n",
      "        \n",
      "          Changing the input separator:\n",
      "          ```python\n",
      "          tensor_a = tf.range(2)\n",
      "          tensor_b = tensor_a * 2\n",
      "          tf.print(tensor_a, tensor_b, output_stream=sys.stderr, sep=',')\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1],[0 2]\" to sys.stderr)\n",
      "        \n",
      "          Usage in a `tf.function`:\n",
      "        \n",
      "          ```python\n",
      "          @tf.function\n",
      "          def f():\n",
      "              tensor = tf.range(10)\n",
      "              tf.print(tensor, output_stream=sys.stderr)\n",
      "              return tensor\n",
      "        \n",
      "          range_tensor = f()\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1 2 ... 7 8 9]\" to sys.stderr)\n",
      "        \n",
      "        *Compatibility usage in TF 1.x graphs*:\n",
      "        \n",
      "          In graphs manually created outside of `tf.function`, this method returns\n",
      "          the created TF operator that prints the data. To make sure the\n",
      "          operator runs, users need to pass the produced op to\n",
      "          `tf.compat.v1.Session`'s run method, or to use the op as a control\n",
      "          dependency for executed ops by specifying\n",
      "          `with tf.compat.v1.control_dependencies([print_op])`.\n",
      "        \n",
      "          ```python\n",
      "          tf.compat.v1.disable_v2_behavior()  # for TF1 compatibility only\n",
      "        \n",
      "          sess = tf.compat.v1.Session()\n",
      "          with sess.as_default():\n",
      "            tensor = tf.range(10)\n",
      "            print_op = tf.print(\"tensors:\", tensor, {2: tensor * 2},\n",
      "                                output_stream=sys.stdout)\n",
      "            with tf.control_dependencies([print_op]):\n",
      "              tripled_tensor = tensor * 3\n",
      "        \n",
      "            sess.run(tripled_tensor)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"tensors: [0 1 2 ... 7 8 9] {2: [0 2 4 ... 14 16 18]}\" to\n",
      "          sys.stdout)\n",
      "        \n",
      "        Note: In Jupyter notebooks and colabs, `tf.print` prints to the notebook\n",
      "          cell outputs. It will not write to the notebook kernel's console logs.\n",
      "        \n",
      "        Args:\n",
      "          *inputs: Positional arguments that are the inputs to print. Inputs in the\n",
      "            printed output will be separated by spaces. Inputs may be python\n",
      "            primitives, tensors, data structures such as dicts and lists that may\n",
      "            contain tensors (with the data structures possibly nested in arbitrary\n",
      "            ways), and printable python objects.\n",
      "          output_stream: The output stream, logging level, or file to print to.\n",
      "            Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info,\n",
      "            tf.compat.v1.logging.warning, tf.compat.v1.logging.error,\n",
      "            absl.logging.info, absl.logging.warning and absl.logging.error are also\n",
      "            supported. To print to a file, pass a string started with \"file://\"\n",
      "            followed by the file path, e.g., \"file:///tmp/foo.out\".\n",
      "          summarize: The first and last `summarize` elements within each dimension are\n",
      "            recursively printed per Tensor. If None, then the first 3 and last 3\n",
      "            elements of each dimension are printed for each tensor. If set to -1, it\n",
      "            will print all elements of every tensor.\n",
      "          sep: The string to use to separate the inputs. Defaults to \" \".\n",
      "          end: End character that is appended at the end the printed string. Defaults\n",
      "            to the newline character.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          None when executing eagerly. During graph tracing this returns\n",
      "          a TF operator that prints the specified inputs in the specified output\n",
      "          stream or logging level. This operator will be automatically executed\n",
      "          except inside of `tf.compat.v1` graphs and sessions.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If an unsupported output stream is specified.\n",
      "    \n",
      "    py_func(func, inp, Tout, stateful=True, name=None)\n",
      "        Wraps a python function and uses it as a TensorFlow op.\n",
      "        \n",
      "        Given a python function `func`, which takes numpy arrays as its\n",
      "        arguments and returns numpy arrays as its outputs, wrap this function as an\n",
      "        operation in a TensorFlow graph. The following snippet constructs a simple\n",
      "        TensorFlow graph that invokes the `np.sinh()` NumPy function as a operation\n",
      "        in the graph:\n",
      "        \n",
      "        ```python\n",
      "        def my_func(x):\n",
      "          # x will be a numpy array with the contents of the placeholder below\n",
      "          return np.sinh(x)\n",
      "        input = tf.compat.v1.placeholder(tf.float32)\n",
      "        y = tf.compat.v1.py_func(my_func, [input], tf.float32)\n",
      "        ```\n",
      "        \n",
      "        **N.B.** The `tf.compat.v1.py_func()` operation has the following known\n",
      "        limitations:\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `GraphDef`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.compat.v1.py_func()`. If you are using distributed\n",
      "          TensorFlow, you\n",
      "          must run a `tf.distribute.Server` in the same process as the program that\n",
      "          calls\n",
      "          `tf.compat.v1.py_func()` and you must pin the created operation to a device\n",
      "          in that\n",
      "          server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        Note: It produces tensors of unknown shape and rank as shape inference\n",
      "          does not work on arbitrary Python code.\n",
      "          If you need the shape, you need to set it based on statically\n",
      "          available information.\n",
      "        \n",
      "          E.g.\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          import numpy as np\n",
      "        \n",
      "          def make_synthetic_data(i):\n",
      "              return np.cast[np.uint8](i) * np.ones([20,256,256,3],\n",
      "                      dtype=np.float32) / 10.\n",
      "        \n",
      "          def preprocess_fn(i):\n",
      "              ones = tf.py_function(make_synthetic_data,[i],tf.float32)\n",
      "              ones.set_shape(tf.TensorShape([None, None, None, None]))\n",
      "              ones = tf.image.resize(ones, [224,224])\n",
      "              return ones\n",
      "        \n",
      "          ds = tf.data.Dataset.range(10)\n",
      "          ds = ds.map(preprocess_fn)\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function, which accepts `ndarray` objects as arguments and\n",
      "            returns a list of `ndarray` objects (or a single `ndarray`). This function\n",
      "            must accept as many arguments as there are tensors in `inp`, and these\n",
      "            argument types will match the corresponding `tf.Tensor` objects in `inp`.\n",
      "            The returns `ndarray`s must match the number and types defined `Tout`.\n",
      "            Important Note: Input and output numpy `ndarray`s of `func` are not\n",
      "            guaranteed to be copies. In some cases their underlying memory will be\n",
      "            shared with the corresponding TensorFlow tensors. In-place modification or\n",
      "            storing `func` input or return values in python datastructures without\n",
      "            explicit (np.)copy can have non-deterministic consequences.\n",
      "          inp: A list of `Tensor` objects.\n",
      "          Tout: A list or tuple of tensorflow data types or a single tensorflow data\n",
      "            type if there is only one, indicating what `func` returns.\n",
      "          stateful: (Boolean.) If True, the function should be considered stateful. If\n",
      "            a function is stateless, when given the same input it will return the same\n",
      "            output and have no observable side effects. Optimizations such as common\n",
      "            sub-expression elimination are only performed on stateless operations.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` or a single `Tensor` which `func` computes.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but `tf.numpy_function` is a\n",
      "        near-exact replacement, just drop the `stateful` argument (all\n",
      "        `tf.numpy_function` calls are considered stateful). It is compatible with\n",
      "        eager execution and `tf.function`.\n",
      "        \n",
      "        `tf.py_function` is a close but not an exact replacement, passing TensorFlow\n",
      "        tensors to the wrapped function instead of NumPy arrays, which provides\n",
      "        gradients and can take advantage of accelerators.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> def fn_using_numpy(x):\n",
      "        ...   x[0] = 0.\n",
      "        ...   return x\n",
      "        >>> tf.compat.v1.py_func(fn_using_numpy, inp=[tf.constant([1., 2.])],\n",
      "        ...     Tout=tf.float32, stateful=False)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 2.], dtype=float32)>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.numpy_function(fn_using_numpy, inp=[tf.constant([1., 2.])],\n",
      "        ...     Tout=tf.float32)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 2.], dtype=float32)>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    py_function = eager_py_func(func=None, inp=None, Tout=None, name=None)\n",
      "        Wraps a python function into a TensorFlow op that executes it eagerly.\n",
      "        \n",
      "        Using `tf.py_function` inside a `tf.function` allows you to run a python\n",
      "        function using eager execution, inside the `tf.function`'s graph.\n",
      "        This has two main effects:\n",
      "        \n",
      "        1. This allows you to use nofunc=None, inp=None, Tout=None tensorflow code\n",
      "        inside your `tf.function`.\n",
      "        2. It allows you to run python control logic in a `tf.function` without\n",
      "        relying on `tf.autograph` to convert the code to use tensorflow control logic\n",
      "        (tf.cond, tf.while_loop).\n",
      "        \n",
      "        Both of these features can be useful for debugging.\n",
      "        \n",
      "        Since `tf.py_function` operates on `Tensor`s it is still\n",
      "        differentiable (once).\n",
      "        \n",
      "        There are two ways to use this function:\n",
      "        \n",
      "        ### As a decorator\n",
      "        \n",
      "        Use `tf.py_function` as a decorator to ensure the function always runs\n",
      "        eagerly.\n",
      "        \n",
      "        When using `tf.py_function` as a decorator:\n",
      "        \n",
      "        * you must set `Tout`\n",
      "        * you may set `name`\n",
      "        * you must not set `func` or `inp`\n",
      "        \n",
      "        For example, you might use `tf.py_function` to\n",
      "        implement the log huber function.\n",
      "        \n",
      "        >>> @tf.py_function(Tout=tf.float32)\n",
      "        ... def py_log_huber(x, m):\n",
      "        ...   print('Running with eager execution.')\n",
      "        ...   if tf.abs(x) <= m:\n",
      "        ...     return x**2\n",
      "        ...   else:\n",
      "        ...     return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))\n",
      "        \n",
      "        Under eager execution the function operates normally:\n",
      "        \n",
      "        >>> x = tf.constant(1.0)\n",
      "        >>> m = tf.constant(2.0)\n",
      "        >>>\n",
      "        >>> print(py_log_huber(x,m).numpy())\n",
      "        Running with eager execution.\n",
      "        1.0\n",
      "        \n",
      "        Inside a `tf.function` the `tf.py_function` is not converted to a `tf.Graph`.:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def tf_wrapper(x):\n",
      "        ...   print('Tracing.')\n",
      "        ...   m = tf.constant(2.0)\n",
      "        ...   return py_log_huber(x,m)\n",
      "        \n",
      "        The `tf.py_function` only executes eagerly, and only when the `tf.function`\n",
      "        is called:\n",
      "        \n",
      "        >>> print(tf_wrapper(x).numpy())\n",
      "        Tracing.\n",
      "        Running with eager execution.\n",
      "        1.0\n",
      "        >>> print(tf_wrapper(x).numpy())\n",
      "        Running with eager execution.\n",
      "        1.0\n",
      "        \n",
      "        \n",
      "        Gradients work as expected:\n",
      "        \n",
      "        >>> with tf.GradientTape() as t:\n",
      "        ...   t.watch(x)\n",
      "        ...   y = tf_wrapper(x)\n",
      "        Running with eager execution.\n",
      "        >>>\n",
      "        >>> t.gradient(y, x).numpy()\n",
      "        2.0\n",
      "        \n",
      "        ### Inplace\n",
      "        \n",
      "        You can also skip the decorator and use `tf.py_function` in-place.\n",
      "        This form is a useful shortcut if you don't control the function's source,\n",
      "        but it is harder to read.\n",
      "        \n",
      "        >>> # No decorator\n",
      "        >>> def log_huber(x, m):\n",
      "        ...   if tf.abs(x) <= m:\n",
      "        ...     return x**2\n",
      "        ...   else:\n",
      "        ...     return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))\n",
      "        >>>\n",
      "        >>> x = tf.constant(1.0)\n",
      "        >>> m = tf.constant(2.0)\n",
      "        >>>\n",
      "        >>> tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32).numpy()\n",
      "        1.0\n",
      "        \n",
      "        ### More info\n",
      "        \n",
      "        You can also use `tf.py_function` to debug your models at runtime\n",
      "        using Python tools, i.e., you can isolate portions of your code that\n",
      "        you want to debug, wrap them in Python functions and insert `pdb` tracepoints\n",
      "        or print statements as desired, and wrap those functions in\n",
      "        `tf.py_function`.\n",
      "        \n",
      "        For more information on eager execution, see the\n",
      "        [Eager guide](https://tensorflow.org/guide/eager).\n",
      "        \n",
      "        `tf.py_function` is similar in spirit to `tf.numpy_function`, but unlike\n",
      "        the latter, the former lets you use TensorFlow operations in the wrapped\n",
      "        Python function. In particular, while `tf.compat.v1.py_func` only runs on CPUs\n",
      "        and wraps functions that take NumPy arrays as inputs and return NumPy arrays\n",
      "        as outputs, `tf.py_function` can be placed on GPUs and wraps functions\n",
      "        that take Tensors as inputs, execute TensorFlow operations in their bodies,\n",
      "        and return Tensors as outputs.\n",
      "        \n",
      "        Note: We recommend to avoid using `tf.py_function` outside of prototyping\n",
      "        and experimentation due to the following known limitations:\n",
      "        \n",
      "        * Calling `tf.py_function` will acquire the Python Global Interpreter Lock\n",
      "          (GIL) that allows only one thread to run at any point in time. This will\n",
      "          preclude efficient parallelization and distribution of the execution of the\n",
      "          program.\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `GraphDef`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.py_function()`. If you are using distributed\n",
      "          TensorFlow, you must run a `tf.distribute.Server` in the same process as the\n",
      "          program that calls `tf.py_function()` and you must pin the created\n",
      "          operation to a device in that server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        * Currently `tf.py_function` is not compatible with XLA. Calling\n",
      "          `tf.py_function` inside `tf.function(jit_compile=True)` will raise an\n",
      "          error.\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function that accepts `inp` as arguments, and returns a value\n",
      "            (or list of values) whose type is described by `Tout`. Do not set `func`\n",
      "            when using `tf.py_function` as a decorator.\n",
      "          inp: Input arguments for `func`.  A list whose elements are `Tensor`s or\n",
      "            `CompositeTensors` (such as `tf.RaggedTensor`); or a single `Tensor` or\n",
      "            `CompositeTensor`. Do not set `inp` when using `tf.py_function` as a\n",
      "            decorator.\n",
      "          Tout: The type(s) of the value(s) returned by `func`.  One of the following.\n",
      "            * If `func` returns a `Tensor` (or a value that can be converted to a\n",
      "            Tensor): the `tf.DType` for that value. * If `func` returns a\n",
      "            `CompositeTensor`: The `tf.TypeSpec` for that value. * If `func` returns\n",
      "            `None`: the empty list (`[]`). * If `func` returns a list of `Tensor` and\n",
      "            `CompositeTensor` values: a corresponding list of `tf.DType`s and\n",
      "            `tf.TypeSpec`s for each value.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          * If `func` is `None` this returns a decorator that will ensure the\n",
      "          decorated function will always run with eager execution even if called\n",
      "          from a `tf.function`/`tf.Graph`.\n",
      "          * If used `func` is not `None` this executes `func` with eager execution\n",
      "          and returns the result: a `Tensor`, `CompositeTensor`, or list of\n",
      "          `Tensor` and `CompositeTensor`; or an empty list if `func` returns `None`.\n",
      "    \n",
      "    qr(input: Annotated[Any, ~TV_Qr_T], full_matrices: bool = False, name=None)\n",
      "        Computes the QR decompositions of one or more matrices.\n",
      "        \n",
      "        Computes the QR decomposition of each inner matrix in `tensor` such that\n",
      "        `tensor[..., :, :] = q[..., :, :] * r[..., :,:])`\n",
      "        \n",
      "        Currently, the gradient for the QR decomposition is well-defined only when\n",
      "        the first `P` columns of the inner matrix are linearly independent, where\n",
      "        `P` is the minimum of `M` and `N`, the 2 inner-most dimmensions of `tensor`.\n",
      "        \n",
      "        ```python\n",
      "        # a is a tensor.\n",
      "        # q is a tensor of orthonormal matrices.\n",
      "        # r is a tensor of upper triangular matrices.\n",
      "        q, r = qr(a)\n",
      "        q_full, r_full = qr(a, full_matrices=True)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            A tensor of shape `[..., M, N]` whose inner-most 2 dimensions\n",
      "            form matrices of size `[M, N]`. Let `P` be the minimum of `M` and `N`.\n",
      "          full_matrices: An optional `bool`. Defaults to `False`.\n",
      "            If true, compute full-sized `q` and `r`. If false\n",
      "            (the default), compute only the leading `P` columns of `q`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (q, r).\n",
      "        \n",
      "          q: A `Tensor`. Has the same type as `input`.\n",
      "          r: A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    quantize(input, min_range, max_range, T, mode='MIN_COMBINED', round_mode='HALF_AWAY_FROM_ZERO', name=None, narrow_range=False, axis=None, ensure_minimum_range=0.01)\n",
      "        Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.\n",
      "        \n",
      "        [min_range, max_range] are scalar floats that specify the range for\n",
      "        the 'input' data. The 'mode' attribute controls exactly which calculations are\n",
      "        used to convert the float values to their quantized equivalents.  The\n",
      "        'round_mode' attribute controls which rounding tie-breaking algorithm is used\n",
      "        when rounding float values to their quantized equivalents.\n",
      "        \n",
      "        In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:\n",
      "        \n",
      "        ```\n",
      "        out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)\n",
      "        if T == qint8: out[i] -= (range(T) + 1) / 2.0\n",
      "        ```\n",
      "        \n",
      "        here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`\n",
      "        \n",
      "        *MIN_COMBINED Mode Example*\n",
      "        \n",
      "        Assume the input is type float and has a possible range of [0.0, 6.0] and the\n",
      "        output type is quint8 ([0, 255]). The min_range and max_range values should be\n",
      "        specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each\n",
      "        value of the input by 255/6 and cast to quint8.\n",
      "        \n",
      "        If the output type was qint8 ([-128, 127]), the operation will additionally\n",
      "        subtract each value by 128 prior to casting, so that the range of values aligns\n",
      "        with the range of qint8.\n",
      "        \n",
      "        If the mode is 'MIN_FIRST', then this approach is used:\n",
      "        \n",
      "        ```\n",
      "        num_discrete_values = 1 << (# of bits in T)\n",
      "        range_adjust = num_discrete_values / (num_discrete_values - 1)\n",
      "        range = (range_max - range_min) * range_adjust\n",
      "        range_scale = num_discrete_values / range\n",
      "        quantized = round(input * range_scale) - round(range_min * range_scale) +\n",
      "          numeric_limits<T>::min()\n",
      "        quantized = max(quantized, numeric_limits<T>::min())\n",
      "        quantized = min(quantized, numeric_limits<T>::max())\n",
      "        ```\n",
      "        \n",
      "        The biggest difference between this and MIN_COMBINED is that the minimum range\n",
      "        is rounded first, before it's subtracted from the rounded value. With\n",
      "        MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing\n",
      "        and dequantizing will introduce a larger and larger error.\n",
      "        \n",
      "        *SCALED mode Example*\n",
      "        \n",
      "        `SCALED` mode matches the quantization approach used in\n",
      "        `QuantizeAndDequantize{V2|V3}`.\n",
      "        \n",
      "        If the mode is `SCALED`, the quantization is performed by multiplying each\n",
      "        input value by a scaling_factor.\n",
      "        The scaling_factor is determined from `min_range` and `max_range` to be as large\n",
      "        as possible such that the range from `min_range` to `max_range` is representable\n",
      "        within values of type T.\n",
      "        \n",
      "        ```c++\n",
      "        \n",
      "          const int min_T = std::numeric_limits<T>::min();\n",
      "          const int max_T = std::numeric_limits<T>::max();\n",
      "          const float max_float = std::numeric_limits<float>::max();\n",
      "        \n",
      "          const float scale_factor_from_min_side =\n",
      "              (min_T * min_range > 0) ? min_T / min_range : max_float;\n",
      "          const float scale_factor_from_max_side =\n",
      "              (max_T * max_range > 0) ? max_T / max_range : max_float;\n",
      "        \n",
      "          const float scale_factor = std::min(scale_factor_from_min_side,\n",
      "                                              scale_factor_from_max_side);\n",
      "        ```\n",
      "        \n",
      "        We next use the scale_factor to adjust min_range and max_range as follows:\n",
      "        \n",
      "        ```c++\n",
      "              min_range = min_T / scale_factor;\n",
      "              max_range = max_T / scale_factor;\n",
      "        ```\n",
      "        \n",
      "        \n",
      "        e.g. if T = qint8, and initially min_range = -10, and max_range = 9, we would\n",
      "        compare -128/-10.0 = 12.8 to 127/9.0 = 14.11, and set scaling_factor = 12.8\n",
      "        In this case, min_range would remain -10, but max_range would be adjusted to\n",
      "        127 / 12.8 = 9.921875\n",
      "        \n",
      "        So we will quantize input values in the range (-10, 9.921875) to (-128, 127).\n",
      "        \n",
      "        The input tensor can now be quantized by clipping values to the range\n",
      "        `min_range` to `max_range`, then multiplying by scale_factor as follows:\n",
      "        \n",
      "        ```c++\n",
      "        result = round(min(max_range, max(min_range, input)) * scale_factor)\n",
      "        ```\n",
      "        \n",
      "        The adjusted `min_range` and `max_range` are returned as outputs 2 and 3 of\n",
      "        this operation. These outputs should be used as the range for any further\n",
      "        calculations.\n",
      "        \n",
      "        \n",
      "        *narrow_range (bool) attribute*\n",
      "        \n",
      "        If true, we do not use the minimum quantized value.\n",
      "        i.e. for int8 the quantized output, it would be restricted to the range\n",
      "        -127..127 instead of the full -128..127 range.\n",
      "        This is provided for compatibility with certain inference backends.\n",
      "        (Only applies to SCALED mode)\n",
      "        \n",
      "        \n",
      "        *axis (int) attribute*\n",
      "        \n",
      "        An optional `axis` attribute can specify a dimension index of the input tensor,\n",
      "        such that quantization ranges will be calculated and applied separately for each\n",
      "        slice of the tensor along that dimension. This is useful for per-channel\n",
      "        quantization.\n",
      "        \n",
      "        If axis is specified, min_range and max_range\n",
      "        \n",
      "        if `axis`=None, per-tensor quantization is performed as normal.\n",
      "        \n",
      "        \n",
      "        *ensure_minimum_range (float) attribute*\n",
      "        \n",
      "        Ensures the minimum quantization range is at least this value.\n",
      "        The legacy default value for this is 0.01, but it is strongly suggested to\n",
      "        set it to 0 for new uses.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `float32`.\n",
      "          min_range: A `Tensor` of type `float32`.\n",
      "            The minimum value of the quantization range. This value may be adjusted by the\n",
      "            op depending on other parameters. The adjusted value is written to `output_min`.\n",
      "            If the `axis` attribute is specified, this must be a 1-D tensor whose size\n",
      "            matches the `axis` dimension of the input and output tensors.\n",
      "          max_range: A `Tensor` of type `float32`.\n",
      "            The maximum value of the quantization range. This value may be adjusted by the\n",
      "            op depending on other parameters. The adjusted value is written to `output_max`.\n",
      "            If the `axis` attribute is specified, this must be a 1-D tensor whose size\n",
      "            matches the `axis` dimension of the input and output tensors.\n",
      "          T: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.\n",
      "          mode: An optional `string` from: `\"MIN_COMBINED\", \"MIN_FIRST\", \"SCALED\"`. Defaults to `\"MIN_COMBINED\"`.\n",
      "          round_mode: An optional `string` from: `\"HALF_AWAY_FROM_ZERO\", \"HALF_TO_EVEN\"`. Defaults to `\"HALF_AWAY_FROM_ZERO\"`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          axis: An optional `int`. Defaults to `-1`.\n",
      "          ensure_minimum_range: An optional `float`. Defaults to `0.01`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output, output_min, output_max).\n",
      "        \n",
      "          output: A `Tensor` of type `T`.\n",
      "          output_min: A `Tensor` of type `float32`.\n",
      "          output_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    quantize_v2(input, min_range, max_range, T, mode='MIN_COMBINED', name=None, round_mode='HALF_AWAY_FROM_ZERO', narrow_range=False, axis=None, ensure_minimum_range=0.01)\n",
      "        Please use `tf.quantization.quantize` instead.\n",
      "    \n",
      "    quantized_concat(concat_dim: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], values: Annotated[List[Any], ~TV_QuantizedConcat_T], input_mins: Annotated[List[Any], <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], input_maxes: Annotated[List[Any], <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], name=None)\n",
      "        Concatenates quantized tensors along one dimension.\n",
      "        \n",
      "        Args:\n",
      "          concat_dim: A `Tensor` of type `int32`.\n",
      "            0-D.  The dimension along which to concatenate.  Must be in the\n",
      "            range [0, rank(values)).\n",
      "          values: A list of at least 2 `Tensor` objects with the same type.\n",
      "            The `N` Tensors to concatenate. Their ranks and types must match,\n",
      "            and their sizes must match in all dimensions except `concat_dim`.\n",
      "          input_mins: A list with the same length as `values` of `Tensor` objects with type `float32`.\n",
      "            The minimum scalar values for each of the input tensors.\n",
      "          input_maxes: A list with the same length as `values` of `Tensor` objects with type `float32`.\n",
      "            The maximum scalar values for each of the input tensors.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output, output_min, output_max).\n",
      "        \n",
      "          output: A `Tensor`. Has the same type as `values`.\n",
      "          output_min: A `Tensor` of type `float32`.\n",
      "          output_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    ragged_fill_empty_rows(value_rowids: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>], values: Annotated[Any, ~TV_RaggedFillEmptyRows_T], nrows: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>], default_value: Annotated[Any, ~TV_RaggedFillEmptyRows_T], name=None)\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          value_rowids: A `Tensor` of type `int64`.\n",
      "          values: A `Tensor`.\n",
      "          nrows: A `Tensor` of type `int64`.\n",
      "          default_value: A `Tensor`. Must have the same type as `values`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output_value_rowids, output_values, empty_row_indicator, reverse_index_map).\n",
      "        \n",
      "          output_value_rowids: A `Tensor` of type `int64`.\n",
      "          output_values: A `Tensor`. Has the same type as `values`.\n",
      "          empty_row_indicator: A `Tensor` of type `bool`.\n",
      "          reverse_index_map: A `Tensor` of type `int64`.\n",
      "    \n",
      "    ragged_fill_empty_rows_grad(reverse_index_map: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>], grad_values: Annotated[Any, ~TV_RaggedFillEmptyRowsGrad_T], name=None)\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          reverse_index_map: A `Tensor` of type `int64`.\n",
      "          grad_values: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (d_values, d_default_value).\n",
      "        \n",
      "          d_values: A `Tensor`. Has the same type as `grad_values`.\n",
      "          d_default_value: A `Tensor`. Has the same type as `grad_values`.\n",
      "    \n",
      "    random_crop(value, size, seed=None, name=None)\n",
      "        Randomly crops a tensor to a given size.\n",
      "        \n",
      "        Slices a shape `size` portion out of `value` at a uniformly chosen offset.\n",
      "        Requires `value.shape >= size`.\n",
      "        \n",
      "        If a dimension should not be cropped, pass the full size of that dimension.\n",
      "        For example, RGB images can be cropped with\n",
      "        `size = [crop_height, crop_width, 3]`.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> image = [[1, 2, 3], [4, 5, 6]]\n",
      "        >>> result = tf.image.random_crop(value=image, size=(1, 3))\n",
      "        >>> result.shape.as_list()\n",
      "        [1, 3]\n",
      "        \n",
      "        For producing deterministic results given a `seed` value, use\n",
      "        `tf.image.stateless_random_crop`. Unlike using the `seed` param with\n",
      "        `tf.image.random_*` ops, `tf.image.stateless_random_*` ops guarantee the same\n",
      "        results given the same seed independent of how many times the function is\n",
      "        called, and independent of global seed settings (e.g. tf.random.set_seed).\n",
      "        \n",
      "        Args:\n",
      "          value: Input tensor to crop.\n",
      "          size: 1-D tensor with size the rank of `value`.\n",
      "          seed: Python integer. Used to create a random seed. See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A cropped tensor of the same rank as `value` and shape `size`.\n",
      "    \n",
      "    random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)\n",
      "        Draws `shape` samples from each of the given Gamma distribution(s).\n",
      "        \n",
      "        `alpha` is the shape parameter describing the distribution(s), and `beta` is\n",
      "        the inverse scale parameter(s).\n",
      "        \n",
      "        Note: Because internal calculations are done using `float64` and casting has\n",
      "        `floor` semantics, we must manually map zero outcomes to the smallest\n",
      "        possible positive floating-point value, i.e., `np.finfo(dtype).tiny`.  This\n",
      "        means that `np.finfo(dtype).tiny` occurs more frequently than it otherwise\n",
      "        should.  This bias can only happen for small values of `alpha`, i.e.,\n",
      "        `alpha << 1` or large values of `beta`, i.e., `beta >> 1`.\n",
      "        \n",
      "        The samples are differentiable w.r.t. alpha and beta.\n",
      "        The derivatives are computed using the approach described in\n",
      "        (Figurnov et al., 2018).\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        samples = tf.random.gamma([10], [0.5, 1.5])\n",
      "        # samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents\n",
      "        # the samples drawn from each distribution\n",
      "        \n",
      "        samples = tf.random.gamma([7, 5], [0.5, 1.5])\n",
      "        # samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1]\n",
      "        # represents the 7x5 samples drawn from each of the two distributions\n",
      "        \n",
      "        alpha = tf.constant([[1.],[3.],[5.]])\n",
      "        beta = tf.constant([[3., 4.]])\n",
      "        samples = tf.random.gamma([30], alpha=alpha, beta=beta)\n",
      "        # samples has shape [30, 3, 2], with 30 samples each of 3x2 distributions.\n",
      "        \n",
      "        loss = tf.reduce_mean(tf.square(samples))\n",
      "        dloss_dalpha, dloss_dbeta = tf.gradients(loss, [alpha, beta])\n",
      "        # unbiased stochastic derivatives of the loss function\n",
      "        alpha.shape == dloss_dalpha.shape  # True\n",
      "        beta.shape == dloss_dbeta.shape  # True\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output samples\n",
      "            to be drawn per alpha/beta-parameterized distribution.\n",
      "          alpha: A Tensor or Python value or N-D array of type `dtype`. `alpha`\n",
      "            provides the shape parameter(s) describing the gamma distribution(s) to\n",
      "            sample. Must be broadcastable with `beta`.\n",
      "          beta: A Tensor or Python value or N-D array of type `dtype`. Defaults to 1.\n",
      "            `beta` provides the inverse scale parameter(s) of the gamma\n",
      "            distribution(s) to sample. Must be broadcastable with `alpha`.\n",
      "          dtype: The type of alpha, beta, and the output: `float16`, `float32`, or\n",
      "            `float64`.\n",
      "          seed: A Python integer. Used to create a random seed for the distributions.\n",
      "            See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          samples: a `Tensor` of shape\n",
      "            `tf.concat([shape, tf.shape(alpha + beta)], axis=0)` with values of type\n",
      "            `dtype`.\n",
      "        \n",
      "        References:\n",
      "          Implicit Reparameterization Gradients:\n",
      "            [Figurnov et al., 2018]\n",
      "            (http://papers.nips.cc/paper/7326-implicit-reparameterization-gradients)\n",
      "            ([pdf]\n",
      "            (http://papers.nips.cc/paper/7326-implicit-reparameterization-gradients.pdf))\n",
      "    \n",
      "    random_index_shuffle(index: Annotated[Any, ~TV_RandomIndexShuffle_dtype], seed: Annotated[Any, ~TV_RandomIndexShuffle_Tseed], max_index: Annotated[Any, ~TV_RandomIndexShuffle_dtype], rounds: int = 4, name=None) -> Annotated[Any, ~TV_RandomIndexShuffle_dtype]\n",
      "        Outputs the position of `value` in a permutation of [0, ..., max_index].\n",
      "        \n",
      "        Output values are a bijection of the `index` for any combination and `seed` and `max_index`.\n",
      "        \n",
      "        If multiple inputs are vectors (matrix in case of seed) then the size of the\n",
      "        first dimension must match.\n",
      "        \n",
      "        The outputs are deterministic.\n",
      "        \n",
      "        Args:\n",
      "          index: A `Tensor`. Must be one of the following types: `int32`, `uint32`, `int64`, `uint64`.\n",
      "            A scalar tensor or a vector of dtype `dtype`. The index (or indices) to be shuffled. Must be within [0, max_index].\n",
      "          seed: A `Tensor`. Must be one of the following types: `int32`, `uint32`, `int64`, `uint64`.\n",
      "            A tensor of dtype `Tseed` and shape [3] or [n, 3]. The random seed.\n",
      "          max_index: A `Tensor`. Must have the same type as `index`.\n",
      "            A scalar tensor or vector of dtype `dtype`. The upper bound(s) of the interval (inclusive).\n",
      "          rounds: An optional `int`. Defaults to `4`.\n",
      "            The number of rounds to use the in block cipher.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `index`.\n",
      "    \n",
      "    random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a normal distribution.\n",
      "        \n",
      "        Example that generates a new set of random values every time:\n",
      "        \n",
      "        >>> tf.random.set_seed(5);\n",
      "        >>> tf.random.normal([4], 0, 1, tf.float32)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=..., dtype=float32)>\n",
      "        \n",
      "        Example that outputs a reproducible result:\n",
      "        \n",
      "        >>> tf.random.set_seed(5);\n",
      "        >>> tf.random.normal([2,2], 0, 1, tf.float32, seed=1)\n",
      "        <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "        array([[-1.3768897 , -0.01258316],\n",
      "              [-0.169515   ,  1.0824056 ]], dtype=float32)>\n",
      "        \n",
      "        In this case, we are setting both the global and operation-level seed to\n",
      "        ensure this result is reproducible.  See `tf.random.set_seed` for more\n",
      "        information.\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          mean: A Tensor or Python value of type `dtype`, broadcastable with `stddev`.\n",
      "            The mean of the normal distribution.\n",
      "          stddev: A Tensor or Python value of type `dtype`, broadcastable with `mean`.\n",
      "            The standard deviation of the normal distribution.\n",
      "          dtype: The float type of the output: `float16`, `bfloat16`, `float32`,\n",
      "            `float64`. Defaults to `float32`.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random normal values.\n",
      "    \n",
      "    random_poisson(lam, shape, dtype=tf.float32, seed=None, name=None)\n",
      "        Draws `shape` samples from each of the given Poisson distribution(s).\n",
      "        \n",
      "        `lam` is the rate parameter describing the distribution(s).\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        samples = tf.random.poisson([0.5, 1.5], [10])\n",
      "        # samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents\n",
      "        # the samples drawn from each distribution\n",
      "        \n",
      "        samples = tf.random.poisson([12.2, 3.3], [7, 5])\n",
      "        # samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1]\n",
      "        # represents the 7x5 samples drawn from each of the two distributions\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          lam: A Tensor or Python value or N-D array of type `dtype`.\n",
      "            `lam` provides the rate parameter(s) describing the poisson\n",
      "            distribution(s) to sample.\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output samples\n",
      "            to be drawn per \"rate\"-parameterized distribution.\n",
      "          dtype: The type of the output: `float16`, `float32`, `float64`, `int32` or\n",
      "            `int64`.\n",
      "          seed: A Python integer. Used to create a random seed for the distributions.\n",
      "            See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          samples: a `Tensor` of shape `tf.concat([shape, tf.shape(lam)], axis=0)`\n",
      "            with values of type `dtype`.\n",
      "    \n",
      "    random_shuffle(value, seed=None, name=None)\n",
      "        Randomly shuffles a tensor along its first dimension.\n",
      "        \n",
      "        The tensor is shuffled along dimension 0, such that each `value[j]` is mapped\n",
      "        to one and only one `output[i]`. For example, a mapping that might occur for a\n",
      "        3x2 tensor is:\n",
      "        \n",
      "        ```python\n",
      "        [[1, 2],       [[5, 6],\n",
      "         [3, 4],  ==>   [1, 2],\n",
      "         [5, 6]]        [3, 4]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          value: A Tensor to be shuffled.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of same shape and type as `value`, shuffled along its first\n",
      "          dimension.\n",
      "    \n",
      "    random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a uniform distribution.\n",
      "        \n",
      "        The generated values follow a uniform distribution in the range\n",
      "        `[minval, maxval)`. The lower bound `minval` is included in the range, while\n",
      "        the upper bound `maxval` is excluded.\n",
      "        \n",
      "        For floats, the default range is `[0, 1)`.  For ints, at least `maxval` must\n",
      "        be specified explicitly.\n",
      "        \n",
      "        In the integer case, the random integers are slightly biased unless\n",
      "        `maxval - minval` is an exact power of two.  The bias is small for values of\n",
      "        `maxval - minval` significantly smaller than the range of the output (either\n",
      "        `2**32` or `2**64`).\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.random.uniform(shape=[2])\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([..., ...], dtype=float32)>\n",
      "        >>> tf.random.uniform(shape=[], minval=-1., maxval=0.)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=-...>\n",
      "        >>> tf.random.uniform(shape=[], minval=5, maxval=10, dtype=tf.int64)\n",
      "        <tf.Tensor: shape=(), dtype=int64, numpy=...>\n",
      "        \n",
      "        The `seed` argument produces a deterministic sequence of tensors across\n",
      "        multiple calls. To repeat that sequence, use `tf.random.set_seed`:\n",
      "        \n",
      "        >>> tf.random.set_seed(5)\n",
      "        >>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        >>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
      "        >>> tf.random.set_seed(5)\n",
      "        >>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        >>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
      "        \n",
      "        Without `tf.random.set_seed` but with a `seed` argument is specified, small\n",
      "        changes to function graphs or previously executed operations will change the\n",
      "        returned value. See `tf.random.set_seed` for details.\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          minval: A Tensor or Python value of type `dtype`, broadcastable with\n",
      "            `shape` (for integer types, broadcasting is not supported, so it needs to\n",
      "            be a scalar). The lower bound on the range of random values to generate\n",
      "            (inclusive).  Defaults to 0.\n",
      "          maxval: A Tensor or Python value of type `dtype`, broadcastable with\n",
      "            `shape` (for integer types, broadcasting is not supported, so it needs to\n",
      "            be a scalar). The upper bound on the range of random values to generate\n",
      "            (exclusive). Defaults to 1 if `dtype` is floating point.\n",
      "          dtype: The type of the output: `float16`, `bfloat16`, `float32`, `float64`,\n",
      "            `int32`, or `int64`. Defaults to `float32`.\n",
      "          seed: A Python integer. Used in combination with `tf.random.set_seed` to\n",
      "            create a reproducible sequence of tensors across multiple calls.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random uniform values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `dtype` is integral and `maxval` is not specified.\n",
      "    \n",
      "    range(start, limit=None, delta=1, dtype=None, name='range')\n",
      "        Creates a sequence of numbers.\n",
      "        \n",
      "        Creates a sequence of numbers that begins at `start` and extends by\n",
      "        increments of `delta` up to but not including `limit`.\n",
      "        \n",
      "        The dtype of the resulting tensor is inferred from the inputs unless\n",
      "        it is provided explicitly.\n",
      "        \n",
      "        Like the Python builtin `range`, `start` defaults to 0, so that\n",
      "        `range(n) = range(0, n)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> start = 3\n",
      "        >>> limit = 18\n",
      "        >>> delta = 3\n",
      "        >>> tf.range(start, limit, delta)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 3,  6,  9, 12, 15], dtype=int32)>\n",
      "        \n",
      "        >>> start = 3\n",
      "        >>> limit = 1\n",
      "        >>> delta = -0.5\n",
      "        >>> tf.range(start, limit, delta)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32,\n",
      "        numpy=array([3. , 2.5, 2. , 1.5], dtype=float32)>\n",
      "        \n",
      "        >>> limit = 5\n",
      "        >>> tf.range(limit)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          start: A 0-D `Tensor` (scalar). Acts as first entry in the range if `limit`\n",
      "            is not None; otherwise, acts as range limit and first entry defaults to 0.\n",
      "          limit: A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None,\n",
      "            defaults to the value of `start` while the first entry of the range\n",
      "            defaults to 0.\n",
      "          delta: A 0-D `Tensor` (scalar). Number that increments `start`. Defaults to\n",
      "            1.\n",
      "          dtype: The type of the elements of the resulting tensor.\n",
      "          name: A name for the operation. Defaults to \"range\".\n",
      "        \n",
      "        Returns:\n",
      "          An 1-D `Tensor` of type `dtype`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.arange\n",
      "        @end_compatibility\n",
      "    \n",
      "    rank(input, name=None)\n",
      "        Returns the rank of a tensor.\n",
      "        \n",
      "        See also `tf.shape`.\n",
      "        \n",
      "        Returns a 0-D `int32` `Tensor` representing the rank of `input`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # shape of tensor 't' is [2, 2, 3]\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.rank(t)  # 3\n",
      "        ```\n",
      "        \n",
      "        **Note**: The rank of a tensor is not the same as the rank of a matrix. The\n",
      "        rank of a tensor is the number of indices required to uniquely select each\n",
      "        element of the tensor. Rank is also known as \"order\", \"degree\", or \"ndims.\"\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int32`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.ndim\n",
      "        @end_compatibility\n",
      "    \n",
      "    read_file(filename, name=None)\n",
      "        Reads the contents of file.\n",
      "        \n",
      "        This operation returns a tensor with the entire contents of the input\n",
      "        filename. It does not do any parsing, it just returns the contents as\n",
      "        they are. Usually, this is the first step in the input pipeline.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> with open(\"/tmp/file.txt\", \"w\") as f:\n",
      "        ...   f.write(\"asdf\")\n",
      "        ...\n",
      "        4\n",
      "        >>> tf.io.read_file(\"/tmp/file.txt\")\n",
      "        <tf.Tensor: shape=(), dtype=string, numpy=b'asdf'>\n",
      "        \n",
      "        Example of using the op in a function to read an image, decode it and reshape\n",
      "        the tensor containing the pixel data:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def load_image(filename):\n",
      "        ...   raw = tf.io.read_file(filename)\n",
      "        ...   image = tf.image.decode_png(raw, channels=3)\n",
      "        ...   # the `print` executes during tracing.\n",
      "        ...   print(\"Initial shape: \", image.shape)\n",
      "        ...   image.set_shape([28, 28, 3])\n",
      "        ...   print(\"Final shape: \", image.shape)\n",
      "        ...   return image\n",
      "        \n",
      "        Args:\n",
      "          filename: string. filename to read from.\n",
      "          name: string.  Optional name for the op.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of dtype \"string\", with the file contents.\n",
      "    \n",
      "    real(input, name=None)\n",
      "        Returns the real part of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the real part of each element in `input` considered as a complex number.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n",
      "        tf.math.real(x)  # [-2.25, 3.25]\n",
      "        ```\n",
      "        \n",
      "        If `input` is already real, it is returned unchanged.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must have numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    realdiv = real_div(x: typing.Annotated[_any, ~TV_RealDiv_T], y: typing.Annotated[_any, ~TV_RealDiv_T], name=None) -> typing.Annotated[_any, ~TV_RealDiv_T]\n",
      "        Returns x / y element-wise for real types.\n",
      "        \n",
      "        If `x` and `y` are reals, this will return the floating-point division.\n",
      "        \n",
      "        *NOTE*: `Div` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    reciprocal(x: typing.Annotated[_any, ~TV_Reciprocal_T], name=None) -> typing.Annotated[_any, ~TV_Reciprocal_T]\n",
      "        Computes the reciprocal of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = 1 / x\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    recompute_grad(f)\n",
      "        Defines a function as a recompute-checkpoint for the tape auto-diff.\n",
      "        \n",
      "        Tape checkpointing is a technique to reduce the memory consumption of the\n",
      "        auto-diff tape:\n",
      "        \n",
      "        - Without tape checkpointing operations and intermediate values are\n",
      "        recorded to the tape for use in the backward pass.\n",
      "        \n",
      "        - With tape checkpointing, only the function call and its inputs are\n",
      "        recorded. During back-propagation the `recompute_grad` custom gradient\n",
      "        (`tf.custom_gradient`) recomputes the function under a localized Tape object.\n",
      "        This recomputation of the function during backpropagation performs redundant\n",
      "        calculation, but reduces the overall memory usage of the Tape.\n",
      "        \n",
      "        >>> y = tf.Variable(1.0)\n",
      "        \n",
      "        >>> def my_function(x):\n",
      "        ...   tf.print('running')\n",
      "        ...   z = x*y\n",
      "        ...   return z\n",
      "        \n",
      "        >>> my_function_recompute = tf.recompute_grad(my_function)\n",
      "        \n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   r = tf.constant(1.0)\n",
      "        ...   for i in range(4):\n",
      "        ...     r = my_function_recompute(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, [y])\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        Without `recompute_grad`, the tape contains all intermitate steps, and no\n",
      "        recomputation is performed.\n",
      "        \n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   r = tf.constant(1.0)\n",
      "        ...   for i in range(4):\n",
      "        ...     r = my_function(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, [y])\n",
      "        \n",
      "        \n",
      "        If `f` was a `tf.keras` `Model` or `Layer` object, methods and attributes\n",
      "        such as `f.variables` are not available on the returned function `g`.\n",
      "        Either keep a reference of `f` , or use `g.__wrapped__` for accessing\n",
      "        these variables and methods.\n",
      "        \n",
      "        \n",
      "        >>> def print_running_and_return(x):\n",
      "        ...   tf.print(\"running\")\n",
      "        ...   return x\n",
      "        \n",
      "        >>> model = tf.keras.Sequential([\n",
      "        ...   tf.keras.layers.Lambda(print_running_and_return),\n",
      "        ...   tf.keras.layers.Dense(2)\n",
      "        ... ])\n",
      "        \n",
      "        >>> model_recompute = tf.recompute_grad(model)\n",
      "        \n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   r = tf.constant([[1,2]])\n",
      "        ...   for i in range(4):\n",
      "        ...     r = model_recompute(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, model.variables)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        Alternatively, use the `__wrapped__` attribute to access the original\n",
      "        model object.\n",
      "        \n",
      "        >>> grad = tape.gradient(r, model_recompute.__wrapped__.variables)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a `Tensor` or sequence of `Tensor` outputs.\n",
      "        \n",
      "        Returns:\n",
      "          A function `g` wrapping `f` that defines a custom gradient, which recomputes\n",
      "          `f` on the backwards pass of a gradient call.\n",
      "    \n",
      "    reduce_all = reduce_all_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes `tf.math.logical_and` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.logical_and` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[True,  True], [False, False]])\n",
      "          >>> tf.math.reduce_all(x)\n",
      "          <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "          >>> tf.math.reduce_all(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False, False])>\n",
      "          >>> tf.math.reduce_all(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The boolean tensor to reduce.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.all\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_any = reduce_any_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes `tf.math.logical_or` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.logical_or` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[True,  True], [False, False]])\n",
      "          >>> tf.reduce_any(x)\n",
      "          <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "          >>> tf.reduce_any(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>\n",
      "          >>> tf.reduce_any(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The boolean tensor to reduce.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.any\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_join(inputs, axis=None, keep_dims=None, separator='', name=None, reduction_indices=None, keepdims=None)\n",
      "        Joins all strings into a single string, or joins along an axis.\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.strings.join` op.\n",
      "        \n",
      "        >>> tf.strings.reduce_join([['abc','123'],\n",
      "        ...                         ['def','456']]).numpy()\n",
      "        b'abc123def456'\n",
      "        >>> tf.strings.reduce_join([['abc','123'],\n",
      "        ...                         ['def','456']], axis=-1).numpy()\n",
      "        array([b'abc123', b'def456'], dtype=object)\n",
      "        >>> tf.strings.reduce_join([['abc','123'],\n",
      "        ...                         ['def','456']],\n",
      "        ...                        axis=-1,\n",
      "        ...                        separator=\" \").numpy()\n",
      "        array([b'abc 123', b'def 456'], dtype=object)\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `tf.string` tensor.\n",
      "          axis: Which axis to join along. The default behavior is to join all\n",
      "            elements, producing a scalar.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          separator: a string added between each string being joined.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.string` tensor.\n",
      "    \n",
      "    reduce_logsumexp = reduce_logsumexp_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes log(sum(exp(elements across dimensions of a tensor))). (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` has no entries, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        This function is more numerically stable than log(sum(exp(input))). It avoids\n",
      "        overflows caused by taking the exp of large inputs and underflows caused by\n",
      "        taking the log of small inputs.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[0., 0., 0.], [0., 0., 0.]])\n",
      "        tf.reduce_logsumexp(x)  # log(6)\n",
      "        tf.reduce_logsumexp(x, 0)  # [log(2), log(2), log(2)]\n",
      "        tf.reduce_logsumexp(x, 1)  # [log(3), log(3)]\n",
      "        tf.reduce_logsumexp(x, 1, keepdims=True)  # [[log(3)], [log(3)]]\n",
      "        tf.reduce_logsumexp(x, [0, 1])  # log(6)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_max = reduce_max_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes `tf.math.maximum` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.maximum` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        Usage example:\n",
      "        \n",
      "          >>> x = tf.constant([5, 1, 2, 4])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=5>\n",
      "          >>> x = tf.constant([-5, -1, -2, -4])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=-1>\n",
      "          >>> x = tf.constant([4, float('nan')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('nan'), float('nan')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('-inf'), float('inf')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=inf>\n",
      "        \n",
      "        See the numpy docs for `np.amax` and `np.nanmax` behavior.\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have real numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_mean = reduce_mean_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the mean of elements across dimensions of a tensor.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis` by computing the\n",
      "        mean of elements across the dimensions in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a tensor with a single\n",
      "        element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([[1., 1.], [2., 2.]])\n",
      "        >>> tf.reduce_mean(x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=1.5>\n",
      "        >>> tf.reduce_mean(x, 0)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.5, 1.5], dtype=float32)>\n",
      "        >>> tf.reduce_mean(x, 1)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.mean\n",
      "        \n",
      "        Please note that `np.mean` has a `dtype` parameter that could be used to\n",
      "        specify the output type. By default this is `dtype=float64`. On the other\n",
      "        hand, `tf.reduce_mean` has an aggressive type inference from `input_tensor`,\n",
      "        for example:\n",
      "        \n",
      "        >>> x = tf.constant([1, 0, 1, 0])\n",
      "        >>> tf.reduce_mean(x)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
      "        >>> y = tf.constant([1., 0., 1., 0.])\n",
      "        >>> tf.reduce_mean(y)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=0.5>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_min = reduce_min_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the `tf.math.minimum` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.minimum` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        Usage example:\n",
      "        \n",
      "          >>> x = tf.constant([5, 1, 2, 4])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "          >>> x = tf.constant([-5, -1, -2, -4])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=-5>\n",
      "          >>> x = tf.constant([4, float('nan')])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('nan'), float('nan')])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('-inf'), float('inf')])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=-inf>\n",
      "        \n",
      "        See the numpy docs for `np.amin` and `np.nanmin` behavior.\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have real numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_prod = reduce_prod_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes `tf.math.multiply` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.multiply` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[1., 2.], [3., 4.]])\n",
      "          >>> tf.math.reduce_prod(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=24.>\n",
      "          >>> tf.math.reduce_prod(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 8.], dtype=float32)>\n",
      "          >>> tf.math.reduce_prod(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 12.],\n",
      "          dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.prod\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_sum = reduce_sum_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the sum of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.add` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> # x has a shape of (2, 3) (two rows and three columns):\n",
      "          >>> x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
      "          >>> x.numpy()\n",
      "          array([[1, 1, 1],\n",
      "                 [1, 1, 1]], dtype=int32)\n",
      "          >>> # sum all the elements\n",
      "          >>> # 1 + 1 + 1 + 1 + 1+ 1 = 6\n",
      "          >>> tf.reduce_sum(x).numpy()\n",
      "          6\n",
      "          >>> # reduce along the first dimension\n",
      "          >>> # the result is [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "          >>> tf.reduce_sum(x, 0).numpy()\n",
      "          array([2, 2, 2], dtype=int32)\n",
      "          >>> # reduce along the second dimension\n",
      "          >>> # the result is [1, 1] + [1, 1] + [1, 1] = [3, 3]\n",
      "          >>> tf.reduce_sum(x, 1).numpy()\n",
      "          array([3, 3], dtype=int32)\n",
      "          >>> # keep the original dimensions\n",
      "          >>> tf.reduce_sum(x, 1, keepdims=True).numpy()\n",
      "          array([[3],\n",
      "                 [3]], dtype=int32)\n",
      "          >>> # reduce along both dimensions\n",
      "          >>> # the result is 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
      "          >>> # or, equivalently, reduce along rows, then reduce the resultant array\n",
      "          >>> # [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "          >>> # 2 + 2 + 2 = 6\n",
      "          >>> tf.reduce_sum(x, [0, 1]).numpy()\n",
      "          6\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor, of the same dtype as the input_tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
      "        int64 while tensorflow returns the same dtype as the input.\n",
      "        @end_compatibility\n",
      "    \n",
      "    regex_replace(input, pattern, rewrite, replace_global=True, name=None)\n",
      "        Replace elements of `input` matching regex `pattern` with `rewrite`.\n",
      "        \n",
      "        >>> tf.strings.regex_replace(\"Text with tags.<br /><b>contains html</b>\",\n",
      "        ...                          \"<[^>]+>\", \" \")\n",
      "        <tf.Tensor: shape=(), dtype=string, numpy=b'Text with tags.  contains html '>\n",
      "        \n",
      "        Args:\n",
      "          input: string `Tensor`, the source strings to process.\n",
      "          pattern: string or scalar string `Tensor`, regular expression to use,\n",
      "            see more details at https://github.com/google/re2/wiki/Syntax\n",
      "          rewrite: string or scalar string `Tensor`, value to use in match\n",
      "            replacement, supports backslash-escaped digits (\\1 to \\9) can be to insert\n",
      "            text matching corresponding parenthesized group.\n",
      "          replace_global: `bool`, if `True` replace all non-overlapping matches,\n",
      "            else replace only the first match.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          string `Tensor` of the same shape as `input` with specified replacements.\n",
      "    \n",
      "    register_tensor_conversion_function(base_type, conversion_func, priority=100)\n",
      "        Registers a function for converting objects of `base_type` to `Tensor`.\n",
      "        \n",
      "        The conversion function must have the following signature:\n",
      "        \n",
      "        ```python\n",
      "            def conversion_func(value, dtype=None, name=None, as_ref=False):\n",
      "              # ...\n",
      "        ```\n",
      "        \n",
      "        It must return a `Tensor` with the given `dtype` if specified. If the\n",
      "        conversion function creates a new `Tensor`, it should use the given\n",
      "        `name` if specified. All exceptions will be propagated to the caller.\n",
      "        \n",
      "        The conversion function may return `NotImplemented` for some\n",
      "        inputs. In this case, the conversion process will continue to try\n",
      "        subsequent conversion functions.\n",
      "        \n",
      "        If `as_ref` is true, the function must return a `Tensor` reference,\n",
      "        such as a `Variable`.\n",
      "        \n",
      "        NOTE: The conversion functions will execute in order of priority,\n",
      "        followed by order of registration. To ensure that a conversion function\n",
      "        `F` runs before another conversion function `G`, ensure that `F` is\n",
      "        registered with a smaller priority than `G`.\n",
      "        \n",
      "        Args:\n",
      "          base_type: The base type or tuple of base types for all objects that\n",
      "            `conversion_func` accepts.\n",
      "          conversion_func: A function that converts instances of `base_type` to\n",
      "            `Tensor`.\n",
      "          priority: Optional integer that indicates the priority for applying this\n",
      "            conversion function. Conversion functions with smaller priority values run\n",
      "            earlier than conversion functions with larger priority values. Defaults to\n",
      "            100.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the arguments do not have the appropriate type.\n",
      "    \n",
      "    repeat(input, repeats, axis=None, name=None)\n",
      "        Repeat elements of `input`.\n",
      "        \n",
      "        See also `tf.concat`, `tf.stack`, `tf.tile`.\n",
      "        \n",
      "        Args:\n",
      "          input: An `N`-dimensional Tensor.\n",
      "          repeats: An 1-D `int` Tensor. The number of repetitions for each element.\n",
      "            repeats is broadcasted to fit the shape of the given axis. `len(repeats)`\n",
      "            must equal `input.shape[axis]` if axis is not None.\n",
      "          axis: An int. The axis along which to repeat values. By default, (axis=None),\n",
      "            use the flattened input array, and return a flat output array.\n",
      "          name: A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor which has the same shape as `input`, except along the given axis.\n",
      "            If axis is None then the output array is flattened to match the flattened\n",
      "            input array.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> repeat(['a', 'b', 'c'], repeats=[3, 0, 2], axis=0)\n",
      "        <tf.Tensor: shape=(5,), dtype=string,\n",
      "        numpy=array([b'a', b'a', b'a', b'c', b'c'], dtype=object)>\n",
      "        \n",
      "        >>> repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=0)\n",
      "        <tf.Tensor: shape=(5, 2), dtype=int32, numpy=\n",
      "        array([[1, 2],\n",
      "               [1, 2],\n",
      "               [3, 4],\n",
      "               [3, 4],\n",
      "               [3, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=1)\n",
      "        <tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
      "        array([[1, 1, 2, 2, 2],\n",
      "               [3, 3, 4, 4, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> repeat(3, repeats=4)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 3, 3, 3], dtype=int32)>\n",
      "        \n",
      "        >>> repeat([[1,2], [3,4]], repeats=2)\n",
      "        <tf.Tensor: shape=(8,), dtype=int32,\n",
      "        numpy=array([1, 1, 2, 2, 3, 3, 4, 4], dtype=int32)>\n",
      "    \n",
      "    report_uninitialized_variables(var_list=None, name='report_uninitialized_variables')\n",
      "        Adds ops to list the names of uninitialized variables.\n",
      "        \n",
      "        When run, it returns a 1-D tensor containing the names of uninitialized\n",
      "        variables if there are any, or an empty array if there are none.\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to check. Defaults to the value of\n",
      "            `global_variables() + local_variables()`\n",
      "          name: Optional name of the `Operation`.\n",
      "        \n",
      "        Returns:\n",
      "          A 1-D tensor containing names of the uninitialized variables, or an empty\n",
      "          1-D tensor if there are no variables or no uninitialized variables.\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    required_space_to_batch_paddings(input_shape, block_shape, base_paddings=None, name=None)\n",
      "        Calculate padding required to make block_shape divide input_shape.\n",
      "        \n",
      "        This function can be used to calculate a suitable paddings argument for use\n",
      "        with space_to_batch_nd and batch_to_space_nd.\n",
      "        \n",
      "        Args:\n",
      "          input_shape: int32 Tensor of shape [N].\n",
      "          block_shape: int32 Tensor of shape [N].\n",
      "          base_paddings: Optional int32 Tensor of shape [N, 2].  Specifies the minimum\n",
      "            amount of padding to use.  All elements must be >= 0.  If not specified,\n",
      "            defaults to 0.\n",
      "          name: string.  Optional name prefix.\n",
      "        \n",
      "        Returns:\n",
      "          (paddings, crops), where:\n",
      "        \n",
      "          `paddings` and `crops` are int32 Tensors of rank 2 and shape [N, 2]\n",
      "          satisfying:\n",
      "        \n",
      "              paddings[i, 0] = base_paddings[i, 0].\n",
      "              0 <= paddings[i, 1] - base_paddings[i, 1] < block_shape[i]\n",
      "              (input_shape[i] + paddings[i, 0] + paddings[i, 1]) % block_shape[i] == 0\n",
      "        \n",
      "              crops[i, 0] = 0\n",
      "              crops[i, 1] = paddings[i, 1] - base_paddings[i, 1]\n",
      "        \n",
      "        Raises: ValueError if called with incompatible shapes.\n",
      "    \n",
      "    reset_default_graph() -> None\n",
      "        Clears the default graph stack and resets the global default graph.\n",
      "        \n",
      "        NOTE: The default graph is a property of the current thread. This\n",
      "        function applies only to the current thread.  Calling this function while\n",
      "        a `tf.compat.v1.Session` or `tf.compat.v1.InteractiveSession` is active will\n",
      "        result in undefined\n",
      "        behavior. Using any previously created `tf.Operation` or `tf.Tensor` objects\n",
      "        after calling this function will result in undefined behavior.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `reset_default_graph` does not work with either eager execution or\n",
      "        `tf.function`, and you should not invoke it directly. To migrate code that\n",
      "        uses Graph-related functions to TF2, rewrite the code without them. See the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate) for more\n",
      "        description about the behavior and semantic changes between Tensorflow 1 and\n",
      "        Tensorflow 2.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          AssertionError: If this function is called within a nested graph.\n",
      "    \n",
      "    reshape(tensor, shape, name=None)\n",
      "        Reshapes a tensor.\n",
      "        \n",
      "        Given `tensor`, this operation returns a new `tf.Tensor` that has the same\n",
      "        values as `tensor` in the same order, except with a new shape given by\n",
      "        `shape`.\n",
      "        \n",
      "        >>> t1 = [[1, 2, 3],\n",
      "        ...       [4, 5, 6]]\n",
      "        >>> print(tf.shape(t1).numpy())\n",
      "        [2 3]\n",
      "        >>> t2 = tf.reshape(t1, [6])\n",
      "        >>> t2\n",
      "        <tf.Tensor: shape=(6,), dtype=int32,\n",
      "          numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "        >>> tf.reshape(t2, [3, 2])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        \n",
      "        The `tf.reshape` does not change the order of or the total number of elements\n",
      "        in the tensor, and so it can reuse the underlying data buffer. This makes it\n",
      "        a fast operation independent of how big of a tensor it is operating on.\n",
      "        \n",
      "        >>> tf.reshape([1, 2, 3], [2, 2])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError: Input to reshape is a tensor with 3 values, but the\n",
      "        requested shape has 4\n",
      "        \n",
      "        To instead reorder the data to rearrange the dimensions of a tensor, see\n",
      "        `tf.transpose`.\n",
      "        \n",
      "        >>> t = [[1, 2, 3],\n",
      "        ...      [4, 5, 6]]\n",
      "        >>> tf.reshape(t, [3, 2]).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        >>> tf.transpose(t, perm=[1, 0]).numpy()\n",
      "        array([[1, 4],\n",
      "               [2, 5],\n",
      "               [3, 6]], dtype=int32)\n",
      "        \n",
      "        If one component of `shape` is the special value -1, the size of that\n",
      "        dimension is computed so that the total size remains constant.  In particular,\n",
      "        a `shape` of `[-1]` flattens into 1-D.  At most one component of `shape` can\n",
      "        be -1.\n",
      "        \n",
      "        >>> t = [[1, 2, 3],\n",
      "        ...      [4, 5, 6]]\n",
      "        >>> tf.reshape(t, [-1])\n",
      "        <tf.Tensor: shape=(6,), dtype=int32,\n",
      "          numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "        >>> tf.reshape(t, [3, -1])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        >>> tf.reshape(t, [-1, 2])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        \n",
      "        `tf.reshape(t, [])` reshapes a tensor `t` with one element to a scalar.\n",
      "        \n",
      "        >>> tf.reshape([7], []).numpy()\n",
      "        7\n",
      "        \n",
      "        More examples:\n",
      "        \n",
      "        >>> t = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [9]\n",
      "        >>> tf.reshape(t, [3, 3])\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[1, 2, 3],\n",
      "                 [4, 5, 6],\n",
      "                 [7, 8, 9]], dtype=int32)>\n",
      "        \n",
      "        >>> t = [[[1, 1], [2, 2]],\n",
      "        ...      [[3, 3], [4, 4]]]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [2 2 2]\n",
      "        >>> tf.reshape(t, [2, 4])\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "          array([[1, 1, 2, 2],\n",
      "                 [3, 3, 4, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> t = [[[1, 1, 1],\n",
      "        ...       [2, 2, 2]],\n",
      "        ...      [[3, 3, 3],\n",
      "        ...       [4, 4, 4]],\n",
      "        ...      [[5, 5, 5],\n",
      "        ...       [6, 6, 6]]]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [3 2 3]\n",
      "        >>> # Pass '[-1]' to flatten 't'.\n",
      "        >>> tf.reshape(t, [-1])\n",
      "        <tf.Tensor: shape=(18,), dtype=int32,\n",
      "          numpy=array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n",
      "          dtype=int32)>\n",
      "        >>> # -- Using -1 to infer the shape --\n",
      "        >>> # Here -1 is inferred to be 9:\n",
      "        >>> tf.reshape(t, [2, -1])\n",
      "        <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "          array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                 [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "        >>> # -1 is inferred to be 2:\n",
      "        >>> tf.reshape(t, [-1, 9])\n",
      "        <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "          array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                 [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "        >>> # -1 is inferred to be 3:\n",
      "        >>> tf.reshape(t, [ 2, -1, 3])\n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=\n",
      "          array([[[1, 1, 1],\n",
      "                  [2, 2, 2],\n",
      "                  [3, 3, 3]],\n",
      "                 [[4, 4, 4],\n",
      "                  [5, 5, 5],\n",
      "                  [6, 6, 6]]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Defines the shape of the output tensor.\n",
      "          name: Optional string. A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    resource_variables_enabled() -> bool\n",
      "        Returns `True` if resource variables are enabled.\n",
      "        \n",
      "        Resource variables are improved versions of TensorFlow variables with a\n",
      "        well-defined memory model. Accessing a resource variable reads its value, and\n",
      "        all ops which access a specific read value of the variable are guaranteed to\n",
      "        see the same value for that tensor. Writes which happen after a read (by\n",
      "        having a control or data dependency on the read) are guaranteed not to affect\n",
      "        the value of the read tensor, and similarly writes which happen before a read\n",
      "        are guaranteed to affect the value. No guarantees are made about unordered\n",
      "        read/write pairs.\n",
      "        \n",
      "        Calling tf.enable_resource_variables() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "    \n",
      "    reverse = reverse_v2(tensor: Annotated[Any, ~TV_ReverseV2_T], axis: Annotated[Any, ~TV_ReverseV2_Tidx], name=None) -> Annotated[Any, ~TV_ReverseV2_T]\n",
      "        Reverses specific dimensions of a tensor.\n",
      "        \n",
      "        Given a `tensor`, and a `int32` tensor `axis` representing the set of\n",
      "        dimensions of `tensor` to reverse. This operation reverses each dimension\n",
      "        `i` for which there exists `j` s.t. `axis[j] == i`.\n",
      "        \n",
      "        `tensor` can have up to 8 dimensions. The number of dimensions specified\n",
      "        in `axis` may be 0 or more entries. If an index is specified more than\n",
      "        once, a InvalidArgument error is raised.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 't' is [[[[ 0,  1,  2,  3],\n",
      "        #                  [ 4,  5,  6,  7],\n",
      "        #                  [ 8,  9, 10, 11]],\n",
      "        #                 [[12, 13, 14, 15],\n",
      "        #                  [16, 17, 18, 19],\n",
      "        #                  [20, 21, 22, 23]]]]\n",
      "        # tensor 't' shape is [1, 2, 3, 4]\n",
      "        \n",
      "        # 'dims' is [3] or 'dims' is [-1]\n",
      "        reverse(t, dims) ==> [[[[ 3,  2,  1,  0],\n",
      "                                [ 7,  6,  5,  4],\n",
      "                                [ 11, 10, 9, 8]],\n",
      "                               [[15, 14, 13, 12],\n",
      "                                [19, 18, 17, 16],\n",
      "                                [23, 22, 21, 20]]]]\n",
      "        \n",
      "        # 'dims' is '[1]' (or 'dims' is '[-3]')\n",
      "        reverse(t, dims) ==> [[[[12, 13, 14, 15],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [20, 21, 22, 23]\n",
      "                               [[ 0,  1,  2,  3],\n",
      "                                [ 4,  5,  6,  7],\n",
      "                                [ 8,  9, 10, 11]]]]\n",
      "        \n",
      "        # 'dims' is '[2]' (or 'dims' is '[-2]')\n",
      "        reverse(t, dims) ==> [[[[8, 9, 10, 11],\n",
      "                                [4, 5, 6, 7],\n",
      "                                [0, 1, 2, 3]]\n",
      "                               [[20, 21, 22, 23],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [12, 13, 14, 15]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `int64`, `uint64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.\n",
      "            Up to 8-D.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. The indices of the dimensions to reverse. Must be in the range\n",
      "            `[-rank(tensor), rank(tensor))`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    reverse_sequence(input, seq_lengths, seq_axis=None, batch_axis=None, name=None, seq_dim=None, batch_dim=None)\n",
      "        Reverses variable length slices. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(seq_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        seq_dim is deprecated, use seq_axis instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(batch_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        batch_dim is deprecated, use batch_axis instead\n",
      "        \n",
      "        This op first slices `input` along the dimension `batch_axis`, and for\n",
      "        each slice `i`, reverses the first `seq_lengths[i]` elements along the\n",
      "        dimension `seq_axis`.\n",
      "        \n",
      "        The elements of `seq_lengths` must obey `seq_lengths[i] <=\n",
      "        input.dims[seq_axis]`, and `seq_lengths` must be a vector of length\n",
      "        `input.dims[batch_axis]`.\n",
      "        \n",
      "        The output slice `i` along dimension `batch_axis` is then given by\n",
      "        input slice `i`, with the first `seq_lengths[i]` slices along\n",
      "        dimension `seq_axis` reversed.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> seq_lengths = [7, 2, 3, 5]\n",
      "        >>> input = [[1, 2, 3, 4, 5, 0, 0, 0], [1, 2, 0, 0, 0, 0, 0, 0],\n",
      "        ...          [1, 2, 3, 4, 0, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7, 8]]\n",
      "        >>> output = tf.reverse_sequence(input, seq_lengths, seq_axis=1, batch_axis=0)\n",
      "        >>> output\n",
      "        <tf.Tensor: shape=(4, 8), dtype=int32, numpy=\n",
      "        array([[0, 0, 5, 4, 3, 2, 1, 0],\n",
      "               [2, 1, 0, 0, 0, 0, 0, 0],\n",
      "               [3, 2, 1, 4, 0, 0, 0, 0],\n",
      "               [5, 4, 3, 2, 1, 6, 7, 8]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The input to reverse.\n",
      "          seq_lengths: A `Tensor`. Must be one of the following types: `int32`,\n",
      "            `int64`. 1-D with length `input.dims(batch_axis)` and `max(seq_lengths) <=\n",
      "            input.dims(seq_axis)`\n",
      "          seq_axis: An `int`. The dimension which is partially reversed.\n",
      "          batch_axis: An optional `int`. Defaults to `0`. The dimension along which\n",
      "            reversal is performed.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor. Has the same type as input.\n",
      "    \n",
      "    reverse_v2(tensor: Annotated[Any, ~TV_ReverseV2_T], axis: Annotated[Any, ~TV_ReverseV2_Tidx], name=None) -> Annotated[Any, ~TV_ReverseV2_T]\n",
      "        Reverses specific dimensions of a tensor.\n",
      "        \n",
      "        Given a `tensor`, and a `int32` tensor `axis` representing the set of\n",
      "        dimensions of `tensor` to reverse. This operation reverses each dimension\n",
      "        `i` for which there exists `j` s.t. `axis[j] == i`.\n",
      "        \n",
      "        `tensor` can have up to 8 dimensions. The number of dimensions specified\n",
      "        in `axis` may be 0 or more entries. If an index is specified more than\n",
      "        once, a InvalidArgument error is raised.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 't' is [[[[ 0,  1,  2,  3],\n",
      "        #                  [ 4,  5,  6,  7],\n",
      "        #                  [ 8,  9, 10, 11]],\n",
      "        #                 [[12, 13, 14, 15],\n",
      "        #                  [16, 17, 18, 19],\n",
      "        #                  [20, 21, 22, 23]]]]\n",
      "        # tensor 't' shape is [1, 2, 3, 4]\n",
      "        \n",
      "        # 'dims' is [3] or 'dims' is [-1]\n",
      "        reverse(t, dims) ==> [[[[ 3,  2,  1,  0],\n",
      "                                [ 7,  6,  5,  4],\n",
      "                                [ 11, 10, 9, 8]],\n",
      "                               [[15, 14, 13, 12],\n",
      "                                [19, 18, 17, 16],\n",
      "                                [23, 22, 21, 20]]]]\n",
      "        \n",
      "        # 'dims' is '[1]' (or 'dims' is '[-3]')\n",
      "        reverse(t, dims) ==> [[[[12, 13, 14, 15],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [20, 21, 22, 23]\n",
      "                               [[ 0,  1,  2,  3],\n",
      "                                [ 4,  5,  6,  7],\n",
      "                                [ 8,  9, 10, 11]]]]\n",
      "        \n",
      "        # 'dims' is '[2]' (or 'dims' is '[-2]')\n",
      "        reverse(t, dims) ==> [[[[8, 9, 10, 11],\n",
      "                                [4, 5, 6, 7],\n",
      "                                [0, 1, 2, 3]]\n",
      "                               [[20, 21, 22, 23],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [12, 13, 14, 15]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `int64`, `uint64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.\n",
      "            Up to 8-D.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. The indices of the dimensions to reverse. Must be in the range\n",
      "            `[-rank(tensor), rank(tensor))`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    rfftnd(input: Annotated[Any, ~TV_RFFTND_Treal], fft_length: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], axes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], Tcomplex: ~TV_RFFTND_Tcomplex = tf.complex64, name=None) -> Annotated[Any, ~TV_RFFTND_Tcomplex]\n",
      "        ND fast real Fourier transform.\n",
      "        \n",
      "        Computes the n-dimensional real discrete Fourier transform over designated\n",
      "        dimensions of `input`. The designated dimensions of `input` are assumed to be\n",
      "        the result of `RFFTND`. The length of the last axis transformed will be\n",
      "        fft_length[-1]//2+1.\n",
      "        \n",
      "        If fft_length[i]<shape(input)[i], the input is cropped. If\n",
      "        fft_length[i]>shape(input)[i], the input is padded with zeros. If fft_length\n",
      "        is not given, the default shape(input) is used.\n",
      "        \n",
      "        Axes mean the dimensions to perform the transform on. Default is to perform on\n",
      "        all axes.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "            A complex tensor.\n",
      "          fft_length: A `Tensor` of type `int32`.\n",
      "            An int32 tensor. The FFT length for each dimension.\n",
      "          axes: A `Tensor` of type `int32`.\n",
      "            An int32 tensor with a same shape as fft_length. Axes to perform the transform.\n",
      "          Tcomplex: An optional `tf.DType` from: `tf.complex64, tf.complex128`. Defaults to `tf.complex64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `Tcomplex`.\n",
      "    \n",
      "    rint(x: typing.Annotated[_any, ~TV_Rint_T], name=None) -> typing.Annotated[_any, ~TV_Rint_T]\n",
      "        Returns element-wise integer closest to x.\n",
      "        \n",
      "        If the result is midway between two representable values,\n",
      "        the even representable is chosen.\n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        rint(-1.5) ==> -2.0\n",
      "        rint(0.5000001) ==> 1.0\n",
      "        rint([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) ==> [-2., -2., -0., 0., 2., 2., 2.]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    roll(input, shift, axis, name=None)\n",
      "        Rolls the elements of a tensor along an axis.\n",
      "        \n",
      "        The elements are shifted positively (towards larger indices) by the offset of\n",
      "        `shift` along the dimension of `axis`. Negative `shift` values will shift\n",
      "        elements in the opposite direction. Elements that roll passed the last position\n",
      "        will wrap around to the first and vice versa. Multiple shifts along multiple\n",
      "        axes may be specified.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # 't' is [0, 1, 2, 3, 4]\n",
      "        roll(t, shift=2, axis=0) ==> [3, 4, 0, 1, 2]\n",
      "        \n",
      "        # shifting along multiple dimensions\n",
      "        # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
      "        roll(t, shift=[1, -2], axis=[0, 1]) ==> [[7, 8, 9, 5, 6], [2, 3, 4, 0, 1]]\n",
      "        \n",
      "        # shifting along the same axis multiple times\n",
      "        # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
      "        roll(t, shift=[2, -3], axis=[1, 1]) ==> [[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          shift: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Dimension must be 0-D or 1-D. `shift[i]` specifies the number of places by which\n",
      "            elements are shifted positively (towards larger indices) along the dimension\n",
      "            specified by `axis[i]`. Negative shifts will roll the elements in the opposite\n",
      "            direction.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Dimension must be 0-D or 1-D. `axis[i]` specifies the dimension that the shift\n",
      "            `shift[i]` should occur. If the same axis is referenced more than once, the\n",
      "            total shift for that axis will be the sum of all the shifts that belong to that\n",
      "            axis.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    round(x, name=None)\n",
      "        Rounds the values of a tensor to the nearest integer, element-wise.\n",
      "        \n",
      "        Rounds half to even.  Also known as bankers rounding. If you want to round\n",
      "        according to the current system rounding mode use tf::cint.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0.9, 2.5, 2.3, 1.5, -4.5])\n",
      "        tf.round(x)  # [ 1.0, 2.0, 2.0, 2.0, -4.0 ]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, or `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of same shape and type as `x`.\n",
      "    \n",
      "    rsqrt(x, name=None)\n",
      "        Computes reciprocal of square root of x element-wise.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([2., 0., -2.])\n",
      "        >>> tf.math.rsqrt(x)\n",
      "        <tf.Tensor: shape=(3,), dtype=float32,\n",
      "        numpy=array([0.707, inf, nan], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    saturate_cast(value, dtype, name=None)\n",
      "        Performs a safe saturating cast of `value` to `dtype`.\n",
      "        \n",
      "        This function casts the input to `dtype` without overflow.  If\n",
      "        there is a danger that values would over or underflow in the cast, this op\n",
      "        applies the appropriate clamping before the cast.  See `tf.cast` for more\n",
      "        details.\n",
      "        \n",
      "        Args:\n",
      "          value: A `Tensor`.\n",
      "          dtype: The desired output `DType`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `value` safely cast to `dtype`.\n",
      "    \n",
      "    scalar_mul(scalar, x, name=None)\n",
      "        Multiplies a scalar times a `Tensor` or `IndexedSlices` object.\n",
      "        \n",
      "        This is a special case of `tf.math.multiply`, where the first value must be a\n",
      "        `scalar`. Unlike the general form of `tf.math.multiply`, this is operation is\n",
      "        guaranteed to be efficient for `tf.IndexedSlices`.\n",
      "        \n",
      "        >>> x = tf.reshape(tf.range(30, dtype=tf.float32), [10, 3])\n",
      "        >>> with tf.GradientTape() as g:\n",
      "        ...   g.watch(x)\n",
      "        ...   y = tf.gather(x, [1, 2])  # IndexedSlices\n",
      "        ...   z = tf.math.scalar_mul(10.0, y)\n",
      "        \n",
      "        Args:\n",
      "          scalar: A 0-D scalar `Tensor`. Must have known shape.\n",
      "          x: A `Tensor` or `IndexedSlices` to be scaled.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `scalar * x` of the same type (`Tensor` or `IndexedSlices`) as `x`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if scalar is not a 0-D `scalar`.\n",
      "    \n",
      "    scan(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, infer_shape=True, reverse=False, name=None)\n",
      "        scan on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        See also `tf.map_fn`.\n",
      "        \n",
      "        The simplest version of `scan` repeatedly applies the callable `fn` to a\n",
      "        sequence of elements from first to last. The elements are made of the tensors\n",
      "        unpacked from `elems` on dimension 0. The callable fn takes two tensors as\n",
      "        arguments. The first argument is the accumulated value computed from the\n",
      "        preceding invocation of fn, and the second is the value at the current\n",
      "        position of `elems`. If `initializer` is None, `elems` must contain at least\n",
      "        one element, and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `[len(values)] + fn(initializer, values[0]).shape`.\n",
      "        If reverse=True, it's fn(initializer, values[-1]).shape.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and accumulator.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The second argument of\n",
      "        `fn` must match the structure of `elems`.\n",
      "        \n",
      "        If no `initializer` is provided, the output structure and dtypes of `fn`\n",
      "        are assumed to be the same as its input; and in this case, the first\n",
      "        argument of `fn` must match the structure of `elems`.\n",
      "        \n",
      "        If an `initializer` is provided, then the output of `fn` must have the same\n",
      "        structure as `initializer`; and the first argument of `fn` must match\n",
      "        this structure.\n",
      "        \n",
      "        For example, if `elems` is `(t1, [t2, t3])` and `initializer` is\n",
      "        `[i1, i2]` then an appropriate signature for `fn` in `python2` is:\n",
      "        `fn = lambda (acc_p1, acc_p2), (t1, [t2, t3]):` and `fn` must return a list,\n",
      "        `[acc_n1, acc_n2]`.  An alternative correct signature for `fn`, and the\n",
      "         one that works in `python3`, is:\n",
      "        `fn = lambda a, t:`, where `a` and `t` correspond to the input tuples.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.  It accepts two arguments.  The first will\n",
      "            have the same structure as `initializer` if one is provided, otherwise it\n",
      "            will have the same structure as `elems`.  The second will have the same\n",
      "            (possibly nested) structure as `elems`.  Its output must have the same\n",
      "            structure as `initializer` if one is provided, otherwise it must have the\n",
      "            same structure as `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            initial value for the accumulator, and the expected output type of `fn`.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "          reverse: (optional) True scans the tensor last to first (instead of first to\n",
      "            last).\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors.  Each tensor packs the\n",
      "          results of applying `fn` to tensors unpacked from `elems` along the first\n",
      "          dimension, and the previous accumulator value(s), from first to last (or\n",
      "          last to first, if `reverse=True`).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable or the structure of the output of\n",
      "            `fn` and `initializer` do not match.\n",
      "          ValueError: if the lengths of the output of `fn` and `initializer`\n",
      "            do not match.\n",
      "        \n",
      "        Examples:\n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          sum = scan(lambda a, x: a + x, elems)\n",
      "          # sum == [1, 3, 6, 10, 15, 21]\n",
      "          sum = scan(lambda a, x: a + x, elems, reverse=True)\n",
      "          # sum == [21, 20, 18, 15, 11, 6]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          initializer = np.array(0)\n",
      "          sum_one = scan(\n",
      "              lambda a, x: x[0] - x[1] + a, (elems + 1, elems), initializer)\n",
      "          # sum_one == [1, 2, 3, 4, 5, 6]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 0, 0, 0, 0, 0])\n",
      "          initializer = (np.array(0), np.array(1))\n",
      "          fibonaccis = scan(lambda a, _: (a[1], a[0] + a[1]), elems, initializer)\n",
      "          # fibonaccis == ([1, 1, 2, 3, 5, 8], [1, 2, 3, 5, 8, 13])\n",
      "          ```\n",
      "    \n",
      "    scatter_add(ref, indices, updates, use_locking=False, name=None)\n",
      "        Adds sparse updates to the variable referenced by `resource`.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] += updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] += updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the updated value.\n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions add.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A `Variable`.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to store in `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the updated values after the update is done.\n",
      "    \n",
      "    scatter_div(ref, indices, updates, use_locking=False, name=None)\n",
      "        Divides a variable reference by sparse updates.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] /= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] /= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions divide.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of values\n",
      "            that `ref` is divided by.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the operation\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_max(ref, indices, updates, use_locking=False, name=None)\n",
      "        Reduces sparse updates into a variable reference using the `max` operation.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = max(ref[indices, ...], updates[...])\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...],\n",
      "            updates[i, ..., j, ...])\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions combine.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterAdd.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `half`,\n",
      "            `bfloat16`, `float32`, `float64`, `int32`, `int64`. Should be from a\n",
      "            `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to reduce into `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the update\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_min(ref, indices, updates, use_locking=False, name=None)\n",
      "        Reduces sparse updates into a variable reference using the `min` operation.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = min(ref[indices, ...], updates[...])\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...],\n",
      "            updates[i, ..., j, ...])\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions combine.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterAdd.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `half`,\n",
      "            `bfloat16`, `float32`, `float64`, `int32`, `int64`. Should be from a\n",
      "            `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to reduce into `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the update\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_mul(ref, indices, updates, use_locking=False, name=None)\n",
      "        Multiplies sparse updates into a variable reference.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] *= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] *= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions multiply.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to multiply to `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the operation\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd(indices: Annotated[Any, ~TV_ScatterNd_Tindices], updates: Annotated[Any, ~TV_ScatterNd_T], shape: Annotated[Any, ~TV_ScatterNd_Tindices], name=None) -> Annotated[Any, ~TV_ScatterNd_T]\n",
      "        Scatters `updates` into a tensor of shape `shape` according to `indices`.\n",
      "        \n",
      "        Scatter sparse `updates` according to individual values at the specified\n",
      "        `indices`. This op returns an output tensor with the `shape` you specify. This\n",
      "        op is the inverse of the `tf.gather_nd` operator which extracts values or slices\n",
      "        from a given tensor.\n",
      "        \n",
      "        This operation is similar to `tf.tensor_scatter_nd_add`, except that the tensor\n",
      "        is zero-initialized. Calling `tf.scatter_nd(indices, updates, shape)`\n",
      "        is identical to calling\n",
      "        `tf.tensor_scatter_nd_add(tf.zeros(shape, updates.dtype), indices, updates)`\n",
      "        \n",
      "        If `indices` contains duplicates, the associated `updates` are accumulated\n",
      "        (summed) into the output tensor.\n",
      "        \n",
      "        **WARNING**: For floating-point data types, the output may be nondeterministic.\n",
      "        This is because the order in which the updates are applied is nondeterministic\n",
      "        and when floating-point numbers are added in different orders the resulting\n",
      "        numerical approximation error can be slightly different. However, the output\n",
      "        will be deterministic if op determinism is enabled via\n",
      "        `tf.config.experimental.enable_op_determinism`.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into the output tensor. The\n",
      "        last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices of elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.\n",
      "        \n",
      "        `updates` is a tensor with shape:\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of the scatter op is to insert individual elements in\n",
      "        a tensor by index. Consider an example where you want to insert 4 scattered\n",
      "        elements in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd1.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            shape = tf.constant([8])\n",
      "            scatter = tf.scatter_nd(indices, updates, shape)\n",
      "            print(scatter)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [0, 11, 0, 10, 9, 0, 0, 12]\n",
      "        \n",
      "        You can also insert entire slices of a higher rank tensor all at once. For\n",
      "        example, you can insert two slices in the first dimension of a rank-3 tensor\n",
      "        with two matrices of new values.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd2.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[1], [3]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            shape = tf.constant([4, 4, 4])\n",
      "            scatter = tf.scatter_nd(indices, updates, shape)\n",
      "            print(scatter)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "             [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            Tensor of indices.\n",
      "          updates: A `Tensor`. Values to scatter into the output tensor.\n",
      "          shape: A `Tensor`. Must have the same type as `indices`.\n",
      "            1-D. The shape of the output tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `updates`.\n",
      "    \n",
      "    scatter_nd_add(ref, indices, updates, use_locking=False, name=None)\n",
      "        Applies sparse addition to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "        8 elements. In Python, that addition would look like this:\n",
      "        \n",
      "        ```python\n",
      "        ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "        indices = tf.constant([[4], [3], [1], [7]])\n",
      "        updates = tf.constant([9, 10, 11, 12])\n",
      "        add = tf.compat.v1.scatter_nd_add(ref, indices, updates)\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print sess.run(add)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, 13, 3, 14, 14, 6, 7, 20]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. A mutable Tensor. Should be from a Variable node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd_sub(ref, indices, updates, use_locking=False, name=None)\n",
      "        Applies sparse subtraction to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to subtract 4 scattered elements from a rank-1 tensor\n",
      "        with 8 elements. In Python, that update would look like this:\n",
      "        \n",
      "        ```python\n",
      "        ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "        indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "        updates = tf.constant([9, 10, 11, 12])\n",
      "        op = tf.compat.v1.scatter_nd_sub(ref, indices, updates)\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print sess.run(op)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, -9, 3, -6, -6, 6, 7, -4]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. A mutable Tensor. Should be from a Variable node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            An optional bool. Defaults to True. If True, the assignment will\n",
      "            be protected by a lock; otherwise the behavior is undefined,\n",
      "            but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Applies sparse `updates` to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to update 4 scattered elements to a rank-1 tensor to\n",
      "        8 elements. In Python, that update would look like this:\n",
      "        \n",
      "        ```python\n",
      "            ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "            indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            update = tf.compat.v1.scatter_nd_update(ref, indices, updates)\n",
      "            with tf.compat.v1.Session() as sess:\n",
      "              print sess.run(update)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, 11, 3, 10, 9, 6, 7, 12]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A Variable.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A Tensor. Must have the same type as ref. A tensor of updated\n",
      "            values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `True`.\n",
      "            An optional bool. Defaults to True. If True, the assignment will\n",
      "            be protected by a lock; otherwise the behavior is undefined,\n",
      "            but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The value of the variable after the update.\n",
      "    \n",
      "    scatter_sub(ref, indices, updates, use_locking=False, name=None)\n",
      "        Subtracts sparse updates to a variable reference.\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] -= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] -= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their (negated) contributions add.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or\n",
      "        `updates.shape = []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\"\n",
      "             src=\"https://www.tensorflow.org/images/ScatterSub.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to subtract from `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the subtraction will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Applies sparse updates to a variable reference.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        If values in `ref` is to be updated more than once, because there are\n",
      "        duplicate entries in `indices`, the order at which the updates happen\n",
      "        for each value is undefined.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterUpdate.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A `Variable`.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to store in `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `True`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the updated values after the update is done.\n",
      "    \n",
      "    searchsorted(sorted_sequence, values, side='left', out_type=tf.int32, name=None)\n",
      "        Searches for where a value would go in a sorted sequence.\n",
      "        \n",
      "        This is not a method for checking containment (like python `in`).\n",
      "        \n",
      "        The typical use case for this operation is \"binning\", \"bucketing\", or\n",
      "        \"discretizing\". The `values` are assigned to bucket-indices based on the\n",
      "        **edges** listed in `sorted_sequence`. This operation\n",
      "        returns the bucket-index for each value.\n",
      "        \n",
      "        >>> edges = [-1, 3.3, 9.1, 10.0]\n",
      "        >>> values = [0.0, 4.1, 12.0]\n",
      "        >>> tf.searchsorted(edges, values).numpy()\n",
      "        array([1, 2, 4], dtype=int32)\n",
      "        \n",
      "        The `side` argument controls which index is returned if a value lands exactly\n",
      "        on an edge:\n",
      "        \n",
      "        >>> seq = [0, 3, 9, 10, 10]\n",
      "        >>> values = [0, 4, 10]\n",
      "        >>> tf.searchsorted(seq, values).numpy()\n",
      "        array([0, 2, 3], dtype=int32)\n",
      "        >>> tf.searchsorted(seq, values, side=\"right\").numpy()\n",
      "        array([1, 2, 5], dtype=int32)\n",
      "        \n",
      "        The `axis` is not settable for this operation. It always operates on the\n",
      "        innermost dimension (`axis=-1`). The operation will accept any number of\n",
      "        outer dimensions. Here it is applied to the rows of a matrix:\n",
      "        \n",
      "        >>> sorted_sequence = [[0., 3., 8., 9., 10.],\n",
      "        ...                    [1., 2., 3., 4., 5.]]\n",
      "        >>> values = [[9.8, 2.1, 4.3],\n",
      "        ...           [0.1, 6.6, 4.5, ]]\n",
      "        >>> tf.searchsorted(sorted_sequence, values).numpy()\n",
      "        array([[4, 1, 2],\n",
      "               [0, 5, 4]], dtype=int32)\n",
      "        \n",
      "        Note: This operation assumes that `sorted_sequence` **is sorted** along the\n",
      "        innermost axis, maybe using `tf.sort(..., axis=-1)`. **If the sequence is not\n",
      "        sorted, no error is raised** and the content of the returned tensor is not well\n",
      "        defined.\n",
      "        \n",
      "        Args:\n",
      "          sorted_sequence: N-D `Tensor` containing a sorted sequence.\n",
      "          values: N-D `Tensor` containing the search values.\n",
      "          side: 'left' or 'right'; 'left' corresponds to lower_bound and 'right' to\n",
      "            upper_bound.\n",
      "          out_type: The output type (`int32` or `int64`).  Default is `tf.int32`.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          An N-D `Tensor` the size of `values` containing the result of applying\n",
      "          either lower_bound or upper_bound (depending on side) to each value.  The\n",
      "          result is not a global index to the entire `Tensor`, but the index in the\n",
      "          last dimension.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the last dimension of `sorted_sequence >= 2^31-1` elements.\n",
      "                      If the total size of `values` exceeds `2^31 - 1` elements.\n",
      "                      If the first `N-1` dimensions of the two tensors don't match.\n",
      "    \n",
      "    segment_max(data: typing.Annotated[_any, ~TV_SegmentMax_T], segment_ids: typing.Annotated[_any, ~TV_SegmentMax_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentMax_T]\n",
      "        Computes the maximum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\max_j(data_j)\\\\) where `max` is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the max is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as the same as a smaller following index.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMax.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_max(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[4, 3, 3, 4],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_mean(data: typing.Annotated[_any, ~TV_SegmentMean_T], segment_ids: typing.Annotated[_any, ~TV_SegmentMean_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentMean_T]\n",
      "        Computes the mean along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\frac{\\sum_j data_j}{N}\\\\) where `mean` is\n",
      "        over `j` such that `segment_ids[j] == i` and `N` is the total number of\n",
      "        values summed.\n",
      "        \n",
      "        If the mean is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as a smaller following index when computing the numerator\n",
      "        of the mean.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMean.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1.0,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_mean(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[2.5, 2.5, 2.5, 2.5],\n",
      "               [5., 6., 7., 8.]], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_min(data: typing.Annotated[_any, ~TV_SegmentMin_T], segment_ids: typing.Annotated[_any, ~TV_SegmentMin_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentMin_T]\n",
      "        Computes the minimum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\min_j(data_j)\\\\) where `min` is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the min is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as the same as a smaller following index.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMin.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_min(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[1, 2, 2, 1],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_prod(data: typing.Annotated[_any, ~TV_SegmentProd_T], segment_ids: typing.Annotated[_any, ~TV_SegmentProd_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentProd_T]\n",
      "        Computes the product along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\prod_j data_j\\\\) where the product is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the product is empty for a given segment ID `i`, `output[i] = 1`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as the same as a smaller following index.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentProd.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_prod(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[4, 6, 6, 4],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_sum(data: typing.Annotated[_any, ~TV_SegmentSum_T], segment_ids: typing.Annotated[_any, ~TV_SegmentSum_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentSum_T]\n",
      "        Computes the sum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\sum_j data_j\\\\) where sum is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the sum is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as the same as a smaller following index.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentSum.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_sum(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[5, 5, 5, 5],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    self_adjoint_eig(tensor, name=None)\n",
      "        Computes the eigen decomposition of a batch of self-adjoint matrices.\n",
      "        \n",
      "        Computes the eigenvalues and eigenvectors of the innermost N-by-N matrices\n",
      "        in `tensor` such that\n",
      "        `tensor[...,:,:] * v[..., :,i] = e[..., i] * v[...,:,i]`, for i=0...N-1.\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., N, N]`. Only the lower triangular part of\n",
      "            each inner inner matrix is referenced.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          e: Eigenvalues. Shape is `[..., N]`. Sorted in non-decreasing order.\n",
      "          v: Eigenvectors. Shape is `[..., N, N]`. The columns of the inner most\n",
      "            matrices contain eigenvectors of the corresponding matrices in `tensor`\n",
      "    \n",
      "    self_adjoint_eigvals(tensor, name=None)\n",
      "        Computes the eigenvalues of one or more self-adjoint matrices.\n",
      "        \n",
      "        Note: If your program backpropagates through this function, you should replace\n",
      "        it with a call to tf.linalg.eigh (possibly ignoring the second output) to\n",
      "        avoid computing the eigen decomposition twice. This is because the\n",
      "        eigenvectors are used to compute the gradient w.r.t. the eigenvalues. See\n",
      "        _SelfAdjointEigV2Grad in linalg_grad.py.\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., N, N]`.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          e: Eigenvalues. Shape is `[..., N]`. The vector `e[..., :]` contains the `N`\n",
      "            eigenvalues of `tensor[..., :, :]`.\n",
      "    \n",
      "    sequence_mask(lengths, maxlen=None, dtype=tf.bool, name=None)\n",
      "        Returns a mask tensor representing the first N positions of each cell.\n",
      "        \n",
      "        If `lengths` has shape `[d_1, d_2, ..., d_n]` the resulting tensor `mask` has\n",
      "        dtype `dtype` and shape `[d_1, d_2, ..., d_n, maxlen]`, with\n",
      "        \n",
      "        ```\n",
      "        mask[i_1, i_2, ..., i_n, j] = (j < lengths[i_1, i_2, ..., i_n])\n",
      "        ```\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        tf.sequence_mask([1, 3, 2], 5)  # [[True, False, False, False, False],\n",
      "                                        #  [True, True, True, False, False],\n",
      "                                        #  [True, True, False, False, False]]\n",
      "        \n",
      "        tf.sequence_mask([[1, 3],[2,0]])  # [[[True, False, False],\n",
      "                                          #   [True, True, True]],\n",
      "                                          #  [[True, True, False],\n",
      "                                          #   [False, False, False]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          lengths: integer tensor, all its values <= maxlen.\n",
      "          maxlen: scalar integer tensor, size of last dimension of returned tensor.\n",
      "            Default is the maximum value in `lengths`.\n",
      "          dtype: output type of the resulting tensor.\n",
      "          name: name of the op.\n",
      "        \n",
      "        Returns:\n",
      "          A mask tensor of shape `lengths.shape + (maxlen,)`, cast to specified dtype.\n",
      "        Raises:\n",
      "          ValueError: if `maxlen` is not a scalar.\n",
      "    \n",
      "    serialize_many_sparse(sp_input, name=None, out_type=tf.string)\n",
      "        Serialize `N`-minibatch `SparseTensor` into an `[N, 3]` `Tensor`.\n",
      "        \n",
      "        The `SparseTensor` must have rank `R` greater than 1, and the first dimension\n",
      "        is treated as the minibatch dimension.  Elements of the `SparseTensor`\n",
      "        must be sorted in increasing order of this first dimension.  The serialized\n",
      "        `SparseTensor` objects going into each row of the output `Tensor` will have\n",
      "        rank `R-1`.\n",
      "        \n",
      "        The minibatch size `N` is extracted from `sparse_shape[0]`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input rank `R` `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          out_type: The `dtype` to use for serialization.\n",
      "        \n",
      "        Returns:\n",
      "          A matrix (2-D `Tensor`) with `N` rows and `3` columns. Each column\n",
      "          represents serialized `SparseTensor`'s indices, values, and shape\n",
      "          (respectively).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    serialize_sparse(sp_input, name=None, out_type=tf.string)\n",
      "        Serialize a `SparseTensor` into a 3-vector (1-D `Tensor`) object.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          out_type: The `dtype` to use for serialization.\n",
      "        \n",
      "        Returns:\n",
      "          A 3-vector (1-D `Tensor`), with each column representing the serialized\n",
      "          `SparseTensor`'s indices, values, and shape (respectively).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    serialize_tensor(tensor, name=None)\n",
      "        Transforms a Tensor into a serialized TensorProto proto.\n",
      "        \n",
      "        This operation transforms data in a `tf.Tensor` into a `tf.Tensor` of type\n",
      "        `tf.string` containing the data in a binary string in little-endian format.\n",
      "        This operation can transform scalar data and linear arrays, but it is most\n",
      "        useful in converting multidimensional arrays into a format accepted by binary\n",
      "        storage formats such as a `TFRecord` or `tf.train.Example`.\n",
      "        \n",
      "        See also:\n",
      "        - `tf.io.parse_tensor`: inverse operation of `tf.io.serialize_tensor` that\n",
      "        transforms a scalar string containing a serialized Tensor in little-endian\n",
      "        format into a Tensor of a specified type.\n",
      "        - `tf.ensure_shape`: `parse_tensor` cannot statically determine the shape of\n",
      "        the parsed tensor. Use `tf.ensure_shape` to set the static shape when running\n",
      "        under a `tf.function`\n",
      "        - `.SerializeToString`, serializes a proto to a binary-string\n",
      "        \n",
      "        Example of serializing scalar data:\n",
      "        \n",
      "        >>> t = tf.constant(1)\n",
      "        >>> tf.io.serialize_tensor(t)\n",
      "        <tf.Tensor: shape=(), dtype=string, numpy=b'\\x08...\\x00'>\n",
      "        \n",
      "        Example of storing non-scalar data into a `tf.train.Example`:\n",
      "        \n",
      "        >>> t1 = [[1, 2]]\n",
      "        >>> t2 = [[7, 8]]\n",
      "        >>> nonscalar = tf.concat([t1, t2], 0)\n",
      "        >>> nonscalar\n",
      "        <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "        array([[1, 2],\n",
      "               [7, 8]], dtype=int32)>\n",
      "        \n",
      "        Serialize the data using `tf.io.serialize_tensor`.\n",
      "        \n",
      "        >>> serialized_nonscalar = tf.io.serialize_tensor(nonscalar)\n",
      "        >>> serialized_nonscalar\n",
      "        <tf.Tensor: shape=(), dtype=string, numpy=b'\\x08...\\x00'>\n",
      "        \n",
      "        Store the data in a `tf.train.Feature`.\n",
      "        \n",
      "        >>> feature_of_bytes = tf.train.Feature(\n",
      "        ...   bytes_list=tf.train.BytesList(value=[serialized_nonscalar.numpy()]))\n",
      "        >>> feature_of_bytes\n",
      "        bytes_list {\n",
      "          value: \"\\010...\\000\"\n",
      "        }\n",
      "        \n",
      "        Put the `tf.train.Feature` message into a `tf.train.Example`.\n",
      "        \n",
      "        >>> features_for_example = {\n",
      "        ...   'feature0': feature_of_bytes\n",
      "        ... }\n",
      "        >>> example_proto = tf.train.Example(\n",
      "        ...   features=tf.train.Features(feature=features_for_example))\n",
      "        >>> example_proto\n",
      "        features {\n",
      "          feature {\n",
      "            key: \"feature0\"\n",
      "            value {\n",
      "              bytes_list {\n",
      "                value: \"\\010...\\000\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `tf.Tensor`.\n",
      "          name: string.  Optional name for the op.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor of dtype string.\n",
      "    \n",
      "    set_random_seed(seed)\n",
      "        Sets the graph-level random seed for the default graph.\n",
      "        \n",
      "        Operations that rely on a random seed actually derive it from two seeds:\n",
      "        the graph-level and operation-level seeds. This sets the graph-level seed.\n",
      "        \n",
      "        Its interactions with operation-level seeds is as follows:\n",
      "        \n",
      "          1. If neither the graph-level nor the operation seed is set:\n",
      "            A random seed is used for this op.\n",
      "          2. If the graph-level seed is set, but the operation seed is not:\n",
      "            The system deterministically picks an operation seed in conjunction with\n",
      "            the graph-level seed so that it gets a unique random sequence. Within the\n",
      "            same version of tensorflow and user code, this sequence is deterministic.\n",
      "            However across different versions, this sequence might change. If the\n",
      "            code depends on particular seeds to work, specify both graph-level\n",
      "            and operation-level seeds explicitly.\n",
      "          3. If the graph-level seed is not set, but the operation seed is set:\n",
      "            A default graph-level seed and the specified operation seed are used to\n",
      "            determine the random sequence.\n",
      "          4. If both the graph-level and the operation seed are set:\n",
      "            Both seeds are used in conjunction to determine the random sequence.\n",
      "        \n",
      "        To illustrate the user-visible effects, consider these examples:\n",
      "        \n",
      "        To generate different sequences across sessions, set neither\n",
      "        graph-level nor op-level seeds:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.random.uniform([1])\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A3'\n",
      "          print(sess2.run(a))  # generates 'A4'\n",
      "          print(sess2.run(b))  # generates 'B3'\n",
      "          print(sess2.run(b))  # generates 'B4'\n",
      "        ```\n",
      "        \n",
      "        To generate the same repeatable sequence for an op across sessions, set the\n",
      "        seed for the op:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.random.uniform([1], seed=1)\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        # Repeatedly running this block with the same graph will generate the same\n",
      "        # sequence of values for 'a', but different sequences of values for 'b'.\n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A1'\n",
      "          print(sess2.run(a))  # generates 'A2'\n",
      "          print(sess2.run(b))  # generates 'B3'\n",
      "          print(sess2.run(b))  # generates 'B4'\n",
      "        ```\n",
      "        \n",
      "        To make the random sequences generated by all ops be repeatable across\n",
      "        sessions, set a graph-level seed:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.random.set_random_seed(1234)\n",
      "        a = tf.random.uniform([1])\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        # Repeatedly running this block with the same graph will generate the same\n",
      "        # sequences of 'a' and 'b'.\n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A1'\n",
      "          print(sess2.run(a))  # generates 'A2'\n",
      "          print(sess2.run(b))  # generates 'B1'\n",
      "          print(sess2.run(b))  # generates 'B2'\n",
      "        ```\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        'tf.compat.v1.set_random_seed' is compatible with eager mode. However,\n",
      "        in eager mode this API will set the global seed instead of the\n",
      "        graph-level seed of the default graph. In TF2 this API is changed to\n",
      "        [tf.random.set_seed]\n",
      "        (https://www.tensorflow.org/api_docs/python/tf/random/set_seed).\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          seed: integer.\n",
      "    \n",
      "    setdiff1d(x, y, index_dtype=tf.int32, name=None)\n",
      "        Computes the difference between two lists of numbers or strings.\n",
      "        \n",
      "        Given a list `x` and a list `y`, this operation returns a list `out` that\n",
      "        represents all values that are in `x` but not in `y`. The returned list `out`\n",
      "        is sorted in the same order that the numbers appear in `x` (duplicates are\n",
      "        preserved). This operation also returns a list `idx` that represents the\n",
      "        position of each `out` element in `x`. In other words:\n",
      "        \n",
      "        `out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]`\n",
      "        \n",
      "        For example, given this input:\n",
      "        \n",
      "        ```\n",
      "        x = [1, 2, 3, 4, 5, 6]\n",
      "        y = [1, 3, 5]\n",
      "        ```\n",
      "        \n",
      "        This operation would return:\n",
      "        \n",
      "        ```\n",
      "        out ==> [2, 4, 6]\n",
      "        idx ==> [1, 3, 5]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D. Values to keep.\n",
      "          y: A `Tensor`. Must have the same type as `x`. 1-D. Values to remove.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (out, idx).\n",
      "        \n",
      "          out: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    shape(input, name=None, out_type=None)\n",
      "        Returns the shape of a tensor.\n",
      "        \n",
      "        This operation returns a 1-D integer tensor representing the shape of `input`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.shape(t)  # [2, 2, 3]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          out_type: (Optional) The specified output type of the operation (`int32`\n",
      "          or `int64`). Defaults to `tf.int32`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    shape_n(input, out_type=tf.int32, name=None)\n",
      "        Returns shape of a list of tensors.\n",
      "        \n",
      "        Given a list of tensors, `tf.shape_n` is much faster than applying `tf.shape`\n",
      "        to each tensor individually.\n",
      "        >>> a = tf.ones([1, 2])\n",
      "        >>> b = tf.ones([2, 3])\n",
      "        >>> c = tf.ones([3, 4])\n",
      "        >>> tf.shape_n([a, b, c])\n",
      "        [<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>,\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>,\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>]\n",
      "        \n",
      "        Args:\n",
      "          input: A list of at least 1 `Tensor` object with the same dtype.\n",
      "          out_type: The specified output type of the operation (`int32` or `int64`).\n",
      "            Defaults to `tf.int32`(optional).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` specifying the shape of each input tensor with type of\n",
      "          `out_type`.\n",
      "    \n",
      "    sigmoid(x, name=None)\n",
      "        Computes sigmoid of `x` element-wise.\n",
      "        \n",
      "        Formula for calculating $\\mathrm{sigmoid}(x) = y = 1 / (1 + \\exp(-x))$.\n",
      "        \n",
      "        For $x \\in (-\\infty, \\infty)$, $\\mathrm{sigmoid}(x) \\in (0, 1)$.\n",
      "        \n",
      "        Example Usage:\n",
      "        \n",
      "        If a positive number is large, then its sigmoid will approach to 1 since the\n",
      "        formula will be `y = <large_num> / (1 + <large_num>)`\n",
      "        \n",
      "        >>> x = tf.constant([0.0, 1.0, 50.0, 100.0])\n",
      "        >>> tf.math.sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32,\n",
      "        numpy=array([0.5, 0.7310586, 1.0, 1.0], dtype=float32)>\n",
      "        \n",
      "        If a negative number is large, its sigmoid will approach to 0 since the\n",
      "        formula will be `y = 1 / (1 + <large_num>)`\n",
      "        \n",
      "        >>> x = tf.constant([-100.0, -50.0, -1.0, 0.0])\n",
      "        >>> tf.math.sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
      "        array([0.0000000e+00, 1.9287499e-22, 2.6894143e-01, 0.5],\n",
      "              dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor with type `float16`, `float32`, `float64`, `complex64`, or\n",
      "            `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor with the same type as `x`.\n",
      "        \n",
      "        Usage Example:\n",
      "        \n",
      "        >>> x = tf.constant([-128.0, 0.0, 128.0], dtype=tf.float32)\n",
      "        >>> tf.sigmoid(x)\n",
      "        <tf.Tensor: shape=(3,), dtype=float32,\n",
      "        numpy=array([0. , 0.5, 1. ], dtype=float32)>\n",
      "        \n",
      "        @compatibility(scipy)\n",
      "        Equivalent to scipy.special.expit\n",
      "        @end_compatibility\n",
      "    \n",
      "    sign(x, name=None)\n",
      "        Returns an element-wise indication of the sign of a number.\n",
      "        \n",
      "        `y = sign(x) = -1 if x < 0; 0 if x == 0; 1 if x > 0`.\n",
      "        \n",
      "        For complex numbers, `y = sign(x) = x / |x| if x != 0, otherwise y = 0`.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> # real number\n",
      "        >>> tf.math.sign([0., 2., -3.])\n",
      "        <tf.Tensor: shape=(3,), dtype=float32,\n",
      "        numpy=array([ 0.,  1., -1.], dtype=float32)>\n",
      "        \n",
      "        >>> # complex number\n",
      "        >>> tf.math.sign([1 + 1j, 0 + 0j])\n",
      "        <tf.Tensor: shape=(2,), dtype=complex128,\n",
      "        numpy=array([0.70710678+0.70710678j, 0.        +0.j        ])>\n",
      "        \n",
      "        Args:\n",
      "         x: A Tensor. Must be one of the following types: bfloat16, half, float32,\n",
      "           float64, int32, int64, complex64, complex128.\n",
      "         name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "         A Tensor. Has the same type as x.\n",
      "        \n",
      "         If x is a SparseTensor, returns SparseTensor(x.indices,\n",
      "           tf.math.sign(x.values, ...), x.dense_shape).\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.sign(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    sin(x: typing.Annotated[_any, ~TV_Sin_T], name=None) -> typing.Annotated[_any, ~TV_Sin_T]\n",
      "        Computes sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes sine of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `[-1,1]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10, float(\"inf\")])\n",
      "          tf.math.sin(x) ==> [nan -0.4121185 -0.47942555 0.84147096 0.9320391 -0.87329733 -0.54402107 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    sinh(x: typing.Annotated[_any, ~TV_Sinh_T], name=None) -> typing.Annotated[_any, ~TV_Sinh_T]\n",
      "        Computes hyperbolic sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic sine of every\n",
      "          element in the tensor. Input range is `[-inf,inf]` and output range\n",
      "          is `[-inf,inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 2, 10, float(\"inf\")])\n",
      "          tf.math.sinh(x) ==> [-inf -4.0515420e+03 -5.2109528e-01 1.1752012e+00 1.5094614e+00 3.6268604e+00 1.1013232e+04 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    size(input, name=None, out_type=None)\n",
      "        Returns the size of a tensor.\n",
      "        \n",
      "        Returns a 0-D `Tensor` representing the number of elements in `input`\n",
      "        of type `out_type`. Defaults to tf.int32.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.size(t)  # 12\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          out_type: (Optional) The specified non-quantized numeric output type of the\n",
      "            operation. Defaults to `tf.int32`. (Note: there is an experimental\n",
      "            flag, `tf_shape_default_int64` that changes the default to `tf.int64`.\n",
      "            This is an unsupported, experimental setting that causes known breakages.)\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`. Defaults to `tf.int32`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.size()\n",
      "        @end_compatibility\n",
      "    \n",
      "    slice(input_, begin, size, name=None)\n",
      "        Extracts a slice from a tensor.\n",
      "        \n",
      "        See also `tf.strided_slice`.\n",
      "        \n",
      "        This operation extracts a slice of size `size` from a tensor `input_` starting\n",
      "        at the location specified by `begin`. The slice `size` is represented as a\n",
      "        tensor shape, where `size[i]` is the number of elements of the 'i'th dimension\n",
      "        of `input_` that you want to slice. The starting location (`begin`) for the\n",
      "        slice is represented as an offset in each dimension of `input_`. In other\n",
      "        words, `begin[i]` is the offset into the i'th dimension of `input_` that you\n",
      "        want to slice from.\n",
      "        \n",
      "        Note that `tf.Tensor.__getitem__` is typically a more pythonic way to\n",
      "        perform slices, as it allows you to write `foo[3:7, :-2]` instead of\n",
      "        `tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2])`.\n",
      "        \n",
      "        `begin` is zero-based; `size` is one-based. If `size[i]` is -1,\n",
      "        all remaining elements in dimension i are included in the\n",
      "        slice. In other words, this is equivalent to setting:\n",
      "        \n",
      "        `size[i] = input_.dim_size(i) - begin[i]`\n",
      "        \n",
      "        This operation requires that:\n",
      "        \n",
      "        `0 <= begin[i] <= begin[i] + size[i] <= Di  for i in [0, n]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
      "                         [[3, 3, 3], [4, 4, 4]],\n",
      "                         [[5, 5, 5], [6, 6, 6]]])\n",
      "        tf.slice(t, [1, 0, 0], [1, 1, 3])  # [[[3, 3, 3]]]\n",
      "        tf.slice(t, [1, 0, 0], [1, 2, 3])  # [[[3, 3, 3],\n",
      "                                           #   [4, 4, 4]]]\n",
      "        tf.slice(t, [1, 0, 0], [2, 1, 3])  # [[[3, 3, 3]],\n",
      "                                           #  [[5, 5, 5]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_: A `Tensor`.\n",
      "          begin: An `int32` or `int64` `Tensor`.\n",
      "          size: An `int32` or `int64` `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` the same type as `input_`.\n",
      "    \n",
      "    sort(values, axis=-1, direction='ASCENDING', name=None)\n",
      "        Sorts a tensor.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        >>> a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        >>> tf.sort(a).numpy()\n",
      "        array([  1.  ,   2.8 ,  10.  ,  26.9 ,  62.3 , 166.32], dtype=float32)\n",
      "        \n",
      "        >>> tf.sort(a, direction='DESCENDING').numpy()\n",
      "        array([166.32,  62.3 ,  26.9 ,  10.  ,   2.8 ,   1.  ], dtype=float32)\n",
      "        \n",
      "        For multidimensional inputs you can control which axis the sort is applied\n",
      "        along. The default `axis=-1` sorts the innermost axis.\n",
      "        \n",
      "        >>> mat = [[3,2,1],\n",
      "        ...        [2,1,3],\n",
      "        ...        [1,3,2]]\n",
      "        >>> tf.sort(mat, axis=-1).numpy()\n",
      "        array([[1, 2, 3],\n",
      "               [1, 2, 3],\n",
      "               [1, 2, 3]], dtype=int32)\n",
      "        >>> tf.sort(mat, axis=0).numpy()\n",
      "        array([[1, 1, 1],\n",
      "               [2, 2, 2],\n",
      "               [3, 3, 3]], dtype=int32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "          * `tf.argsort`: Like sort, but it returns the sort indices.\n",
      "          * `tf.math.top_k`: A partial sort that returns a fixed number of top values\n",
      "            and corresponding indices.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          values: 1-D or higher **numeric** `Tensor`.\n",
      "          axis: The axis along which to sort. The default is -1, which sorts the last\n",
      "            axis.\n",
      "          direction: The direction in which to sort the values (`'ASCENDING'` or\n",
      "            `'DESCENDING'`).\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same dtype and shape as `values`, with the elements\n",
      "              sorted along the given `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          tf.errors.InvalidArgumentError: If the `values.dtype` is not a `float` or\n",
      "              `int` type.\n",
      "          ValueError: If axis is not a constant scalar, or the direction is invalid.\n",
      "    \n",
      "    space_to_batch(input, paddings, block_size=None, name=None, block_shape=None)\n",
      "        SpaceToBatch for 4-D tensors of type T.\n",
      "        \n",
      "        This is a legacy version of the more general SpaceToBatchND.\n",
      "        \n",
      "        Zero-pads and then rearranges (permutes) blocks of spatial data into batch.\n",
      "        More specifically, this op outputs a copy of the input tensor where values from\n",
      "        the `height` and `width` dimensions are moved to the `batch` dimension. After\n",
      "        the zero-padding, both `height` and `width` of the input must be divisible by the\n",
      "        block size.\n",
      "        \n",
      "        The attr `block_size` must be greater than one. It indicates the block size.\n",
      "        \n",
      "          * Non-overlapping blocks of size `block_size x block size` in the height and\n",
      "            width dimensions are rearranged into the batch dimension at each location.\n",
      "          * The batch of the output tensor is `batch * block_size * block_size`.\n",
      "          * Both height_pad and width_pad must be divisible by block_size.\n",
      "        \n",
      "        The shape of the output will be:\n",
      "        \n",
      "            [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,\n",
      "             depth]\n",
      "        \n",
      "        Some examples:\n",
      "        \n",
      "        (1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [2]], [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "        ```\n",
      "        \n",
      "        (2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 3]` and value:\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "              [[5],   [6],  [7],  [8]],\n",
      "              [[9],  [10], [11],  [12]],\n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 2, 2, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [3]], [[9], [11]]],\n",
      "             [[[2], [4]], [[10], [12]]],\n",
      "             [[[5], [7]], [[13], [15]]],\n",
      "             [[[6], [8]], [[14], [16]]]]\n",
      "        ```\n",
      "        \n",
      "        (4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "              [[5],   [6],  [7],  [8]]],\n",
      "             [[[9],  [10], [11],  [12]],\n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[8, 1, 2, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],\n",
      "             [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]\n",
      "        ```\n",
      "        \n",
      "        Among others, this operation is useful for reducing atrous convolution into\n",
      "        regular convolution.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. 4-D with shape `[batch, height, width, depth]`.\n",
      "          paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D tensor of non-negative integers with shape `[2, 2]`. It specifies\n",
      "              the padding of the input with zeros across the spatial dimensions as follows:\n",
      "        \n",
      "                  paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]\n",
      "        \n",
      "              The effective spatial dimensions of the zero-padded input tensor will be:\n",
      "        \n",
      "                  height_pad = pad_top + height + pad_bottom\n",
      "                  width_pad = pad_left + width + pad_right\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    space_to_batch_nd(input: Annotated[Any, ~TV_SpaceToBatchND_T], block_shape: Annotated[Any, ~TV_SpaceToBatchND_Tblock_shape], paddings: Annotated[Any, ~TV_SpaceToBatchND_Tpaddings], name=None) -> Annotated[Any, ~TV_SpaceToBatchND_T]\n",
      "        SpaceToBatch for N-D tensors of type T.\n",
      "        \n",
      "        This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into a\n",
      "        grid of blocks of shape `block_shape`, and interleaves these blocks with the\n",
      "        \"batch\" dimension (0) such that in the output, the spatial dimensions\n",
      "        `[1, ..., M]` correspond to the position within the grid, and the batch\n",
      "        dimension combines both the position within a spatial block and the original\n",
      "        batch position.  Prior to division into blocks, the spatial dimensions of the\n",
      "        input are optionally zero padded according to `paddings`. See below for a\n",
      "        precise description.\n",
      "        \n",
      "        This operation is equivalent to the following steps:\n",
      "        \n",
      "        1. Zero-pad the start and end of dimensions `[1, ..., M]` of the\n",
      "           input according to `paddings` to produce `padded` of shape `padded_shape`.\n",
      "        \n",
      "        2. Reshape `padded` to `reshaped_padded` of shape:\n",
      "        \n",
      "             [batch] +\n",
      "             [padded_shape[1] / block_shape[0],\n",
      "               block_shape[0],\n",
      "              ...,\n",
      "              padded_shape[M] / block_shape[M-1],\n",
      "              block_shape[M-1]] +\n",
      "             remaining_shape\n",
      "        \n",
      "        3. Permute dimensions of `reshaped_padded` to produce\n",
      "           `permuted_reshaped_padded` of shape:\n",
      "        \n",
      "             block_shape +\n",
      "             [batch] +\n",
      "             [padded_shape[1] / block_shape[0],\n",
      "              ...,\n",
      "              padded_shape[M] / block_shape[M-1]] +\n",
      "             remaining_shape\n",
      "        \n",
      "        4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch\n",
      "           dimension, producing an output tensor of shape:\n",
      "        \n",
      "             [batch * prod(block_shape)] +\n",
      "             [padded_shape[1] / block_shape[0],\n",
      "              ...,\n",
      "              padded_shape[M] / block_shape[M-1]] +\n",
      "             remaining_shape\n",
      "        \n",
      "        Some examples:\n",
      "        \n",
      "        (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and\n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [2]], [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "        ```\n",
      "        \n",
      "        (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and\n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 3]` and value:\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and\n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "              [[5],   [6],  [7],  [8]],\n",
      "              [[9],  [10], [11],  [12]],\n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 2, 2, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [3]], [[9], [11]]],\n",
      "             [[[2], [4]], [[10], [12]]],\n",
      "             [[[5], [7]], [[13], [15]]],\n",
      "             [[[6], [8]], [[14], [16]]]]\n",
      "        ```\n",
      "        \n",
      "        (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and\n",
      "            paddings = `[[0, 0], [2, 0]]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "              [[5],   [6],  [7],  [8]]],\n",
      "             [[[9],  [10], [11],  [12]],\n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[8, 1, 3, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[0], [1], [3]]], [[[0], [9], [11]]],\n",
      "             [[[0], [2], [4]]], [[[0], [10], [12]]],\n",
      "             [[[0], [5], [7]]], [[[0], [13], [15]]],\n",
      "             [[[0], [6], [8]]], [[[0], [14], [16]]]]\n",
      "        ```\n",
      "        \n",
      "        Among others, this operation is useful for reducing atrous convolution into\n",
      "        regular convolution.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "            N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,\n",
      "            where spatial_shape has `M` dimensions.\n",
      "          block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with shape `[M]`, all values must be >= 1.\n",
      "          paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D with shape `[M, 2]`, all values must be >= 0.\n",
      "              `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension\n",
      "              `i + 1`, which corresponds to spatial dimension `i`.  It is required that\n",
      "              `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    space_to_depth(input, block_size, name=None, data_format='NHWC')\n",
      "        SpaceToDepth for tensors of type T.\n",
      "        \n",
      "        Rearranges blocks of spatial data, into depth. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `height`\n",
      "        and `width` dimensions are moved to the `depth` dimension.\n",
      "        The attr `block_size` indicates the input block size.\n",
      "        \n",
      "          * Non-overlapping blocks of size `block_size x block size` are rearranged\n",
      "            into depth at each location.\n",
      "          * The depth of the output tensor is `block_size * block_size * input_depth`.\n",
      "          * The Y, X coordinates within each block of the input become the high order\n",
      "            component of the output channel index.\n",
      "          * The input tensor's height and width must be divisible by block_size.\n",
      "        \n",
      "        The `data_format` attr specifies the layout of the input and output tensors\n",
      "        with the following options:\n",
      "          \"NHWC\": `[ batch, height, width, channels ]`\n",
      "          \"NCHW\": `[ batch, channels, height, width ]`\n",
      "          \"NCHW_VECT_C\":\n",
      "              `qint8 [ batch, channels / 4, height, width, 4 ]`\n",
      "        \n",
      "        It is useful to consider the operation as transforming a 6-D Tensor.\n",
      "        e.g. for data_format = NHWC,\n",
      "             Each element in the input tensor can be specified via 6 coordinates,\n",
      "             ordered by decreasing memory layout significance as:\n",
      "             n,oY,bY,oX,bX,iC  (where n=batch index, oX, oY means X or Y coordinates\n",
      "                                within the output image, bX, bY means coordinates\n",
      "                                within the input block, iC means input channels).\n",
      "             The output would be a transpose to the following layout:\n",
      "             n,oY,oX,bY,bX,iC\n",
      "        \n",
      "        This operation is useful for resizing the activations between convolutions\n",
      "        (but keeping all data), e.g. instead of pooling. It is also useful for training\n",
      "        purely convolutional models.\n",
      "        \n",
      "        For example, given an input of shape `[1, 2, 2, 1]`, data_format = \"NHWC\" and\n",
      "        block_size = 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [2]],\n",
      "              [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation will output a tensor of shape `[1, 1, 1, 4]`:\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3, 4]]]]\n",
      "        ```\n",
      "        \n",
      "        Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,\n",
      "        the corresponding output will have a single element (i.e. width and height are\n",
      "        both 1) and will have a depth of 4 channels (1 * block_size * block_size).\n",
      "        The output element shape is `[1, 1, 4]`.\n",
      "        \n",
      "        For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation, for block_size of 2, will return the following tensor of shape\n",
      "        `[1, 1, 1, 12]`\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [5],  [6]],\n",
      "              [[3],   [4],  [7],  [8]],\n",
      "              [[9],  [10], [13],  [14]],\n",
      "              [[11], [12], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        the operator will return the following tensor of shape `[1 2 2 4]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4],\n",
      "               [5, 6, 7, 8]],\n",
      "              [[9, 10, 11, 12],\n",
      "               [13, 14, 15, 16]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          block_size: An `int` that is `>= 2`. The size of the spatial block.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\", \"NCHW_VECT_C\"`. Defaults to `\"NHWC\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    sparse_add(a, b, threshold=None, thresh=None)\n",
      "        Adds two tensors, at least one of each is a `SparseTensor`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(thresh)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        thresh is deprecated, use threshold instead\n",
      "        \n",
      "        If one `SparseTensor` and one `Tensor` are passed in, returns a `Tensor`.  If\n",
      "        both arguments are `SparseTensor`s, this returns a `SparseTensor`.  The order\n",
      "        of arguments does not matter.  Use vanilla `tf.add()` for adding two dense\n",
      "        `Tensor`s.\n",
      "        \n",
      "        The shapes of the two operands must match: broadcasting is not supported.\n",
      "        \n",
      "        The indices of any input `SparseTensor` are assumed ordered in standard\n",
      "        lexicographic order.  If this is not the case, before this step run\n",
      "        `SparseReorder` to restore index ordering.\n",
      "        \n",
      "        If both arguments are sparse, we perform \"clipping\" as follows.  By default,\n",
      "        if two values sum to zero at some index, the output `SparseTensor` would still\n",
      "        include that particular location in its index, storing a zero in the\n",
      "        corresponding value slot.  To override this, callers can specify `thresh`,\n",
      "        indicating that if the sum has a magnitude strictly smaller than `thresh`, its\n",
      "        corresponding value and index would then not be included.  In particular,\n",
      "        `thresh == 0.0` (default) means everything is kept and actual thresholding\n",
      "        happens only for a positive value.\n",
      "        \n",
      "        For example, suppose the logical sum of two sparse operands is (densified):\n",
      "        \n",
      "            [       2]\n",
      "            [.1     0]\n",
      "            [ 6   -.2]\n",
      "        \n",
      "        Then,\n",
      "        \n",
      "        * `thresh == 0` (the default): all 5 index/value pairs will be returned.\n",
      "        * `thresh == 0.11`: only .1 and 0 will vanish, and the remaining three\n",
      "            index/value pairs will be returned.\n",
      "        * `thresh == 0.21`: .1, 0, and -.2 will vanish.\n",
      "        \n",
      "        Args:\n",
      "          a: The first operand; `SparseTensor` or `Tensor`.\n",
      "          b: The second operand; `SparseTensor` or `Tensor`. At least one operand\n",
      "            must be sparse.\n",
      "          threshold: An optional 0-D `Tensor` (defaults to `0`). The magnitude\n",
      "            threshold that determines if an output value/index pair takes space. Its\n",
      "            dtype should match that of the values if they are real; if the latter are\n",
      "            complex64/complex128, then the dtype should be float32/float64,\n",
      "            correspondingly.\n",
      "          thresh: Deprecated alias for `threshold`.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or a `Tensor`, representing the sum.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If both `a` and `b` are `Tensor`s.  Use `tf.add()` instead.\n",
      "    \n",
      "    sparse_concat(axis, sp_inputs, name=None, expand_nonconcat_dim=False, concat_dim=None, expand_nonconcat_dims=None)\n",
      "        Concatenates a list of `SparseTensor` along the specified dimension. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(concat_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        concat_dim is deprecated, use axis instead\n",
      "        \n",
      "        Concatenation is with respect to the dense versions of each sparse input.\n",
      "        It is assumed that each inputs is a `SparseTensor` whose elements are ordered\n",
      "        along increasing dimension number.\n",
      "        \n",
      "        If expand_nonconcat_dim is False, all inputs' shapes must match, except for\n",
      "        the concat dimension. If expand_nonconcat_dim is True, then inputs' shapes are\n",
      "        allowed to vary among all inputs.\n",
      "        \n",
      "        The `indices`, `values`, and `shapes` lists must have the same length.\n",
      "        \n",
      "        If expand_nonconcat_dim is False, then the output shape is identical to the\n",
      "        inputs', except along the concat dimension, where it is the sum of the inputs'\n",
      "        sizes along that dimension.\n",
      "        \n",
      "        If expand_nonconcat_dim is True, then the output shape along the non-concat\n",
      "        dimensions will be expand to be the largest among all inputs, and it is the\n",
      "        sum of the inputs sizes along the concat dimension.\n",
      "        \n",
      "        The output elements will be resorted to preserve the sort order along\n",
      "        increasing dimension number.\n",
      "        \n",
      "        This op runs in `O(M log M)` time, where `M` is the total number of non-empty\n",
      "        values across all inputs. This is due to the need for an internal sort in\n",
      "        order to concatenate efficiently across an arbitrary dimension.\n",
      "        \n",
      "        For example, if `axis = 1` and the inputs are\n",
      "        \n",
      "            sp_inputs[0]: shape = [2, 3]\n",
      "            [0, 2]: \"a\"\n",
      "            [1, 0]: \"b\"\n",
      "            [1, 1]: \"c\"\n",
      "        \n",
      "            sp_inputs[1]: shape = [2, 4]\n",
      "            [0, 1]: \"d\"\n",
      "            [0, 2]: \"e\"\n",
      "        \n",
      "        then the output will be\n",
      "        \n",
      "            shape = [2, 7]\n",
      "            [0, 2]: \"a\"\n",
      "            [0, 4]: \"d\"\n",
      "            [0, 5]: \"e\"\n",
      "            [1, 0]: \"b\"\n",
      "            [1, 1]: \"c\"\n",
      "        \n",
      "        Graphically this is equivalent to doing\n",
      "        \n",
      "            [    a] concat [  d e  ] = [    a   d e  ]\n",
      "            [b c  ]        [       ]   [b c          ]\n",
      "        \n",
      "        Another example, if 'axis = 1' and the inputs are\n",
      "        \n",
      "            sp_inputs[0]: shape = [3, 3]\n",
      "            [0, 2]: \"a\"\n",
      "            [1, 0]: \"b\"\n",
      "            [2, 1]: \"c\"\n",
      "        \n",
      "            sp_inputs[1]: shape = [2, 4]\n",
      "            [0, 1]: \"d\"\n",
      "            [0, 2]: \"e\"\n",
      "        \n",
      "        if expand_nonconcat_dim = False, this will result in an error. But if\n",
      "        expand_nonconcat_dim = True, this will result in:\n",
      "        \n",
      "            shape = [3, 7]\n",
      "            [0, 2]: \"a\"\n",
      "            [0, 4]: \"d\"\n",
      "            [0, 5]: \"e\"\n",
      "            [1, 0]: \"b\"\n",
      "            [2, 1]: \"c\"\n",
      "        \n",
      "        Graphically this is equivalent to doing\n",
      "        \n",
      "            [    a] concat [  d e  ] = [    a   d e  ]\n",
      "            [b    ]        [       ]   [b            ]\n",
      "            [  c  ]                    [  c          ]\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          axis: Dimension to concatenate along. Must be in range [-rank, rank),\n",
      "            where rank is the number of dimensions in each input `SparseTensor`.\n",
      "          sp_inputs: List of `SparseTensor` to concatenate.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          expand_nonconcat_dim: Whether to allow the expansion in the non-concat\n",
      "            dimensions. Defaulted to False.\n",
      "          concat_dim: The old (deprecated) name for axis.\n",
      "          expand_nonconcat_dims: alias for expand_nonconcat_dim\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the concatenated output.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_inputs` is not a list of `SparseTensor`.\n",
      "    \n",
      "    sparse_fill_empty_rows(sp_input, default_value, name=None)\n",
      "        Fills empty rows in the input 2-D `SparseTensor` with a default value.\n",
      "        \n",
      "        This op adds entries with the specified `default_value` at index\n",
      "        `[row, 0]` for any row in the input that does not already have a value.\n",
      "        \n",
      "        For example, suppose `sp_input` has shape `[5, 6]` and non-empty values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Rows 1 and 4 are empty, so the output will be of shape `[5, 6]` with values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [1, 0]: default_value\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "            [4, 0]: default_value\n",
      "        \n",
      "        Note that the input may have empty columns at the end, with no effect on\n",
      "        this op.\n",
      "        \n",
      "        The output `SparseTensor` will be in row-major order and will have the\n",
      "        same shape as the input.\n",
      "        \n",
      "        This op also returns an indicator vector such that\n",
      "        \n",
      "            empty_row_indicator[i] = True iff row i was an empty row.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: A `SparseTensor` with shape `[N, M]`.\n",
      "          default_value: The value to fill for empty rows, with the same type as\n",
      "            `sp_input.`\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          sp_ordered_output: A `SparseTensor` with shape `[N, M]`, and with all empty\n",
      "            rows filled in with `default_value`.\n",
      "          empty_row_indicator: A bool vector of length `N` indicating whether each\n",
      "            input row was empty.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_mask(a, mask_indices, name=None)\n",
      "        Masks elements of `IndexedSlices`.\n",
      "        \n",
      "        Given an `IndexedSlices` instance `a`, returns another `IndexedSlices` that\n",
      "        contains a subset of the slices of `a`. Only the slices at indices not\n",
      "        specified in `mask_indices` are returned.\n",
      "        \n",
      "        This is useful when you need to extract a subset of slices in an\n",
      "        `IndexedSlices` object.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # `a` contains slices at indices [12, 26, 37, 45] from a large tensor\n",
      "        # with shape [1000, 10]\n",
      "        a.indices  # [12, 26, 37, 45]\n",
      "        tf.shape(a.values)  # [4, 10]\n",
      "        \n",
      "        # `b` will be the subset of `a` slices at its second and third indices, so\n",
      "        # we want to mask its first and last indices (which are at absolute\n",
      "        # indices 12, 45)\n",
      "        b = tf.sparse.mask(a, [12, 45])\n",
      "        \n",
      "        b.indices  # [26, 37]\n",
      "        tf.shape(b.values)  # [2, 10]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          a: An `IndexedSlices` instance.\n",
      "          mask_indices: Indices of elements to mask.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The masked `IndexedSlices` instance.\n",
      "    \n",
      "    sparse_matmul = sparse_mat_mul(a: typing.Annotated[_any, ~TV_SparseMatMul_Ta], b: typing.Annotated[_any, ~TV_SparseMatMul_Tb], transpose_a: bool = False, transpose_b: bool = False, a_is_sparse: bool = False, b_is_sparse: bool = False, name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Multiply matrix \"a\" by matrix \"b\". (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.linalg.matmul` instead\n",
      "        \n",
      "        The inputs must be two-dimensional matrices and the inner dimension of \"a\" must\n",
      "        match the outer dimension of \"b\". Both \"a\" and \"b\" must be `Tensor`s not\n",
      "        `SparseTensor`s.  This op is optimized for the case where at least one of \"a\" or\n",
      "        \"b\" is sparse, in the sense that they have a large proportion of zero values.\n",
      "        The breakeven for using this versus a dense matrix multiply on one platform was\n",
      "        30% zero values in the sparse matrix.\n",
      "        \n",
      "        The gradient computation of this operation will only take advantage of sparsity\n",
      "        in the input gradient when that gradient comes from a Relu.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.\n",
      "          b: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.\n",
      "          transpose_a: An optional `bool`. Defaults to `False`.\n",
      "          transpose_b: An optional `bool`. Defaults to `False`.\n",
      "          a_is_sparse: An optional `bool`. Defaults to `False`.\n",
      "          b_is_sparse: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    sparse_maximum(sp_a, sp_b, name=None)\n",
      "        Returns the element-wise max of two SparseTensors.\n",
      "        \n",
      "        Assumes the two SparseTensors have the same shape, i.e., no broadcasting.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "          >>> sp_zero = tf.sparse.SparseTensor([[0]], [0], [7])\n",
      "          >>> sp_one = tf.sparse.SparseTensor([[1]], [1], [7])\n",
      "          >>> res = tf.sparse.maximum(sp_zero, sp_one)\n",
      "          >>> res.indices\n",
      "          <tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
      "          array([[0],\n",
      "                 [1]])>\n",
      "          >>> res.values\n",
      "          <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>\n",
      "          >>> res.dense_shape\n",
      "          <tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.sparse.reduce_max`\n",
      "        \n",
      "        Args:\n",
      "          sp_a: a `SparseTensor` operand whose dtype is real, and indices\n",
      "            lexicographically ordered.\n",
      "          sp_b: the other `SparseTensor` operand with the same requirements (and the\n",
      "            same shape).\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: the output SparseTensor.\n",
      "    \n",
      "    sparse_merge(sp_ids, sp_values, vocab_size, name=None, already_sorted=False)\n",
      "        Combines a batch of feature ids and values into a single `SparseTensor`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        No similar op available at this time.\n",
      "        \n",
      "        The most common use case for this function occurs when feature ids and\n",
      "        their corresponding values are stored in `Example` protos on disk.\n",
      "        `parse_example` will return a batch of ids and a batch of values, and this\n",
      "        function joins them into a single logical `SparseTensor` for use in\n",
      "        functions such as `sparse_tensor_dense_matmul`, `sparse_to_dense`, etc.\n",
      "        \n",
      "        The `SparseTensor` returned by this function has the following properties:\n",
      "        \n",
      "          - `indices` is equivalent to `sp_ids.indices` with the last\n",
      "            dimension discarded and replaced with `sp_ids.values`.\n",
      "          - `values` is simply `sp_values.values`.\n",
      "          - If `sp_ids.dense_shape = [D0, D1, ..., Dn, K]`, then\n",
      "            `output.shape = [D0, D1, ..., Dn, vocab_size]`.\n",
      "        \n",
      "        For example, consider the following feature vectors:\n",
      "        \n",
      "        ```python\n",
      "          vector1 = [-3, 0, 0, 0, 0, 0]\n",
      "          vector2 = [ 0, 1, 0, 4, 1, 0]\n",
      "          vector3 = [ 5, 0, 0, 9, 0, 0]\n",
      "        ```\n",
      "        \n",
      "        These might be stored sparsely in the following Example protos by storing\n",
      "        only the feature ids (column number if the vectors are treated as a matrix)\n",
      "        of the non-zero elements and the corresponding values:\n",
      "        \n",
      "        ```python\n",
      "          examples = [Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[0])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[-3]))}),\n",
      "                      Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[1, 4, 3])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[1, 1, 4]))}),\n",
      "                      Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[0, 3])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[5, 9]))})]\n",
      "        ```\n",
      "        \n",
      "        The result of calling parse_example on these examples will produce a\n",
      "        dictionary with entries for \"ids\" and \"values\". Passing those two objects\n",
      "        to this function along with vocab_size=6, will produce a `SparseTensor` that\n",
      "        sparsely represents all three instances. Namely, the `indices` property will\n",
      "        contain the coordinates of the non-zero entries in the feature matrix (the\n",
      "        first dimension is the row number in the matrix, i.e., the index within the\n",
      "        batch, and the second dimension is the column number, i.e., the feature id);\n",
      "        `values` will contain the actual values. `shape` will be the shape of the\n",
      "        original matrix, i.e., (3, 6). For our example above, the output will be\n",
      "        equal to:\n",
      "        \n",
      "        ```python\n",
      "          SparseTensor(indices=[[0, 0], [1, 1], [1, 3], [1, 4], [2, 0], [2, 3]],\n",
      "                       values=[-3, 1, 4, 1, 5, 9],\n",
      "                       dense_shape=[3, 6])\n",
      "        ```\n",
      "        \n",
      "        This method generalizes to higher-dimensions by simply providing a list for\n",
      "        both the sp_ids as well as the vocab_size.\n",
      "        In this case the resulting `SparseTensor` has the following properties:\n",
      "          - `indices` is equivalent to `sp_ids[0].indices` with the last\n",
      "            dimension discarded and concatenated with\n",
      "            `sp_ids[0].values, sp_ids[1].values, ...`.\n",
      "          - `values` is simply `sp_values.values`.\n",
      "          - If `sp_ids.dense_shape = [D0, D1, ..., Dn, K]`, then\n",
      "            `output.shape = [D0, D1, ..., Dn] + vocab_size`.\n",
      "        \n",
      "        Args:\n",
      "          sp_ids: A single `SparseTensor` with `values` property of type `int32`\n",
      "            or `int64` or a Python list of such `SparseTensor`s or a list thereof.\n",
      "          sp_values: A `SparseTensor` of any type.\n",
      "          vocab_size: A scalar `int64` Tensor (or Python int) containing the new size\n",
      "            of the last dimension, `all(0 <= sp_ids.values < vocab_size)`.\n",
      "            Or a list thereof with `all(0 <= sp_ids[i].values < vocab_size[i])` for\n",
      "            all `i`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "          already_sorted: A boolean to specify whether the per-batch values in\n",
      "           `sp_values` are already sorted. If so skip sorting, False by default\n",
      "           (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` compactly representing a batch of feature ids and values,\n",
      "          useful for passing to functions that expect such a `SparseTensor`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_values` is not a `SparseTensor`. Or if `sp_ids` is neither\n",
      "            a `SparseTensor` nor a list thereof. Or if `vocab_size` is not a\n",
      "            `Tensor` or a Python int and `sp_ids` is a `SparseTensor`. Or if\n",
      "            `vocab_size` is not a or list thereof and `sp_ids` is a list.\n",
      "          ValueError: If `sp_ids` and `vocab_size` are lists of different lengths.\n",
      "    \n",
      "    sparse_minimum(sp_a, sp_b, name=None)\n",
      "        Returns the element-wise min of two SparseTensors.\n",
      "        \n",
      "        Assumes the two SparseTensors have the same shape, i.e., no broadcasting.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "          >>> sp_zero = tf.sparse.SparseTensor([[0]], [0], [7])\n",
      "          >>> sp_one = tf.sparse.SparseTensor([[1]], [1], [7])\n",
      "          >>> res = tf.sparse.minimum(sp_zero, sp_one)\n",
      "          >>> res.indices\n",
      "          <tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
      "          array([[0],\n",
      "                 [1]])>\n",
      "          >>> res.values\n",
      "          <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>\n",
      "          >>> res.dense_shape\n",
      "          <tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>\n",
      "        \n",
      "        Args:\n",
      "          sp_a: a `SparseTensor` operand whose dtype is real, and indices\n",
      "            lexicographically ordered.\n",
      "          sp_b: the other `SparseTensor` operand with the same requirements (and the\n",
      "            same shape).\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: the output SparseTensor.\n",
      "    \n",
      "    sparse_placeholder(dtype, shape=None, name=None)\n",
      "        Inserts a placeholder for a sparse tensor that will be always fed.\n",
      "        \n",
      "        **Important**: This sparse tensor will produce an error if evaluated.\n",
      "        Its value must be fed using the `feed_dict` optional argument to\n",
      "        `Session.run()`, `Tensor.eval()`, or `Operation.run()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.compat.v1.sparse.placeholder(tf.float32)\n",
      "        y = tf.sparse.reduce_sum(x)\n",
      "        \n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "        \n",
      "          indices = np.array([[3, 2, 0], [4, 5, 1]], dtype=np.int64)\n",
      "          values = np.array([1.0, 2.0], dtype=np.float32)\n",
      "          shape = np.array([7, 9, 2], dtype=np.int64)\n",
      "          print(sess.run(y, feed_dict={\n",
      "            x: tf.compat.v1.SparseTensorValue(indices, values, shape)}))  # Will\n",
      "            succeed.\n",
      "          print(sess.run(y, feed_dict={\n",
      "            x: (indices, values, shape)}))  # Will succeed.\n",
      "        \n",
      "          sp = tf.sparse.SparseTensor(indices=indices, values=values,\n",
      "                                      dense_shape=shape)\n",
      "          sp_value = sp.eval(session=sess)\n",
      "          print(sess.run(y, feed_dict={x: sp_value}))  # Will succeed.\n",
      "        ```\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          dtype: The type of `values` elements in the tensor to be fed.\n",
      "          shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "            specified, you can feed a sparse tensor of any shape.\n",
      "          name: A name for prefixing the operations (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` that may be used as a handle for feeding a value, but not\n",
      "          evaluated directly.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if eager execution is enabled\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is not compatible with eager execution and `tf.function`. To migrate\n",
      "        to TF2, rewrite the code to be compatible with eager execution. Check the\n",
      "        [migration\n",
      "        guide](https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls)\n",
      "        on replacing `Session.run` calls. In TF2, you can just pass tensors directly\n",
      "        into ops and layers. If you want to explicitly set up your inputs, also see\n",
      "        [Keras functional API](https://www.tensorflow.org/guide/keras/functional) on\n",
      "        how to use `tf.keras.Input` to replace `tf.compat.v1.sparse_placeholder`.\n",
      "        `tf.function` arguments also do the job of `tf.compat.v1.sparse_placeholder`.\n",
      "        For more details please read [Better\n",
      "        performance with tf.function](https://www.tensorflow.org/guide/function).\n",
      "        @end_compatibility\n",
      "    \n",
      "    sparse_reduce_max(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes `tf.sparse.maximum` of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(reduction_axes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_axes is deprecated, use axis instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.sparse.maximum` op.\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_max()`.  In particular, this Op also returns a dense `Tensor`\n",
      "        instead of a sparse one.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        similar to the indexing rules in Python.\n",
      "        \n",
      "        The values not defined in `sp_input` don't participate in the reduce max,\n",
      "        as opposed to be implicitly assumed 0 -- hence it can return negative values\n",
      "        for sparse `reduction_axes`. But, in case there are no values in\n",
      "        `reduction_axes`, it will reduce to 0. See second example below.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          # 'x' represents [[1, ?, 2]\n",
      "          #                 [?, 3, ?]]\n",
      "          # where ? is implicitly-zero.\n",
      "        \n",
      "          >>> x = tf.sparse.SparseTensor([[0, 0], [0, 2], [1, 1]], [1, 2, 3], [2, 3])\n",
      "          >>> tf.sparse.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=3>\n",
      "          >>> tf.sparse.reduce_max(x, 0)\n",
      "          <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 2], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_max(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_max(x, 1, keepdims=True)\n",
      "          <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
      "          array([[2],\n",
      "                 [3]], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_max(x, [0, 1])\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=3>\n",
      "        \n",
      "          # 'y' represents [[-7, ?]\n",
      "          #                 [ 4, 3]\n",
      "          #                 [ ?, ?]\n",
      "        \n",
      "          >>> y = tf.sparse.SparseTensor([[0, 0,], [1, 0], [1, 1]], [-7, 4, 3],\n",
      "          ... [3, 2])\n",
      "          >>> tf.sparse.reduce_max(y, 1)\n",
      "          <tf.Tensor: shape=(3,), dtype=int32, numpy=array([-7,  4,  0], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of `axis`.\n",
      "          keep_dims:  Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced Tensor.\n",
      "    \n",
      "    sparse_reduce_max_sparse(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_max()`.  In contrast to SparseReduceSum, this Op returns a\n",
      "        SparseTensor.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        which are interpreted according to the indexing rules in Python.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced SparseTensor.\n",
      "    \n",
      "    sparse_reduce_sum(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes `tf.sparse.add` of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(reduction_axes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_axes is deprecated, use axis instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.sparse.add` op.\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_sum()`.  In particular, this Op also returns a dense `Tensor`\n",
      "        instead of a sparse one.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        similar to the indexing rules in Python.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          # 'x' represents [[1, ?, 1]\n",
      "          #                 [?, 1, ?]]\n",
      "          # where ? is implicitly-zero.\n",
      "        \n",
      "          >>> x = tf.sparse.SparseTensor([[0, 0], [0, 2], [1, 1]], [1, 1, 1], [2, 3])\n",
      "          >>> tf.sparse.reduce_sum(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=3>\n",
      "          >>> tf.sparse.reduce_sum(x, 0)\n",
      "          <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 1, 1], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_sum(x, 1)  # Can also use -1 as the axis\n",
      "          <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 1], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_sum(x, 1, keepdims=True)\n",
      "          <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
      "          array([[2],\n",
      "                 [1]], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_sum(x, [0, 1])\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=3>\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of `axis`.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced Tensor.\n",
      "    \n",
      "    sparse_reduce_sum_sparse(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_sum()`.  In contrast to SparseReduceSum, this Op returns a\n",
      "        SparseTensor.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        which are interpreted according to the indexing rules in Python.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced SparseTensor.\n",
      "    \n",
      "    sparse_reorder(sp_input, name=None)\n",
      "        Reorders a `SparseTensor` into the canonical, row-major ordering.\n",
      "        \n",
      "        Note that by convention, all sparse ops preserve the canonical ordering\n",
      "        along increasing dimension number. The only time ordering can be violated\n",
      "        is during manual manipulation of the indices and values to add entries.\n",
      "        \n",
      "        Reordering does not affect the shape of the `SparseTensor`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[4, 5]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 3]: b\n",
      "            [0, 1]: a\n",
      "            [3, 1]: d\n",
      "            [2, 0]: c\n",
      "        \n",
      "        then the output will be a `SparseTensor` of shape `[4, 5]` and\n",
      "        `indices` / `values`:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same shape and non-empty values, but in\n",
      "          canonical ordering.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_reset_shape(sp_input, new_shape=None)\n",
      "        Resets the shape of a `SparseTensor` with indices and values unchanged.\n",
      "        \n",
      "        If `new_shape` is None, returns a copy of `sp_input` with its shape reset\n",
      "        to the tight bounding box of `sp_input`. This will be a shape consisting of\n",
      "        all zeros if sp_input has no values.\n",
      "        \n",
      "        If `new_shape` is provided, then it must be larger or equal in all dimensions\n",
      "        compared to the shape of `sp_input`. When this condition is met, the returned\n",
      "        SparseTensor will have its shape reset to `new_shape` and its indices and\n",
      "        values unchanged from that of `sp_input.`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          Consider a `sp_input` with shape [2, 3, 5]:\n",
      "        \n",
      "            [0, 0, 1]: a\n",
      "            [0, 1, 0]: b\n",
      "            [0, 2, 2]: c\n",
      "            [1, 0, 3]: d\n",
      "        \n",
      "          - It is an error to set `new_shape` as [3, 7] since this represents a\n",
      "            rank-2 tensor while `sp_input` is rank-3. This is either a ValueError\n",
      "            during graph construction (if both shapes are known) or an OpError during\n",
      "            run time.\n",
      "        \n",
      "          - Setting `new_shape` as [2, 3, 6] will be fine as this shape is larger or\n",
      "            equal in every dimension compared to the original shape [2, 3, 5].\n",
      "        \n",
      "          - On the other hand, setting new_shape as [2, 3, 4] is also an error: The\n",
      "            third dimension is smaller than the original shape [2, 3, 5] (and an\n",
      "            `InvalidArgumentError` will be raised).\n",
      "        \n",
      "          - If `new_shape` is None, the returned SparseTensor will have a shape\n",
      "            [2, 3, 4], which is the tight bounding box of `sp_input`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          new_shape: None or a vector representing the new shape for the returned\n",
      "            `SparseTensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` indices and values unchanged from `sp_input`. Its shape is\n",
      "            `new_shape` if that is set. Otherwise it is the tight bounding box of\n",
      "             `sp_input`\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError: If `new_shape` represents a tensor with a different rank from\n",
      "            that of `sp_input` (if shapes are known when graph is constructed).\n",
      "          ValueError:  If `new_shape` is determined during graph build to have\n",
      "            dimension sizes that are too small.\n",
      "          OpError:\n",
      "            - If `new_shape` has dimension sizes that are too small.\n",
      "            - If shapes are not known during graph construction time, and during run\n",
      "              time it is found out that the ranks do not match.\n",
      "    \n",
      "    sparse_reshape(sp_input, shape, name=None)\n",
      "        Reshapes a `SparseTensor` to represent values in a new dense shape.\n",
      "        \n",
      "        This operation has the same semantics as `reshape` on the represented dense\n",
      "        tensor.  The indices of non-empty values in `sp_input` are recomputed based\n",
      "        on the new dense shape, and a new `SparseTensor` is returned containing the\n",
      "        new indices and new shape.  The order of non-empty values in `sp_input` is\n",
      "        unchanged.\n",
      "        \n",
      "        If one component of `shape` is the special value -1, the size of that\n",
      "        dimension is computed so that the total dense size remains constant.  At\n",
      "        most one component of `shape` can be -1.  The number of dense elements\n",
      "        implied by `shape` must be the same as the number of dense elements\n",
      "        originally represented by `sp_input`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[2, 3, 6]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 0, 0]: a\n",
      "            [0, 0, 1]: b\n",
      "            [0, 1, 0]: c\n",
      "            [1, 0, 0]: d\n",
      "            [1, 2, 3]: e\n",
      "        \n",
      "        and `shape` is `[9, -1]`, then the output will be a `SparseTensor` of\n",
      "        shape `[9, 4]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 0]: a\n",
      "            [0, 1]: b\n",
      "            [1, 2]: c\n",
      "            [4, 2]: d\n",
      "            [8, 1]: e\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          shape: A 1-D (vector) int64 `Tensor` specifying the new dense shape of the\n",
      "            represented `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same non-empty values but with indices calculated\n",
      "          by the new dense shape.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError:  If argument `shape` requests a `SparseTensor` with a different\n",
      "            number of elements than `sp_input`.\n",
      "          ValueError:  If `shape` has more than one inferred (== -1) dimension.\n",
      "    \n",
      "    sparse_retain(sp_input, to_retain)\n",
      "        Retains specified non-empty values within a `SparseTensor`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[4, 5]` and 4 non-empty string values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        and `to_retain = [True, False, False, True]`, then the output will\n",
      "        be a `SparseTensor` of shape `[4, 5]` with 2 non-empty values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor` with `N` non-empty elements.\n",
      "          to_retain: A bool vector of length `N` with `M` true values.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same shape as the input and `M` non-empty\n",
      "          elements corresponding to the true positions in `to_retain`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_segment_mean(data, indices, segment_ids, name=None, num_segments=None, sparse_gradient=False)\n",
      "        Computes the mean along sparse segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Like `tf.math.segment_mean`, but `segment_ids` can have rank less than\n",
      "        `data`'s first dimension, selecting a subset of dimension 0, specified by\n",
      "        `indices`.\n",
      "        `segment_ids` is allowed to have missing ids, in which case the output will\n",
      "        be zeros at those indices. In those cases `num_segments` is used to determine\n",
      "        the size of the output.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "          sparse_gradient: An optional `bool`. Defaults to `False`. If `True`, the\n",
      "            gradient of this function will be sparse (`IndexedSlices`) instead of\n",
      "            dense (`Tensor`). The sparse gradient will contain one non-zero row for\n",
      "            each unique index in `indices`.\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_segment_sqrt_n(data, indices, segment_ids, name=None, num_segments=None, sparse_gradient=False)\n",
      "        Computes the sum along sparse segments of a tensor divided by the sqrt(N).\n",
      "        \n",
      "        `N` is the size of the segment being reduced.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "          sparse_gradient: An optional `bool`. Defaults to `False`. If `True`, the\n",
      "            gradient of this function will be sparse (IndexedSlices) instead of dense\n",
      "            (Tensor).\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_segment_sum(data, indices, segment_ids, name=None, num_segments=None, sparse_gradient=False)\n",
      "        Computes the sum along sparse segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Like `tf.math.segment_sum`, but `segment_ids` can have rank less than `data`'s\n",
      "        first dimension, selecting a subset of dimension 0, specified by `indices`.\n",
      "        `segment_ids` is allowed to have missing ids, in which case the output will\n",
      "        be zeros at those indices. In those cases `num_segments` is used to determine\n",
      "        the size of the output.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])\n",
      "        \n",
      "        # Select two rows, one segment.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))\n",
      "        # => [[0 0 0 0]]\n",
      "        \n",
      "        # Select two rows, two segment.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))\n",
      "        # => [[ 1  2  3  4]\n",
      "        #     [-1 -2 -3 -4]]\n",
      "        \n",
      "        # With missing segment ids.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 2]),\n",
      "                              num_segments=4)\n",
      "        # => [[ 1  2  3  4]\n",
      "        #     [ 0  0  0  0]\n",
      "        #     [-1 -2 -3 -4]\n",
      "        #     [ 0  0  0  0]]\n",
      "        \n",
      "        # Select all rows, two segments.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))\n",
      "        # => [[0 0 0 0]\n",
      "        #     [5 6 7 8]]\n",
      "        \n",
      "        # Which is equivalent to:\n",
      "        tf.math.segment_sum(c, tf.constant([0, 0, 1]))\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "          sparse_gradient: An optional `bool`. Defaults to `False`. If `True`, the\n",
      "            gradient of this function will be sparse (`IndexedSlices`) instead of\n",
      "            dense (`Tensor`). The sparse gradient will contain one non-zero row for\n",
      "            each unique index in `indices`.\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_slice(sp_input, start, size, name=None)\n",
      "        Slice a `SparseTensor` based on the `start` and `size`.\n",
      "        \n",
      "        For example, if the input is\n",
      "        \n",
      "            input_tensor = shape = [2, 7]\n",
      "            [    a   d e  ]\n",
      "            [b c          ]\n",
      "        \n",
      "        Graphically the output tensors are:\n",
      "        \n",
      "            sparse.slice([0, 0], [2, 4]) = shape = [2, 4]\n",
      "            [    a  ]\n",
      "            [b c    ]\n",
      "        \n",
      "            sparse.slice([0, 4], [2, 3]) = shape = [2, 3]\n",
      "            [ d e  ]\n",
      "            [      ]\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The `SparseTensor` to split.\n",
      "          start: 1-D. tensor represents the start of the slice.\n",
      "          size: 1-D. tensor represents the size of the slice.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` objects resulting from splicing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_softmax(sp_input, name=None)\n",
      "        Applies softmax to a batched N-D `SparseTensor`.\n",
      "        \n",
      "        The inputs represent an N-D SparseTensor with logical shape `[..., B, C]`\n",
      "        (where `N >= 2`), and with indices sorted in the canonical lexicographic\n",
      "        order.\n",
      "        \n",
      "        This op is equivalent to applying the normal `tf.nn.softmax()` to each\n",
      "        innermost logical submatrix with shape `[B, C]`, but with the catch that *the\n",
      "        implicitly zero elements do not participate*.  Specifically, the algorithm is\n",
      "        equivalent to:\n",
      "        \n",
      "          (1) Applies `tf.nn.softmax()` to a densified view of each innermost\n",
      "              submatrix with shape `[B, C]`, along the size-C dimension;\n",
      "          (2) Masks out the original implicitly-zero locations;\n",
      "          (3) Renormalizes the remaining elements.\n",
      "        \n",
      "        Hence, the `SparseTensor` result has exactly the same non-zero indices and\n",
      "        shape.\n",
      "        \n",
      "        Example using a 3-D SparseTensor:\n",
      "        \n",
      "          >>> st = tf.sparse.from_dense(\n",
      "          ...   [[[0., np.e],\n",
      "          ...     [1., 0.]],\n",
      "          ...\n",
      "          ...    [[np.e, 0.],\n",
      "          ...     [np.e, np.e]]])\n",
      "          >>> res = tf.sparse.softmax(st)\n",
      "          >>> res.indices\n",
      "          <tf.Tensor: shape=(5, 3), dtype=int64, numpy=\n",
      "          array([[0, 0, 1],\n",
      "                 [0, 1, 0],\n",
      "                 [1, 0, 0],\n",
      "                 [1, 1, 0],\n",
      "                 [1, 1, 1]])>\n",
      "          >>> res.values\n",
      "          <tf.Tensor: ... numpy=array([1. , 1. , 1. , 0.5, 0.5], dtype=float32)>\n",
      "          >>> res.dense_shape\n",
      "          <tf.Tensor: shape=(3,), dtype=int64, numpy=array([2, 2, 2])>\n",
      "          >>> tf.sparse.to_dense(res)\n",
      "          <tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
      "          array([[[0. , 1. ],\n",
      "                  [1. , 0. ]],\n",
      "                 [[1. , 0. ],\n",
      "                  [0.5, 0.5]]], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          sp_input: N-D `SparseTensor`, where `N >= 2`.\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: N-D `SparseTensor` representing the results.\n",
      "    \n",
      "    sparse_split(keyword_required=KeywordRequired(), sp_input=None, num_split=None, axis=None, name=None, split_dim=None)\n",
      "        Split a `SparseTensor` into `num_split` tensors along `axis`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(split_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        split_dim is deprecated, use axis instead\n",
      "        \n",
      "        If the `sp_input.dense_shape[axis]` is not an integer multiple of `num_split`\n",
      "        each slice starting from 0:`shape[axis] % num_split` gets extra one\n",
      "        dimension. For example, if `axis = 1` and `num_split = 2` and the\n",
      "        input is:\n",
      "        \n",
      "            input_tensor = shape = [2, 7]\n",
      "            [    a   d e  ]\n",
      "            [b c          ]\n",
      "        \n",
      "        Graphically the output tensors are:\n",
      "        \n",
      "            output_tensor[0] =\n",
      "            [    a   ]\n",
      "            [b c     ]\n",
      "        \n",
      "            output_tensor[1] =\n",
      "            [ d e  ]\n",
      "            [      ]\n",
      "        \n",
      "        Args:\n",
      "          keyword_required: Python 2 standin for * (temporary for argument reorder)\n",
      "          sp_input: The `SparseTensor` to split.\n",
      "          num_split: A Python integer. The number of ways to split.\n",
      "          axis: A 0-D `int32` `Tensor`. The dimension along which to split. Must be in\n",
      "            range [-rank, rank), where rank is the number of dimensions in the input\n",
      "            `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          split_dim: Deprecated old name for axis.\n",
      "        \n",
      "        Returns:\n",
      "          `num_split` `SparseTensor` objects resulting from splitting `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError: If the deprecated `split_dim` and `axis` are both non None.\n",
      "    \n",
      "    sparse_tensor_dense_matmul(sp_a, b, adjoint_a=False, adjoint_b=False, name=None)\n",
      "        Multiply SparseTensor (or dense Matrix) (of rank 2) \"A\" by dense matrix\n",
      "        \n",
      "        (or SparseTensor) \"B\". Please note that one and only one of the inputs MUST\n",
      "        be a SparseTensor and the other MUST be a dense matrix.\n",
      "        \n",
      "        The following input format is recommended (but not required) for optimal\n",
      "        performance:\n",
      "        \n",
      "        * If `adjoint_a == false`: `A` should be sorted in lexicographically\n",
      "          increasing order.  Use `sparse.reorder` if you're not sure.\n",
      "        * If `adjoint_a == true`: `A` should be sorted in order of increasing\n",
      "          dimension 1 (i.e., \"column major\" order instead of \"row major\" order).\n",
      "        \n",
      "        Args:\n",
      "          sp_a: SparseTensor (or dense Matrix) A, of rank 2.\n",
      "          b: dense Matrix (or SparseTensor) B, with the same dtype as sp_a.\n",
      "          adjoint_a: Use the adjoint of A in the matrix multiply.  If A is complex,\n",
      "            this is transpose(conj(A)).  Otherwise it's transpose(A).\n",
      "          adjoint_b: Use the adjoint of B in the matrix multiply.  If B is complex,\n",
      "            this is transpose(conj(B)).  Otherwise it's transpose(B).\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A dense matrix (pseudo-code in dense np.matrix notation):\n",
      "            `A = A.H if adjoint_a else A`\n",
      "            `B = B.H if adjoint_b else B`\n",
      "            `return A*B`\n",
      "        \n",
      "        Notes:\n",
      "        \n",
      "        Using `tf.nn.embedding_lookup_sparse` for sparse multiplication:\n",
      "        \n",
      "        It's not obvious but you can consider `embedding_lookup_sparse` as another\n",
      "        sparse and dense multiplication. In some situations, you may prefer to use\n",
      "        `embedding_lookup_sparse` even though you're not dealing with embeddings.\n",
      "        \n",
      "        There are two questions to ask in the decision process: Do you need gradients\n",
      "        computed as sparse too? Is your sparse data represented as two\n",
      "        `SparseTensor`s: ids and values? There is more explanation about data format\n",
      "        below. If you answer any of these questions as yes, consider using\n",
      "        `tf.nn.embedding_lookup_sparse`.\n",
      "        \n",
      "        Following explains differences between the expected SparseTensors:\n",
      "        For example if dense form of your sparse data has shape `[3, 5]` and values:\n",
      "        \n",
      "            [[  a      ]\n",
      "             [b       c]\n",
      "             [    d    ]]\n",
      "        \n",
      "        \n",
      "        `SparseTensor` format expected by `sparse_tensor_dense_matmul`:\n",
      "         `sp_a` (indices, values):\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [1, 0]: b\n",
      "            [1, 4]: c\n",
      "            [2, 2]: d\n",
      "        \n",
      "        `SparseTensor` format expected by `embedding_lookup_sparse`:\n",
      "         `sp_ids`                 `sp_weights`\n",
      "        \n",
      "            [0, 0]: 1                [0, 0]: a\n",
      "            [1, 0]: 0                [1, 0]: b\n",
      "            [1, 1]: 4                [1, 1]: c\n",
      "            [2, 0]: 2                [2, 0]: d\n",
      "        \n",
      "        \n",
      "        Deciding when to use `sparse_tensor_dense_matmul` vs.\n",
      "        `matmul`(a_is_sparse=True):\n",
      "        \n",
      "        There are a number of questions to ask in the decision process, including:\n",
      "        \n",
      "        * Will the SparseTensor `A` fit in memory if densified?\n",
      "        * Is the column count of the product large (>> 1)?\n",
      "        * Is the density of `A` larger than approximately 15%?\n",
      "        \n",
      "        If the answer to several of these questions is yes, consider\n",
      "        converting the `SparseTensor` to a dense one and using `tf.matmul` with\n",
      "        `a_is_sparse=True`.\n",
      "        \n",
      "        This operation tends to perform well when `A` is more sparse, if the column\n",
      "        size of the product is small (e.g. matrix-vector multiplication), if\n",
      "        `sp_a.dense_shape` takes on large values.\n",
      "        \n",
      "        Below is a rough speed comparison between `sparse_tensor_dense_matmul`,\n",
      "        labeled 'sparse', and `matmul`(a_is_sparse=True), labeled 'dense'.  For\n",
      "        purposes of the comparison, the time spent converting from a `SparseTensor` to\n",
      "        a dense `Tensor` is not included, so it is overly conservative with respect to\n",
      "        the time ratio.\n",
      "        \n",
      "        Benchmark system:\n",
      "        CPU: Intel Ivybridge with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:12MB\n",
      "        GPU: NVidia Tesla k40c\n",
      "        \n",
      "        Compiled with:\n",
      "        `-c opt --config=cuda --copt=-mavx`\n",
      "        \n",
      "        ```\n",
      "        tensorflow/python/sparse_tensor_dense_matmul_op_test --benchmarks\n",
      "        A sparse [m, k] with % nonzero values between 1% and 80%\n",
      "        B dense [k, n]\n",
      "        \n",
      "        % nnz  n   gpu   m     k     dt(dense)     dt(sparse)   dt(sparse)/dt(dense)\n",
      "        0.01   1   True  100   100   0.000221166   0.00010154   0.459112\n",
      "        0.01   1   True  100   1000  0.00033858    0.000109275  0.322745\n",
      "        0.01   1   True  1000  100   0.000310557   9.85661e-05  0.317385\n",
      "        0.01   1   True  1000  1000  0.0008721     0.000100875  0.115669\n",
      "        0.01   1   False 100   100   0.000208085   0.000107603  0.51711\n",
      "        0.01   1   False 100   1000  0.000327112   9.51118e-05  0.290762\n",
      "        0.01   1   False 1000  100   0.000308222   0.00010345   0.335635\n",
      "        0.01   1   False 1000  1000  0.000865721   0.000101397  0.117124\n",
      "        0.01   10  True  100   100   0.000218522   0.000105537  0.482958\n",
      "        0.01   10  True  100   1000  0.000340882   0.000111641  0.327506\n",
      "        0.01   10  True  1000  100   0.000315472   0.000117376  0.372064\n",
      "        0.01   10  True  1000  1000  0.000905493   0.000123263  0.136128\n",
      "        0.01   10  False 100   100   0.000221529   9.82571e-05  0.44354\n",
      "        0.01   10  False 100   1000  0.000330552   0.000112615  0.340687\n",
      "        0.01   10  False 1000  100   0.000341277   0.000114097  0.334324\n",
      "        0.01   10  False 1000  1000  0.000819944   0.000120982  0.147549\n",
      "        0.01   25  True  100   100   0.000207806   0.000105977  0.509981\n",
      "        0.01   25  True  100   1000  0.000322879   0.00012921   0.400181\n",
      "        0.01   25  True  1000  100   0.00038262    0.00014158   0.370035\n",
      "        0.01   25  True  1000  1000  0.000865438   0.000202083  0.233504\n",
      "        0.01   25  False 100   100   0.000209401   0.000104696  0.499979\n",
      "        0.01   25  False 100   1000  0.000321161   0.000130737  0.407076\n",
      "        0.01   25  False 1000  100   0.000377012   0.000136801  0.362856\n",
      "        0.01   25  False 1000  1000  0.000861125   0.00020272   0.235413\n",
      "        0.2    1   True  100   100   0.000206952   9.69219e-05  0.46833\n",
      "        0.2    1   True  100   1000  0.000348674   0.000147475  0.422959\n",
      "        0.2    1   True  1000  100   0.000336908   0.00010122   0.300439\n",
      "        0.2    1   True  1000  1000  0.001022      0.000203274  0.198898\n",
      "        0.2    1   False 100   100   0.000207532   9.5412e-05   0.459746\n",
      "        0.2    1   False 100   1000  0.000356127   0.000146824  0.41228\n",
      "        0.2    1   False 1000  100   0.000322664   0.000100918  0.312764\n",
      "        0.2    1   False 1000  1000  0.000998987   0.000203442  0.203648\n",
      "        0.2    10  True  100   100   0.000211692   0.000109903  0.519165\n",
      "        0.2    10  True  100   1000  0.000372819   0.000164321  0.440753\n",
      "        0.2    10  True  1000  100   0.000338651   0.000144806  0.427596\n",
      "        0.2    10  True  1000  1000  0.00108312    0.000758876  0.70064\n",
      "        0.2    10  False 100   100   0.000215727   0.000110502  0.512231\n",
      "        0.2    10  False 100   1000  0.000375419   0.0001613    0.429653\n",
      "        0.2    10  False 1000  100   0.000336999   0.000145628  0.432132\n",
      "        0.2    10  False 1000  1000  0.00110502    0.000762043  0.689618\n",
      "        0.2    25  True  100   100   0.000218705   0.000129913  0.594009\n",
      "        0.2    25  True  100   1000  0.000394794   0.00029428   0.745402\n",
      "        0.2    25  True  1000  100   0.000404483   0.0002693    0.665788\n",
      "        0.2    25  True  1000  1000  0.0012002     0.00194494   1.62052\n",
      "        0.2    25  False 100   100   0.000221494   0.0001306    0.589632\n",
      "        0.2    25  False 100   1000  0.000396436   0.000297204  0.74969\n",
      "        0.2    25  False 1000  100   0.000409346   0.000270068  0.659754\n",
      "        0.2    25  False 1000  1000  0.00121051    0.00193737   1.60046\n",
      "        0.5    1   True  100   100   0.000214981   9.82111e-05  0.456836\n",
      "        0.5    1   True  100   1000  0.000415328   0.000223073  0.537101\n",
      "        0.5    1   True  1000  100   0.000358324   0.00011269   0.314492\n",
      "        0.5    1   True  1000  1000  0.00137612    0.000437401  0.317851\n",
      "        0.5    1   False 100   100   0.000224196   0.000101423  0.452386\n",
      "        0.5    1   False 100   1000  0.000400987   0.000223286  0.556841\n",
      "        0.5    1   False 1000  100   0.000368825   0.00011224   0.304318\n",
      "        0.5    1   False 1000  1000  0.00136036    0.000429369  0.31563\n",
      "        0.5    10  True  100   100   0.000222125   0.000112308  0.505608\n",
      "        0.5    10  True  100   1000  0.000461088   0.00032357   0.701753\n",
      "        0.5    10  True  1000  100   0.000394624   0.000225497  0.571422\n",
      "        0.5    10  True  1000  1000  0.00158027    0.00190898   1.20801\n",
      "        0.5    10  False 100   100   0.000232083   0.000114978  0.495418\n",
      "        0.5    10  False 100   1000  0.000454574   0.000324632  0.714146\n",
      "        0.5    10  False 1000  100   0.000379097   0.000227768  0.600817\n",
      "        0.5    10  False 1000  1000  0.00160292    0.00190168   1.18638\n",
      "        0.5    25  True  100   100   0.00023429    0.000151703  0.647501\n",
      "        0.5    25  True  100   1000  0.000497462   0.000598873  1.20386\n",
      "        0.5    25  True  1000  100   0.000460778   0.000557038  1.20891\n",
      "        0.5    25  True  1000  1000  0.00170036    0.00467336   2.74845\n",
      "        0.5    25  False 100   100   0.000228981   0.000155334  0.678371\n",
      "        0.5    25  False 100   1000  0.000496139   0.000620789  1.25124\n",
      "        0.5    25  False 1000  100   0.00045473    0.000551528  1.21287\n",
      "        0.5    25  False 1000  1000  0.00171793    0.00467152   2.71927\n",
      "        0.8    1   True  100   100   0.000222037   0.000105301  0.47425\n",
      "        0.8    1   True  100   1000  0.000410804   0.000329327  0.801664\n",
      "        0.8    1   True  1000  100   0.000349735   0.000131225  0.375212\n",
      "        0.8    1   True  1000  1000  0.00139219    0.000677065  0.48633\n",
      "        0.8    1   False 100   100   0.000214079   0.000107486  0.502085\n",
      "        0.8    1   False 100   1000  0.000413746   0.000323244  0.781261\n",
      "        0.8    1   False 1000  100   0.000348983   0.000131983  0.378193\n",
      "        0.8    1   False 1000  1000  0.00136296    0.000685325  0.50282\n",
      "        0.8    10  True  100   100   0.000229159   0.00011825   0.516017\n",
      "        0.8    10  True  100   1000  0.000498845   0.000532618  1.0677\n",
      "        0.8    10  True  1000  100   0.000383126   0.00029935   0.781336\n",
      "        0.8    10  True  1000  1000  0.00162866    0.00307312   1.88689\n",
      "        0.8    10  False 100   100   0.000230783   0.000124958  0.541452\n",
      "        0.8    10  False 100   1000  0.000493393   0.000550654  1.11606\n",
      "        0.8    10  False 1000  100   0.000377167   0.000298581  0.791642\n",
      "        0.8    10  False 1000  1000  0.00165795    0.00305103   1.84024\n",
      "        0.8    25  True  100   100   0.000233496   0.000175241  0.75051\n",
      "        0.8    25  True  100   1000  0.00055654    0.00102658   1.84458\n",
      "        0.8    25  True  1000  100   0.000463814   0.000783267  1.68875\n",
      "        0.8    25  True  1000  1000  0.00186905    0.00755344   4.04132\n",
      "        0.8    25  False 100   100   0.000240243   0.000175047  0.728625\n",
      "        0.8    25  False 100   1000  0.000578102   0.00104499   1.80763\n",
      "        0.8    25  False 1000  100   0.000485113   0.000776849  1.60138\n",
      "        0.8    25  False 1000  1000  0.00211448    0.00752736   3.55992\n",
      "        ```\n",
      "    \n",
      "    sparse_tensor_to_dense(sp_input, default_value=None, validate_indices=True, name=None)\n",
      "        Converts a `SparseTensor` into a dense tensor.\n",
      "        \n",
      "        For this sparse tensor with three non-empty values:\n",
      "        \n",
      "        >>> sp_input = tf.sparse.SparseTensor(\n",
      "        ...   dense_shape=[3, 5],\n",
      "        ...   values=[7, 8, 9],\n",
      "        ...   indices =[[0, 1],\n",
      "        ...             [0, 3],\n",
      "        ...             [2, 0]])\n",
      "        \n",
      "        The output will be a dense `[3, 5]` tensor with values:\n",
      "        \n",
      "        >>> tf.sparse.to_dense(sp_input).numpy()\n",
      "        array([[0, 7, 0, 8, 0],\n",
      "               [0, 0, 0, 0, 0],\n",
      "               [9, 0, 0, 0, 0]], dtype=int32)\n",
      "        \n",
      "        Note: Indices must be without repeats.  This is only tested if\n",
      "        `validate_indices` is `True`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          default_value: Scalar value to set for indices not specified in\n",
      "            `sp_input`.  Defaults to zero.\n",
      "          validate_indices: A boolean value.  If `True`, indices are checked to make\n",
      "            sure they are sorted in lexicographic order and that there are no repeats.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A dense tensor with shape `sp_input.dense_shape` and values specified by\n",
      "          the non-empty values in `sp_input`. Indices not in `sp_input` are assigned\n",
      "          `default_value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value=0, validate_indices=True, name=None)\n",
      "        Converts a sparse representation into a dense tensor. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "        \n",
      "        Builds an array `dense` with shape `output_shape` such that\n",
      "        \n",
      "        ```python\n",
      "        # If sparse_indices is scalar\n",
      "        dense[i] = (i == sparse_indices ? sparse_values : default_value)\n",
      "        \n",
      "        # If sparse_indices is a vector, then for each i\n",
      "        dense[sparse_indices[i]] = sparse_values[i]\n",
      "        \n",
      "        # If sparse_indices is an n by d matrix, then for each i in [0, n)\n",
      "        dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]\n",
      "        ```\n",
      "        \n",
      "        All other values in `dense` are set to `default_value`.  If `sparse_values`\n",
      "        is a scalar, all sparse indices are set to this single value.\n",
      "        \n",
      "        Indices should be sorted in lexicographic order, and indices must not\n",
      "        contain any repeats. If `validate_indices` is True, these properties\n",
      "        are checked during execution.\n",
      "        \n",
      "        Args:\n",
      "          sparse_indices: A 0-D, 1-D, or 2-D `Tensor` of type `int32` or `int64`.\n",
      "            `sparse_indices[i]` contains the complete index where `sparse_values[i]`\n",
      "            will be placed.\n",
      "          output_shape: A 1-D `Tensor` of the same type as `sparse_indices`.  Shape\n",
      "            of the dense output tensor.\n",
      "          sparse_values: A 0-D or 1-D `Tensor`.  Values corresponding to each row of\n",
      "            `sparse_indices`, or a scalar value to be used for all sparse indices.\n",
      "          default_value: A 0-D `Tensor` of the same type as `sparse_values`.  Value\n",
      "            to set for indices not specified in `sparse_indices`.  Defaults to zero.\n",
      "          validate_indices: A boolean value.  If True, indices are checked to make\n",
      "            sure they are sorted in lexicographic order and that there are no repeats.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Dense `Tensor` of shape `output_shape`.  Has the same type as\n",
      "          `sparse_values`.\n",
      "    \n",
      "    sparse_to_indicator(sp_input, vocab_size, name=None)\n",
      "        Converts a `SparseTensor` of ids into a dense bool indicator tensor.\n",
      "        \n",
      "        The last dimension of `sp_input.indices` is discarded and replaced with\n",
      "        the values of `sp_input`.  If `sp_input.dense_shape = [D0, D1, ..., Dn, K]`,\n",
      "        then `output.shape = [D0, D1, ..., Dn, vocab_size]`, where\n",
      "        \n",
      "            output[d_0, d_1, ..., d_n, sp_input[d_0, d_1, ..., d_n, k]] = True\n",
      "        \n",
      "        and False elsewhere in `output`.\n",
      "        \n",
      "        For example, if `sp_input.dense_shape = [2, 3, 4]` with non-empty values:\n",
      "        \n",
      "            [0, 0, 0]: 0\n",
      "            [0, 1, 0]: 10\n",
      "            [1, 0, 3]: 103\n",
      "            [1, 1, 1]: 150\n",
      "            [1, 1, 2]: 149\n",
      "            [1, 1, 3]: 150\n",
      "            [1, 2, 1]: 121\n",
      "        \n",
      "        and `vocab_size = 200`, then the output will be a `[2, 3, 200]` dense bool\n",
      "        tensor with False everywhere except at positions\n",
      "        \n",
      "            (0, 0, 0), (0, 1, 10), (1, 0, 103), (1, 1, 149), (1, 1, 150),\n",
      "            (1, 2, 121).\n",
      "        \n",
      "        Note that repeats are allowed in the input SparseTensor.\n",
      "        This op is useful for converting `SparseTensor`s into dense formats for\n",
      "        compatibility with ops that expect dense tensors.\n",
      "        \n",
      "        The input `SparseTensor` must be in row-major order.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: A `SparseTensor` with `values` property of type `int32` or\n",
      "            `int64`.\n",
      "          vocab_size: A scalar int64 Tensor (or Python int) containing the new size\n",
      "            of the last dimension, `all(0 <= sp_input.values < vocab_size)`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A dense bool indicator tensor representing the indices with specified value.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_transpose(sp_input, perm=None, name=None)\n",
      "        Transposes a `SparseTensor`.\n",
      "        \n",
      "        Permutes the dimensions according to the value of `perm`.  This is the sparse\n",
      "        version of `tf.transpose`.\n",
      "        \n",
      "        The returned tensor's dimension `i` will correspond to the input dimension\n",
      "        `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is the rank\n",
      "        of the input tensor. Hence, by default, this operation performs a regular\n",
      "        matrix transpose on 2-D input Tensors.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.SparseTensor(indices=[[0, 1], [0, 3], [2, 3], [3, 1]],\n",
      "        ...                     values=[1.1, 2.2, 3.3, 4.4],\n",
      "        ...                     dense_shape=[4, 5])\n",
      "        >>> print('x =', tf.sparse.to_dense(x))\n",
      "        x = tf.Tensor(\n",
      "        [[0.  1.1 0.  2.2 0. ]\n",
      "        [0.  0.  0.  0.  0. ]\n",
      "        [0.  0.  0.  3.3 0. ]\n",
      "        [0.  4.4 0.  0.  0. ]], shape=(4, 5), dtype=float32)\n",
      "        \n",
      "        >>> x_transpose = tf.sparse.transpose(x)\n",
      "        >>> print('x_transpose =', tf.sparse.to_dense(x_transpose))\n",
      "        x_transpose = tf.Tensor(\n",
      "        [[0.  0.  0.  0. ]\n",
      "        [1.1 0.  0.  4.4]\n",
      "        [0.  0.  0.  0. ]\n",
      "        [2.2 0.  3.3 0. ]\n",
      "        [0.  0.  0.  0. ]], shape=(5, 4), dtype=float32)\n",
      "        \n",
      "        Equivalently, you could call `tf.sparse.transpose(x, perm=[1, 0])`.  The\n",
      "        `perm` argument is more useful for n-dimensional tensors where n > 2.\n",
      "        \n",
      "        >>> x = tf.SparseTensor(indices=[[0, 0, 1], [0, 0, 3], [1, 2, 3], [1, 3, 1]],\n",
      "        ...                     values=[1.1, 2.2, 3.3, 4.4],\n",
      "        ...                     dense_shape=[2, 4, 5])\n",
      "        >>> print('x =', tf.sparse.to_dense(x))\n",
      "        x = tf.Tensor(\n",
      "        [[[0.  1.1 0.  2.2 0. ]\n",
      "          [0.  0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  0.  0. ]]\n",
      "        [[0.  0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  3.3 0. ]\n",
      "          [0.  4.4 0.  0.  0. ]]], shape=(2, 4, 5), dtype=float32)\n",
      "        \n",
      "        As above, simply calling `tf.sparse.transpose` will default to `perm=[2,1,0]`.\n",
      "        \n",
      "        To take the transpose of a batch of sparse matrices, where 0 is the batch\n",
      "        dimension, you would set `perm=[0,2,1]`.\n",
      "        \n",
      "        >>> x_transpose = tf.sparse.transpose(x, perm=[0, 2, 1])\n",
      "        >>> print('x_transpose =', tf.sparse.to_dense(x_transpose))\n",
      "        x_transpose = tf.Tensor(\n",
      "        [[[0.  0.  0.  0. ]\n",
      "          [1.1 0.  0.  0. ]\n",
      "          [0.  0.  0.  0. ]\n",
      "          [2.2 0.  0.  0. ]\n",
      "          [0.  0.  0.  0. ]]\n",
      "        [[0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  4.4]\n",
      "          [0.  0.  0.  0. ]\n",
      "          [0.  0.  3.3 0. ]\n",
      "          [0.  0.  0.  0. ]]], shape=(2, 5, 4), dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          perm: A permutation vector of the dimensions of `sp_input`.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed `SparseTensor`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    split(value, num_or_size_splits, axis=0, num=None, name='split')\n",
      "        Splits a tensor `value` into a list of sub tensors.\n",
      "        \n",
      "        See also `tf.unstack`.\n",
      "        \n",
      "        If `num_or_size_splits` is an `int`,  then it splits `value` along the\n",
      "        dimension `axis` into `num_or_size_splits` smaller tensors. This requires that\n",
      "        `value.shape[axis]` is divisible by `num_or_size_splits`.\n",
      "        \n",
      "        If `num_or_size_splits` is a 1-D Tensor (or list), then `value` is split into\n",
      "        `len(num_or_size_splits)` elements. The shape of the `i`-th\n",
      "        element has the same size as the `value` except along dimension `axis` where\n",
      "        the size is `num_or_size_splits[i]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.Variable(tf.random.uniform([5, 30], -1, 1))\n",
      "        >>>\n",
      "        >>> # Split `x` into 3 tensors along dimension 1\n",
      "        >>> s0, s1, s2 = tf.split(x, num_or_size_splits=3, axis=1)\n",
      "        >>> tf.shape(s0).numpy()\n",
      "        array([ 5, 10], dtype=int32)\n",
      "        >>>\n",
      "        >>> # Split `x` into 3 tensors with sizes [4, 15, 11] along dimension 1\n",
      "        >>> split0, split1, split2 = tf.split(x, [4, 15, 11], 1)\n",
      "        >>> tf.shape(split0).numpy()\n",
      "        array([5, 4], dtype=int32)\n",
      "        >>> tf.shape(split1).numpy()\n",
      "        array([ 5, 15], dtype=int32)\n",
      "        >>> tf.shape(split2).numpy()\n",
      "        array([ 5, 11], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          value: The `Tensor` to split.\n",
      "          num_or_size_splits: Either an `int` indicating the number of splits\n",
      "            along `axis` or a 1-D integer `Tensor` or Python list containing the sizes\n",
      "            of each output tensor along `axis`. If an `int`, then it must evenly\n",
      "            divide `value.shape[axis]`; otherwise the sum of sizes along the split\n",
      "            axis must match that of the `value`.\n",
      "          axis: An `int` or scalar `int32` `Tensor`. The dimension along which\n",
      "            to split. Must be in the range `[-rank(value), rank(value))`. Defaults to\n",
      "            0.\n",
      "          num: Optional, an `int`, used to specify the number of outputs when it\n",
      "            cannot be inferred from the shape of `size_splits`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          if `num_or_size_splits` is an `int` returns a list of\n",
      "          `num_or_size_splits` `Tensor` objects; if `num_or_size_splits` is a 1-D\n",
      "          list or 1-D `Tensor` returns `num_or_size_splits.get_shape[0]`\n",
      "          `Tensor` objects resulting from splitting `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `num` is unspecified and cannot be inferred.\n",
      "          ValueError: If `num_or_size_splits` is a scalar `Tensor`.\n",
      "    \n",
      "    sqrt(x, name=None)\n",
      "        Computes element-wise square root of the input tensor.\n",
      "        \n",
      "        Note: This operation does not support integer types.\n",
      "        \n",
      "        >>> x = tf.constant([[4.0], [16.0]])\n",
      "        >>> tf.sqrt(x)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
      "          array([[2.],\n",
      "                 [4.]], dtype=float32)>\n",
      "        >>> y = tf.constant([[-4.0], [16.0]])\n",
      "        >>> tf.sqrt(y)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
      "          array([[nan],\n",
      "                 [ 4.]], dtype=float32)>\n",
      "        >>> z = tf.constant([[-1.0], [16.0]], dtype=tf.complex128)\n",
      "        >>> tf.sqrt(z)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=complex128, numpy=\n",
      "          array([[0.0+1.j],\n",
      "                 [4.0+0.j]])>\n",
      "        \n",
      "        Note: In order to support complex type, please provide an input tensor\n",
      "        of `complex64` or `complex128`.\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor` of type `bfloat16`, `half`, `float32`, `float64`,\n",
      "            `complex64`, `complex128`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of same size, type and sparsity as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.sqrt(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    square(x: typing.Annotated[_any, ~TV_Square_T], name=None) -> typing.Annotated[_any, ~TV_Square_T]\n",
      "        Computes square of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = x * x = x^2\\\\).\n",
      "        \n",
      "        >>> tf.math.square([-2., 0., 3.])\n",
      "        <tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 0., 9.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.square(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    squared_difference(x: typing.Annotated[_any, ~TV_SquaredDifference_T], y: typing.Annotated[_any, ~TV_SquaredDifference_T], name=None) -> typing.Annotated[_any, ~TV_SquaredDifference_T]\n",
      "        Returns conj(x - y)(x - y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.squared_difference` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    squeeze(input, axis=None, name=None, squeeze_dims=None)\n",
      "        Removes dimensions of size 1 from the shape of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(squeeze_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of the same type with\n",
      "        all dimensions of size 1 removed. If you don't want to remove all size 1\n",
      "        dimensions, you can remove specific size 1 dimensions by specifying\n",
      "        `axis`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "        >>> t = tf.ones([1, 2, 1, 3, 1, 1])\n",
      "        >>> print(tf.shape(tf.squeeze(t)).numpy())\n",
      "        [2 3]\n",
      "        \n",
      "        Or, to remove specific size 1 dimensions:\n",
      "        \n",
      "        >>> # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "        >>> t = tf.ones([1, 2, 1, 3, 1, 1])\n",
      "        >>> print(tf.shape(tf.squeeze(t, [2, 4])).numpy())\n",
      "        [1 2 3 1]\n",
      "        \n",
      "        Note: if `input` is a `tf.RaggedTensor`, then this operation takes `O(N)`\n",
      "        time, where `N` is the number of elements in the squeezed dimensions.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The `input` to squeeze.\n",
      "          axis: An optional list of `ints`. Defaults to `[]`. If specified, only\n",
      "            squeezes the dimensions listed. The dimension index starts at 0. It is an\n",
      "            error to squeeze a dimension that is not 1. Must be in the range\n",
      "            `[-rank(input), rank(input))`. Must be specified if `input` is a\n",
      "            `RaggedTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          squeeze_dims: Deprecated keyword argument that is now axis.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "          Contains the same data as `input`, but has one or more dimensions of\n",
      "          size 1 removed.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When both `squeeze_dims` and `axis` are specified.\n",
      "    \n",
      "    stack(values, axis=0, name='stack')\n",
      "        Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.\n",
      "        \n",
      "        See also `tf.concat`, `tf.tile`, `tf.repeat`.\n",
      "        \n",
      "        Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "        each tensor in `values`, by packing them along the `axis` dimension.\n",
      "        Given a list of length `N` of tensors of shape `(A, B, C)`;\n",
      "        \n",
      "        if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.\n",
      "        if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.\n",
      "        Etc.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1, 4])\n",
      "        >>> y = tf.constant([2, 5])\n",
      "        >>> z = tf.constant([3, 6])\n",
      "        >>> tf.stack([x, y, z])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "        array([[1, 4],\n",
      "               [2, 5],\n",
      "               [3, 6]], dtype=int32)>\n",
      "        >>> tf.stack([x, y, z], axis=1)\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[1, 2, 3],\n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        This is the opposite of unstack.  The numpy equivalent is `np.stack`\n",
      "        \n",
      "        >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))\n",
      "        True\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects with the same shape and type.\n",
      "          axis: An `int`. The axis to stack along. Defaults to the first dimension.\n",
      "            Negative values wrap around, so the valid range is `[-(R+1), R+1)`.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: A stacked `Tensor` with the same type as `values`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `axis` is out of the range [-(R+1), R+1).\n",
      "    \n",
      "    stop_gradient(input, name=None)\n",
      "        Stops gradient computation.\n",
      "        \n",
      "        When executed in a graph, this op outputs its input tensor as-is.\n",
      "        \n",
      "        When building ops to compute gradients, this op prevents the contribution of\n",
      "        its inputs to be taken into account.  Normally, the gradient generator adds ops\n",
      "        to a graph to compute the derivatives of a specified 'loss' by recursively\n",
      "        finding out inputs that contributed to its computation.  If you insert this op\n",
      "        in the graph it inputs are masked from the gradient generator.  They are not\n",
      "        taken into account for computing gradients.\n",
      "        \n",
      "        This is useful any time you want to compute a value with TensorFlow but need\n",
      "        to pretend that the value was a constant. For example, the softmax function\n",
      "        for a vector x can be written as\n",
      "        \n",
      "        ```python\n",
      "        \n",
      "          def softmax(x):\n",
      "            numerator = tf.exp(x)\n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "            return numerator / denominator\n",
      "        ```\n",
      "        \n",
      "        This however is susceptible to overflow if the values in x are large. An\n",
      "        alternative more stable way is to subtract the maximum of x from each of the\n",
      "        values.\n",
      "        \n",
      "        ```python\n",
      "        \n",
      "          def stable_softmax(x):\n",
      "            z = x - tf.reduce_max(x)\n",
      "            numerator = tf.exp(z)\n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "            return numerator / denominator\n",
      "        ```\n",
      "        \n",
      "        However, when we backprop through the softmax to x, we dont want to backprop\n",
      "        through the `tf.reduce_max(x)` (if the max values are not unique then the\n",
      "        gradient could flow to the wrong input) calculation and treat that as a\n",
      "        constant. Therefore, we should write this out as\n",
      "        \n",
      "        ```python\n",
      "        \n",
      "          def stable_softmax(x):\n",
      "            z = x - tf.stop_gradient(tf.reduce_max(x))\n",
      "            numerator = tf.exp(z)\n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "            return numerator / denominator\n",
      "        ```\n",
      "        \n",
      "        Some other examples include:\n",
      "        \n",
      "        *  The *EM* algorithm where the *M-step* should not involve backpropagation\n",
      "           through the output of the *E-step*.\n",
      "        *  Contrastive divergence training of Boltzmann machines where, when\n",
      "           differentiating the energy function, the training must not backpropagate\n",
      "           through the graph that generated the samples from the model.\n",
      "        *  Adversarial training, where no backprop should happen through the adversarial\n",
      "           example generation process.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    strided_slice(input_, begin, end, strides=None, begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0, var=None, name=None)\n",
      "        Extracts a strided slice of a tensor (generalized Python array indexing).\n",
      "        \n",
      "        See also `tf.slice`.\n",
      "        \n",
      "        **Instead of calling this op directly most users will want to use the\n",
      "        NumPy-style slicing syntax (e.g. `tensor[..., 3:4:-1, tf.newaxis, 3]`), which\n",
      "        is supported via `tf.Tensor.__getitem__` and `tf.Variable.__getitem__`.**\n",
      "        The interface of this op is a low-level encoding of the slicing syntax.\n",
      "        \n",
      "        Roughly speaking, this op extracts a slice of size `(end-begin)/stride`\n",
      "        from the given `input_` tensor. Starting at the location specified by `begin`\n",
      "        the slice continues by adding `stride` to the index until all dimensions are\n",
      "        not less than `end`.\n",
      "        Note that a stride can be negative, which causes a reverse slice.\n",
      "        \n",
      "        Given a Python slice `input[spec0, spec1, ..., specn]`,\n",
      "        this function will be called as follows.\n",
      "        \n",
      "        `begin`, `end`, and `strides` will be vectors of length n.\n",
      "        n in general is not equal to the rank of the `input_` tensor.\n",
      "        \n",
      "        In each mask field (`begin_mask`, `end_mask`, `ellipsis_mask`,\n",
      "        `new_axis_mask`, `shrink_axis_mask`) the ith bit will correspond to\n",
      "        the ith spec.\n",
      "        \n",
      "        If the ith bit of `begin_mask` is set, `begin[i]` is ignored and\n",
      "        the fullest possible range in that dimension is used instead.\n",
      "        `end_mask` works analogously, except with the end range.\n",
      "        \n",
      "        `foo[5:,:,:3]` on a 7x8x9 tensor is equivalent to `foo[5:7,0:8,0:3]`.\n",
      "        `foo[::-1]` reverses a tensor with shape 8.\n",
      "        \n",
      "        If the ith bit of `ellipsis_mask` is set, as many unspecified dimensions\n",
      "        as needed will be inserted between other dimensions. Only one\n",
      "        non-zero bit is allowed in `ellipsis_mask`.\n",
      "        \n",
      "        For example `foo[3:5,...,4:5]` on a shape 10x3x3x10 tensor is\n",
      "        equivalent to `foo[3:5,:,:,4:5]` and\n",
      "        `foo[3:5,...]` is equivalent to `foo[3:5,:,:,:]`.\n",
      "        \n",
      "        If the ith bit of `new_axis_mask` is set, then `begin`,\n",
      "        `end`, and `stride` are ignored and a new length 1 dimension is\n",
      "        added at this point in the output tensor.\n",
      "        \n",
      "        For example,\n",
      "        `foo[:4, tf.newaxis, :2]` would produce a shape `(4, 1, 2)` tensor.\n",
      "        \n",
      "        If the ith bit of `shrink_axis_mask` is set, it implies that the ith\n",
      "        specification shrinks the dimensionality by 1, taking on the value at index\n",
      "        `begin[i]`. `end[i]` and `strides[i]` are ignored in this case. For example in\n",
      "        Python one might do `foo[:, 3, :]` which would result in `shrink_axis_mask`\n",
      "        equal to 2.\n",
      "        \n",
      "        \n",
      "        NOTE: `begin` and `end` are zero-indexed.\n",
      "        `strides` entries must be non-zero.\n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
      "                         [[3, 3, 3], [4, 4, 4]],\n",
      "                         [[5, 5, 5], [6, 6, 6]]])\n",
      "        tf.strided_slice(t, [1, 0, 0], [2, 1, 3], [1, 1, 1])  # [[[3, 3, 3]]]\n",
      "        tf.strided_slice(t, [1, 0, 0], [2, 2, 3], [1, 1, 1])  # [[[3, 3, 3],\n",
      "                                                              #   [4, 4, 4]]]\n",
      "        tf.strided_slice(t, [1, -1, 0], [2, -3, 3], [1, -1, 1])  # [[[4, 4, 4],\n",
      "                                                                 #   [3, 3, 3]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_: A `Tensor`.\n",
      "          begin: An `int32` or `int64` `Tensor`.\n",
      "          end: An `int32` or `int64` `Tensor`.\n",
      "          strides: An `int32` or `int64` `Tensor`.\n",
      "          begin_mask: An `int32` mask.\n",
      "          end_mask: An `int32` mask.\n",
      "          ellipsis_mask: An `int32` mask.\n",
      "          new_axis_mask: An `int32` mask.\n",
      "          shrink_axis_mask: An `int32` mask.\n",
      "          var: The variable corresponding to `input_` or None\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` the same type as `input`.\n",
      "    \n",
      "    string_join(inputs, separator='', name=None)\n",
      "        Perform element-wise concatenation of a list of string tensors.\n",
      "        \n",
      "        Given a list of string tensors of same shape, performs element-wise\n",
      "        concatenation of the strings of the same index in all tensors.\n",
      "        \n",
      "        \n",
      "        >>> tf.strings.join(['abc','def']).numpy()\n",
      "        b'abcdef'\n",
      "        >>> tf.strings.join([['abc','123'],\n",
      "        ...                  ['def','456'],\n",
      "        ...                  ['ghi','789']]).numpy()\n",
      "        array([b'abcdefghi', b'123456789'], dtype=object)\n",
      "        >>> tf.strings.join([['abc','123'],\n",
      "        ...                  ['def','456']],\n",
      "        ...                  separator=\" \").numpy()\n",
      "        array([b'abc def', b'123 456'], dtype=object)\n",
      "        \n",
      "        The reduction version of this elementwise operation is\n",
      "        `tf.strings.reduce_join`\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `tf.Tensor` objects of same size and `tf.string` dtype.\n",
      "          separator: A string added between each string being joined.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.string` tensor.\n",
      "    \n",
      "    string_split(source, sep=None, skip_empty=True, delimiter=None, result_type='SparseTensor', name=None)\n",
      "        Split elements of `source` based on `delimiter`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(delimiter)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        delimiter is deprecated, please use sep instead.\n",
      "        \n",
      "        Let N be the size of `source` (typically N will be the batch size). Split each\n",
      "        element of `source` based on `delimiter` and return a `SparseTensor`\n",
      "        or `RaggedTensor` containing the split tokens. Empty tokens are ignored.\n",
      "        \n",
      "        If `sep` is an empty string, each element of the `source` is split\n",
      "        into individual strings, each containing one byte. (This includes splitting\n",
      "        multibyte sequences of UTF-8.) If delimiter contains multiple bytes, it is\n",
      "        treated as a set of delimiters with each considered a potential split point.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> print(tf.compat.v1.string_split(['hello world', 'a b c']))\n",
      "        SparseTensor(indices=tf.Tensor( [[0 0] [0 1] [1 0] [1 1] [1 2]], ...),\n",
      "                     values=tf.Tensor([b'hello' b'world' b'a' b'b' b'c'], ...),\n",
      "                     dense_shape=tf.Tensor([2 3], shape=(2,), dtype=int64))\n",
      "        \n",
      "        >>> print(tf.compat.v1.string_split(['hello world', 'a b c'],\n",
      "        ...     result_type=\"RaggedTensor\"))\n",
      "        <tf.RaggedTensor [[b'hello', b'world'], [b'a', b'b', b'c']]>\n",
      "        \n",
      "        Args:\n",
      "          source: `1-D` string `Tensor`, the strings to split.\n",
      "          sep: `0-D` string `Tensor`, the delimiter character, the string should\n",
      "            be length 0 or 1. Default is ' '.\n",
      "          skip_empty: A `bool`. If `True`, skip the empty strings from the result.\n",
      "          delimiter: deprecated alias for `sep`.\n",
      "          result_type: The tensor type for the result: one of `\"RaggedTensor\"` or\n",
      "            `\"SparseTensor\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If delimiter is not a string.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or `RaggedTensor` of rank `2`, the strings split according\n",
      "          to the delimiter.  The first column of the indices corresponds to the row\n",
      "          in `source` and the second column corresponds to the index of the split\n",
      "          component in this row.\n",
      "    \n",
      "    string_strip(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Strip leading and trailing whitespaces from the Tensor.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.strings.strip([\"\\nTensorFlow\", \"     The python library    \"]).numpy()\n",
      "        array([b'TensorFlow', b'The python library'], dtype=object)\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. A string `Tensor` of any shape.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    string_to_hash_bucket = string_to_hash_bucket_v1(string_tensor=None, num_buckets=None, name=None, input=None)\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process.\n",
      "        \n",
      "        Note that the hash function may change from time to time.\n",
      "        This functionality will be deprecated and it's recommended to use\n",
      "        `tf.string_to_hash_bucket_fast()` or `tf.string_to_hash_bucket_strong()`.\n",
      "        \n",
      "        Args:\n",
      "          string_tensor: A `Tensor` of type `string`.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_hash_bucket_fast(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], num_buckets: int, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>]\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process and will never change. However, it is not suitable for cryptography.\n",
      "        This function may be used when CPU time is scarce and inputs are trusted or\n",
      "        unimportant. There is a risk of adversaries constructing inputs that all hash\n",
      "        to the same bucket. To prevent this problem, use a strong hash function with\n",
      "        `tf.string_to_hash_bucket_strong`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.strings.to_hash_bucket_fast([\"Hello\", \"TensorFlow\", \"2.x\"], 3).numpy()\n",
      "        array([0, 2, 2])\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. The strings to assign a hash bucket.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_hash_bucket_strong(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], num_buckets: int, key, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>]\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process. The hash function is a keyed hash function, where attribute `key`\n",
      "        defines the key of the hash function. `key` is an array of 2 elements.\n",
      "        \n",
      "        A strong hash is important when inputs may be malicious, e.g. URLs with\n",
      "        additional components. Adversaries could try to make their inputs hash to the\n",
      "        same bucket for a denial-of-service attack or to skew the results. A strong\n",
      "        hash can be used to make it difficult to find inputs with a skewed hash value\n",
      "        distribution over buckets. This requires that the hash function is\n",
      "        seeded by a high-entropy (random) \"key\" unknown to the adversary.\n",
      "        \n",
      "        The additional robustness comes at a cost of roughly 4x higher compute\n",
      "        time than `tf.string_to_hash_bucket_fast`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.strings.to_hash_bucket_strong([\"Hello\", \"TF\"], 3, [1, 2]).numpy()\n",
      "        array([2, 0])\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. The strings to assign a hash bucket.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          key: A list of `ints`.\n",
      "            The key used to seed the hash function, passed as a list of two uint64\n",
      "            elements.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_number = string_to_number_v1(string_tensor=None, out_type=tf.float32, name=None, input=None)\n",
      "        Converts each string in the input Tensor to the specified numeric type.\n",
      "        \n",
      "        (Note that int32 overflow results in an error while float overflow\n",
      "        results in a rounded value.)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> strings = [\"5.0\", \"3.0\", \"7.0\"]\n",
      "        >>> tf.strings.to_number(strings)\n",
      "        <tf.Tensor: shape=(3,), dtype=float32, numpy=array([5., 3., 7.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          string_tensor: A `Tensor` of type `string`.\n",
      "          out_type: An optional `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.int64`. Defaults to `tf.float32`.\n",
      "            The numeric type to interpret each string in `string_tensor` as.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    substr = substr_deprecated(input, pos, len, name=None, unit='BYTE')\n",
      "        Return substrings from `Tensor` of strings.\n",
      "        \n",
      "        For each string in the input `Tensor`, creates a substring starting at index\n",
      "        `pos` with a total length of `len`.\n",
      "        \n",
      "        If `len` defines a substring that would extend beyond the length of the input\n",
      "        string, or if `len` is negative, then as many characters as possible are used.\n",
      "        \n",
      "        A negative `pos` indicates distance within the string backwards from the end.\n",
      "        \n",
      "        If `pos` specifies an index which is out of range for any of the input strings,\n",
      "        then an `InvalidArgumentError` is thrown.\n",
      "        \n",
      "        `pos` and `len` must have the same shape, otherwise a `ValueError` is thrown on\n",
      "        Op creation.\n",
      "        \n",
      "        *NOTE*: `Substr` supports broadcasting up to two dimensions. More about\n",
      "        broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        ---\n",
      "        \n",
      "        Examples\n",
      "        \n",
      "        Using scalar `pos` and `len`:\n",
      "        \n",
      "        ```python\n",
      "        input = [b'Hello', b'World']\n",
      "        position = 1\n",
      "        length = 3\n",
      "        \n",
      "        output = [b'ell', b'orl']\n",
      "        ```\n",
      "        \n",
      "        Using `pos` and `len` with same shape as `input`:\n",
      "        \n",
      "        ```python\n",
      "        input = [[b'ten', b'eleven', b'twelve'],\n",
      "                 [b'thirteen', b'fourteen', b'fifteen'],\n",
      "                 [b'sixteen', b'seventeen', b'eighteen']]\n",
      "        position = [[1, 2, 3],\n",
      "                    [1, 2, 3],\n",
      "                    [1, 2, 3]]\n",
      "        length =   [[2, 3, 4],\n",
      "                    [4, 3, 2],\n",
      "                    [5, 5, 5]]\n",
      "        \n",
      "        output = [[b'en', b'eve', b'lve'],\n",
      "                  [b'hirt', b'urt', b'te'],\n",
      "                  [b'ixtee', b'vente', b'hteen']]\n",
      "        ```\n",
      "        \n",
      "        Broadcasting `pos` and `len` onto `input`:\n",
      "        \n",
      "        ```\n",
      "        input = [[b'ten', b'eleven', b'twelve'],\n",
      "                 [b'thirteen', b'fourteen', b'fifteen'],\n",
      "                 [b'sixteen', b'seventeen', b'eighteen'],\n",
      "                 [b'nineteen', b'twenty', b'twentyone']]\n",
      "        position = [1, 2, 3]\n",
      "        length =   [1, 2, 3]\n",
      "        \n",
      "        output = [[b'e', b'ev', b'lve'],\n",
      "                  [b'h', b'ur', b'tee'],\n",
      "                  [b'i', b've', b'hte'],\n",
      "                  [b'i', b'en', b'nty']]\n",
      "        ```\n",
      "        \n",
      "        Broadcasting `input` onto `pos` and `len`:\n",
      "        \n",
      "        ```\n",
      "        input = b'thirteen'\n",
      "        position = [1, 5, 7]\n",
      "        length =   [3, 2, 1]\n",
      "        \n",
      "        output = [b'hir', b'ee', b'n']\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "        \n",
      "          * `ValueError`: If the first argument cannot be converted to a\n",
      "             Tensor of `dtype string`.\n",
      "          * `InvalidArgumentError`: If indices are out of range.\n",
      "          * `ValueError`: If `pos` and `len` are not the same shape.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Tensor of strings\n",
      "          pos: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Scalar defining the position of first character in each substring\n",
      "          len: A `Tensor`. Must have the same type as `pos`.\n",
      "            Scalar defining the number of characters to include in each substring\n",
      "          unit: An optional `string` from: `\"BYTE\", \"UTF8_CHAR\"`. Defaults to `\"BYTE\"`.\n",
      "            The unit that is used to create the substring.  One of: `\"BYTE\"` (for\n",
      "            defining position and length by bytes) or `\"UTF8_CHAR\"` (for the UTF-8\n",
      "            encoded Unicode code points).  The default is `\"BYTE\"`. Results are undefined if\n",
      "            `unit=UTF8_CHAR` and the `input` strings do not contain structurally valid\n",
      "            UTF-8.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    subtract(x, y, name=None)\n",
      "        Returns x - y element-wise.\n",
      "        \n",
      "        *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Both input and output have a range `(-inf, inf)`.\n",
      "        \n",
      "        Example usages below.\n",
      "        \n",
      "        Subtract operation between an array and a scalar:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = 1\n",
      "        >>> tf.subtract(x, y)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        >>> tf.subtract(y, x)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "        \n",
      "        Note that binary `-` operator can be used instead:\n",
      "        \n",
      "        >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "        >>> y = tf.convert_to_tensor(1)\n",
      "        >>> x - y\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        \n",
      "        Subtract operation between an array and a tensor of same shape:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "        >>> tf.subtract(y, x)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "        \n",
      "        **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "        non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "        of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "        conversion.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "        >>> y = [2**8 + 1, 2**8 + 2]\n",
      "        >>> tf.subtract(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "        \n",
      "        When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "        [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "        . The two input array shapes are compared element-wise. Starting with the\n",
      "        trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "        needs to be `1`.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "        >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "        >>> tf.subtract(x, y)\n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "        array([[[0., 0., 0.],\n",
      "                [0., 0., 0.],\n",
      "                [0., 0., 0.]],\n",
      "               [[0., 0., 0.],\n",
      "                [0., 0., 0.],\n",
      "                [0., 0., 0.]]])>\n",
      "        \n",
      "        Example with inputs of different dimensions:\n",
      "        \n",
      "        >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "        >>> y = np.ones(6).reshape(1, 6)\n",
      "        >>> tf.subtract(x, y)\n",
      "        <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "        array([[[0., 0., 0., 0., 0., 0.],\n",
      "                [0., 0., 0., 0., 0., 0.],\n",
      "                [0., 0., 0., 0., 0., 0.]],\n",
      "               [[0., 0., 0., 0., 0., 0.],\n",
      "                [0., 0., 0., 0., 0., 0.],\n",
      "                [0., 0., 0., 0., 0., 0.]]])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    svd(tensor, full_matrices=False, compute_uv=True, name=None)\n",
      "        Computes the singular value decompositions of one or more matrices.\n",
      "        \n",
      "        Computes the SVD of each inner matrix in `tensor` such that\n",
      "        `tensor[..., :, :] = u[..., :, :] * diag(s[..., :, :]) *\n",
      "         transpose(conj(v[..., :, :]))`\n",
      "        \n",
      "        ```python\n",
      "        # a is a tensor.\n",
      "        # s is a tensor of singular values.\n",
      "        # u is a tensor of left singular vectors.\n",
      "        # v is a tensor of right singular vectors.\n",
      "        s, u, v = svd(a)\n",
      "        s = svd(a, compute_uv=False)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., M, N]`. Let `P` be the minimum of `M` and\n",
      "            `N`.\n",
      "          full_matrices: If true, compute full-sized `u` and `v`. If false\n",
      "            (the default), compute only the leading `P` singular vectors.\n",
      "            Ignored if `compute_uv` is `False`.\n",
      "          compute_uv: If `True` then left and right singular vectors will be\n",
      "            computed and returned in `u` and `v`, respectively. Otherwise, only the\n",
      "            singular values will be computed, which can be significantly faster.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          s: Singular values. Shape is `[..., P]`. The values are sorted in reverse\n",
      "            order of magnitude, so s[..., 0] is the largest value, s[..., 1] is the\n",
      "            second largest, etc.\n",
      "          u: Left singular vectors. If `full_matrices` is `False` (default) then\n",
      "            shape is `[..., M, P]`; if `full_matrices` is `True` then shape is\n",
      "            `[..., M, M]`. Not returned if `compute_uv` is `False`.\n",
      "          v: Right singular vectors. If `full_matrices` is `False` (default) then\n",
      "            shape is `[..., N, P]`. If `full_matrices` is `True` then shape is\n",
      "            `[..., N, N]`. Not returned if `compute_uv` is `False`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Mostly equivalent to numpy.linalg.svd, except that\n",
      "          * The order of output  arguments here is `s`, `u`, `v` when `compute_uv` is\n",
      "            `True`, as opposed to `u`, `s`, `v` for numpy.linalg.svd.\n",
      "          * full_matrices is `False` by default as opposed to `True` for\n",
      "             numpy.linalg.svd.\n",
      "          * tf.linalg.svd uses the standard definition of the SVD\n",
      "            \\\\(A = U \\Sigma V^H\\\\), such that the left singular vectors of `a` are\n",
      "            the columns of `u`, while the right singular vectors of `a` are the\n",
      "            columns of `v`. On the other hand, numpy.linalg.svd returns the adjoint\n",
      "            \\\\(V^H\\\\) as the third output argument.\n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        import numpy as np\n",
      "        s, u, v = tf.linalg.svd(a)\n",
      "        tf_a_approx = tf.matmul(u, tf.matmul(tf.linalg.diag(s), v, adjoint_b=True))\n",
      "        u, s, v_adj = np.linalg.svd(a, full_matrices=False)\n",
      "        np_a_approx = np.dot(u, np.dot(np.diag(s), v_adj))\n",
      "        # tf_a_approx and np_a_approx should be numerically close.\n",
      "        ```\n",
      "        @end_compatibility\n",
      "    \n",
      "    switch_case(branch_index, branch_fns, default=None, name='switch_case')\n",
      "        Create a switch/case operation, i.e.\n",
      "        \n",
      "        an integer-indexed conditional.\n",
      "        \n",
      "        See also `tf.case`.\n",
      "        \n",
      "        This op can be substantially more efficient than `tf.case` when exactly one\n",
      "        branch will be selected. `tf.switch_case` is more like a C++ switch/case\n",
      "        statement than `tf.case`, which is more like an if/elif/elif/else chain.\n",
      "        \n",
      "        The `branch_fns` parameter is either a dict from `int` to callables, or list\n",
      "        of (`int`, callable) pairs, or simply a list of callables (in which case the\n",
      "        index is implicitly the key). The `branch_index` `Tensor` is used to select an\n",
      "        element in `branch_fns` with matching `int` key, falling back to `default`\n",
      "        if none match, or `max(keys)` if no `default` is provided. The keys must form\n",
      "        a contiguous set from `0` to `len(branch_fns) - 1`.\n",
      "        \n",
      "        `tf.switch_case` supports nested structures as implemented in `tf.nest`. All\n",
      "        callables must return the same (possibly nested) value structure of lists,\n",
      "        tuples, and/or named tuples.\n",
      "        \n",
      "        **Example:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```c++\n",
      "        switch (branch_index) {  // c-style switch\n",
      "          case 0: return 17;\n",
      "          case 1: return 31;\n",
      "          default: return -1;\n",
      "        }\n",
      "        ```\n",
      "        or\n",
      "        ```python\n",
      "        branches = {0: lambda: 17, 1: lambda: 31}\n",
      "        branches.get(branch_index, lambda: -1)()\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        def f1(): return tf.constant(17)\n",
      "        def f2(): return tf.constant(31)\n",
      "        def f3(): return tf.constant(-1)\n",
      "        r = tf.switch_case(branch_index, branch_fns={0: f1, 1: f2}, default=f3)\n",
      "        # Equivalent: tf.switch_case(branch_index, branch_fns={0: f1, 1: f2, 2: f3})\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          branch_index: An int Tensor specifying which of `branch_fns` should be\n",
      "            executed.\n",
      "          branch_fns: A `dict` mapping `int`s to callables, or a `list` of (`int`,\n",
      "            callable) pairs, or simply a list of callables (in which case the index\n",
      "            serves as the key). Each callable must return a matching structure of\n",
      "            tensors.\n",
      "          default: Optional callable that returns a structure of tensors.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The tensors returned by the callable identified by `branch_index`, or those\n",
      "          returned by `default` if no key matches and `default` was provided, or those\n",
      "          returned by the max-keyed `branch_fn` if no `default` is provided.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `branch_fns` is not a list/dictionary.\n",
      "          TypeError: If `branch_fns` is a list but does not contain 2-tuples or\n",
      "                     callables.\n",
      "          TypeError: If `fns[i]` is not callable for any i, or `default` is not\n",
      "                     callable.\n",
      "    \n",
      "    tables_initializer(name='init_all_tables')\n",
      "        Returns an Op that initializes all tables of the default graph.\n",
      "        \n",
      "        Args:\n",
      "          name: Optional name for the initialization op.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all tables.  Note that if there are\n",
      "          not tables the returned Op is a NoOp.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.tables_initializer` is no longer needed with eager execution and\n",
      "        `tf.function`. In TF2, when creating an initializable table like a\n",
      "        `tf.lookup.StaticHashTable`, the table will automatically be initialized on\n",
      "        creation.\n",
      "        \n",
      "        #### Before & After Usage Example\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> with tf.compat.v1.Session():\n",
      "        ...   init = tf.compat.v1.lookup.KeyValueTensorInitializer(['a', 'b'], [1, 2])\n",
      "        ...   table = tf.compat.v1.lookup.StaticHashTable(init, default_value=-1)\n",
      "        ...   tf.compat.v1.tables_initializer().run()\n",
      "        ...   result = table.lookup(tf.constant(['a', 'c'])).eval()\n",
      "        >>> result\n",
      "        array([ 1, -1], dtype=int32)\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> init = tf.lookup.KeyValueTensorInitializer(['a', 'b'], [1, 2])\n",
      "        >>> table = tf.lookup.StaticHashTable(init, default_value=-1)\n",
      "        >>> table.lookup(tf.constant(['a', 'c'])).numpy()\n",
      "        array([ 1, -1], dtype=int32)\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    tan(x: typing.Annotated[_any, ~TV_Tan_T], name=None) -> typing.Annotated[_any, ~TV_Tan_T]\n",
      "        Computes tan of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes tangent of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `(-inf, inf)`. If input lies outside the boundary, `nan`\n",
      "          is returned.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.tan(x) ==> [nan 0.45231566 -0.5463025 1.5574077 2.572152 -1.7925274 0.32097113 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    tanh(x: typing.Annotated[_any, ~TV_Tanh_T], name=None) -> typing.Annotated[_any, ~TV_Tanh_T]\n",
      "        Computes hyperbolic tangent of `x` element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic tangent of every\n",
      "          element in the tensor. Input range is `[-inf, inf]` and\n",
      "          output range is `[-1,1]`.\n",
      "        \n",
      "          >>> x = tf.constant([-float(\"inf\"), -5, -0.5, 1, 1.2, 2, 3, float(\"inf\")])\n",
      "          >>> tf.math.tanh(x)\n",
      "          <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
      "          array([-1.0, -0.99990916, -0.46211717,  0.7615942 ,  0.8336547 ,\n",
      "                  0.9640276 ,  0.9950547 ,  1.0], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.tanh(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    tensor_scatter_add(tensor: Annotated[Any, ~TV_TensorScatterAdd_T], indices: Annotated[Any, ~TV_TensorScatterAdd_Tindices], updates: Annotated[Any, ~TV_TensorScatterAdd_T], name=None) -> Annotated[Any, ~TV_TensorScatterAdd_T]\n",
      "        Adds sparse `updates` to an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by adding sparse `updates` to the passed\n",
      "        in `tensor`.\n",
      "        This operation is very similar to `tf.compat.v1.scatter_nd_add`, except that the\n",
      "        updates are added onto an existing tensor (as opposed to a variable). If the\n",
      "        memory for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `tensor.shape`.  The last dimension of `indices` can be at most the rank of\n",
      "        `tensor.shape`:\n",
      "        \n",
      "        ```\n",
      "        indices.shape[-1] <= tensor.shape.rank\n",
      "        ```\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = tensor.shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < tensor.shape.rank`) along dimension\n",
      "        `indices.shape[-1]` of `tensor.shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "        ```\n",
      "        indices.shape[:-1] + tensor.shape[indices.shape[-1]:]\n",
      "        ```\n",
      "        \n",
      "        The simplest form of `tensor_scatter_nd_add` is to add individual elements to a\n",
      "        tensor by index. For example, say we want to add 4 elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        >>> indices = tf.constant([[4], [3], [1], [7]])\n",
      "        >>> updates = tf.constant([9, 10, 11, 12])\n",
      "        >>> tensor = tf.ones([8], dtype=tf.int32)\n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        >>> updated\n",
      "        <tf.Tensor: shape=(8,), dtype=int32,\n",
      "        numpy=array([ 1, 12,  1, 11, 10,  1,  1, 13], dtype=int32)>\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        >>> indices = tf.constant([[0], [2]])\n",
      "        >>> updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "        ...                        [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "        >>> tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        >>> updated\n",
      "        <tf.Tensor: shape=(4, 4, 4), dtype=int32,\n",
      "        numpy=array([[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "                     [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]], dtype=int32)>\n",
      "        \n",
      "        Note: on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_add = tensor_scatter_add(tensor: Annotated[Any, ~TV_TensorScatterAdd_T], indices: Annotated[Any, ~TV_TensorScatterAdd_Tindices], updates: Annotated[Any, ~TV_TensorScatterAdd_T], name=None) -> Annotated[Any, ~TV_TensorScatterAdd_T]\n",
      "        Adds sparse `updates` to an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by adding sparse `updates` to the passed\n",
      "        in `tensor`.\n",
      "        This operation is very similar to `tf.compat.v1.scatter_nd_add`, except that the\n",
      "        updates are added onto an existing tensor (as opposed to a variable). If the\n",
      "        memory for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `tensor.shape`.  The last dimension of `indices` can be at most the rank of\n",
      "        `tensor.shape`:\n",
      "        \n",
      "        ```\n",
      "        indices.shape[-1] <= tensor.shape.rank\n",
      "        ```\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = tensor.shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < tensor.shape.rank`) along dimension\n",
      "        `indices.shape[-1]` of `tensor.shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "        ```\n",
      "        indices.shape[:-1] + tensor.shape[indices.shape[-1]:]\n",
      "        ```\n",
      "        \n",
      "        The simplest form of `tensor_scatter_nd_add` is to add individual elements to a\n",
      "        tensor by index. For example, say we want to add 4 elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        >>> indices = tf.constant([[4], [3], [1], [7]])\n",
      "        >>> updates = tf.constant([9, 10, 11, 12])\n",
      "        >>> tensor = tf.ones([8], dtype=tf.int32)\n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        >>> updated\n",
      "        <tf.Tensor: shape=(8,), dtype=int32,\n",
      "        numpy=array([ 1, 12,  1, 11, 10,  1,  1, 13], dtype=int32)>\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        >>> indices = tf.constant([[0], [2]])\n",
      "        >>> updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "        ...                        [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "        >>> tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        >>> updated\n",
      "        <tf.Tensor: shape=(4, 4, 4), dtype=int32,\n",
      "        numpy=array([[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "                     [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]], dtype=int32)>\n",
      "        \n",
      "        Note: on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_max = tensor_scatter_max(tensor: Annotated[Any, ~TV_TensorScatterMax_T], indices: Annotated[Any, ~TV_TensorScatterMax_Tindices], updates: Annotated[Any, ~TV_TensorScatterMax_T], name=None) -> Annotated[Any, ~TV_TensorScatterMax_T]\n",
      "        Apply a sparse update to a tensor taking the element-wise maximum.\n",
      "        \n",
      "        Returns a new tensor copied from `tensor` whose values are element-wise maximum between\n",
      "        tensor and updates according to the indices.\n",
      "        \n",
      "        >>> tensor = [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "        >>> indices = [[1], [4], [5]]\n",
      "        >>> updates = [1, -1, 1]\n",
      "        >>> tf.tensor_scatter_nd_max(tensor, indices, updates).numpy()\n",
      "        array([0, 1, 0, 0, 0, 1, 0, 0], dtype=int32)\n",
      "        \n",
      "        Refer to `tf.tensor_scatter_nd_update` for more details.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_min = tensor_scatter_min(tensor: Annotated[Any, ~TV_TensorScatterMin_T], indices: Annotated[Any, ~TV_TensorScatterMin_Tindices], updates: Annotated[Any, ~TV_TensorScatterMin_T], name=None) -> Annotated[Any, ~TV_TensorScatterMin_T]\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_sub = tensor_scatter_sub(tensor: Annotated[Any, ~TV_TensorScatterSub_T], indices: Annotated[Any, ~TV_TensorScatterSub_Tindices], updates: Annotated[Any, ~TV_TensorScatterSub_T], name=None) -> Annotated[Any, ~TV_TensorScatterSub_T]\n",
      "        Subtracts sparse `updates` from an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by subtracting sparse `updates` from the\n",
      "        passed in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd_sub`, except that the updates\n",
      "        are subtracted from an existing tensor (as opposed to a variable). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of tensor_scatter_sub is to subtract individual elements\n",
      "        from a tensor by index. For example, say we want to insert 4 scattered elements\n",
      "        in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter subtract operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "            print(updated)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, -10, 1, -9, -8, 1, 1, -11]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "            print(updated)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_update(tensor, indices, updates, name=None)\n",
      "        Scatter `updates` into an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by applying sparse `updates` to the\n",
      "        input `tensor`. This is similar to an index assignment.\n",
      "        \n",
      "        ```\n",
      "        # Not implemented: tensors cannot be updated inplace.\n",
      "        tensor[indices] = updates\n",
      "        ```\n",
      "        \n",
      "        If an out of bound index is found on CPU, an error is returned.\n",
      "        \n",
      "        > **WARNING**: There are some GPU specific semantics for this operation.\n",
      "        >\n",
      "        > - If an out of bound index is found, the index is ignored.\n",
      "        > - The order in which updates are applied is nondeterministic, so the output\n",
      "        >   will be nondeterministic if `indices` contains duplicates.\n",
      "        \n",
      "        This operation is very similar to `tf.scatter_nd`, except that the updates are\n",
      "        scattered onto an existing tensor (as opposed to a zero-tensor). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        In general:\n",
      "        \n",
      "        * `indices` is an integer tensor - the indices to update in `tensor`.\n",
      "        * `indices` has **at least two** axes, the last axis is the depth of the\n",
      "          index vectors.\n",
      "        * For each index vector in `indices` there is a corresponding entry in\n",
      "          `updates`.\n",
      "        * If the length of the index vectors matches the rank of the `tensor`, then\n",
      "          the index vectors each point to scalars in `tensor` and each update is a\n",
      "          scalar.\n",
      "        * If the length of the index vectors is less than the rank of `tensor`, then\n",
      "          the index vectors each point to the slices of `tensor` and shape of the updates\n",
      "          must match that slice.\n",
      "        \n",
      "        Overall this leads to the following shape constraints:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Typical usage is often much simpler than this general form, and it\n",
      "        can be better understood starting with simple examples:\n",
      "        \n",
      "        ### Scalar updates\n",
      "        \n",
      "        The simplest usage inserts scalar elements into a tensor by index.\n",
      "        In this case, the `index_depth` must equal the rank of the\n",
      "        input `tensor`, slice each column of `indices` is an index into an axis of the\n",
      "        input `tensor`.\n",
      "        \n",
      "        In this simplest case the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        assert updates.shape == [num_updates]\n",
      "        assert index_depth == tf.rank(tensor)`\n",
      "        ```\n",
      "        \n",
      "        For example, to insert 4 scattered elements in a rank-1 tensor with\n",
      "        8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\"\n",
      "          src=\"https://www.tensorflow.org/images/ScatterNd1.png\">\n",
      "        </div>\n",
      "        \n",
      "        This scatter operation would look like this:\n",
      "        \n",
      "        >>> tensor = [0, 0, 0, 0, 0, 0, 0, 0]    # tf.rank(tensor) == 1\n",
      "        >>> indices = [[1], [3], [4], [7]]       # num_updates == 4, index_depth == 1\n",
      "        >>> updates = [9, 10, 11, 12]            # num_updates == 4\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor([ 0 9  0 10  11  0  0 12], shape=(8,), dtype=int32)\n",
      "        \n",
      "        The length (first axis) of `updates` must equal the length of the `indices`:\n",
      "        `num_updates`. This is the number of updates being inserted. Each scalar\n",
      "        update is inserted into `tensor` at the indexed location.\n",
      "        \n",
      "        For a higher rank input `tensor` scalar updates can be inserted by using an\n",
      "        `index_depth` that matches `tf.rank(tensor)`:\n",
      "        \n",
      "        >>> tensor = [[1, 1], [1, 1], [1, 1]]    # tf.rank(tensor) == 2\n",
      "        >>> indices = [[0, 1], [2, 0]]           # num_updates == 2, index_depth == 2\n",
      "        >>> updates = [5, 10]                    # num_updates == 2\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor(\n",
      "            [[ 1  5]\n",
      "             [ 1  1]\n",
      "             [10  1]], shape=(3, 2), dtype=int32)\n",
      "        \n",
      "        ### Slice updates\n",
      "        \n",
      "        When the input `tensor` has more than one axis scatter can be used to update\n",
      "        entire slices.\n",
      "        \n",
      "        In this case it's helpful to think of the input `tensor` as being a two level\n",
      "        array-of-arrays. The shape of this two level array is split into the\n",
      "        `outer_shape` and the `inner_shape`.\n",
      "        \n",
      "        `indices` indexes into the outer level of the input tensor (`outer_shape`).\n",
      "        and replaces the sub-array at that location with the corresponding item from\n",
      "        the `updates` list. The shape of each update is `inner_shape`.\n",
      "        \n",
      "        When updating a list of slices the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == [num_updates, inner_shape]\n",
      "        ```\n",
      "        \n",
      "        For example, to update rows of a `(6, 3)` `tensor`:\n",
      "        \n",
      "        >>> tensor = tf.zeros([6, 3], dtype=tf.int32)\n",
      "        \n",
      "        Use an index depth of one.\n",
      "        \n",
      "        >>> indices = tf.constant([[2], [4]])     # num_updates == 2, index_depth == 1\n",
      "        >>> num_updates, index_depth = indices.shape.as_list()\n",
      "        \n",
      "        The `outer_shape` is `6`, the inner shape is `3`:\n",
      "        \n",
      "        >>> outer_shape = tensor.shape[:index_depth]\n",
      "        >>> inner_shape = tensor.shape[index_depth:]\n",
      "        \n",
      "        2 rows are being indexed so 2 `updates` must be supplied.\n",
      "        Each update must be shaped to match the `inner_shape`.\n",
      "        \n",
      "        >>> # num_updates == 2, inner_shape==3\n",
      "        >>> updates = tf.constant([[1, 2, 3],\n",
      "        ...                        [4, 5, 6]])\n",
      "        \n",
      "        Altogether this gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 0, 0],\n",
      "               [1, 2, 3],\n",
      "               [0, 0, 0],\n",
      "               [4, 5, 6],\n",
      "               [0, 0, 0]], dtype=int32)\n",
      "        \n",
      "        #### More slice update examples\n",
      "        \n",
      "        A tensor representing a batch of uniformly sized video clips naturally has 5\n",
      "        axes: `[batch_size, time, width, height, channels]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> batch_size, time, width, height, channels = 13,11,7,5,3\n",
      "        >>> video_batch = tf.zeros([batch_size, time, width, height, channels])\n",
      "        \n",
      "        To replace a selection of video clips:\n",
      "          * Use an `index_depth` of 1 (indexing the `outer_shape`: `[batch_size]`)\n",
      "          * Provide updates each with a shape matching the `inner_shape`:\n",
      "            `[time, width, height, channels]`.\n",
      "        \n",
      "        To replace the first two clips with ones:\n",
      "        \n",
      "        >>> indices = [[0],[1]]\n",
      "        >>> new_clips = tf.ones([2, time, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_clips)\n",
      "        \n",
      "        To replace a selection of frames in the videos:\n",
      "        \n",
      "        * `indices` must have an `index_depth` of 2 for the `outer_shape`:\n",
      "          `[batch_size, time]`.\n",
      "        * `updates` must be shaped like a list of images.  Each update must have a\n",
      "          shape, matching the `inner_shape`: `[width, height, channels]`.\n",
      "        \n",
      "        To replace the first frame of the first three video clips:\n",
      "        \n",
      "        >>> indices = [[0, 0], [1, 0], [2, 0]] # num_updates=3, index_depth=2\n",
      "        >>> new_images = tf.ones([\n",
      "        ...   # num_updates=3, inner_shape=(width, height, channels)\n",
      "        ...   3, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_images)\n",
      "        \n",
      "        ### Folded indices\n",
      "        \n",
      "        In simple cases it's convenient to think of `indices` and `updates` as\n",
      "        lists, but this is not a strict requirement. Instead of a flat `num_updates`,\n",
      "        the `indices` and `updates` can be folded into a `batch_shape`. This\n",
      "        `batch_shape` is all axes of the `indices`, except for the innermost\n",
      "        `index_depth` axis.\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        ```\n",
      "        \n",
      "        Note: The one exception is that the `batch_shape` cannot be `[]`. You can't\n",
      "        update a single index by passing indices with shape `[index_depth]`.\n",
      "        \n",
      "        `updates` must have a matching `batch_shape` (the axes before `inner_shape`).\n",
      "        \n",
      "        ```\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Note: The result is equivalent to flattening the `batch_shape` axes of\n",
      "        `indices` and `updates`. This generalization just avoids the need\n",
      "        for reshapes when it is more natural to construct \"folded\" indices and\n",
      "        updates.\n",
      "        \n",
      "        With this generalization the full shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        For example, to draw an `X` on a `(5,5)` matrix start with these indices:\n",
      "        \n",
      "        >>> tensor = tf.zeros([5,5])\n",
      "        >>> indices = tf.constant([\n",
      "        ...  [[0,0],\n",
      "        ...   [1,1],\n",
      "        ...   [2,2],\n",
      "        ...   [3,3],\n",
      "        ...   [4,4]],\n",
      "        ...  [[0,4],\n",
      "        ...   [1,3],\n",
      "        ...   [2,2],\n",
      "        ...   [3,1],\n",
      "        ...   [4,0]],\n",
      "        ... ])\n",
      "        >>> indices.shape.as_list()  # batch_shape == [2, 5], index_depth == 2\n",
      "        [2, 5, 2]\n",
      "        \n",
      "        Here the `indices` do not have a shape of `[num_updates, index_depth]`, but a\n",
      "        shape of `batch_shape+[index_depth]`.\n",
      "        \n",
      "        Since the `index_depth` is equal to the rank of `tensor`:\n",
      "        \n",
      "        * `outer_shape` is `(5,5)`\n",
      "        * `inner_shape` is `()` - each update is scalar\n",
      "        * `updates.shape` is `batch_shape + inner_shape == (5,2) + ()`\n",
      "        \n",
      "        >>> updates = [\n",
      "        ...   [1,1,1,1,1],\n",
      "        ...   [1,1,1,1,1],\n",
      "        ... ]\n",
      "        \n",
      "        Putting this together gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[1., 0., 0., 0., 1.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [0., 0., 1., 0., 0.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [1., 0., 0., 0., 1.]], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          tensor: Tensor to copy/update.\n",
      "          indices: Indices to update.\n",
      "          updates: Updates to apply at the indices.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A new tensor with the given shape and updates applied according to the\n",
      "          indices.\n",
      "    \n",
      "    tensor_scatter_sub(tensor: Annotated[Any, ~TV_TensorScatterSub_T], indices: Annotated[Any, ~TV_TensorScatterSub_Tindices], updates: Annotated[Any, ~TV_TensorScatterSub_T], name=None) -> Annotated[Any, ~TV_TensorScatterSub_T]\n",
      "        Subtracts sparse `updates` from an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by subtracting sparse `updates` from the\n",
      "        passed in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd_sub`, except that the updates\n",
      "        are subtracted from an existing tensor (as opposed to a variable). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of tensor_scatter_sub is to subtract individual elements\n",
      "        from a tensor by index. For example, say we want to insert 4 scattered elements\n",
      "        in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter subtract operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "            print(updated)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, -10, 1, -9, -8, 1, 1, -11]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "            print(updated)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_update = tensor_scatter_nd_update(tensor, indices, updates, name=None)\n",
      "        Scatter `updates` into an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by applying sparse `updates` to the\n",
      "        input `tensor`. This is similar to an index assignment.\n",
      "        \n",
      "        ```\n",
      "        # Not implemented: tensors cannot be updated inplace.\n",
      "        tensor[indices] = updates\n",
      "        ```\n",
      "        \n",
      "        If an out of bound index is found on CPU, an error is returned.\n",
      "        \n",
      "        > **WARNING**: There are some GPU specific semantics for this operation.\n",
      "        >\n",
      "        > - If an out of bound index is found, the index is ignored.\n",
      "        > - The order in which updates are applied is nondeterministic, so the output\n",
      "        >   will be nondeterministic if `indices` contains duplicates.\n",
      "        \n",
      "        This operation is very similar to `tf.scatter_nd`, except that the updates are\n",
      "        scattered onto an existing tensor (as opposed to a zero-tensor). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        In general:\n",
      "        \n",
      "        * `indices` is an integer tensor - the indices to update in `tensor`.\n",
      "        * `indices` has **at least two** axes, the last axis is the depth of the\n",
      "          index vectors.\n",
      "        * For each index vector in `indices` there is a corresponding entry in\n",
      "          `updates`.\n",
      "        * If the length of the index vectors matches the rank of the `tensor`, then\n",
      "          the index vectors each point to scalars in `tensor` and each update is a\n",
      "          scalar.\n",
      "        * If the length of the index vectors is less than the rank of `tensor`, then\n",
      "          the index vectors each point to the slices of `tensor` and shape of the updates\n",
      "          must match that slice.\n",
      "        \n",
      "        Overall this leads to the following shape constraints:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Typical usage is often much simpler than this general form, and it\n",
      "        can be better understood starting with simple examples:\n",
      "        \n",
      "        ### Scalar updates\n",
      "        \n",
      "        The simplest usage inserts scalar elements into a tensor by index.\n",
      "        In this case, the `index_depth` must equal the rank of the\n",
      "        input `tensor`, slice each column of `indices` is an index into an axis of the\n",
      "        input `tensor`.\n",
      "        \n",
      "        In this simplest case the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        assert updates.shape == [num_updates]\n",
      "        assert index_depth == tf.rank(tensor)`\n",
      "        ```\n",
      "        \n",
      "        For example, to insert 4 scattered elements in a rank-1 tensor with\n",
      "        8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\"\n",
      "          src=\"https://www.tensorflow.org/images/ScatterNd1.png\">\n",
      "        </div>\n",
      "        \n",
      "        This scatter operation would look like this:\n",
      "        \n",
      "        >>> tensor = [0, 0, 0, 0, 0, 0, 0, 0]    # tf.rank(tensor) == 1\n",
      "        >>> indices = [[1], [3], [4], [7]]       # num_updates == 4, index_depth == 1\n",
      "        >>> updates = [9, 10, 11, 12]            # num_updates == 4\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor([ 0 9  0 10  11  0  0 12], shape=(8,), dtype=int32)\n",
      "        \n",
      "        The length (first axis) of `updates` must equal the length of the `indices`:\n",
      "        `num_updates`. This is the number of updates being inserted. Each scalar\n",
      "        update is inserted into `tensor` at the indexed location.\n",
      "        \n",
      "        For a higher rank input `tensor` scalar updates can be inserted by using an\n",
      "        `index_depth` that matches `tf.rank(tensor)`:\n",
      "        \n",
      "        >>> tensor = [[1, 1], [1, 1], [1, 1]]    # tf.rank(tensor) == 2\n",
      "        >>> indices = [[0, 1], [2, 0]]           # num_updates == 2, index_depth == 2\n",
      "        >>> updates = [5, 10]                    # num_updates == 2\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor(\n",
      "            [[ 1  5]\n",
      "             [ 1  1]\n",
      "             [10  1]], shape=(3, 2), dtype=int32)\n",
      "        \n",
      "        ### Slice updates\n",
      "        \n",
      "        When the input `tensor` has more than one axis scatter can be used to update\n",
      "        entire slices.\n",
      "        \n",
      "        In this case it's helpful to think of the input `tensor` as being a two level\n",
      "        array-of-arrays. The shape of this two level array is split into the\n",
      "        `outer_shape` and the `inner_shape`.\n",
      "        \n",
      "        `indices` indexes into the outer level of the input tensor (`outer_shape`).\n",
      "        and replaces the sub-array at that location with the corresponding item from\n",
      "        the `updates` list. The shape of each update is `inner_shape`.\n",
      "        \n",
      "        When updating a list of slices the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == [num_updates, inner_shape]\n",
      "        ```\n",
      "        \n",
      "        For example, to update rows of a `(6, 3)` `tensor`:\n",
      "        \n",
      "        >>> tensor = tf.zeros([6, 3], dtype=tf.int32)\n",
      "        \n",
      "        Use an index depth of one.\n",
      "        \n",
      "        >>> indices = tf.constant([[2], [4]])     # num_updates == 2, index_depth == 1\n",
      "        >>> num_updates, index_depth = indices.shape.as_list()\n",
      "        \n",
      "        The `outer_shape` is `6`, the inner shape is `3`:\n",
      "        \n",
      "        >>> outer_shape = tensor.shape[:index_depth]\n",
      "        >>> inner_shape = tensor.shape[index_depth:]\n",
      "        \n",
      "        2 rows are being indexed so 2 `updates` must be supplied.\n",
      "        Each update must be shaped to match the `inner_shape`.\n",
      "        \n",
      "        >>> # num_updates == 2, inner_shape==3\n",
      "        >>> updates = tf.constant([[1, 2, 3],\n",
      "        ...                        [4, 5, 6]])\n",
      "        \n",
      "        Altogether this gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 0, 0],\n",
      "               [1, 2, 3],\n",
      "               [0, 0, 0],\n",
      "               [4, 5, 6],\n",
      "               [0, 0, 0]], dtype=int32)\n",
      "        \n",
      "        #### More slice update examples\n",
      "        \n",
      "        A tensor representing a batch of uniformly sized video clips naturally has 5\n",
      "        axes: `[batch_size, time, width, height, channels]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> batch_size, time, width, height, channels = 13,11,7,5,3\n",
      "        >>> video_batch = tf.zeros([batch_size, time, width, height, channels])\n",
      "        \n",
      "        To replace a selection of video clips:\n",
      "          * Use an `index_depth` of 1 (indexing the `outer_shape`: `[batch_size]`)\n",
      "          * Provide updates each with a shape matching the `inner_shape`:\n",
      "            `[time, width, height, channels]`.\n",
      "        \n",
      "        To replace the first two clips with ones:\n",
      "        \n",
      "        >>> indices = [[0],[1]]\n",
      "        >>> new_clips = tf.ones([2, time, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_clips)\n",
      "        \n",
      "        To replace a selection of frames in the videos:\n",
      "        \n",
      "        * `indices` must have an `index_depth` of 2 for the `outer_shape`:\n",
      "          `[batch_size, time]`.\n",
      "        * `updates` must be shaped like a list of images.  Each update must have a\n",
      "          shape, matching the `inner_shape`: `[width, height, channels]`.\n",
      "        \n",
      "        To replace the first frame of the first three video clips:\n",
      "        \n",
      "        >>> indices = [[0, 0], [1, 0], [2, 0]] # num_updates=3, index_depth=2\n",
      "        >>> new_images = tf.ones([\n",
      "        ...   # num_updates=3, inner_shape=(width, height, channels)\n",
      "        ...   3, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_images)\n",
      "        \n",
      "        ### Folded indices\n",
      "        \n",
      "        In simple cases it's convenient to think of `indices` and `updates` as\n",
      "        lists, but this is not a strict requirement. Instead of a flat `num_updates`,\n",
      "        the `indices` and `updates` can be folded into a `batch_shape`. This\n",
      "        `batch_shape` is all axes of the `indices`, except for the innermost\n",
      "        `index_depth` axis.\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        ```\n",
      "        \n",
      "        Note: The one exception is that the `batch_shape` cannot be `[]`. You can't\n",
      "        update a single index by passing indices with shape `[index_depth]`.\n",
      "        \n",
      "        `updates` must have a matching `batch_shape` (the axes before `inner_shape`).\n",
      "        \n",
      "        ```\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Note: The result is equivalent to flattening the `batch_shape` axes of\n",
      "        `indices` and `updates`. This generalization just avoids the need\n",
      "        for reshapes when it is more natural to construct \"folded\" indices and\n",
      "        updates.\n",
      "        \n",
      "        With this generalization the full shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        For example, to draw an `X` on a `(5,5)` matrix start with these indices:\n",
      "        \n",
      "        >>> tensor = tf.zeros([5,5])\n",
      "        >>> indices = tf.constant([\n",
      "        ...  [[0,0],\n",
      "        ...   [1,1],\n",
      "        ...   [2,2],\n",
      "        ...   [3,3],\n",
      "        ...   [4,4]],\n",
      "        ...  [[0,4],\n",
      "        ...   [1,3],\n",
      "        ...   [2,2],\n",
      "        ...   [3,1],\n",
      "        ...   [4,0]],\n",
      "        ... ])\n",
      "        >>> indices.shape.as_list()  # batch_shape == [2, 5], index_depth == 2\n",
      "        [2, 5, 2]\n",
      "        \n",
      "        Here the `indices` do not have a shape of `[num_updates, index_depth]`, but a\n",
      "        shape of `batch_shape+[index_depth]`.\n",
      "        \n",
      "        Since the `index_depth` is equal to the rank of `tensor`:\n",
      "        \n",
      "        * `outer_shape` is `(5,5)`\n",
      "        * `inner_shape` is `()` - each update is scalar\n",
      "        * `updates.shape` is `batch_shape + inner_shape == (5,2) + ()`\n",
      "        \n",
      "        >>> updates = [\n",
      "        ...   [1,1,1,1,1],\n",
      "        ...   [1,1,1,1,1],\n",
      "        ... ]\n",
      "        \n",
      "        Putting this together gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[1., 0., 0., 0., 1.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [0., 0., 1., 0., 0.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [1., 0., 0., 0., 1.]], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          tensor: Tensor to copy/update.\n",
      "          indices: Indices to update.\n",
      "          updates: Updates to apply at the indices.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A new tensor with the given shape and updates applied according to the\n",
      "          indices.\n",
      "    \n",
      "    tensordot(a, b, axes, name=None)\n",
      "        Tensor contraction of a and b along specified axes and outer product.\n",
      "        \n",
      "        Tensordot (also known as tensor contraction) sums the product of elements\n",
      "        from `a` and `b` over the indices specified by `axes`.\n",
      "        \n",
      "        This operation corresponds to `numpy.tensordot(a, b, axes)`.\n",
      "        \n",
      "        Example 1: When `a` and `b` are matrices (order 2), the case `axes=1`\n",
      "        is equivalent to matrix multiplication.\n",
      "        \n",
      "        Example 2: When `a` and `b` are matrices (order 2), the case\n",
      "        `axes = [[1], [0]]` is equivalent to matrix multiplication.\n",
      "        \n",
      "        Example 3: When `a` and `b` are matrices (order 2), the case `axes=0` gives\n",
      "        the outer product, a tensor of order 4.\n",
      "        \n",
      "        Example 4: Suppose that \\\\(a_{ijk}\\\\) and \\\\(b_{lmn}\\\\) represent two\n",
      "        tensors of order 3. Then, `contract(a, b, [[0], [2]])` is the order 4 tensor\n",
      "        \\\\(c_{jklm}\\\\) whose entry\n",
      "        corresponding to the indices \\\\((j,k,l,m)\\\\) is given by:\n",
      "        \n",
      "        \\\\( c_{jklm} = \\sum_i a_{ijk} b_{lmi} \\\\).\n",
      "        \n",
      "        In general, `order(c) = order(a) + order(b) - 2*len(axes[0])`.\n",
      "        \n",
      "        Args:\n",
      "          a: `Tensor` of type `float32` or `float64`.\n",
      "          b: `Tensor` with the same type as `a`.\n",
      "          axes: Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k].\n",
      "            If axes is a scalar, sum over the last N axes of a and the first N axes of\n",
      "            b in order. If axes is a list or `Tensor` the first and second row contain\n",
      "            the set of unique integers specifying axes along which the contraction is\n",
      "            computed, for `a` and `b`, respectively. The number of axes for `a` and\n",
      "            `b` must be equal. If `axes=0`, computes the outer product between `a` and\n",
      "            `b`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same type as `a`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the shapes of `a`, `b`, and `axes` are incompatible.\n",
      "          IndexError: If the values in axes exceed the rank of the corresponding\n",
      "            tensor.\n",
      "    \n",
      "    tile(input: Annotated[Any, ~TV_Tile_T], multiples: Annotated[Any, ~TV_Tile_Tmultiples], name=None) -> Annotated[Any, ~TV_Tile_T]\n",
      "        Constructs a tensor by tiling a given tensor.\n",
      "        \n",
      "        This operation creates a new tensor by replicating `input` `multiples` times.\n",
      "        The output tensor's i'th dimension has `input.dims(i) * multiples[i]` elements,\n",
      "        and the values of `input` are replicated `multiples[i]` times along the 'i'th\n",
      "        dimension. For example, tiling `[a b c d]` by `[2]` produces\n",
      "        `[a b c d a b c d]`.\n",
      "        \n",
      "        >>> a = tf.constant([[1,2,3],[4,5,6]], tf.int32)\n",
      "        >>> b = tf.constant([1,2], tf.int32)\n",
      "        >>> tf.tile(a, b)\n",
      "        <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
      "        array([[1, 2, 3, 1, 2, 3],\n",
      "               [4, 5, 6, 4, 5, 6]], dtype=int32)>\n",
      "        >>> c = tf.constant([2,1], tf.int32)\n",
      "        >>> tf.tile(a, c)\n",
      "        <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
      "        array([[1, 2, 3],\n",
      "               [4, 5, 6],\n",
      "               [1, 2, 3],\n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        >>> d = tf.constant([2,2], tf.int32)\n",
      "        >>> tf.tile(a, d)\n",
      "        <tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
      "        array([[1, 2, 3, 1, 2, 3],\n",
      "               [4, 5, 6, 4, 5, 6],\n",
      "               [1, 2, 3, 1, 2, 3],\n",
      "               [4, 5, 6, 4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Can be of any rank.\n",
      "          multiples: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. Length must be the same as the number of dimensions in `input`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    timestamp(name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float64'>]\n",
      "        Provides the time since epoch in seconds.\n",
      "        \n",
      "        Returns the timestamp as a `float64` for seconds since the Unix epoch.\n",
      "        \n",
      "        Common usages include:\n",
      "        * Logging\n",
      "        * Providing a random number seed\n",
      "        * Debugging graph execution\n",
      "        * Generating timing information, mainly through comparison of timestamps\n",
      "        \n",
      "        Note: In graph mode, the timestamp is computed when the op is executed,\n",
      "        not when it is added to the graph.  In eager mode, the timestamp is computed\n",
      "        when the op is eagerly executed.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float64`.\n",
      "    \n",
      "    to_bfloat16(x, name='ToBFloat16')\n",
      "        Casts a tensor to type `bfloat16`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `bfloat16`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `bfloat16`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.bfloat16)`. There are no further issues with eager execution\n",
      "        or tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_bfloat16(tf.constant(3.14, dtype=tf.float32))\n",
      "        <tf.Tensor: shape=(), dtype=bfloat16, numpy=3.14>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(3.14, dtype=tf.float32), tf.bfloat16)\n",
      "        <tf.Tensor: shape=(), dtype=bfloat16, numpy=3.14>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_complex128(x, name='ToComplex128')\n",
      "        Casts a tensor to type `complex128`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `complex128`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `complex128`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.complex128)`. There are no further issues with eager\n",
      "        execution or tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_complex128(tf.constant(1. + 2.j, dtype=tf.complex64))\n",
      "        <tf.Tensor: shape=(), dtype=complex128, numpy=(1+2j)>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(1. + 2.j, dtype=tf.complex64), tf.complex128)\n",
      "        <tf.Tensor: shape=(), dtype=complex128, numpy=(1+2j)>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_complex64(x, name='ToComplex64')\n",
      "        Casts a tensor to type `complex64`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `complex64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `complex64`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.complex64)`. There are no further issues with eager execution\n",
      "        or tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_complex64(tf.constant(1. + 2.j, dtype=tf.complex128))\n",
      "        <tf.Tensor: shape=(), dtype=complex64, numpy=(1+2j)>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(1. + 2.j, dtype=tf.complex128), tf.complex64)\n",
      "        <tf.Tensor: shape=(), dtype=complex64, numpy=(1+2j)>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_double(x, name='ToDouble')\n",
      "        Casts a tensor to type `float64`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `float64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `float64`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.double)`. There are no further issues with eager execution or\n",
      "        tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_double(tf.constant(3.14, dtype=tf.float32))\n",
      "        <tf.Tensor: shape=(), dtype=float64, numpy=3.14>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(3.14, dtype=tf.float32), tf.double)\n",
      "        <tf.Tensor: shape=(), dtype=float64, numpy=3.14>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_float(x, name='ToFloat')\n",
      "        Casts a tensor to type `float32`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `float32`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `float32`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.float32)`. There are no further issues with eager execution\n",
      "        or tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_float(tf.constant(3.14, dtype=tf.double))\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=3.14>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(3.14, dtype=tf.double), tf.float32)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=3.14>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_int32(x, name='ToInt32')\n",
      "        Casts a tensor to type `int32`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `int32`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `int32`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.int32)`. There are no further issues with eager execution or\n",
      "        tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_int32(tf.constant(1, dtype=tf.int64))\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(1, dtype=tf.int64), tf.int32)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_int64(x, name='ToInt64')\n",
      "        Casts a tensor to type `int64`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `int64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `int64`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.int64)`. There are no further issues with eager execution or\n",
      "        tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_int64(tf.constant(1, dtype=tf.int32))\n",
      "        <tf.Tensor: shape=(), dtype=int64, numpy=1>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(1, dtype=tf.int32), tf.int64)\n",
      "        <tf.Tensor: shape=(), dtype=int64, numpy=1>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    trace(x, name=None)\n",
      "        Compute the trace of a tensor `x`.\n",
      "        \n",
      "        `trace(x)` returns the sum along the main diagonal of each inner-most matrix\n",
      "        in x. If x is of rank `k` with shape `[I, J, K, ..., L, M, N]`, then output\n",
      "        is a tensor of rank `k-2` with dimensions `[I, J, K, ..., L]` where\n",
      "        \n",
      "        `output[i, j, k, ..., l] = trace(x[i, j, k, ..., l, :, :])`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2], [3, 4]])\n",
      "        tf.linalg.trace(x)  # 5\n",
      "        \n",
      "        x = tf.constant([[1, 2, 3],\n",
      "                         [4, 5, 6],\n",
      "                         [7, 8, 9]])\n",
      "        tf.linalg.trace(x)  # 15\n",
      "        \n",
      "        x = tf.constant([[[1, 2, 3],\n",
      "                          [4, 5, 6],\n",
      "                          [7, 8, 9]],\n",
      "                         [[-1, -2, -3],\n",
      "                          [-4, -5, -6],\n",
      "                          [-7, -8, -9]]])\n",
      "        tf.linalg.trace(x)  # [15, -15]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The trace of input tensor.\n",
      "    \n",
      "    trainable_variables(scope=None)\n",
      "        Returns all variables created with `trainable=True`.\n",
      "        \n",
      "        When passed `trainable=True`, the `Variable()` constructor automatically\n",
      "        adds new variables to the graph collection\n",
      "        `GraphKeys.TRAINABLE_VARIABLES`. This convenience function returns the\n",
      "        contents of that collection.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Not compatible with eager execution and `tf.function`. In particular, Graph\n",
      "        collections are deprecated in TF2. Instead please create a `tf.Module`\n",
      "        container for all your model state, including variables.\n",
      "        You can then list all the trainable variables in your `tf.Module` through the\n",
      "        `trainable_variables` attribute.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variable objects.\n",
      "    \n",
      "    transpose(a, perm=None, name='transpose', conjugate=False)\n",
      "        Transposes `a`.\n",
      "        \n",
      "        Permutes the dimensions according to `perm`.\n",
      "        \n",
      "        The returned tensor's dimension i will correspond to the input dimension\n",
      "        `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is\n",
      "        the rank of the input tensor. Hence, by default, this operation performs a\n",
      "        regular matrix transpose on 2-D input Tensors. If conjugate is True and\n",
      "        `a.dtype` is either `complex64` or `complex128` then the values of `a`\n",
      "        are conjugated and transposed.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        In `numpy` transposes are memory-efficient constant time operations as they\n",
      "        simply return a new view of the same data with adjusted `strides`.\n",
      "        \n",
      "        TensorFlow does not support strides, so `transpose` returns a new tensor with\n",
      "        the items permuted.\n",
      "        @end_compatibility\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.transpose(x)  # [[1, 4]\n",
      "                         #  [2, 5]\n",
      "                         #  [3, 6]]\n",
      "        \n",
      "        # Equivalently\n",
      "        tf.transpose(x, perm=[1, 0])  # [[1, 4]\n",
      "                                      #  [2, 5]\n",
      "                                      #  [3, 6]]\n",
      "        \n",
      "        # If x is complex, setting conjugate=True gives the conjugate transpose\n",
      "        x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "                         [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "        tf.transpose(x, conjugate=True)  # [[1 - 1j, 4 - 4j],\n",
      "                                         #  [2 - 2j, 5 - 5j],\n",
      "                                         #  [3 - 3j, 6 - 6j]]\n",
      "        \n",
      "        # 'perm' is more useful for n-dimensional tensors, for n > 2\n",
      "        x = tf.constant([[[ 1,  2,  3],\n",
      "                          [ 4,  5,  6]],\n",
      "                         [[ 7,  8,  9],\n",
      "                          [10, 11, 12]]])\n",
      "        \n",
      "        # Take the transpose of the matrices in dimension-0\n",
      "        # (this common operation has a shorthand `linalg.matrix_transpose`)\n",
      "        tf.transpose(x, perm=[0, 2, 1])  # [[[1,  4],\n",
      "                                         #   [2,  5],\n",
      "                                         #   [3,  6]],\n",
      "                                         #  [[7, 10],\n",
      "                                         #   [8, 11],\n",
      "                                         #   [9, 12]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`.\n",
      "          perm: A permutation of the dimensions of `a`.\n",
      "          name: A name for the operation (optional).\n",
      "          conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "            to tf.math.conj(tf.transpose(input)).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed `Tensor`.\n",
      "    \n",
      "    truediv(x, y, name=None)\n",
      "        Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "        \n",
      "        NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "        division operator semantics.\n",
      "        \n",
      "        This function forces Python 3 division operator semantics where all integer\n",
      "        arguments are cast to floating types first.   This op is generated by normal\n",
      "        `x / y` division in Python 3 and in Python 2.7 with\n",
      "        `from __future__ import division`.  If you want integer division that rounds\n",
      "        down, use `x // y` or `tf.math.floordiv`.\n",
      "        \n",
      "        `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "        point, the output will have the same type.  If the inputs are integral, the\n",
      "        inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "        and `int64` (matching the behavior of Numpy).\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of numeric type.\n",
      "          y: `Tensor` denominator of numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` evaluated in floating point.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` and `y` have different dtypes.\n",
      "    \n",
      "    truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a truncated normal distribution.\n",
      "        \n",
      "        The values are drawn from a normal distribution with specified mean and\n",
      "        standard deviation, discarding and re-drawing any samples that are more than\n",
      "        two standard deviations from the mean.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.random.truncated_normal(shape=[2])\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([..., ...], dtype=float32)>\n",
      "        \n",
      "        >>> tf.random.truncated_normal(shape=[2], mean=3, stddev=1, dtype=tf.float32)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([..., ...], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          mean: A 0-D Tensor or Python value of type `dtype`. The mean of the\n",
      "            truncated normal distribution.\n",
      "          stddev: A 0-D Tensor or Python value of type `dtype`. The standard deviation\n",
      "            of the normal distribution, before truncation.\n",
      "          dtype: The type of the output. Restricted to floating-point types:\n",
      "            `tf.half`, `tf.float`, `tf.double`, etc.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See `tf.random.set_seed` for more information.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random truncated normal values.\n",
      "    \n",
      "    truncatediv = truncate_div(x: typing.Annotated[_any, ~TV_TruncateDiv_T], y: typing.Annotated[_any, ~TV_TruncateDiv_T], name=None) -> typing.Annotated[_any, ~TV_TruncateDiv_T]\n",
      "        Returns x / y element-wise, rounded towards zero.\n",
      "        \n",
      "        Truncation designates that negative numbers will round fractional quantities\n",
      "        toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different\n",
      "        than Python semantics. See `FloorDiv` for a division function that matches\n",
      "        Python Semantics.\n",
      "        \n",
      "        *NOTE*: `truncatediv` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    truncatemod = truncate_mod(x: typing.Annotated[_any, ~TV_TruncateMod_T], y: typing.Annotated[_any, ~TV_TruncateMod_T], name=None) -> typing.Annotated[_any, ~TV_TruncateMod_T]\n",
      "        Returns element-wise remainder of division. This emulates C semantics in that\n",
      "        \n",
      "        the result here is consistent with a truncating divide. E.g. `truncate(x / y) *\n",
      "        y + truncate_mod(x, y) = x`.\n",
      "        \n",
      "        *NOTE*: `truncatemod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    tuple(tensors, name=None, control_inputs=None)\n",
      "        Group tensors together.\n",
      "        \n",
      "        This creates a tuple of tensors with the same values as the `tensors`\n",
      "        argument, except that the value of each tensor is only returned after the\n",
      "        values of all tensors have been computed.\n",
      "        \n",
      "        `control_inputs` contains additional ops that have to finish before this op\n",
      "        finishes, but whose outputs are not returned.\n",
      "        \n",
      "        This can be used as a \"join\" mechanism for parallel computations: all the\n",
      "        argument tensors can be computed in parallel, but the values of any tensor\n",
      "        returned by `tuple` are only available after all the parallel computations\n",
      "        are done.\n",
      "        \n",
      "        See also `tf.group` and\n",
      "        `tf.control_dependencies`.\n",
      "        \n",
      "        Args:\n",
      "          tensors: A list of `Tensor`s or `IndexedSlices`, some entries can be `None`.\n",
      "          name: (optional) A name to use as a `name_scope` for the operation.\n",
      "          control_inputs: List of additional ops to finish before returning.\n",
      "        \n",
      "        Returns:\n",
      "          Same as `tensors`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `tensors` does not contain any `Tensor` or `IndexedSlices`.\n",
      "          TypeError: If `control_inputs` is not a list of `Operation` or `Tensor`\n",
      "            objects.\n",
      "    \n",
      "    type_spec_from_value(value) -> tensorflow.python.framework.type_spec.TypeSpec\n",
      "        Returns a `tf.TypeSpec` that represents the given `value`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> tf.type_spec_from_value(tf.constant([1, 2, 3]))\n",
      "          TensorSpec(shape=(3,), dtype=tf.int32, name=None)\n",
      "          >>> tf.type_spec_from_value(np.array([4.0, 5.0], np.float64))\n",
      "          TensorSpec(shape=(2,), dtype=tf.float64, name=None)\n",
      "          >>> tf.type_spec_from_value(tf.ragged.constant([[1, 2], [3, 4, 5]]))\n",
      "          RaggedTensorSpec(TensorShape([2, None]), tf.int32, 1, tf.int64)\n",
      "        \n",
      "          >>> example_input = tf.ragged.constant([[1, 2], [3]])\n",
      "          >>> @tf.function(input_signature=[tf.type_spec_from_value(example_input)])\n",
      "          ... def f(x):\n",
      "          ...   return tf.reduce_sum(x, axis=1)\n",
      "        \n",
      "        Args:\n",
      "          value: A value that can be accepted or returned by TensorFlow APIs. Accepted\n",
      "            types for `value` include `tf.Tensor`, any value that can be converted to\n",
      "            `tf.Tensor` using `tf.convert_to_tensor`, and any subclass of\n",
      "            `CompositeTensor` (such as `tf.RaggedTensor`).\n",
      "        \n",
      "        Returns:\n",
      "          A `TypeSpec` that is compatible with `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If a TypeSpec cannot be built for `value`, because its type\n",
      "            is not supported.\n",
      "    \n",
      "    unique(x, out_idx=tf.int32, name=None)\n",
      "        Finds unique elements in a 1-D tensor.\n",
      "        \n",
      "        This operation returns a tensor `y` containing all of the unique elements of `x`\n",
      "        sorted in the same order that they occur in `x`; `x` does not need to be sorted.\n",
      "        This operation also returns a tensor `idx` the same size as `x` that contains\n",
      "        the index of each value of `x` in the unique output `y`. In other words:\n",
      "        \n",
      "        `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```\n",
      "        # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
      "        y, idx = unique(x)\n",
      "        y ==> [1, 2, 4, 7, 8]\n",
      "        idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]\n",
      "        ```\n",
      "        \n",
      "        ```\n",
      "        # tensor 'x' is [4, 5, 1, 2, 3, 3, 4, 5]\n",
      "        y, idx = unique(x)\n",
      "        y ==> [4, 5, 1, 2, 3]\n",
      "        idx ==> [0, 1, 2, 3, 4, 4, 0, 1]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (y, idx).\n",
      "        \n",
      "          y: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    unique_with_counts(x, out_idx=tf.int32, name=None)\n",
      "        Finds unique elements in a 1-D tensor.\n",
      "        \n",
      "        This operation returns a tensor `y` containing all of the unique elements of `x`\n",
      "        sorted in the same order that they occur in `x`. This operation also returns a\n",
      "        tensor `idx` the same size as `x` that contains the index of each value of `x`\n",
      "        in the unique output `y`. Finally, it returns a third tensor `count` that\n",
      "        contains the count of each element of `y` in `x`. In other words:\n",
      "        \n",
      "        `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
      "        y, idx, count = unique_with_counts(x)\n",
      "        y ==> [1, 2, 4, 7, 8]\n",
      "        idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]\n",
      "        count ==> [2, 1, 3, 1, 2]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (y, idx, count).\n",
      "        \n",
      "          y: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "          count: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    unravel_index(indices: Annotated[Any, ~TV_UnravelIndex_Tidx], dims: Annotated[Any, ~TV_UnravelIndex_Tidx], name=None) -> Annotated[Any, ~TV_UnravelIndex_Tidx]\n",
      "        Converts an array of flat indices into a tuple of coordinate arrays.\n",
      "        \n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```\n",
      "        y = tf.unravel_index(indices=[2, 5, 7], dims=[3, 3])\n",
      "        # 'dims' represent a hypothetical (3, 3) tensor of indices:\n",
      "        # [[0, 1, *2*],\n",
      "        #  [3, 4, *5*],\n",
      "        #  [6, *7*, 8]]\n",
      "        # For each entry from 'indices', this operation returns\n",
      "        # its coordinates (marked with '*'), such as\n",
      "        # 2 ==> (0, 2)\n",
      "        # 5 ==> (1, 2)\n",
      "        # 7 ==> (2, 1)\n",
      "        y ==> [[0, 1, 2], [2, 2, 1]]\n",
      "        ```\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.unravel_index\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            An 0-D or 1-D `int` Tensor whose elements are indices into the\n",
      "            flattened version of an array of dimensions dims.\n",
      "          dims: A `Tensor`. Must have the same type as `indices`.\n",
      "            An 1-D `int` Tensor. The shape of the array to use for unraveling\n",
      "            indices.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `indices`.\n",
      "    \n",
      "    unsorted_segment_max(data: typing.Annotated[_any, ~TV_UnsortedSegmentMax_T], segment_ids: typing.Annotated[_any, ~TV_UnsortedSegmentMax_Tindices], num_segments: typing.Annotated[_any, ~TV_UnsortedSegmentMax_Tnumsegments], name=None) -> typing.Annotated[_any, ~TV_UnsortedSegmentMax_T]\n",
      "        Computes the maximum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to `tf.math.unsorted_segment_sum`,\n",
      "        Instead of computing the sum over segments, it computes the maximum such that:\n",
      "        \n",
      "        \\\\(output_i = \\max_{j...} data[j...]\\\\) where max is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.\n",
      "        \n",
      "        If the maximum is empty for a given segment ID `i`, it outputs the smallest\n",
      "        possible value for the specific numeric type,\n",
      "        `output[i] = numeric_limits<T>::lowest()`.\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/UnsortedSegmentMax.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        >>> tf.math.unsorted_segment_max(c, tf.constant([0, 1, 0]), num_segments=2).numpy()\n",
      "        array([[4, 3, 3, 4],\n",
      "               [5,  6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "        \n",
      "            Caution: The values are always validated to be in range on CPU, never validated\n",
      "            on GPU.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_mean(data, segment_ids, num_segments, name=None)\n",
      "        Computes the mean along segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the `tf.math.unsorted_segment_sum` operator.\n",
      "        Instead of computing the sum over segments, it computes the mean of all\n",
      "        entries belonging to a segment such that:\n",
      "        \n",
      "        \\\\(output_i = 1/N_i \\sum_{j...} data[j...]\\\\) where the sum is over tuples\n",
      "        `j...` such that `segment_ids[j...] == i` with \\\\N_i\\\\ being the number of\n",
      "        occurrences of id \\\\i\\\\.\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 0.\n",
      "        \n",
      "        If the given segment ID `i` is negative, the value is dropped and will not\n",
      "        be added to the sum of the segment.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with floating point or complex dtype.\n",
      "          segment_ids: An integer tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "            The values are always validated to be in range on CPU,\n",
      "            never validated on GPU.\n",
      "          num_segments: An integer scalar `Tensor`.  The number of distinct segment\n",
      "            IDs.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.  Has same shape as data, except for the first `segment_ids.rank`\n",
      "          dimensions, which are replaced with a single dimension which has size\n",
      "         `num_segments`.\n",
      "    \n",
      "    unsorted_segment_min(data: typing.Annotated[_any, ~TV_UnsortedSegmentMin_T], segment_ids: typing.Annotated[_any, ~TV_UnsortedSegmentMin_Tindices], num_segments: typing.Annotated[_any, ~TV_UnsortedSegmentMin_Tnumsegments], name=None) -> typing.Annotated[_any, ~TV_UnsortedSegmentMin_T]\n",
      "        Computes the minimum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to `tf.math.unsorted_segment_sum`,\n",
      "        Instead of computing the sum over segments, it computes the minimum such that:\n",
      "        \n",
      "        \\\\(output_i = \\min_{j...} data_[j...]\\\\) where min is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.\n",
      "        \n",
      "        If the minimum is empty for a given segment ID `i`, it outputs the largest\n",
      "        possible value for the specific numeric type,\n",
      "        `output[i] = numeric_limits<T>::max()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        >>> tf.math.unsorted_segment_min(c, tf.constant([0, 1, 0]), num_segments=2).numpy()\n",
      "        array([[1, 2, 2, 1],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "        \n",
      "            Caution: The values are always validated to be in range on CPU, never validated\n",
      "            on GPU.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_prod(data: typing.Annotated[_any, ~TV_UnsortedSegmentProd_T], segment_ids: typing.Annotated[_any, ~TV_UnsortedSegmentProd_Tindices], num_segments: typing.Annotated[_any, ~TV_UnsortedSegmentProd_Tnumsegments], name=None) -> typing.Annotated[_any, ~TV_UnsortedSegmentProd_T]\n",
      "        Computes the product along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to `tf.math.unsorted_segment_sum`,\n",
      "        Instead of computing the sum over segments, it computes the product of all\n",
      "        entries belonging to a segment such that:\n",
      "        \n",
      "        \\\\(output_i = \\prod_{j...} data[j...]\\\\) where the product is over tuples\n",
      "        `j...` such that `segment_ids[j...] == i`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        >>> tf.math.unsorted_segment_prod(c, tf.constant([0, 1, 0]), num_segments=2).numpy()\n",
      "        array([[4, 6, 6, 4],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 1.\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "        \n",
      "            Caution: The values are always validated to be in range on CPU, never validated\n",
      "            on GPU.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_sqrt_n(data, segment_ids, num_segments, name=None)\n",
      "        Computes the sum along segments of a tensor divided by the sqrt(N).\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the `tf.math.unsorted_segment_sum` operator.\n",
      "        Additionally to computing the sum over segments, it divides the results by\n",
      "        sqrt(N).\n",
      "        \n",
      "        \\\\(output_i = 1/sqrt(N_i) \\sum_{j...} data[j...]\\\\) where the sum is over\n",
      "        tuples `j...` such that `segment_ids[j...] == i` with \\\\N_i\\\\ being the\n",
      "        number of occurrences of id \\\\i\\\\.\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 0.\n",
      "        \n",
      "        Note that this op only supports floating point and complex dtypes,\n",
      "        due to tf.sqrt only supporting these types.\n",
      "        \n",
      "        If the given segment ID `i` is negative, the value is dropped and will not\n",
      "        be added to the sum of the segment.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with floating point or complex dtype.\n",
      "          segment_ids: An integer tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be in the range `[0, num_segments)`.\n",
      "            The values are always validated to be in range on CPU,\n",
      "            never validated on GPU.\n",
      "          num_segments: An integer scalar `Tensor`.  The number of distinct segment\n",
      "            IDs.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.  Has same shape as data, except for the first `segment_ids.rank`\n",
      "          dimensions, which are replaced with a single dimension which has size\n",
      "         `num_segments`.\n",
      "    \n",
      "    unsorted_segment_sum(data: typing.Annotated[_any, ~TV_UnsortedSegmentSum_T], segment_ids: typing.Annotated[_any, ~TV_UnsortedSegmentSum_Tindices], num_segments: typing.Annotated[_any, ~TV_UnsortedSegmentSum_Tnumsegments], name=None) -> typing.Annotated[_any, ~TV_UnsortedSegmentSum_T]\n",
      "        Computes the sum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output[i] = \\sum_{j...} data[j...]\\\\) where the sum is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.  Unlike `SegmentSum`, `segment_ids`\n",
      "        need not be sorted and need not cover all values in the full\n",
      "        range of valid values.\n",
      "        \n",
      "        If the sum is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        If the given segment ID `i` is negative, the value is dropped and will not be\n",
      "        added to the sum of the segment.\n",
      "        \n",
      "        `num_segments` should equal the number of distinct segment IDs.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/UnsortedSegmentSum.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        >>> c = [[1,2,3,4], [5,6,7,8], [4,3,2,1]]\n",
      "        >>> tf.math.unsorted_segment_sum(c, [0, 1, 0], num_segments=2).numpy()\n",
      "        array([[5, 5, 5, 5],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "        \n",
      "            Caution: The values are always validated to be in range on CPU, never validated\n",
      "            on GPU.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unstack(value, num=None, axis=0, name='unstack')\n",
      "        Unpacks the given dimension of a rank-`R` tensor into rank-`(R-1)` tensors.\n",
      "        \n",
      "        Unpacks tensors from `value` by chipping it along the `axis` dimension.\n",
      "        \n",
      "        >>> x = tf.reshape(tf.range(12), (3,4))\n",
      "        >>>\n",
      "        >>> p, q, r = tf.unstack(x)\n",
      "        >>> p.shape.as_list()\n",
      "        [4]\n",
      "        \n",
      "        >>> i, j, k, l = tf.unstack(x, axis=1)\n",
      "        >>> i.shape.as_list()\n",
      "        [3]\n",
      "        \n",
      "        This is the opposite of stack.\n",
      "        \n",
      "        >>> x = tf.stack([i, j, k, l], axis=1)\n",
      "        \n",
      "        More generally if you have a tensor of shape `(A, B, C, D)`:\n",
      "        \n",
      "        >>> A, B, C, D = [2, 3, 4, 5]\n",
      "        >>> t = tf.random.normal(shape=[A, B, C, D])\n",
      "        \n",
      "        The number of tensor returned is equal to the length of the target `axis`:\n",
      "        \n",
      "        >>> axis = 2\n",
      "        >>> items = tf.unstack(t, axis=axis)\n",
      "        >>> len(items) == t.shape[axis]\n",
      "        True\n",
      "        \n",
      "        The shape of each result tensor is equal to the shape of the input tensor,\n",
      "        with the target `axis` removed.\n",
      "        \n",
      "        >>> items[0].shape.as_list()  # [A, B, D]\n",
      "        [2, 3, 5]\n",
      "        \n",
      "        The value of each tensor `items[i]` is equal to the slice of `input` across\n",
      "        `axis` at index `i`:\n",
      "        \n",
      "        >>> for i in range(len(items)):\n",
      "        ...   slice = t[:,:,i,:]\n",
      "        ...   assert tf.reduce_all(slice == items[i])\n",
      "        \n",
      "        #### Python iterable unpacking\n",
      "        \n",
      "        With eager execution you _can_ unstack the 0th axis of a tensor using python's\n",
      "        iterable unpacking:\n",
      "        \n",
      "        >>> t = tf.constant([1,2,3])\n",
      "        >>> a,b,c = t\n",
      "        \n",
      "        `unstack` is still necessary because Iterable unpacking doesn't work in\n",
      "        a `@tf.function`: Symbolic tensors are not iterable.\n",
      "        \n",
      "        You need to use `tf.unstack` here:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def bad(t):\n",
      "        ...   a,b,c = t\n",
      "        ...   return a\n",
      "        >>>\n",
      "        >>> bad(t)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        OperatorNotAllowedInGraphError: ...\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def good(t):\n",
      "        ...   a,b,c = tf.unstack(t)\n",
      "        ...   return a\n",
      "        >>>\n",
      "        >>> good(t).numpy()\n",
      "        1\n",
      "        \n",
      "        #### Unknown shapes\n",
      "        \n",
      "        Eager tensors have concrete values, so their shape is always known.\n",
      "        Inside a `tf.function` the symbolic tensors may have unknown shapes.\n",
      "        If the length of `axis` is unknown `tf.unstack` will fail because it cannot\n",
      "        handle an unknown number of tensors:\n",
      "        \n",
      "        >>> @tf.function(input_signature=[tf.TensorSpec([None], tf.float32)])\n",
      "        ... def bad(t):\n",
      "        ...   tensors = tf.unstack(t)\n",
      "        ...   return tensors[0]\n",
      "        >>>\n",
      "        >>> bad(tf.constant([1.0, 2.0, 3.0]))\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        ValueError: Cannot infer argument `num` from shape (None,)\n",
      "        \n",
      "        If you know the `axis` length you can pass it as the `num` argument. But this\n",
      "        must be a constant value.\n",
      "        \n",
      "        If you actually need a variable number of tensors in a single `tf.function`\n",
      "        trace, you will need to use exlicit loops and a `tf.TensorArray` instead.\n",
      "        \n",
      "        Args:\n",
      "          value: A rank `R > 0` `Tensor` to be unstacked.\n",
      "          num: An `int`. The length of the dimension `axis`. Automatically inferred if\n",
      "            `None` (the default).\n",
      "          axis: An `int`. The axis to unstack along. Defaults to the first dimension.\n",
      "            Negative values wrap around, so the valid range is `[-R, R)`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The list of `Tensor` objects unstacked from `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `axis` is out of the range `[-R, R)`.\n",
      "          ValueError: If `num` is unspecified and cannot be inferred.\n",
      "          InvalidArgumentError: If `num` does not match the shape of `value`.\n",
      "    \n",
      "    variable_axis_size_partitioner(max_shard_bytes, axis=0, bytes_per_string_element=16, max_shards=None)\n",
      "        Get a partitioner for VariableScope to keep shards below `max_shard_bytes`.\n",
      "        \n",
      "        This partitioner will shard a Variable along one axis, attempting to keep\n",
      "        the maximum shard size below `max_shard_bytes`.  In practice, this is not\n",
      "        always possible when sharding along only one axis.  When this happens,\n",
      "        this axis is sharded as much as possible (i.e., every dimension becomes\n",
      "        a separate shard).\n",
      "        \n",
      "        If the partitioner hits the `max_shards` limit, then each shard may end up\n",
      "        larger than `max_shard_bytes`. By default `max_shards` equals `None` and no\n",
      "        limit on the number of shards is enforced.\n",
      "        \n",
      "        One reasonable value for `max_shard_bytes` is `(64 << 20) - 1`, or almost\n",
      "        `64MB`, to keep below the protobuf byte limit.\n",
      "        \n",
      "        Args:\n",
      "          max_shard_bytes: The maximum size any given shard is allowed to be.\n",
      "          axis: The axis to partition along.  Default: outermost axis.\n",
      "          bytes_per_string_element: If the `Variable` is of type string, this provides\n",
      "            an estimate of how large each scalar in the `Variable` is.\n",
      "          max_shards: The maximum number of shards in int created taking precedence\n",
      "            over `max_shard_bytes`.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the byte counts are non-positive.\n",
      "    \n",
      "    variable_creator_scope = variable_creator_scope_v1(variable_creator)\n",
      "        Scope which defines a variable creation function to be used by variable().\n",
      "        \n",
      "        variable_creator is expected to be a function with the following signature:\n",
      "        \n",
      "        ```\n",
      "          def variable_creator(next_creator, **kwargs)\n",
      "        ```\n",
      "        \n",
      "        The creator is supposed to eventually call the next_creator to create a\n",
      "        variable if it does want to create a variable and not call Variable or\n",
      "        ResourceVariable directly. This helps make creators composable. A creator may\n",
      "        choose to create multiple variables, return already existing variables, or\n",
      "        simply register that a variable was created and defer to the next creators in\n",
      "        line. Creators can also modify the keyword arguments seen by the next\n",
      "        creators.\n",
      "        \n",
      "        Custom getters in the variable scope will eventually resolve down to these\n",
      "        custom creators when they do create variables.\n",
      "        \n",
      "        The valid keyword arguments in kwds are:\n",
      "        \n",
      "         * initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
      "              which is the initial value for the Variable. The initial value must have\n",
      "              a shape specified unless `validate_shape` is set to False. Can also be a\n",
      "              callable with no argument that returns the initial value when called. In\n",
      "              that case, `dtype` must be specified. (Note that initializer functions\n",
      "              from init_ops.py must first be bound to a shape before being used here.)\n",
      "         * trainable: If `True`, the default, also adds the variable to the graph\n",
      "              collection `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as\n",
      "              the default list of variables to use by the `Optimizer` classes.\n",
      "              `trainable` defaults to `True`, unless `synchronization` is\n",
      "              set to `ON_READ`, in which case it defaults to `False`.\n",
      "         * collections: List of graph collections keys. The new variable is added to\n",
      "              these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "         * validate_shape: If `False`, allows the variable to be initialized with a\n",
      "              value of unknown shape. If `True`, the default, the shape of\n",
      "              `initial_value` must be known.\n",
      "         * caching_device: Optional device string describing where the Variable\n",
      "              should be cached for reading.  Defaults to the Variable's device.\n",
      "              If not `None`, caches on another device.  Typical use is to cache\n",
      "              on the device where the Ops using the Variable reside, to deduplicate\n",
      "              copying through `Switch` and other conditional statements.\n",
      "         * name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
      "              uniquified automatically.\n",
      "         * dtype: If set, initial_value will be converted to the given type.\n",
      "              If `None`, either the datatype will be kept (if `initial_value` is\n",
      "              a Tensor), or `convert_to_tensor` will decide.\n",
      "         * constraint: A constraint function to be applied to the variable after\n",
      "              updates by some algorithms.\n",
      "         * use_resource: if True, a ResourceVariable is always created.\n",
      "         * synchronization: Indicates when a distributed a variable will be\n",
      "              aggregated. Accepted values are constants defined in the class\n",
      "              `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "              `AUTO` and the current `DistributionStrategy` chooses\n",
      "              when to synchronize.\n",
      "         * aggregation: Indicates how a distributed variable will be aggregated.\n",
      "              Accepted values are constants defined in the class\n",
      "              `tf.VariableAggregation`.\n",
      "        \n",
      "        This set may grow over time, so it's important the signature of creators is as\n",
      "        mentioned above.\n",
      "        \n",
      "        Args:\n",
      "          variable_creator: the passed creator\n",
      "        \n",
      "        Yields:\n",
      "          A scope in which the creator is active\n",
      "    \n",
      "    variable_op_scope(values, name_or_scope, default_name=None, initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, reuse=None, dtype=None, use_resource=None, constraint=None)\n",
      "        Deprecated: context manager for defining an op that creates variables.\n",
      "    \n",
      "    variables_initializer(var_list, name='init')\n",
      "        Returns an Op that initializes a list of variables.\n",
      "        \n",
      "        After you launch the graph in a session, you can run the returned Op to\n",
      "        initialize all the variables in `var_list`. This Op runs all the\n",
      "        initializers of the variables in `var_list` in parallel.\n",
      "        \n",
      "        Calling `initialize_variables()` is equivalent to passing the list of\n",
      "        initializers to `Group()`.\n",
      "        \n",
      "        If `var_list` is empty, however, the function still returns an Op that can\n",
      "        be run. That Op just has no effect.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        In TF2, variables are initialized immediately when they are created. There is\n",
      "        no longer a need to run variable initializers before using them.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to initialize.\n",
      "          name: Optional name for the returned operation.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that run the initializers of all the specified variables.\n",
      "    \n",
      "    vectorized_map(fn, elems, fallback_to_while_loop=True, warn=True)\n",
      "        Parallel map on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This method works similar to `tf.map_fn` but is optimized to run much faster,\n",
      "        possibly with a much larger memory footprint. The speedups are obtained by\n",
      "        vectorization (see [Auto-Vectorizing TensorFlow Graphs: Jacobians,\n",
      "        Auto-Batching and Beyond](https://arxiv.org/pdf/1903.04243.pdf)). The idea\n",
      "        behind vectorization is to semantically launch all the invocations of `fn` in\n",
      "        parallel and fuse corresponding operations across all these invocations. This\n",
      "        fusion is done statically at graph generation time and the generated code is\n",
      "        often similar in performance to a manually fused version.\n",
      "        \n",
      "        Because `tf.vectorized_map` fully parallelizes the batch, this method will\n",
      "        generally be significantly faster than using `tf.map_fn`, especially in eager\n",
      "        mode. However this is an experimental feature and currently has a lot of\n",
      "        limitations:\n",
      "          - There should be no data dependency between the different semantic\n",
      "            invocations of `fn`, i.e. it should be safe to map the elements of the\n",
      "            inputs in any order.\n",
      "          - Stateful kernels may mostly not be supported since these often imply a\n",
      "            data dependency. We do support a limited set of such stateful kernels\n",
      "            though (like RandomFoo, Variable operations like reads, etc).\n",
      "          - `fn` has limited support for control flow operations.\n",
      "          - `fn` should return nested structure of Tensors or Operations. However\n",
      "            if an Operation is returned, it should have zero outputs.\n",
      "          - The shape and dtype of any intermediate or output tensors in the\n",
      "            computation of `fn` should not depend on the input to `fn`.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "        def outer_product(a):\n",
      "          return tf.tensordot(a, a, 0)\n",
      "        \n",
      "        batch_size = 100\n",
      "        a = tf.ones((batch_size, 32, 32))\n",
      "        c = tf.vectorized_map(outer_product, a)\n",
      "        assert c.shape == (batch_size, 32, 32, 32, 32)\n",
      "        ```\n",
      "        \n",
      "        ```python\n",
      "        # Computing per-example gradients\n",
      "        \n",
      "        batch_size = 10\n",
      "        num_features = 32\n",
      "        layer = tf.keras.layers.Dense(1)\n",
      "        \n",
      "        def model_fn(arg):\n",
      "          with tf.GradientTape() as g:\n",
      "            inp, label = arg\n",
      "            inp = tf.expand_dims(inp, 0)\n",
      "            label = tf.expand_dims(label, 0)\n",
      "            prediction = layer(inp)\n",
      "            loss = tf.nn.l2_loss(label - prediction)\n",
      "          return g.gradient(loss, (layer.kernel, layer.bias))\n",
      "        \n",
      "        inputs = tf.random.uniform([batch_size, num_features])\n",
      "        labels = tf.random.uniform([batch_size, 1])\n",
      "        per_example_gradients = tf.vectorized_map(model_fn, (inputs, labels))\n",
      "        assert per_example_gradients[0].shape == (batch_size, num_features, 1)\n",
      "        assert per_example_gradients[1].shape == (batch_size, 1)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed. It accepts one argument, which will have\n",
      "            the same (possibly nested) structure as `elems`, and returns a possibly\n",
      "            nested structure of Tensors and Operations, which may be different than\n",
      "            the structure of `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension. The nested sequence of the\n",
      "            resulting slices will be mapped over by `fn`. The first dimensions of all\n",
      "            elements must broadcast to a consistent value; equivalently, each\n",
      "            element tensor must have first dimension of either `B` or `1`, for some\n",
      "            common batch size `B >= 1`.\n",
      "          fallback_to_while_loop: If true, on failing to vectorize an operation,\n",
      "            the unsupported op is wrapped in a tf.while_loop to execute the map\n",
      "            iterations. Note that this fallback only happens for unsupported ops and\n",
      "            other parts of `fn` are still vectorized. If false, on encountering an\n",
      "            unsupported op, a ValueError is thrown. Note that the fallbacks can result\n",
      "            in slowdowns since vectorization often yields speedup of one to two orders\n",
      "            of magnitude.\n",
      "          warn: If set to `false`, this will supress any warnings due to operation\n",
      "          conversions in the provided `fn` falling back to while loops.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors. Each tensor packs the\n",
      "          results of applying fn to tensors unpacked from elems along the first\n",
      "          dimension, from first to last.\n",
      "        \n",
      "          Although they are less common as user-visible inputs and outputs, note that\n",
      "          tensors of type `tf.variant` which represent tensor lists (for example from\n",
      "          `tf.raw_ops.TensorListFromTensor`) are vectorized by stacking the list\n",
      "          contents rather than the variant itself, and so the container tensor will\n",
      "          have a scalar shape when returned rather than the usual stacked shape. This\n",
      "          improves the performance of control flow gradient vectorization.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If vectorization fails and fallback_to_while_loop is False.\n",
      "    \n",
      "    verify_tensor_all_finite(t=None, msg=None, name=None, x=None, message=None)\n",
      "        Assert that the tensor does not contain any NaN's or Inf's.\n",
      "        \n",
      "        Args:\n",
      "          t: Tensor to check.\n",
      "          msg: Message to log on failure.\n",
      "          name: A name for this operation (optional).\n",
      "          x: Alias for t.\n",
      "          message: Alias for msg.\n",
      "        \n",
      "        Returns:\n",
      "          Same tensor as `t`.\n",
      "    \n",
      "    where(condition, x=None, y=None, name=None)\n",
      "        Return the elements, either from `x` or `y`, depending on the `condition`.\n",
      "        \n",
      "        If both `x` and `y` are None, then this operation returns the coordinates of\n",
      "        true elements of `condition`.  The coordinates are returned in a 2-D tensor\n",
      "        where the first dimension (rows) represents the number of true elements, and\n",
      "        the second dimension (columns) represents the coordinates of the true\n",
      "        elements. Keep in mind, the shape of the output tensor can vary depending on\n",
      "        how many true values there are in input. Indices are output in row-major\n",
      "        order.\n",
      "        \n",
      "        If both non-None, `x` and `y` must have the same shape.\n",
      "        The `condition` tensor must be a scalar if `x` and `y` are scalar.\n",
      "        If `x` and `y` are tensors of higher rank, then `condition` must be either a\n",
      "        vector with size matching the first dimension of `x`, or must have the same\n",
      "        shape as `x`.\n",
      "        \n",
      "        The `condition` tensor acts as a mask that chooses, based on the value at each\n",
      "        element, whether the corresponding element / row in the output should be taken\n",
      "        from `x` (if true) or `y` (if false).\n",
      "        \n",
      "        If `condition` is a vector and `x` and `y` are higher rank matrices, then it\n",
      "        chooses which row (outer dimension) to copy from `x` and `y`. If `condition`\n",
      "        has the same shape as `x` and `y`, then it chooses which element to copy from\n",
      "        `x` and `y`.\n",
      "        \n",
      "        Args:\n",
      "          condition: A `Tensor` of type `bool`\n",
      "          x: A Tensor which may have the same shape as `condition`. If `condition` is\n",
      "            rank 1, `x` may have higher rank, but its first dimension must match the\n",
      "            size of `condition`.\n",
      "          y: A `tensor` with the same shape and type as `x`.\n",
      "          name: A name of the operation (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same type and shape as `x`, `y` if they are non-None.\n",
      "          Otherwise, a `Tensor` with shape `(num_true, rank(condition))`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When exactly one of `x` or `y` is non-None.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This API is compatible with eager execution and `tf.function`. However, this\n",
      "        is still a legacy API endpoint originally designed for TF1. To migrate to\n",
      "        fully-native TF2, please replace its usage with `tf.where` instead, which is\n",
      "        directly backwards compatible with `tf.compat.v1.where`.\n",
      "        \n",
      "        However,`tf.compat.v1.where` is more restrictive than `tf.where`, requiring\n",
      "        `x` and `y` to have the same shape, and returning a `Tensor` with the same\n",
      "        type and shape as `x`, `y` (if they are both non-None).\n",
      "        \n",
      "        `tf.where` will accept `x`, `y` that are not the same shape as long as they\n",
      "        are broadcastable with one another and with `condition`, and will return a\n",
      "        `Tensor` with shape broadcast from `condition`, `x`, and `y`.\n",
      "        \n",
      "        For example, the following works with `tf.where` but not `tf.compat.v1.where`:\n",
      "        \n",
      "        >>> tf.where([True, False, False, True], [1,2,3,4], [100])\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([  1, 100, 100,   4],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        >>> tf.where(True, [1,2,3,4], 100)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    where_v2(condition, x=None, y=None, name=None)\n",
      "        Returns the indices of non-zero elements, or multiplexes `x` and `y`.\n",
      "        \n",
      "        This operation has two modes:\n",
      "        \n",
      "        1. **Return the indices of non-zero elements** - When only\n",
      "           `condition` is provided the result is an `int64` tensor where each row is\n",
      "           the index of a non-zero element of `condition`. The result's shape\n",
      "           is `[tf.math.count_nonzero(condition), tf.rank(condition)]`.\n",
      "        2. **Multiplex `x` and `y`** - When both `x` and `y` are provided the\n",
      "           result has the shape of `x`, `y`, and `condition` broadcast together. The\n",
      "           result is taken from `x` where `condition` is non-zero\n",
      "           or `y` where `condition` is zero.\n",
      "        \n",
      "        #### 1. Return the indices of non-zero elements\n",
      "        \n",
      "        Note: In this mode `condition` can have a dtype of `bool` or any numeric\n",
      "        dtype.\n",
      "        \n",
      "        If `x` and `y` are not provided (both are None):\n",
      "        \n",
      "        `tf.where` will return the indices of `condition` that are non-zero,\n",
      "        in the form of a 2-D tensor with shape `[n, d]`, where `n` is the number of\n",
      "        non-zero elements in `condition` (`tf.count_nonzero(condition)`), and `d` is\n",
      "        the number of axes of `condition` (`tf.rank(condition)`).\n",
      "        \n",
      "        Indices are output in row-major order. The `condition` can have a `dtype` of\n",
      "        `tf.bool`, or any numeric `dtype`.\n",
      "        \n",
      "        Here `condition` is a 1-axis `bool` tensor with 2 `True` values. The result\n",
      "        has a shape of `[2,1]`\n",
      "        \n",
      "        >>> tf.where([True, False, False, True]).numpy()\n",
      "        array([[0],\n",
      "               [3]])\n",
      "        \n",
      "        Here `condition` is a 2-axis integer tensor, with 3 non-zero values. The\n",
      "        result has a shape of `[3, 2]`.\n",
      "        \n",
      "        >>> tf.where([[1, 0, 0], [1, 0, 1]]).numpy()\n",
      "        array([[0, 0],\n",
      "               [1, 0],\n",
      "               [1, 2]])\n",
      "        \n",
      "        Here `condition` is a 3-axis float tensor, with 5 non-zero values. The output\n",
      "        shape is `[5, 3]`.\n",
      "        \n",
      "        >>> float_tensor = [[[0.1, 0], [0, 2.2], [3.5, 1e6]],\n",
      "        ...                 [[0,   0], [0,   0], [99,    0]]]\n",
      "        >>> tf.where(float_tensor).numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 1, 1],\n",
      "               [0, 2, 0],\n",
      "               [0, 2, 1],\n",
      "               [1, 2, 0]])\n",
      "        \n",
      "        These indices are the same that `tf.sparse.SparseTensor` would use to\n",
      "        represent the condition tensor:\n",
      "        \n",
      "        >>> sparse = tf.sparse.from_dense(float_tensor)\n",
      "        >>> sparse.indices.numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 1, 1],\n",
      "               [0, 2, 0],\n",
      "               [0, 2, 1],\n",
      "               [1, 2, 0]])\n",
      "        \n",
      "        A complex number is considered non-zero if either the real or imaginary\n",
      "        component is non-zero:\n",
      "        \n",
      "        >>> tf.where([complex(0.), complex(1.), 0+1j, 1+1j]).numpy()\n",
      "        array([[1],\n",
      "               [2],\n",
      "               [3]])\n",
      "        \n",
      "        #### 2. Multiplex `x` and `y`\n",
      "        \n",
      "        Note: In this mode `condition` must have a dtype of `bool`.\n",
      "        \n",
      "        If `x` and `y` are also provided (both have non-None values) the `condition`\n",
      "        tensor acts as a mask that chooses whether the corresponding\n",
      "        element / row in the output should be taken from `x` (if the element in\n",
      "        `condition` is `True`) or `y` (if it is `False`).\n",
      "        \n",
      "        The shape of the result is formed by\n",
      "        [broadcasting](https://docs.scipy.org/doc/numpy/reference/ufuncs.html)\n",
      "        together the shapes of `condition`, `x`, and `y`.\n",
      "        \n",
      "        When all three inputs have the same size, each is handled element-wise.\n",
      "        \n",
      "        >>> tf.where([True, False, False, True],\n",
      "        ...          [1, 2, 3, 4],\n",
      "        ...          [100, 200, 300, 400]).numpy()\n",
      "        array([  1, 200, 300,   4], dtype=int32)\n",
      "        \n",
      "        There are two main rules for broadcasting:\n",
      "        \n",
      "        1. If a tensor has fewer axes than the others, length-1 axes are added to the\n",
      "           left of the shape.\n",
      "        2. Axes with length-1 are streched to match the coresponding axes of the other\n",
      "           tensors.\n",
      "        \n",
      "        A length-1 vector is streched to match the other vectors:\n",
      "        \n",
      "        >>> tf.where([True, False, False, True], [1, 2, 3, 4], [100]).numpy()\n",
      "        array([  1, 100, 100,   4], dtype=int32)\n",
      "        \n",
      "        A scalar is expanded to match the other arguments:\n",
      "        \n",
      "        >>> tf.where([[True, False], [False, True]], [[1, 2], [3, 4]], 100).numpy()\n",
      "        array([[  1, 100], [100,   4]], dtype=int32)\n",
      "        >>> tf.where([[True, False], [False, True]], 1, 100).numpy()\n",
      "        array([[  1, 100], [100,   1]], dtype=int32)\n",
      "        \n",
      "        A scalar `condition` returns the complete `x` or `y` tensor, with\n",
      "        broadcasting applied.\n",
      "        \n",
      "        >>> tf.where(True, [1, 2, 3, 4], 100).numpy()\n",
      "        array([1, 2, 3, 4], dtype=int32)\n",
      "        >>> tf.where(False, [1, 2, 3, 4], 100).numpy()\n",
      "        array([100, 100, 100, 100], dtype=int32)\n",
      "        \n",
      "        For a non-trivial example of broadcasting, here `condition` has a shape of\n",
      "        `[3]`, `x` has a shape of `[3,3]`, and `y` has a shape of `[3,1]`.\n",
      "        Broadcasting first expands the shape of `condition` to `[1,3]`. The final\n",
      "        broadcast shape is `[3,3]`. `condition` will select columns from `x` and `y`.\n",
      "        Since `y` only has one column, all columns from `y` will be identical.\n",
      "        \n",
      "        >>> tf.where([True, False, True],\n",
      "        ...          x=[[1, 2, 3],\n",
      "        ...             [4, 5, 6],\n",
      "        ...             [7, 8, 9]],\n",
      "        ...          y=[[100],\n",
      "        ...             [200],\n",
      "        ...             [300]]\n",
      "        ... ).numpy()\n",
      "        array([[ 1, 100, 3],\n",
      "               [ 4, 200, 6],\n",
      "               [ 7, 300, 9]], dtype=int32)\n",
      "        \n",
      "        Note that if the gradient of either branch of the `tf.where` generates\n",
      "        a `NaN`, then the gradient of the entire `tf.where` will be `NaN`. This is\n",
      "        because the gradient calculation for `tf.where` combines the two branches, for\n",
      "        performance reasons.\n",
      "        \n",
      "        A workaround is to use an inner `tf.where` to ensure the function has\n",
      "        no asymptote, and to avoid computing a value whose gradient is `NaN` by\n",
      "        replacing dangerous inputs with safe inputs.\n",
      "        \n",
      "        Instead of this,\n",
      "        \n",
      "        >>> x = tf.constant(0., dtype=tf.float32)\n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   y = tf.where(x < 1., 0., 1. / x)\n",
      "        >>> print(tape.gradient(y, x))\n",
      "        tf.Tensor(nan, shape=(), dtype=float32)\n",
      "        \n",
      "        Although, the `1. / x` values are never used, its gradient is a `NaN` when\n",
      "        `x = 0`. Instead, we should guard that with another `tf.where`\n",
      "        \n",
      "        >>> x = tf.constant(0., dtype=tf.float32)\n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   safe_x = tf.where(tf.equal(x, 0.), 1., x)\n",
      "        ...   y = tf.where(x < 1., 0., 1. / safe_x)\n",
      "        >>> print(tape.gradient(y, x))\n",
      "        tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "        * `tf.sparse` - The indices returned by the first form of `tf.where` can be\n",
      "           useful in `tf.sparse.SparseTensor` objects.\n",
      "        * `tf.gather_nd`, `tf.scatter_nd`, and related ops - Given the\n",
      "          list of indices returned from `tf.where` the `scatter` and `gather` family\n",
      "          of ops can be used fetch values or insert values at those indices.\n",
      "        * `tf.strings.length` - `tf.string` is not an allowed dtype for the\n",
      "          `condition`. Use the string length instead.\n",
      "        \n",
      "        Args:\n",
      "          condition: A `tf.Tensor` of dtype bool, or any numeric dtype. `condition`\n",
      "            must have dtype `bool` when `x` and `y` are provided.\n",
      "          x: If provided, a Tensor which is of the same type as `y`, and has a shape\n",
      "            broadcastable with `condition` and `y`.\n",
      "          y: If provided, a Tensor which is of the same type as `x`, and has a shape\n",
      "            broadcastable with `condition` and `x`.\n",
      "          name: A name of the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          If `x` and `y` are provided:\n",
      "            A `Tensor` with the same type as `x` and `y`, and shape that\n",
      "            is broadcast from `condition`, `x`, and `y`.\n",
      "          Otherwise, a `Tensor` with shape `[tf.math.count_nonzero(condition),\n",
      "          tf.rank(condition)]`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When exactly one of `x` or `y` is non-None, or the shapes\n",
      "            are not all broadcastable.\n",
      "    \n",
      "    while_loop(cond, body, loop_vars, shape_invariants=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None, maximum_iterations=None, return_same_structure=False)\n",
      "        Repeat `body` while the condition `cond` is true.\n",
      "        \n",
      "        `cond` is a callable returning a boolean scalar tensor. `body` is a callable\n",
      "        returning a (possibly nested) tuple, namedtuple or list of tensors of the same\n",
      "        arity (length and structure) and types as `loop_vars`. `loop_vars` is a\n",
      "        (possibly nested) tuple, namedtuple or list of tensors that is passed to both\n",
      "        `cond` and `body`. `cond` and `body` both take as many arguments as there are\n",
      "        `loop_vars`.\n",
      "        \n",
      "        In addition to regular Tensors or IndexedSlices, the body may accept and\n",
      "        return TensorArray objects.  The flows of the TensorArray objects will\n",
      "        be appropriately forwarded between loops and during gradient calculations.\n",
      "        \n",
      "        Note that `while_loop` calls `cond` and `body` *exactly once* (inside the\n",
      "        call to `while_loop`, and not at all during `Session.run()`). `while_loop`\n",
      "        stitches together the graph fragments created during the `cond` and `body`\n",
      "        calls with some additional graph nodes to create the graph flow that\n",
      "        repeats `body` until `cond` returns false.\n",
      "        \n",
      "        For correctness, `tf.while_loop()` strictly enforces shape invariants for\n",
      "        the loop variables. A shape invariant is a (possibly partial) shape that\n",
      "        is unchanged across the iterations of the loop. An error will be raised\n",
      "        if the shape of a loop variable after an iteration is determined to be more\n",
      "        general than or incompatible with its shape invariant. For example, a shape\n",
      "        of [11, None] is more general than a shape of [11, 17], and [11, 21] is not\n",
      "        compatible with [11, 17]. By default (if the argument `shape_invariants` is\n",
      "        not specified), it is assumed that the initial shape of each tensor in\n",
      "        `loop_vars` is the same in every iteration. The `shape_invariants` argument\n",
      "        allows the caller to specify a less specific shape invariant for each loop\n",
      "        variable, which is needed if the shape varies between iterations. The\n",
      "        `tf.Tensor.set_shape`\n",
      "        function may also be used in the `body` function to indicate that\n",
      "        the output loop variable has a particular shape. The shape invariant for\n",
      "        SparseTensor and IndexedSlices are treated specially as follows:\n",
      "        \n",
      "        a) If a loop variable is a SparseTensor, the shape invariant must be\n",
      "        TensorShape([r]) where r is the rank of the dense tensor represented\n",
      "        by the sparse tensor. It means the shapes of the three tensors of the\n",
      "        SparseTensor are ([None], [None, r], [r]). NOTE: The shape invariant here\n",
      "        is the shape of the SparseTensor.dense_shape property. It must be the shape of\n",
      "        a vector.\n",
      "        \n",
      "        b) If a loop variable is an IndexedSlices, the shape invariant must be\n",
      "        a shape invariant of the values tensor of the IndexedSlices. It means\n",
      "        the shapes of the three tensors of the IndexedSlices are (shape, [shape[0]],\n",
      "        [shape.ndims]).\n",
      "        \n",
      "        `while_loop` implements non-strict semantics, enabling multiple iterations\n",
      "        to run in parallel. The maximum number of parallel iterations can be\n",
      "        controlled by `parallel_iterations`, which gives users some control over\n",
      "        memory consumption and execution order. For correct programs, `while_loop`\n",
      "        should return the same result for any parallel_iterations > 0.\n",
      "        \n",
      "        For training, TensorFlow stores the tensors that are produced in the\n",
      "        forward inference and are needed in back propagation. These tensors are a\n",
      "        main source of memory consumption and often cause OOM errors when training\n",
      "        on GPUs. When the flag swap_memory is true, we swap out these tensors from\n",
      "        GPU to CPU. This for example allows us to train RNN models with very long\n",
      "        sequences and large batches.\n",
      "        \n",
      "        Args:\n",
      "          cond: A callable that represents the termination condition of the loop.\n",
      "          body: A callable that represents the loop body.\n",
      "          loop_vars: A (possibly nested) tuple, namedtuple or list of numpy array,\n",
      "            `Tensor`, and `TensorArray` objects.\n",
      "          shape_invariants: The shape invariants for the loop variables.\n",
      "          parallel_iterations: The number of iterations allowed to run in parallel. It\n",
      "            must be a positive integer.\n",
      "          back_prop: Whether backprop is enabled for this while loop.\n",
      "          swap_memory: Whether GPU-CPU memory swap is enabled for this loop.\n",
      "          name: Optional name prefix for the returned tensors.\n",
      "          maximum_iterations: Optional maximum number of iterations of the while loop\n",
      "            to run.  If provided, the `cond` output is AND-ed with an additional\n",
      "            condition ensuring the number of iterations executed is no greater than\n",
      "            `maximum_iterations`.\n",
      "          return_same_structure: If True, output has same structure as `loop_vars`. If\n",
      "            eager execution is enabled, this is ignored (and always treated as True).\n",
      "        \n",
      "        Returns:\n",
      "          The output tensors for the loop variables after the loop.\n",
      "           If `return_same_structure` is True, the return value has the same\n",
      "           structure as `loop_vars`.\n",
      "           If `return_same_structure` is False, the return value is a Tensor,\n",
      "           TensorArray or IndexedSlice if the length of `loop_vars` is 1, or a list\n",
      "           otherwise.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `cond` or `body` is not callable.\n",
      "          ValueError: if `loop_vars` is empty.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        i = tf.constant(0)\n",
      "        c = lambda i: tf.less(i, 10)\n",
      "        b = lambda i: tf.add(i, 1)\n",
      "        r = tf.while_loop(c, b, [i])\n",
      "        ```\n",
      "        \n",
      "        Example with nesting and a namedtuple:\n",
      "        \n",
      "        ```python\n",
      "        import collections\n",
      "        Pair = collections.namedtuple('Pair', 'j, k')\n",
      "        ijk_0 = (tf.constant(0), Pair(tf.constant(1), tf.constant(2)))\n",
      "        c = lambda i, p: i < 10\n",
      "        b = lambda i, p: (i + 1, Pair((p.j + p.k), (p.j - p.k)))\n",
      "        ijk_final = tf.while_loop(c, b, ijk_0)\n",
      "        ```\n",
      "        \n",
      "        Example using shape_invariants:\n",
      "        \n",
      "        ```python\n",
      "        i0 = tf.constant(0)\n",
      "        m0 = tf.ones([2, 2])\n",
      "        c = lambda i, m: i < 10\n",
      "        b = lambda i, m: [i+1, tf.concat([m, m], axis=0)]\n",
      "        tf.while_loop(\n",
      "            c, b, loop_vars=[i0, m0],\n",
      "            shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])])\n",
      "        ```\n",
      "        \n",
      "        Example which demonstrates non-strict semantics: In the following\n",
      "        example, the final value of the counter `i` does not depend on `x`. So\n",
      "        the `while_loop` can increment the counter parallel to updates of `x`.\n",
      "        However, because the loop counter at one loop iteration depends\n",
      "        on the value at the previous iteration, the loop counter itself cannot\n",
      "        be incremented in parallel. Hence if we just want the final value of the\n",
      "        counter (which we print on the line `print(sess.run(i))`), then\n",
      "        `x` will never be incremented, but the counter will be updated on a\n",
      "        single thread. Conversely, if we want the value of the output (which we\n",
      "        print on the line `print(sess.run(out).shape)`), then the counter may be\n",
      "        incremented on its own thread, while `x` can be incremented in\n",
      "        parallel on a separate thread. In the extreme case, it is conceivable\n",
      "        that the thread incrementing the counter runs until completion before\n",
      "        `x` is incremented even a single time. The only thing that can never\n",
      "        happen is that the thread updating `x` can never get ahead of the\n",
      "        counter thread because the thread incrementing `x` depends on the value\n",
      "        of the counter.\n",
      "        \n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        \n",
      "        n = 10000\n",
      "        x = tf.constant(list(range(n)))\n",
      "        c = lambda i, x: i < n\n",
      "        b = lambda i, x: (tf.compat.v1.Print(i + 1, [i]), tf.compat.v1.Print(x + 1,\n",
      "        [i], \"x:\"))\n",
      "        i, out = tf.while_loop(c, b, (0, x))\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "            print(sess.run(i))  # prints [0] ... [9999]\n",
      "        \n",
      "            # The following line may increment the counter and x in parallel.\n",
      "            # The counter thread may get ahead of the other thread, but not the\n",
      "            # other way around. So you may see things like\n",
      "            # [9996] x:[9987]\n",
      "            # meaning that the counter thread is on iteration 9996,\n",
      "            # while the other thread is on iteration 9987\n",
      "            print(sess.run(out).shape)\n",
      "        ```\n",
      "    \n",
      "    wrap_function(fn, signature, name=None)\n",
      "        Wraps the TF 1.x function fn into a graph function.\n",
      "        \n",
      "        The python function `fn` will be called once with symbolic arguments specified\n",
      "        in the `signature`, traced, and turned into a graph function. Any variables\n",
      "        created by `fn` will be owned by the object returned by `wrap_function`. The\n",
      "        resulting graph function can be called with tensors which match the\n",
      "        signature.\n",
      "        \n",
      "        ```python\n",
      "        def f(x, do_add):\n",
      "          v = tf.Variable(5.0)\n",
      "          if do_add:\n",
      "            op = v.assign_add(x)\n",
      "          else:\n",
      "            op = v.assign_sub(x)\n",
      "          with tf.control_dependencies([op]):\n",
      "            return v.read_value()\n",
      "        \n",
      "        f_add = tf.compat.v1.wrap_function(f, [tf.TensorSpec((), tf.float32), True])\n",
      "        \n",
      "        assert float(f_add(1.0)) == 6.0\n",
      "        assert float(f_add(1.0)) == 7.0\n",
      "        \n",
      "        # Can call tf.compat.v1.wrap_function again to get a new trace, a new set\n",
      "        # of variables, and possibly different non-template arguments.\n",
      "        f_sub= tf.compat.v1.wrap_function(f, [tf.TensorSpec((), tf.float32), False])\n",
      "        \n",
      "        assert float(f_sub(1.0)) == 4.0\n",
      "        assert float(f_sub(1.0)) == 3.0\n",
      "        ```\n",
      "        \n",
      "        Both `tf.compat.v1.wrap_function` and `tf.function` create a callable\n",
      "        TensorFlow graph. But while `tf.function` runs all stateful operations\n",
      "        (e.g. `tf.print`) and sequences operations to provide the same semantics as\n",
      "        eager execution, `wrap_function` is closer to the behavior of `session.run` in\n",
      "        TensorFlow 1.x. It will not run any operations unless they are required to\n",
      "        compute the function's outputs, either through a data dependency or a control\n",
      "        dependency. Nor will it sequence operations.\n",
      "        \n",
      "        Unlike `tf.function`, `wrap_function` will only trace the Python function\n",
      "        once. As with placeholders in TF 1.x, shapes and dtypes must be provided to\n",
      "        `wrap_function`'s `signature` argument.\n",
      "        \n",
      "        Since it is only traced once, variables and state may be created inside the\n",
      "        function and owned by the function wrapper object.\n",
      "        \n",
      "        Args:\n",
      "          fn: python function to be wrapped\n",
      "          signature: the placeholder and python arguments to be passed to the wrapped\n",
      "            function\n",
      "          name: Optional. The name of the function.\n",
      "        \n",
      "        Returns:\n",
      "          the wrapped graph function.\n",
      "    \n",
      "    write_file(filename: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], contents: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], name=None)\n",
      "        Writes `contents` to the file at input `filename`.\n",
      "        \n",
      "        Creates the file and recursively creates directory if it does not exist.\n",
      "        \n",
      "        Args:\n",
      "          filename: A `Tensor` of type `string`.\n",
      "            scalar. The name of the file to which we write the contents.\n",
      "          contents: A `Tensor` of type `string`.\n",
      "            scalar. The content to be written to the output file.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The created Operation.\n",
      "    \n",
      "    zeros(shape, dtype=tf.float32, name=None, layout=None)\n",
      "        Creates a tensor with all elements set to zero.\n",
      "        \n",
      "        See also `tf.zeros_like`, `tf.ones`, `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        This operation returns a tensor of type `dtype` with shape `shape` and\n",
      "        all elements set to zero.\n",
      "        \n",
      "        >>> tf.zeros([3, 4], tf.int32)\n",
      "        <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
      "        array([[0, 0, 0, 0],\n",
      "               [0, 0, 0, 0],\n",
      "               [0, 0, 0, 0]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          shape: A `list` of integers, a `tuple` of integers, or a 1-D `Tensor` of\n",
      "            type `int32`.\n",
      "          dtype: The DType of an element in the resulting `Tensor`.\n",
      "          name: Optional string. A name for the operation.\n",
      "          layout: Optional, `tf.experimental.dtensor.Layout`. If provided, the result\n",
      "            is a [DTensor](https://www.tensorflow.org/guide/dtensor_overview) with the\n",
      "            provided layout.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to zero.\n",
      "    \n",
      "    zeros_like(tensor, dtype=None, name=None, optimize=True)\n",
      "        Creates a tensor with all elements set to zero.\n",
      "        \n",
      "        See also `tf.zeros`.\n",
      "        \n",
      "        Given a single tensor (`tensor`), this operation returns a tensor of the\n",
      "        same type and shape as `tensor` with all elements set to zero. Optionally,\n",
      "        you can use `dtype` to specify a new type for the returned tensor.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "          >>> tf.zeros_like(tensor)\n",
      "          <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "          array([[0, 0, 0],\n",
      "                 [0, 0, 0]], dtype=int32)>\n",
      "        \n",
      "          >>> tf.zeros_like(tensor, dtype=tf.float32)\n",
      "          <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
      "          array([[0., 0., 0.],\n",
      "                 [0., 0., 0.]], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          dtype: A type for the returned `Tensor`. Must be `float16`, `float32`,\n",
      "            `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`,\n",
      "            `complex64`, `complex128`, `bool` or `string`. (optional)\n",
      "          name: A name for the operation (optional).\n",
      "          optimize: if `True`, attempt to statically determine the shape of `tensor`\n",
      "            and encode it as a constant. (optional, defaults to `True`)\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to zero.\n",
      "    \n",
      "    zeta(x: typing.Annotated[_any, ~TV_Zeta_T], q: typing.Annotated[_any, ~TV_Zeta_T], name=None) -> typing.Annotated[_any, ~TV_Zeta_T]\n",
      "        Compute the Hurwitz zeta function \\\\(\\zeta(x, q)\\\\).\n",
      "        \n",
      "        The Hurwitz zeta function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(\\zeta(x, q) = \\sum_{n=0}^{\\infty} (q + n)^{-x}\\\\)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          q: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "\n",
      "DATA\n",
      "    AUTO_REUSE = <_ReuseMode.AUTO_REUSE: 1>\n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.AUTO_REUSE` is a legacy API that is a no-op when TF2 behaviors\n",
      "        are enabled.\n",
      "        \n",
      "        If you rely on `get_variable` and auto-reuse, see the\n",
      "        [model mapping guide](https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "        for more info on how to migrate your code.\n",
      "        \n",
      "        Note: when you use the `tf.compat.v1.keras.utils.track_tf1_style_variables`\n",
      "        API as described in the above guide, `get_variable` will always behave as if\n",
      "        `v1.AUTO_REUSE` is set. Without the decorator, reuse will be ignored and new\n",
      "        variables will always be created, regardless of if they have already been\n",
      "        created.\n",
      "        @end_compatibility\n",
      "        \n",
      "        When passed in as the value for the `reuse` flag, `AUTO_REUSE` indicates that\n",
      "        get_variable() should create the requested variable if it doesn't exist or, if\n",
      "        it does exist, simply return it.\n",
      "    \n",
      "    COMPILER_VERSION = 'Apple LLVM 14.0.3 (clang-1403.0.22.14.1)'\n",
      "    CXX11_ABI_FLAG = 0\n",
      "    CXX_VERSION = 201703\n",
      "    GIT_VERSION = 'v2.16.1-0-g5bc9d26649c'\n",
      "    GRAPH_DEF_VERSION = 1766\n",
      "    GRAPH_DEF_VERSION_MIN_CONSUMER = 0\n",
      "    GRAPH_DEF_VERSION_MIN_PRODUCER = 0\n",
      "    MONOLITHIC_BUILD = 0\n",
      "    QUANTIZED_DTYPES = frozenset({tf.qint8, tf.quint8, tf.qint32, tf.qint8...\n",
      "    VERSION = '2.16.1'\n",
      "    __all__ = ['AUTO_REUSE', 'AggregationMethod', 'Assert', 'AttrValue', '...\n",
      "    __compiler_version__ = 'Apple LLVM 14.0.3 (clang-1403.0.22.14.1)'\n",
      "    __cxx11_abi_flag__ = 0\n",
      "    __cxx_version__ = 201703\n",
      "    __git_version__ = 'v2.16.1-0-g5bc9d26649c'\n",
      "    __monolithic_build__ = 0\n",
      "    bfloat16 = tf.bfloat16\n",
      "        16-bit bfloat (brain floating point).\n",
      "    \n",
      "    bool = tf.bool\n",
      "        Boolean.\n",
      "    \n",
      "    complex128 = tf.complex128\n",
      "        128-bit complex.\n",
      "    \n",
      "    complex64 = tf.complex64\n",
      "        64-bit complex.\n",
      "    \n",
      "    double = tf.float64\n",
      "        64-bit (double precision) floating-point.\n",
      "    \n",
      "    float16 = tf.float16\n",
      "        16-bit (half precision) floating-point.\n",
      "    \n",
      "    float32 = tf.float32\n",
      "        32-bit (single precision) floating-point.\n",
      "    \n",
      "    float64 = tf.float64\n",
      "        64-bit (double precision) floating-point.\n",
      "    \n",
      "    half = tf.float16\n",
      "        16-bit (half precision) floating-point.\n",
      "    \n",
      "    int16 = tf.int16\n",
      "        Signed 16-bit integer.\n",
      "    \n",
      "    int32 = tf.int32\n",
      "        Signed 32-bit integer.\n",
      "    \n",
      "    int64 = tf.int64\n",
      "        Signed 64-bit integer.\n",
      "    \n",
      "    int8 = tf.int8\n",
      "        Signed 8-bit integer.\n",
      "    \n",
      "    newaxis = None\n",
      "    qint16 = tf.qint16\n",
      "        Signed quantized 16-bit integer.\n",
      "    \n",
      "    qint32 = tf.qint32\n",
      "        signed quantized 32-bit integer.\n",
      "    \n",
      "    qint8 = tf.qint8\n",
      "        Signed quantized 8-bit integer.\n",
      "    \n",
      "    quint16 = tf.quint16\n",
      "        Unsigned quantized 16-bit integer.\n",
      "    \n",
      "    quint8 = tf.quint8\n",
      "        Unsigned quantized 8-bit integer.\n",
      "    \n",
      "    resource = tf.resource\n",
      "        Handle to a mutable, dynamically allocated resource.\n",
      "    \n",
      "    string = tf.string\n",
      "        Variable-length string, represented as byte array.\n",
      "    \n",
      "    uint16 = tf.uint16\n",
      "        Unsigned 16-bit (word) integer.\n",
      "    \n",
      "    uint32 = tf.uint32\n",
      "        Unsigned 32-bit (dword) integer.\n",
      "    \n",
      "    uint64 = tf.uint64\n",
      "        Unsigned 64-bit (qword) integer.\n",
      "    \n",
      "    uint8 = tf.uint8\n",
      "        Unsigned 8-bit (byte) integer.\n",
      "    \n",
      "    variant = tf.variant\n",
      "        Data of arbitrary type (known at runtime).\n",
      "\n",
      "VERSION\n",
      "    2.16.1\n",
      "\n",
      "FILE\n",
      "    /Users/user/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.compat.v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 shape: (150, 2) Batch 2 shape: (150, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 17:58:15.953345: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 6.361\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGzCAYAAAAFROyYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABvjUlEQVR4nO3deXxU1d0/8M/MZDJJyApkhUACREHZKkseRKVqSlxQ6KMtIsqiPxcKaJtShKLEpYoLtVhBUarA4/JApRUt0ICm+tSFlsqiLGFPWIQkQCAJScgkM+f3x/HOltmXZO7k83695jWZM+fee2aSOfPNWTVCCAEiIiKiMKLt6AIQEREROWKAQkRERGGHAQoRERGFHQYoREREFHYYoBAREVHYYYBCREREYYcBChEREYUdBihEREQUdhigEBERUdhhgEJ+e/LJJ6HRaPw6dtWqVdBoNKioqAhuoWxUVFRAo9Fg1apVIbsGEVFOTg6mTZvW0cWIOAxQOqm9e/finnvuQY8ePWAwGJCVlYXJkydj7969HV00ImpH5eXlmDVrFi677DLExcUhLi4OV1xxBWbOnInvvvuuo4sXNJs2bcKTTz7Z0cUgH2i4F0/n89e//hWTJk1C165dcf/99yM3NxcVFRV46623cO7cOaxZswY//elPPZ6ntbUVra2tiImJ8bkMJpMJLS0tMBgMfrfCeFJRUYHc3FysXLmS/90QObFhwwZMnDgRUVFRmDx5MoYMGQKtVov9+/fjr3/9K44dO4by8nL07t27o4sasFmzZmHZsmUIxVdeTk4OfvzjH7O1NsiiOroA1L6OHDmCe++9F3369ME///lPpKamWp579NFHce211+Lee+/Fd999hz59+jg9R0NDA7p06YKoqChERfn3J6TT6aDT6fw6logCd+TIEdx1113o3bs3SktLkZmZaff8Cy+8gNdeew1abXg2tCv1EEWu8PzLo5B56aWX0NjYiDfffNMuOAGA7t2744033kBDQwNefPFFANZxJvv27cPdd9+NlJQUXHPNNXbP2WpqasIjjzyC7t27IyEhAbfffju+//57aDQau+ZVZ2NQcnJyMG7cOHz55ZcYOXIkYmJi0KdPH/zP//yP3TVqamowZ84cDBo0CPHx8UhMTMTNN9+Mb7/9NojvFFFke/HFF9HQ0ICVK1e2CU4AICoqCo888giys7Mtafv378edd96Jrl27IiYmBsOHD8fHH39sd5zy2f7qq69QVFSE1NRUdOnSBT/96U9x5syZNtf5+9//jmuvvRZdunRBQkICbr311jZdzdOmTUN8fDyOHDmCW265BQkJCZg8eTIA4IsvvsDPfvYz9OrVCwaDAdnZ2fjVr36FpqYmu+OXLVsGANBoNJabwmw2Y8mSJbjyyisRExOD9PR0PPTQQzh//rxdOYQQ+N3vfoeePXsiLi4O119/PbvFQ4gtKJ3M3/72N+Tk5ODaa691+vx1112HnJwcbNy40S79Zz/7GfLy8vDcc8+5bSKdNm0a/vznP+Pee+/Ff/3Xf+H//u//cOutt3pdvsOHD+POO+/E/fffj6lTp+Ltt9/GtGnTMGzYMFx55ZUAgKNHj2L9+vX42c9+htzcXFRVVeGNN97AmDFjsG/fPmRlZXl9PaLOasOGDejXrx/y8/O9yr93716MHj0aPXr0wLx589ClSxf8+c9/xoQJE/CXv/ylTbfw7NmzkZKSguLiYlRUVGDJkiWYNWsW1q5da8nzzjvvYOrUqSgsLMQLL7yAxsZGvP7667jmmmuwc+dO5OTkWPK2traisLAQ11xzDRYvXoy4uDgAwAcffIDGxkbMmDED3bp1w7Zt2/Dqq6/i5MmT+OCDDwAADz30EE6dOoVPPvkE77zzTpvX9tBDD2HVqlWYPn06HnnkEZSXl2Pp0qXYuXMnvvrqK+j1egDAwoUL8bvf/Q633HILbrnlFuzYsQNjx46F0Wj06b0nLwnqNC5cuCAAiPHjx7vNd/vttwsAoq6uThQXFwsAYtKkSW3yKc8ptm/fLgCIX/7yl3b5pk2bJgCI4uJiS9rKlSsFAFFeXm5J6927twAg/vnPf1rSqqurhcFgEL/+9a8taZcuXRImk8nuGuXl5cJgMIinn37aLg2AWLlypdvXS9TZ1NbWCgBiwoQJbZ47f/68OHPmjOXW2NgohBDixhtvFIMGDRKXLl2y5DWbzeLqq68WeXl5ljTls11QUCDMZrMl/Ve/+pXQ6XTiwoULQggh6uvrRXJysnjggQfsrl9ZWSmSkpLs0qdOnSoAiHnz5rUpr1I+W4sWLRIajUYcO3bMkjZz5kzh7Cvviy++EADEe++9Z5deUlJil15dXS2io6PFrbfeave6fvvb3woAYurUqW3OTYFhF08nUl9fDwBISEhwm095vq6uzpL28MMPezx/SUkJAOAXv/iFXfrs2bO9LuMVV1xh17qTmpqKyy+/HEePHrWkGQwGS7+4yWTCuXPnEB8fj8svvxw7duzw+lpEnZXy2Y6Pj2/z3I9//GOkpqZabsuWLUNNTQ3+8Y9/4Oc//znq6+tx9uxZnD17FufOnUNhYSEOHTqE77//3u48Dz74oF03yrXXXguTyYRjx44BAD755BNcuHABkyZNspzv7Nmz0Ol0yM/Px2effdambDNmzGiTFhsba/m5oaEBZ8+exdVXXw0hBHbu3Onxvfjggw+QlJSEn/zkJ3blGDZsGOLj4y3l+PTTT2E0GjF79my71/XLX/7S4zXIP+zi6USUwEMJVFxxFsjk5uZ6PP+xY8eg1Wrb5O3Xr5/XZezVq1ebtJSUFLu+YLPZjFdeeQWvvfYaysvLYTKZLM9169bN62sRdVbKZ/vixYttnnvjjTdQX1+Pqqoq3HPPPQBk16sQAk888QSeeOIJp+esrq5Gjx49LI8dP8spKSkAYPksHzp0CABwww03OD1fYmKi3eOoqCj07NmzTb7jx49j4cKF+Pjjj9uMGamtrXV6bluHDh1CbW0t0tLSnD5fXV0NAJbAKi8vz+751NRUy2uj4GKA0okkJSUhMzPT49oG3333HXr06GFXQdj+lxJKrmb2CJtxL8899xyeeOIJ3HfffXjmmWfQtWtXaLVa/PKXv4TZbG6XchKpmVIX7Nmzp81zypgU2wHsyudqzpw5KCwsdHpOx39EPH2WlXO+8847yMjIaJPPcYagbcupwmQy4Sc/+Qlqamrw2GOPoX///ujSpQu+//57TJs2zav6wGw2Iy0tDe+9957T5x0nE1D7YYDSyYwbNw4rVqzAl19+aZmNY+uLL75ARUUFHnroIZ/P3bt3b5jNZpSXl9v9l3H48OGAyuxo3bp1uP766/HWW2/ZpV+4cAHdu3cP6rWIItWtt96KP/3pT9i2bRtGjhzpNq+y5IBer0dBQUFQrt+3b18AQFpamt/n3L17Nw4ePIjVq1djypQplvRPPvmkTV5X6y317dsXn376KUaPHu32HzFlLZhDhw7ZLcFw5syZNi03FBwcg9LJ/OY3v0FsbCweeughnDt3zu65mpoaPPzww4iLi8NvfvMbn8+t/Gf12muv2aW/+uqr/hfYCZ1O12Ym0QcffNCmD5yIXJs7dy7i4uJw3333oaqqqs3ztp+xtLQ0/PjHP8Ybb7yB06dPt8nrbPqwJ4WFhUhMTMRzzz2HlpYWv86ptNLYllUIgVdeeaVNXmXNlAsXLtil//znP4fJZMIzzzzT5pjW1lZL/oKCAuj1erz66qt211uyZInHcpJ/2ILSyeTl5WH16tWYPHkyBg0a1GYl2bNnz+J///d/Lf/d+GLYsGG44447sGTJEpw7d84yzfjgwYMAXP8H46tx48bh6aefxvTp03H11Vdj9+7deO+991wuLEdEbeXl5eH999/HpEmTcPnll1tWkhVCoLy8HO+//z60Wq1l3MeyZctwzTXXYNCgQXjggQfQp08fVFVVYevWrTh58qTP6xAlJibi9ddfx7333ourrroKd911F1JTU3H8+HFs3LgRo0ePxtKlS92eo3///ujbty/mzJmD77//HomJifjLX/7itEVj2LBhAIBHHnkEhYWF0Ol0uOuuuzBmzBg89NBDWLRoEXbt2oWxY8dCr9fj0KFD+OCDD/DKK6/gzjvvRGpqKubMmYNFixZh3LhxuOWWW7Bz5078/e9/Z8ttqHTU9CHqWN99952YNGmSyMzMFHq9XmRkZIhJkyaJ3bt32+VTphKfOXOmzTkcpxkLIURDQ4OYOXOm6Nq1q4iPjxcTJkwQBw4cEADE888/b8nnaprxrbfe2uY6Y8aMEWPGjLE8vnTpkvj1r38tMjMzRWxsrBg9erTYunVrm3ycZkzk2eHDh8WMGTNEv379RExMjIiNjRX9+/cXDz/8sNi1a5dd3iNHjogpU6aIjIwModfrRY8ePcS4cePEunXrLHmUz/Z//vMfu2M/++wzAUB89tlnbdILCwtFUlKSiImJEX379hXTpk0T33zzjSXP1KlTRZcuXZyWf9++faKgoEDEx8eL7t27iwceeEB8++23bT77ra2tYvbs2SI1NVVoNJo2ddebb74phg0bJmJjY0VCQoIYNGiQmDt3rjh16pQlj8lkEk899ZSl7vnxj38s9uzZI3r37s1pxiHAvXgo5Hbt2oUf/ehHePfddy2rPxIREbnDMSgUVLbLSyuWLFkCrVaL6667rgNKREREasQxKBRUL774IrZv347rr78eUVFR+Pvf/46///3vePDBB+329CAiInKHXTwUVJ988gmeeuop7Nu3DxcvXkSvXr1w7733YsGCBX7vfExERJ0PAxQiIiIKOxyDQkRERGGHAQoRERGFHVUMCjCbzTh16hQSEhKCttgXEXlPCIH6+npkZWW12Q8lXLHeIOp4gdQdqghQTp06xRkgRGHgxIkTTneUDUesN4jChz91hyoCFGVr8BMnTrTZgpuIQq+urg7Z2dmWz6IasN4g6niB1B2qCFCU5tnExERWNEQdSE1dJaw3iMKHP3WHOjqTiYiIqFNRRQsKqV9rK7B+PXDyJNCzJzBhAsB124iIyBV+RVDItbYCM2YAn3wCtLQAej2wZQvw2msMUoiIyDl28VDIrV8vg5OkJCAvT95v2SLTiYiInGGAQiF38qRsOUlJkY9TUuTjkyc7tlxERBS+GKBQyPXsKbt1zp+Xj8+fl49VspwGERF1AAYoFHITJgBjxwK1tcChQ/J+7FiZTkRE5AyHKFLIRUXJAbGcxUNERN7iVwS1i6go4M47O7oURESkFuziISIiorDDFhQiAGYzsGcPUFMDdO0KDBwIqGTTXiKiiMQAhTo9sxl45x25NktzM2AwAIWFwD33MEghIuoorH6p09uzRwYn3brJlpNu3YDNm2U6ERF1DAYo1OnV1MiWk65d5eOuXeXjmpqOLRcRUWfGAIU6va5dZbeOEpDU1MjHSsBCRETtjwEKdXoDB8oxJ+fOyW6dc+fk44EDO7pkRESdFwfJUqen1coBsUOHchYPEVG4YIBCBBmMDB7c0aUgIiIF/0ckIiKisMMWFOowRiPw6qtAeTmQmwvMng1ER3t3LBdWIyKKbAxQqEMYjXJH4//8RwYbWi2wYYNcf8RTkMKF1YiIIh+rc+oQr74qg5OYGCA9Xd5v2ybTPeHCakREkY8BCnWI8nLZEpKQIB8nJMjH5eWej+XCakREkc+vAGXZsmXIyclBTEwM8vPzsW3bNrf5L1y4gJkzZyIzMxMGgwGXXXYZNm3a5FeBKTLk5srumPp6+bi+Xj7OzfV8LBdWIyKKfD4HKGvXrkVRURGKi4uxY8cODBkyBIWFhaiurnaa32g04ic/+QkqKiqwbt06HDhwACtWrECPHj0CLjyp1+zZwMiRwKVLQFWVvB85UqZ7woXViIgin0YIIXw5ID8/HyNGjMDSpUsBAGazGdnZ2Zg9ezbmzZvXJv/y5cvx0ksvYf/+/dDr9X4Vsq6uDklJSaitrUViYqJf56Dww1k86qHGz6Aay0wUaQL5HPo0i8doNGL79u2YP3++JU2r1aKgoABbt251eszHH3+MUaNGYebMmfjoo4+QmpqKu+++G4899hh0Op3TY5qbm9Hc3Gx5XFdX50sxSSWio4Ff/9q/Y7mwGjlivUEUWXz6n/Ps2bMwmUxIT0+3S09PT0dlZaXTY44ePYp169bBZDJh06ZNeOKJJ/D73/8ev/vd71xeZ9GiRUhKSrLcsrOzfSkmEXVCrDeIIkvI10Exm81IS0vDm2++CZ1Oh2HDhuH777/HSy+9hOLiYqfHzJ8/H0VFRZbHdXV1rGxCpLUVWL8eOHkS6NkTmDABiHLyV+FtPl+uA/h/ba22bReP2Rzca4TifaDQYb1BFFl8qlq7d+8OnU6Hqqoqu/SqqipkZGQ4PSYzMxN6vd6uO2fAgAGorKyE0WhEtJNBBwaDAQaDwZeikR9aW4EZM4BPPgFaWgC9Xq4v8tpr9l+63ubz5TolJYAQQGmp79fevBkYNUoeqyzUVlAAfPUV8OmnwblGKN4HCi3WG0SRxacunujoaAwbNgylpaWWNLPZjNLSUowaNcrpMaNHj8bhw4dhNpstaQcPHkRmZqbT4ITaz/r18ss2KQnIy5P3W7bIdH/y+XKdjz4CPv7Yv2tv3Ai8/bb9Qm1vvQVs2hS8a4TifSAiIu/5PO+hqKgIK1aswOrVq1FWVoYZM2agoaEB06dPBwBMmTLFbhDtjBkzUFNTg0cffRQHDx7Exo0b8dxzz2HmzJnBexXkl5MnZUtASop8nJIiH5886V8+X65jNMqbv9eur7dfqK2+PvjXCPb7QERE3vO5YXrixIk4c+YMFi5ciMrKSgwdOhQlJSWWgbPHjx+H1ma+Z3Z2NjZv3oxf/epXGDx4MHr06IFHH30Ujz32WPBeBfmlZ0/ZTXH+vPyyPX9ePu7Z0798vlxHaTzz99oJCdbxJzU18nGwrxHs94GIiLzn8zooHYHrGYRGayvwi1/IbgplTMXYsc7HXniTz5frFBTI52zHjHh77Z/8BLj6anms7RiUr7+2Hx8SyDVC8T6omRo/g2osM1GkCeRzyAClk+MsnvZ9H9RKjZ9BNZaZKNIwQCGikFLjZ1CNZSaKNIF8Drk4OBEREYWdTtA43TmptSvi0iVgwQLg6FGgTx/g2WeBmJjgXsPb7iZn3UjO9vtR63tNRBTOWI1GILUuKHbpEjB0KHD4sFxgTaORa5vs3Bm8IMXbReOcLQZXWAjcc499kKLW95qIKNyxiycCqXVBsQULZHCi08lpwzodcOiQTA8WbxeNc7YY3ObNskXF0/nU8F4TEYU7BigRSK0Lih09KlsyYmPl49hY+fjo0eBdw5dF4xwXg2tult09ns6nhveaiCjcMUCJQLYLigHqWVCsTx/ZrdPUJB83NcnHffoE7xrO3pvoaHlzfL+UxeAAeW8wWAMWd+dTw3tNRBTuGKBEoAkT5AJitbWyi6S2Vj5WBoOGq2efld0kJpNsvTCZ5ONnnw3eNZy9N+PHy5tt2q23AvffD5w7J7t1zp2TY1AGDvR8PjW810RE4Y7roEQotc4s4Sye8KTGz6Aay0wUabhQGxGFlBo/g2osM1GkCeRzGGH/51EwOGvF0GqBV18FysuB3Fxg9mw5sHTSJKCiAsjJAf73f4H4+MCu3R7L2pvN3rWMEBFRx2GAQnacrUWyYQOQlgbs2CG/3LVa4MMPgd27gbo6edyePTIoOHnS/yDF2ZoiztYjKSgAvvrKfhNAZ2uZOFuPxGwG3nlHPudufRMiIupYDFDIju1aJLGxcibNoUOyNSUxUc5sqa8Htm6VX/aAzGsyyQGikyYBf/ubf9e2XVMkJUXOiNm4ESgrA666SrZ21NQAb70ly5Oaas330UfyHFlZ1jRlPZI777ReY88emd6tm/V8mzfLoGzw4ADeOCIiCir+z0h2XK1FYjLJ4ASQ97bBie19RYX/13a1pojjeiT19d6vZeK4HklNjWw58bS+CRERdSwGKGTH1VokOp0MDAB5r3SHmEz29zk5/l/b1ZoijuuRJCR4v5aJ43okXbvKbh1P65sQEVHHYoBCdlytRTJqlByfUlUl70eNkl0+gDU4SUqSA2X95WxNEWfrkdx/v0z3tJaJs/VIBg6UY048rW9CREQdi2NQyE5MjNycryNm8URFyUGtzmbxDBtmP+vm3nv9m8Wj1coBsUOHchYPEVE44zooROSRGj+DaiwzUaQJ5HPI/xuJiIgo7LCLh9rwdul2VwueGY1tu4Oio4N7bSIiimys+smOs8XSfFnw7Oc/B266CfjPf6yLum3YINca8RSkeHttIiKKfOziITu2i6Xl5cl7ZcEzW7YLng0cKO83b5aDa//zHznYNj1d3m/bJltUgnVtIiKKfAxQyI6rxdK8XfDs6FHZcuK4qFt5efCuTUREkY8BCtlxtViatwue9ekju3UcF3XLzQ3etYmIKPIxQCE7zhZL82XBs2efBUaOtF/UbeRIOVA2WNcmIqLIx3VQqA3O4iFHavwMqrHMRJEmkM8hq35qIyrKfgdgV7Ra5zsAR0cDv/51aK9NRESRjV08REREFHbYghIBgt0t4ux8ALteiIio/fArRuWCvbiZs/OVlABCAKWlXECNiIjaB7t4VC7Yi5s5O99HHwEff8wF1IiIqP349f/vsmXL8NJLL6GyshJDhgzBq6++ipEjR3o8bs2aNZg0aRLGjx+P9e3w7WYymdDS0hLy63Skc+eAtDQgJ0c+TksDKipk+qVLwTmfySR/vvxyz9fQ6/XQ6XS+X5goTJjNZhiNxo4uRqfCeoOc8TlAWbt2LYqKirB8+XLk5+djyZIlKCwsxIEDB5CWlubyuIqKCsyZMwfXXnttQAX2hhAClZWVuHDhQsiv1dGGD7cujqbVyqm/ZrOc9uvN6q3enE8JUHQ6766RnJyMjIwMaDSawF4cUTszGo0oLy+H2Wzu6KJ0Oqw3yJHPAcrLL7+MBx54ANOnTwcALF++HBs3bsTbb7+NefPmOT3GZDJh8uTJeOqpp/DFF1+EPHBQgpO0tDTExcVF9B+8EMCpU8DFi/JnjQaIjweysuTPwTof4PkaQgg0NjaiuroaAJCZmRmEV0jUPoQQOH36NHQ6HbKzs6HVsge8PbDeIFd8ClCMRiO2b9+O+fPnW9K0Wi0KCgqwdetWl8c9/fTTSEtLw/33348vvvjC43Wam5vR3NxseVxXV+d1GU0mkyU46datm9fHqVmfPnJZeGUAa0qKf8GJu/MB3l0jNjYWAFBdXY20tDQ221K7CaTeAIDW1lY0NjYiKysLcXFxwS4eucF6g5zxKUA5e/YsTCYT0tPT7dLT09Oxf/9+p8d8+eWXeOutt7Br1y6vr7No0SI89dRTvhTNQhlz0pkqGI3GumlfKM/n7TWU976lpYUVDbWbQOoNQP5zAwDR3i57TEHFeoMchbQNs76+Hvfeey9WrFiB7t27e33c/PnzUVtba7mdOHHC52tHcrdOuON7Tx0hGPUGwL/fjsL3nRz51ILSvXt36HQ6VFVV2aVXVVUhIyOjTf4jR46goqICt912myVNGXwWFRWFAwcOoG/fvm2OMxgMMBgMvhQtIgkBNDXJQao6HRAbK9Oqq+V+N9HRckZNsLvKhfCuO8dVPiGAxkZg9WqgWzfXi7px3x0KJtYbRJHFp6+D6OhoDBs2DKWlpZjww/KiZrMZpaWlmDVrVpv8/fv3x+7du+3SHn/8cdTX1+OVV15Bdna2/yWPcELIabx1ddaBqQkJMq2x0ZpWWyvXJglWkCIEcOyY/XXr6oDevR0HxDrP16uXHGRbUwO89ZYMppwt6hbsBeaIiCiy+Py1VlRUhBUrVmD16tUoKyvDjBkz0NDQYJnVM2XKFMsg2piYGAwcONDulpycjISEBAwcOJB9vW40Nckv/Kgo2XISFQWcOQM0NMhgRK+X9w0NMghwZ9WqVUhOTvbquufPy+vqdEBMjLyvq5Pp3uT7/ns520erlWupuFrULdgLzBFR8PlSdxAFm88BysSJE7F48WIsXLgQQ4cOxa5du1BSUmIZOHv8+HGcPn066AVVu2nTpkGj0Vhu3bp1w0033YTvvvvOaX6TSbZMKK0JUVEy7Y03nsRddw0FIIMAIWR3T7C0tFiv+7vfPYKf/3wYhg834LrrhrrMp5RPCKC5Wd4rLTopKTLvyZP21zl5UqYrM4Rc5SPq7HytO1x58sknMXTo0NAU0sa3336LSZMmITs7G7GxsRgwYABeeeWVkF+XIo9fHQOzZs3CsWPH0NzcjH//+9/Iz8+3PPf5559j1apVLo9dtWpVu6wiGwwXLwJvvAFcfTXQt6+8f+MNme6Pm266CadPn8bp06dRWlqKqKgojBs3zmlenU52m7S2ysetrTINkAEAIBdL02jkWJRg0evtr/vTn96HwsKJbcagOOZrbZWPDQZ5r6xzdf68zNuzp/3xPXvKdKVlxlU+IlUKcuXhS93R0bZv3460tDS8++672Lt3LxYsWID58+dj6dKlHV00UhuhArW1tQKAqK2t9Zi3qalJ7Nu3TzQ1NQV0zbIyIbKyhNBo5A2w/pyVJZ/3xdSpU8X48ePt0r744gsBQFRXV1vS5s6dK/Ly8kRsbKzo3TtXzJz5uCgrM4ojR4T44x9XCgB2t+eeWylMJiHOnz8vHnzwQZGWliYMBoO48sorxd/+9jchhBArV64USUlJoqSkRPTv31906dJFFBYWilOnTrUpp9ksRHm5EN9+K8SuXfL+0UeLxZAhQzzmKy8XwmQS4vDhJrFlyz4xYkST6N1biAceEKKlxf46LS0yvXdv+X66ykfhwZfPYLjwtczBqjuCXXn4U3fk5uaKxx9/XBiNRiGErAMc646VK1cKIYJXd7jzi1/8Qlx//fVu8wTt/aewEkjdweGITly8CNx4I1BVZW2tAKw/V1XJ5w8csK6y6vs1LuLdd99Fv3797BaUS0hIwKpVq5CVlYXvvtuNBx54AOnpCfj1r+fi/vsnoqJiDzZuLMG7736K6Gigb98kAGbcfPPNqK+vx7vvvou+ffti3759dmsJNDY2YvHixXjnnXeg1Wpxzz33YM6cOXjvvffsyqXRyAGxtrNzkpLalt9ZPmUWT1YWcOECcP/9rmfxREXJAbGcxUMRpR0qD2/qjt27Zd2RkJCAuXPnYuLEidizZw9KSkrw6aefAgCSkpJgNgev7nCntrYWXYO5WBN1DiEImIKuvVtQli+3/uPj6qbRCPHGG96fc+rUqUKn04kuXbqILl26CAAiMzNTbN++3e1xL730khg2bJjlcXFx29aMzZs3C61WKw4cOOD0HMp/T4cPH7akLVu2TKSnp3tVdmfXdIf/CUUetqB4KQSVh5rrDiGE+Oqrr0RUVJTYvHmz23ysNyJTIHUHN5twYvXq4OZTXH/99di1axd27dqFbdu2obCwEDfffDOOHTtmybN27VqMHj0aGRkZiI+Px+OPP47jx4+7Pe+uXbvQs2dPXHbZZS7zxMXF2a05k5mZadn7goiCJESVh1rrjj179mD8+PEoLi7G2LFjvTqGSMEAxQnH1llnhAAqK307b5cuXdCvXz/069cPI0aMwJ/+9Cc0NDRgxYoVAICtW7di8uTJuOWWW7Bhwwbs3LkTCxYs8Lj1u7KPhTt6vd7usUajgfD0IonINyGqPNRYd+zbtw833ngjHnzwQTz++OMe8xM5Yo+/E+npQHm5+3pGowGcLJ7rE41GA61Wi6amJgDA119/jd69e2PBggWWPLb/IQFysTxlzxDF4MGDcfLkSRw8eNDtf0JEFGLtVHmEe92xd+9e3HDDDZg6dSqeffbZoJ2XOhcGKE5MnQr861/e5fNFc3MzKn/4z+n8+fNYunQpLl68aNkKIC8vD8ePH8eaNWswYsQIbNy4ER9++KHdOXJyclBeXm5pmk1ISMCYMWNw3XXX4Y477sDLL7+Mfv36Yf/+/dBoNLjpppt8K6SNw4cP4+LFi6isrERTU5Nlw8crrriCi+wROROiykNNdceePXtwww03oLCwEEVFRZZy63Q6pKam+nVO6qSCPiImBNp7kGx9vZwNqNM5H+Om08nn6+u9P+fUqVPtpvglJCSIESNGiHXr1tnl+81vfiO6desm4uPjxcSJE8Uf/vAHkZSUZHn+0qVL4o477hDJycl2UwXPnTsnpk+fLrp16yZiYmLEwIEDxYYNG4QQ1qmCtj788EPh6dc/ZsyYNlMTAYjy8nK3x3GwW+ThIFkvhaDyUFvdUVxc7LTe6N27t9vXyXojMgVSd2iECP+BCHV1dUhKSkJtbS0SExPd5r106RLKy8uRm5uLmJgYv6+5f7+cDagsiqvsNwMAmZlAaSnQv7/fp49owfodUPjw5TMYLnwtc9D+bll5+IX1RmQKpO5gF48L/fvLpQrefx9YtUqOfcvIkC2zd9/t//onRBThWHkQBQUDFDfi44EHH5Q3IiKvsfIgChinGRMREVHYYYBCREREYYcBChEREYUdBihEREQUdiI2QFHB7OmIxfee1Ix/vx2D7zs5irgARdk3orGxsYNL0nkp773jHh5E4Uyn0wGAx/1rKDRYb5CjiJtmrNPpkJycbNltMy4uDhplkSQKKSEEGhsbUV1djeTkZEuFT6QGUVFRiIuLw5kzZ6DX66HVRtz/b2GJ9Qa5EnEBCgBk/LARl7dbglNwJScnW34HRGqh0WiQmZmJ8vLyNhvtUeix3iBHERmgKBVNWloaWlpaOro4nYper+d/QKRa0dHRyMvLYzdPO2O9Qc5EZICi0Ol0/KMnIp9otVruBUMUBtjJSkRERGGHAQoRERGFHQYoREREFHYYoBAREVHYYYBCREREYYcBigqVlQGPPCLviYiIIhEDFJUpKwMefhhYs0beM0ghIqJIxABFRZTg5NAhICdH3jNIISKiSMQARSUcg5O4OAYpREQUuRigqIBjcBIdLdOjoxmkEBFRZPIrQFm2bBlycnIQExOD/Px8bNu2zWXeFStW4Nprr0VKSgpSUlJQUFDgNj/ZcxWcKBikEBFRJPI5QFm7di2KiopQXFyMHTt2YMiQISgsLHS5c/Dnn3+OSZMm4bPPPsPWrVuRnZ2NsWPH4vvvvw+48JHOU3CiYJBCRESRRiOEEL4ckJ+fjxEjRmDp0qUAALPZjOzsbMyePRvz5s3zeLzJZEJKSgqWLl2KKVOmeHXNuro6JCUloba2FomJib4UV9UeeUTO1lHGnHjS2AhUVAB33QX88Y+hLh11Jmr8DKqxzESRJpDPoU8tKEajEdu3b0dBQYH1BFotCgoKsHXrVq/O0djYiJaWFnTt2tVlnubmZtTV1dndOqMZM4ABA4CTJwFPu78bjTLfgAHyOKLOhvUGUWTxKUA5e/YsTCYT0tPT7dLT09NRWVnp1Tkee+wxZGVl2QU5jhYtWoSkpCTLLTs725diRowBA4Dly4G8PNky4ipIMRqBo0eBpCTguefkcUSdDesNosjSrrN4nn/+eaxZswYffvghYmJiXOabP38+amtrLbcTJ060YynDi6cgRQlODAYgLQ3YsgU4c6ZDikrUoVhvEEUWnwKU7t27Q6fToaqqyi69qqoKGRkZbo9dvHgxnn/+eWzZsgWDBw92m9dgMCAxMdHu1pm5ClJsg5O8PCA/H9i9G1i6lEEKdT6sN4gii08BSnR0NIYNG4bS0lJLmtlsRmlpKUaNGuXyuBdffBHPPPMMSkpKMHz4cP9L24k5BimNjW2Dk7g4mY9BChERqZ3PXTxFRUVYsWIFVq9ejbKyMsyYMQMNDQ2YPn06AGDKlCmYP3++Jf8LL7yAJ554Am+//TZycnJQWVmJyspKXLx4MXivopOwDVIcgxO9XubR6xmkEBGR+vkcoEycOBGLFy/GwoULMXToUOzatQslJSWWgbPHjx/H6dOnLflff/11GI1G3HnnncjMzLTcFi9eHLxX0YkMGCAHwvbp0zY4UTBIISIitfN5HZSOwPUMrM6ckUHH7t0yCHEMTmy1tMhF2wYNAmbNAlJT26+cFFnU+BlUY5mJIk27rYNCHa+0FPjmG6BfP/fBCSCf79dP5rcZNkRERBT2GKCozI03AsOHA4cPyxYSd1paZL7hw+VxREREasEARWVSU4GxY+Wqsf/+tzVIOXgQeO01eQ/41r3z3ntAr17y3ldlZXJJfu7/Q0REwRTV0QUg35SVAb/9rZzF06WLTEtJAT7+WK6L8pe/ALffDphM3gcn990nj73vPpk2ebL3ZVE2J/z2WznDiKvYEhFRMLAFRUVsdzfu0wdobpaBwYcfygAjKkrer18vpyD7EpzodNYgxZuWFMedlrmTMhERBRMDFJVwDAji4mTLydmzsrVEowG0WnlrbQU2bpRdQK7YBidRUdabN0GKs7IwSCEiomBigKICjgFBdLQMTJTxJgAghAxMoqJkwHDxouyq2bCh7fkcgxOdTqbrdJ6DFGdlAeQ9gxQiIgoWBihhzlVwUlYGmM3WlhNABil6vbzFxQH19W2DFFfBicJdkOIqOFEwSCEiomDhINkw5ktwotXKtKYmGZwoLSlKkPLee0BtrfvgRKGk2w6cveoq98GJwjFI4cBZIiLyBwOUMPb66zIYsQ0Ijh6VgQhgDU4Aa7BiNsvBs0qQEhsrg5QFC4Dz560DYl0FJwqdTrbIGI3A/PnAhAlty+JKdDTQs6fM//rrwB//6OcbQEREnRa7eMLYjBmy9eHkSRkoAHL2jhKYKIEKIIMJs1k+ZzDItNZW2aKSkAA8+yywaJEMHkwmeXNHyRMdLY9zVhZXjEaZb8AAeRwREZGvGKAEmbOFy86cAdas8bxpn2M+292LKyrkF3/37sBll8kWEyUoUe4BICZGtn60tgKNjTI4ee89YNw42dXz9tsy6GhtdR2kmEzy+ehomX/yZOdlAeR9dbX944oKmY/dO0RE5C8GKEGkjBlZs8Y6SFTZ3O+dd9zvLOwqn2Ng0NAgA4+4OPm8bXACAJcuySDBMThReApSnAUnCmdl+f57oKpK3jc0MDghIqLgYIASJM4WLrvvPqC4WO48fOWV8t5ZkGK7Q7GzfEpg0Ls3sH+/HFOSkmJdSVbhOFDWMThRuApS3AUnCmdlUQbj7t8v0xmcEBFRoBigBIGzhct69AD27AH+/GfZLRMXJ7+0HYMP2+BkwADX+bp3B370Izm+xGiUwYQyk0dh25LSuzfQt6/rMjsGKcrNXXCicFYWo1E+/tGP5PNERESBYIASIGdTgZVxGXq97HLZvFkGGnq9ffBRVmYfnOj18pyu8lVWAv/930C3bnJGjskkx5zYtqRotUD//vJ5T2uR2AYpyoBYT8GJElDZlqW2Vt7/93/LdHddWURERN7QCCFERxfCk7q6OiQlJaG2thaJiYkdXRwLV8GJMh4jLk62atTWAl27yu6W1FS50/CuXXK11/h4YOhQa3Biy1W+gwfl5oBCyK4erVYGJE1NcvxHerpvg1Xfe09OJV60yLvgxDagOnMG+OYbYPhw62vzdhdlUo9w/Qy6o8YyE0WaQD6HbEHxkzfBiVYr1yJJSgJqauSKrmfOyHy1tfLYujrX03aNRvn8oUMyv9Eoj//qK9m1k5Iiz6/Vyp+Tk+XgWKPRt1VdJ08Gjh/3PTgBZABy883WQMSx9YctKURE5A8GKH5SFlHr2dO6cNmFC7K1IzbWfhG1qCg5o+bsWdnaUF4uZ7707Cnvy8udX8NZvm++kedJSJDnVWi18roXL8pyAG0XTAtEaam8dr9+zlt7bOn1Mt8338jjiIiIfMUAxU8zZshum2++ka0mgGzBiI+XXS22A1YvXABOn5YBw/DhQG6uHDuya5ccWJqbK/MdPAi89pp1E8DcXHm+PXtkQJKbK4/XauX5zp61XqO+Xi6OptHIcgAyqNm+XbZuKAumOVunZcMGYMgQ+z17vvoKuOkmeQ8AN94or334sOzGcaelBdixQ7aeZGd7/54SEREpuNS9n3bsAI4ckeNADh+WaT16yJttN09dneyeAWSgUlEhA5vDh+WsmcOH5cBSkwn4y19k98xf/gLccYcMTioq5Bd+RYU8z/79spUEkNcAZJBTUyN/PndOjkcBZF4AOHZMlhWwdvd8+60cm3LkiOzasd2zJyUFuPtuWa6yMuD994HRo+WYEmfdPLZaWoB//1t2LTU0AL/9LacdExGR7zhI1g+2OwIra48AslujRw/rWJTqajmLx1FUlAxskpNl0KLVysetrfK51lb55a8sWZ+TIwOU1lbn53MnJsa6N09OjgxkevaUrS1du8rzNjbK7qGmJnmvrGuilC893RqkuBqLAtgHJ83NQK9e8jpcuE39wu0z6A01lpko0nCQbDuyDU6iouQXtDLe5PBhGZhER8uAwzaYsF2vpLVVBgLx8bLrpqVFpmm11o38WlpkS0l6upzC26WL5+DE9hqALJ/BIIOUhgZg714gMVEGIImJ8nFDg3xeCYgaG2XXUZcuMr1bN9lVdPfdsrsnNVW2pAwaJFtXlO4ex+CkTx9rUOTNQF0iIiJbDFB84BicKDsCOwYpu3cDJ07YH+vYTnXxogwElAGtgGyJcVx+vrxcBhJVVZ7L53gNpcWludmaduiQPOehQ9a05mb5mmwDoJoaGbzo9Z6DlMbGtsGJMnDYl9lERKr21VfAVVfJFRJtB3QRkV8YoHjJVXCisA1SlPEggP1sHkfKGBJbSnCi1coWEbPZfjCsr5qbrbscK+c7fty6Cq3t8viOzp71LkhxFZwoGKRQxJsxA7jmGmDnTuDoUeC22xikEAWIAYoXPAUnrig7DvtDCP+PdXU+b9Ntu4o8BSljx8qxNq6CEwWDFIpYM2bIQVaObrtNDsS69VbghReAdetksyYReYUBihfmz5fBiTI+xBXbqcVAYEFGsIcuOyuLu/LZBinKrCC9Xg6crawEnnlGpq1dK2cO9erlOjhRBHNdFqKw4Co4UZw4AWzaBMybJ+f3/+IXDFKIvMQAxQuLFln3q7EdH+LIsTtHo2k7cNVb/h7n7nyO53RXPtvAJSVF3re0yDEzGRnAE0/ItBkz5Oyckyddr4irMBplvgEDrOuyEKmWp+DE0enTcg2Bv/41dGUiiiAMULwwebJsMdBq2w5iteUYoAhhHfvhq0CCG1fn8zbdNjjp3l3O6GlpkS0ltlOOARlsLF8upxJXVLhftt/bvYGIwp6vwYmipgZ45522za1E1AYDFC+UlQEbN8pps4DzIMVkkunR0cDUqdZgxWRyHaTY7kLsyGwObjePcj6tVnbHKGuvKANoY2PbHuMpOFF4ClIYnFBE8Tc4UWzYAHzxRfDKQxShGKB4YLsp4IABcuM/wD5IsQ1O3n4bWLVKLmbmGKTYSkyUAUDXrvbp7mb9eGIwtA2EoqPt0/Ly5JL5eXn2x0VHy3VPFF27ehecKFwFKQxOKKK8+GJgwYninnsCPwdRhPPr63DZsmXIyclBTEwM8vPzsW3bNrf5P/jgA/Tv3x8xMTEYNGgQNm3a5Fdh25vjjsVxccAVV9gHKcpNCU6UHYFnzGgbpADWvXKam+W6Ixcv2g+89afVRAlAWlutxytpSsuJTicDogsX5LoldXXAlVdaF4BrabGuONu9u5y5c+mSd8GJwjFIaWxkcEIR5umng3Oe6urgnIcogvkcoKxduxZFRUUoLi7Gjh07MGTIEBQWFqLaxQfu66+/xqRJk3D//fdj586dmDBhAiZMmIA9e/YEXPhQcgxObBcesw1STKa2wYnCMUjRaoFly2QLb3q6/PIHZMBy+eXWbhdXnM0geuIJ2aWtDOLVauVaUXfcIdOU4OmnP5UbAhoMcpmGvDzggw+ANWvkarZNTfJ+7Vpg/XpZvvPnvQ9OFI5BCoMTiigLFwbnPOG/wwhRxxM+GjlypJg5c6blsclkEllZWWLRokVO8//85z8Xt956q11afn6+eOihh7y+Zm1trQAgamtrfS2uX/btE+K664TIzBRi1Cghxoxpexs1SoikJCH0eiFeeMH9+V57TYiuXeW94t13hUhOFqJbN+s1evRQJv62vUVFCWEwyHslbfx4+2skJAhx1VVC/Pa3QhQXCzFpkhCpqfK+uFim33ijECNGCPHll9Zj//Y3IQYPlveKL78UorDQPp+v7+Hs2fKe1K+9P4PBELIyv/CC6w+qt7fevYNbJqIwFcjn0KfdjI1GI7Zv34758+db0rRaLQoKCrB161anx2zduhVFRUV2aYWFhVi/fr3L6zQ3N6PZZn32uro6X4oZEFctJ46UlpSKCjmA9rbbXLcSzJhhP622rAx48005MFW5RlWV3MdHoXTRKP9otbbKNKUVpbUV+Pvf5SJyY8fKtUkKCuw38LvsMnlT6PVAfr68/pYt8rnUVGDcOHmzNXo0UFLixRvmwoABwB//6P/xRL5qt3pj7lx5/9hj/h2v1QKrVwevPEQRyqcunrNnz8JkMiE9Pd0uPT09HZWVlU6Pqays9Ck/ACxatAhJSUmWW3Z2ti/FDMjrr8sv8J49Q7fwmLNrHDlifd52UKvtz8o4FmXBOKNRLiJXWgp8843cTdl2d2Fn9HqZ75tv5HFEkaJd6425c+XqsL5KSgL+8Q9gzJjgl4kowoTlLJ758+ejtrbWcjvhuPNeCLXHwmPOrtG3r/V52+5p25+V1hNlwbjoaLmI3I03AsOHy40Kld2FXWlpkfmGD5fHEUWKdq83fA1SMjJkcyuDEyKv+BSgdO/eHTqdDlUOW+tWVVUhIyPD6TEZGRk+5QcAg8GAxMREu1t7aY+Fx5xdIz0d6N/fmsdxGXplM0LHKc2TJ7fdXdhVkNLSIp8fNEjmT031vsxE4a5D6g1vg5SMDLkXj7ejzYnItwAlOjoaw4YNQ6lN34DZbEZpaSlGjRrl9JhRo0bZ5QeATz75xGX+cNAeC495E6Qo3AUnCk9BCoMTohDxFKQwOCHyi89dPEVFRVixYgVWr16NsrIyzJgxAw0NDZg+fToAYMqUKXaDaB999FGUlJTg97//Pfbv348nn3wS33zzDWbNmhW8VxEC7bHwmKsgxba7R6fzHJwoXAUpDE6IQmzuXNnk+fDD9ukMToj85nOAMnHiRCxevBgLFy7E0KFDsWvXLpSUlFgGwh4/fhynT5+25L/66qvx/vvv480338SQIUOwbt06rF+/HgMHDgzeqwiR9lh4zNk1Ghvluih6vTUw8RScKByDlMZGBidE7eb112Wg8uWXQGEhgxOiAGiECP8Vg+rq6pCUlITa2tp2HY+iUKYel5VZA4pgLzzm7Bo7dgD33SdbVrwJTmydOSMXifvmGzkglsEJBaKjP4P+UGOZiSJNIJ9Dn9ZB6ayUgOH1160zcNrjGsp15s+Xs3W8DU4Aa0tKaamcrcPghIiI1IQtKETkkRo/g2osM1GkCeRzGJbroBAREVHnpoouHqWRpz2XvCciK+Wzp4IGVwvWG0QdL5C6QxUBSn19PQC065L3RNRWfX09kpStvMMc6w2i8OFP3aGKMShmsxmnTp1CQkICNLab07Sjuro6ZGdn48SJE6rpz1ZjmQF1lluNZQa8L7cQAvX19cjKyoJWq46eYdYb/lNjudVYZkCd5falzIHUHapoQdFqtejZs2dHFwMA2n3p/WBQY5kBdZZbjWUGvCu3WlpOFKw3AqfGcquxzIA6y+1tmf2tO9TxrxARERF1KgxQiIiIKOwwQPGSwWBAcXExDAZDRxfFa2osM6DOcquxzIB6y60Wan1/1VhuNZYZUGe526vMqhgkS0RERJ0LW1CIiIgo7DBAISIiorDDAIWIiIjCDgMUIiIiCjsMUIiIiCjsMEAhIiKisMMAhYiIiMIOAxQiIiIKOwxQiIiIKOwwQCEiIqKwwwCFiIiIwg4DFCIiIgo7DFCIiIgo7DBAISIiorDDAIWIiIjCDgMUIiIiCjsMUIiIiCjsMEAhIiKisMMAhYiIiMIOAxQiIiIKOwxQiIiIKOwwQCEiIqKwwwCFiIiIwg4DFCIiIgo7DFCIiIgo7ER1dAG8YTabcerUKSQkJECj0XR0cYg6HSEE6uvrkZWVBa1WHf/XsN4g6niB1B2qCFBOnTqF7Ozsji4GUad34sQJ9OzZs6OL4RXWG0Thw5+6QxUBSkJCAgD5AhMTEzu4NESdT11dHbKzsy2fRTVgvUHU8QKpO1QRoCjNs4mJiaxoiDqQmrpKWG8QhQ9/6g51dCYTERFRp8IAhYiIiMIOAxQiIiIKOwxQiIiIKOwwQCEiIqKwo4pZPBQCra3A+vXAyZNAz57AhAlAFP8ciIgoPPAbqTNqbQVmzAA++QRoaQH0emDLFuC11xikEBFRWGAXT2e0fr0MTpKSgLw8eb9li0wnIiIKA/x3uTM6eVK2nKSkyMcpKcDZszI9GNh9REREAeK3RmfUs6fs1jl/XgYn58/Lx8HYY4XdR0REFATs4umMJkwAxo4FamuBQ4fk/dixMj1Q7D4iIqIg4L+0nVFUlGzRCEU3TKi7j4iIqFNggKJmgYz1iIoC7rwz+GXy1H3E8SlEROQFfjOoVbiO9ZgwQZZjyxbZcqLXW7uPwrXMREQUdvitoFa2Yz2UlgplrEcoWka85a77aN268CwzERGFHQYoahXOYz1cdR+Fc5mJiCisMEBRq1BPFQ7FOBFvyswxKkREBAYo6uVurEcgQjlOxFOZOUaFiIh+wFpfrUI1VTiUY1s8lTlcx9UQEVG7Y4CiZqGYKqyME9HrgQsX5H1Li/04kUC6YbRa4LLLgO7dga5d5WPHa7e2yp8NBvtrm83Anj1ATY08duBA++OJiChiMEAhe1lZQHMzcPiwNTiJipLpQGDdMGYz8M47Mn9zswxACguBe+6RgUZmJlBXB5w5A2g0gBAyT2am52OJiCiisGYne/36yS4Ws1kGAmazfNyvn3w+kKXs9+yRebt1k60f3boBmzfLdEAGJELYH6OkeTqWiIgiCltQyF5dHTBkiGwNqasDEhNlq0ldnXw+kKnCNTUy6OnaVT7u2hU4dUqmA0BlpbxecjJgNALR0bKbqbISyMhwfywREUUUBihkr2tXICZG/pyRIQOFqChrYKBMFT51CoiLAxobvZ8q3LWr7JpRxpDU1MjHtueOjpbnS0uTg2Sjo2W6p2OJiCii+NXFs2zZMuTk5CAmJgb5+fnYtm2b2/wXLlzAzJkzkZmZCYPBgMsuuwybNm3yq8AUYldcAcTHA19/Lbtyvv5aPr7iCvn87bcDubnA998DBw7I+9xcmQ5Yx6jMmQO89JK8/8UvZPrAgXLcyLlzsmvm3Dn5eOBAeay7XZY9HUtERBHF5xaUtWvXoqioCMuXL0d+fj6WLFmCwsJCHDhwAGlpaW3yG41G/OQnP0FaWhrWrVuHHj164NixY0hOTg5G+SnY9u0DLl4Err5atl4YjfLxvn3A4MHA/v2yZeW66+TYEI1Gdsns3y+f9zRV+J57gKFDnc/E8TQN2d2xREQUUXwOUF5++WU88MADmD59OgBg+fLl2LhxI95++23MmzevTf63334bNTU1+Prrr6HX6wEAOTk5gZVaTdQ2NbamBrh0SQYFNTXWMSjKWI+aGhm05OQATU1AbCxQXW19/uRJ+fy5c7J1JSZGvgfKGBWtVgYy/vB0rNreayIicsmnAMVoNGL79u2YP3++JU2r1aKgoABbt251eszHH3+MUaNGYebMmfjoo4+QmpqKu+++G4899hh0Op3TY5qbm9Hc3Gx5XKcM0FQbNU6NTUwEvv1WTvVVpKbKdEC2lpw6JQMBnQ4wmWQwoLSIpabKY1tbrcdHRcl0T0I5hZkiXsTUG0QEwMcxKGfPnoXJZEJ6erpdenp6OiorK50ec/ToUaxbtw4mkwmbNm3CE088gd///vf43e9+5/I6ixYtQlJSkuWWnZ3tSzHDhxqnxh4+LMd+aLXyS16rlY8PH7bPp0wHdpwW/M031uBEo5H3ra0y3ZNQTmGmiBcx9QYRAWiHdVDMZjPS0tLw5ptvYtiwYZg4cSIWLFiA5cuXuzxm/vz5qK2ttdxOnDgR6mKGhrNptc3N4T019tQpGZj06wf06CHvDQaZDshpv1lZwI03AiNHyvusLJkOABUVMjCJjZXHxcbKxxUVnq/tbAqz4yq2rqjxvaagiph6g4gA+NjF0717d+h0OlRVVdmlV1VVISMjw+kxmZmZ0Ov1dt05AwYMQGVlJYxGI6Kjo9scYzAYYDAYfClaePI0NTaUO/f6Ox5DmUasBAqOOw4r05D1eiA9XZ4/Jsb6mvr0kdcxmazn0WpluqfXHMgOzZyG3OlFTL1BRAB8DFCio6MxbNgwlJaWYsIPO9CazWaUlpZi1qxZTo8ZPXo03n//fZjNZmh/+II8ePAgMjMznQYnEUWZGrt5s7VlQpkaG8qdewMZj+Fpx2F3rwkAnnkGeP99oKpKDpbVaOSsn2ee8fyaA9mh2VO5iIhIVXz+JiwqKsLUqVMxfPhwjBw5EkuWLEFDQ4NlVs+UKVPQo0cPLFq0CAAwY8YMLF26FI8++ihmz56NQ4cO4bnnnsMjjzwS3FcSjrRa11Nj//rX0O3cazseQ2lN2LxZlsPTDBpPU33dvSZAjlUZM0aukaLM8rn8cpl+8KD71xzIDs2eykVERKric4AyceJEnDlzBgsXLkRlZSWGDh2KkpISy8DZ48ePW1pKACA7OxubN2/Gr371KwwePBg9evTAo48+isceeyx4ryKcuZoaG8iS8Z54WlLeE0+7JBuNwOrVwNGjsuvm2Wetq8/W1MiWkvHjrfmVriZvXnMgOzQHMoWZiIjCil99CbNmzXLZpfP555+3SRs1ahT+9a9/+XOpyBXIeAtPQjke49Il2Upx+LB1obZNm4CdO61jUVxdO5SvmYiIIgrbvzuKu2XdAxXKZeEXLJDBiU4HJCTI+0OHZLqna4fyNRMRUUThZoEdJZDxFp6EcjzG0aOy5SQ2Vj6OjQXq62W6p2trtaF7zUREFFH4zdCRAhlv4Ymn8Rj+TnHu00d26zQ1WacRazTWacTKuT/5BCgvlxsJ9u8v9/UBQvuaiYgoYjBA6YwCmeLsbhoxINPGjgX+8x853VmrBTZskLOIIn1aORERBQ3HoHRGgSwpr0wjHjJETh8eMkTubKwshf/qqzI4iYmRC7nFxADbtsl0IiIiL7EFpTMKZIqzu2nEgOzWMZvlAFpA3jc2ynQiIiIvMUDpjJTpvqdOAXFxMoCwne7rbnyKpynMubmyW+fCBdl6cumSfJyb2wEvlIiI1IoBSmd0++3AsmWy60UZJzJypEz3ND7F05LyM2cCf/qTnEZcXy/HqOTlyXQiIiIvMUDpjPbvlwNbr7vOuthacrJM97QcvacpzAcPynEp3brJAbPR0bIV5uBBrvJKREReY4ASau66S/zdcdibc7t7rqZGto7k51vP5bgcvV4vu2mUqcS241PcTWFWxqgUFLQ9NxERkZcYoISSu+4Srdb/HYc9nRtw303jbhxJVpYsz+HD1uAkKkqmeyOUy+wTEVGnwQAllGyn8zp2l1x2mf87Dns6N+C+m8bdOJLWVnncmTMyUAHk4379vHvNnsaoEBEReYEBSii5m87bvXtgOw57mirs7jl340jq6uQYkqgo+XNiogxa6uq8K1col9knIqJOgwFKKLnbvTfQrpCePWUQUV5u3xWjTBX2tGuw0QisXi330OnTB3j2WetuxLGxsmXniitkuc6d862LxtMy+0RERB4wQAmlCRNk18qWLbIFQ6+37t6r1QbWFTJuHPD443KsiDITJy9PpkdFub4uINcmGTrU/thNm4CdO9lFQ0REYYEBSih52rE4kK6QDRtkoNGjh7UFpalJpt95p/vrLlgggxOdTraWNDXJdUsWLAB+/3t20RARUYdjgBJq7nbv9dQV4m4asjIGJS/Pmv/QIes4E3fXPXpUtpzExsrHsbFyUbWjR70rFxERUYgxQAlXZrP7acjuxrd40qeP7NZparK2oGg0Mp2IiCgMsN0+XO3ZY52GPHCgvN+8WaYDsstm7Figtla2nNTW2o8zcefZZ2XLi8kkW05MJvn42WdD+YqIiIi8xhaUcFVT434asqfxLe7ExMgBsQsWtJ3FQ0REFAYYoISrrl1ll82//22/X47tdF9340w8iYmRA2KJiIjCEAOUcNW/P3D6NPCf/9jvONy/f0eXjIiIKOQ4BiVcffwxUFEhpxFffrm8Ly+X6URERBGOAUq4UqYRZ2XJrp2srLa7ChMREUUodvGEq0CmEYeau/VZiIiIgoABSrhyt0x+R/K0PgsREVEQMEAJV4FMIw4l2/VZlE0ON2+WS+Nz9VkiIgoSBijeaG3tmEAhkGnEoeqG8bQ+CxERURAwQPGktRWYMQP45BM5SFWvly0Ir73W8a0ZroSyG6ZrV3k+JfCpqZGPbddnISIiChAHDXiyfr0MTpKS5HLwSUnyi3/9+o4umWuelskPxMCBMtg5d06e79w5+XjgwMDPTURE9IMwbQIII8p035QU+TglRQ5aDefpvqHshtFqZUvM0KGcxUNERCHjV4CybNkyvPTSS6isrMSQIUPw6quvYuTIkR6PW7NmDSZNmoTx48djfTu0QJhMJrS0tAR2ktxcICdHdmMkJclN+XJyZPqlS8EoZvClpAAZGbJ7KjkZuHBBPk5JCV6ZL7vM+rPRaPkxOjoaWgYrpGJmsxlGm79pCj29Xg+dTtfRxaAw43OAsnbtWhQVFWH58uXIz8/HkiVLUFhYiAMHDiAtLc3lcRUVFZgzZw6uvfbagArsDSEEKisrceHChcBPlpcHvPAC0NRkTYuNlS0H5eWBnz8U9Hpg6lQZjCj7+MTEyPQQl1mr1SI3NxfR0dEhvQ5RKBiNRpSXl8NsNnd0UTqd5ORkZGRkQKPRdHRRKEz4HKC8/PLLeOCBBzB9+nQAwPLly7Fx40a8/fbbmDdvntNjTCYTJk+ejKeeegpffPFFcAIHN5TgJC0tDXFxcYH/wefmypaT1lY5MDYpSX7phzMhZICi7OMTExPyMpvNZpw6dQqnT59Gr169WNGQqgghcPr0aeh0OmRnZ7MlsJ0IIdDY2Ijq6moAQGZmZgeXiMKFTwGK0WjE9u3bMX/+fEuaVqtFQUEBtm7d6vK4p59+Gmlpabj//vvxxRdfeLxOc3MzmpubLY/r6uq8LqPJZLIEJ926dfP6OI9iY4N3LoUQcoVYZXZQSop9ECGEbLkxmQCdTpbBly/9UJTZg9TUVJw6dQqtra3Q6/Xtfn3qvAKpNwCgtbUVjY2NyMrKQlxcXLCLR27E/lBXVVdXIy0tjd09BMDHWTxnz56FyWRCenq6XXp6ejoqKyudHvPll1/irbfewooVK7y+zqJFi5CUlGS5ZWdne32sMuYk7CsYIYBjx+Rg28pKeX/smExXnj93Tj5XXS3vz52zPh+mlK4dk8nUwSWhziaQegOw/s2ye7JjKHV2wOMGKWKEtA2zvr4e9957L1asWIHu3bt7fdz8+fNRW1truZ04ccLna4d998L580BdnWwZiYmR93V1Mh2QLSd1dbJLKTZW3tfV2Y+FCUNh/75TxApGvQHwb7ij8H0nRz518XTv3h06nQ5VVVV26VVVVcjIyGiT/8iRI6ioqMBtt91mSVMGn0VFReHAgQPo27dvm+MMBgMMBoMvRVOflhbZGqIs9hYVJce4KP89mExtn29pkelE1EanqDeIOhGfWlCio6MxbNgwlJaWWtLMZjNKS0sxatSoNvn79++P3bt3Y9euXZbb7bffjuuvvx67du3yuQk2ouj1cjxJa6t83NoqHyvjNnQ658+zb5aIiDoBn2fxFBUVYerUqRg+fDhGjhyJJUuWoKGhwTKrZ8qUKejRowcWLVqEmJgYDHRYYTQ5ORkA2qR3Oikpssumrs4afCQmWheEi42Vj+vqZMuJ8nwHDHwlIiJqbz4HKBMnTsSZM2ewcOFCVFZWYujQoSgpKbEMnD1+/Din53lDowF693Y9i0ejkUvUx8X5P4vnB6tWrcIvf/nLkE/vJqLIwrqDOpJfkcSsWbNw7NgxNDc349///jfy8/Mtz33++edYtWqVy2NXrVrVLqvIhptp06ZBo9FYbt26dcNNN9+M706eBNLT5cJvjsGHRiMDlIQEea/R4Mknn8TQoUNDXt5vv/0WkyZNQnZ2NmJjYzFgwAC88sorIb8uEdlzWnfcdBO+++47n87TXnUHADzyyCMYNmwYDAZDu12TIg+bOty5eBF44w3g6quBvn3l/RtvyHQ/3HTTTTh9+jROnz6N0tJSREVFYdy4cUEudHBs374daWlpePfdd7F3714sWLAA8+fPx9KlSzu6aERhL8hVh6rqDsV9992HiRMndnQxSM2ECtTW1goAora21mPepqYmsW/fPtHU1BTYRcvKhMjKEkKjkTfA+nNWlnzeB1OnThXjx4+3S/viiy8EAFFdXW1Jmzt3rsjLyxOxsbEiNzdXPP7448JoNAohhFi5cqUAYHdbuXKlEEKI8+fPiwcffFCkpaUJg8EgrrzySvG3v/3NclxSUpIoKSkR/fv3F126dBGFhYXi1KlTPr2GX/ziF+L66693mydo7z+FFV8+g+HC1zIH6283yFWHquuO4uJiMWTIEK/ysu6ITIHUHdzN2JmLF4EbbwSqquwXRlN+rqqSzx84AMTH+3mJi3j33XfRr18/uxVvExISsGrVKmRlZWH37t144IEHkJCQgLlz52LixInYs2cPSkpK8OmnnwIAkpKSYDabcfPNN6O+vh7vvvsu+vbti3379tmtxtjY2IjFixfjnXfegVarxT333IM5c+bgvffe87rMtbW16KrskExEbbRD1aHKuoPIHwxQnHnvPeD0adertppM8vn33wcefNDr027YsAHxP9RKDQ0NyMzMxIYNG+wGFT/++OOWn3NycjBnzhysWbMGc+fORWxsLOLj4xEVFSXXnflhqfwtH3+Mbdu2oWzfPlx2+eUAgD59+thdu6WlBcuXL7esOzNr1iw8/fTTXpf966+/xtq1a7Fx40avjyHqbEJUdQS/7vjBli1bZN1RVobLftihPNh1B5G/OAbFmdWrg5vvB8r6L7t27cK2bdtQWFiIm2++GceOHbPkWbt2LUaPHo2MjAzEx8fj8ccfx/Hjx9uezGap/F1bt6JnejouMxhc1oxxcXF2i+JlZmZaNufyZM+ePRg/fjyKi4sxduxYn14zUWcSoqojuHWHjV27dqFnz56W4MSZQOoOokAwQHHGsX3WGSHk/jg+6NKlC/r164d+/fphxIgR+NOf/oSGhgbLPkVbt27F5MmTccstt2DDhg3YuXMnFixYAKPR2PZkNkvlxyptxbZL5Ttw3LhPo9FAeLGvz759+3DjjTfiwQcftPsPjYjaClHVEdy6w0asF+sq+Vt3EAWKXTzOpKcD5eXuaxqNBnCyvL8vNBoNtFotmn7YX+frr79G7969sWDBAkse2/+QALmar8lkslsqf/Dll+NkVRUOVlTgMoeNHAOxd+9e3HDDDZg6dSqeffbZoJ2XKFK1U9URWN1hY/DgwTh58iQOHjzothWFqCMwQHFm6lTgX//yLp8PmpubLbs+nz9/HkuXLsXFixctexXl5eXh+PHjWLNmDUaMGIGNGzfiww8/tDtHTk4OysvLsWv/fvQEkJCYiDEjR+K6YcNwx69/jZeffx79rroK+/fvh0ajwU033eRTGRV79uzBDTfcgMLCQhQVFVnKrdPpkJqa6tc5iSJdiKqO4NYdP3TrJCQkYMyYMbjuuutwxx134OWXX0a/fv0CrjsA4PDhw7h48SIqKyvR1NSEXbt2AQCuuOIK7hZN3gv6nKIQaPdpxvX1cj6gTifnCDredDr5fH2916ecOnWq3RS/hIQEMWLECLFu3Tq7fL/5zW9Et27dRHx8vJg4caL4wx/+IJKSkizPX7p0Sdxxxx0iOTlZThV8+mkhdu0S5/75TzH9Zz8T3bp1EzExMWLgwIFiw4YNQgjrVEFbH374oXD36y8uLm4zLRGA6N27t9vXyamCkYnTjL0TgqojdHXHD9OMz507J6ZPnx60ukMIIcaMGeO0/igvL3d5DOuOyBRI3aERIvw7E+vq6pCUlITa2lokJia6zXvp0iWUl5cjNzcXMTEx/l90/345H/D0aflYCOtKr5mZQGkp0L+//+cPhh9m8ThdKr+DBO39p7Diy2cwXPha5mD97aqh6ghHrDsiUyB1B7t4XOnfXy5W8P77wKpVcvRbRoZsm737bv8XMQgmjUYukU9EYUMNVQeRGjBAcSc+Xi5W4MuCBUTU6bHqIAocpxkTERFR2GGAQkRERGGHAQoRERGFnYgNUFQwOSki8X0ntePfcMfg+06OIi5AUZZlbmxs7OCSdE7K0tq2u6ESqYHyN+tpeXgKDaXOdlxanzqviJvFo9PpkJycbNnMKi4uDpoOXhukszCbzThz5gzi4uIQFRVxf1oU4aKiohAXF4czZ85Ar9fb7RRMoSOEQGNjI6qrq5GcnMx/bsgiIr9FlO3EueNm+9NqtejVqxeDQlIdjUaDzMxMlJeXt9nHhkIvOTnZUncTAREaoCgVTVpaGlpaWjq6OJ1KdHQ0//Mk1YqOjkZeXh67edqZXq9nywm1EZEBikKn0/GPnoh8otVqudQ6URjgv7pEREQUdhigEBERUdhhgEJERERhhwEKERERhR0GKERERBR2GKAQERFR2GGAQkRERGGHAQoRERGFHQYoREREFHYYoBAREVHYYYBCREREYcevAGXZsmXIyclBTEwM8vPzsW3bNpd5V6xYgWuvvRYpKSlISUlBQUGB2/xEREREPgcoa9euRVFREYqLi7Fjxw4MGTIEhYWFqK6udpr/888/x6RJk/DZZ59h69atyM7OxtixY/H9998HXHgiIiKKTBohhPDlgPz8fIwYMQJLly4FAJjNZmRnZ2P27NmYN2+ex+NNJhNSUlKwdOlSTJkyxWme5uZmNDc3Wx7X1dUhOzsbtbW1SExM9KW4RBQEdXV1SEpKCuvPIOsNovATSN3hUwuK0WjE9u3bUVBQYD2BVouCggJs3brVq3M0NjaipaUFXbt2dZln0aJFSEpKstyys7N9KSYRdUKsN4gii08BytmzZ2EymZCenm6Xnp6ejsrKSq/O8dhjjyErK8suyHE0f/581NbWWm4nTpzwpZhE1Amx3iCKLFHtebHnn38ea9asweeff46YmBiX+QwGAwwGQzuWjIjUjvUGUWTxKUDp3r07dDodqqqq7NKrqqqQkZHh9tjFixfj+eefx6efforBgwf7XlIiIiLqNHzq4omOjsawYcNQWlpqSTObzSgtLcWoUaNcHvfiiy/imWeeQUlJCYYPH+5/aYk8KSsDHnlE3neG6xIRRSifu3iKioowdepUDB8+HCNHjsSSJUvQ0NCA6dOnAwCmTJmCHj16YNGiRQCAF154AQsXLsT777+PnJwcy1iV+Ph4xMfHB/GlUKdXVgY8/LC8//ZbYPlyYMCAyL0uEVEE83kdlIkTJ2Lx4sVYuHAhhg4dil27dqGkpMQycPb48eM4ffq0Jf/rr78Oo9GIO++8E5mZmZbb4sWLg/cqiJQg4dAhICdH3itBQyRel4gowvm8DkpHUMMaDNSBHIOE6GjAaAQqKoC8vNC1aHTUdTuAGj+DaiwzUaRpt3VQiMKOsyABkPehbNHoqOsSEXUSDFBIvVwFCYpQBQsddV0iok6EAQqpk6cgQRHsYKGjrktE1MkwQCF1OXMGWLMGePll+aXfs6d9kNDQIIOChgZrWnS0zFdWBrz+emDXf/1159c1GoHqannv7LovvyzLfeZMYNcnIuokGKCQepw5AyxdCrzzDqDXA337AidPWoOChgbg4EGZ7+BBa5BiNMp8AwYAM2YEVoYZM+R5bK9rNALffw9UVcl72/STJ2U59XpZ7qVLGaQQEXmBAQqpgxKc7N4NXHklUFkJ/OhHQO/ectbMhQsyKGlqki0XTU3y8YULwZ1VM2CAPE9enjxvQ4MMShoagLg4+8cVFbJ8P/qRLO+VV8ryM0ghIvKIAQqFhruVVT2tuur4vG1wMmCADAQGDLAGKampwL59MiiJirK/37cPyMqyBidKF1EgAYISpPTuDezfD9TXAwYDcOmSvK+vl+lZWdbgxLbcDFKIiDxigELBpwwkXbOm7QBRd885e/6rr+yDE71e5tPr5eODB+XYDwAwmWRQYjbLe5PJ/ty2XUSBBgjdu8vgw2AAmptlUHLxorxvbraW89gx5+VmkEJE5BYDFAoudyurelp11fH5AweAu++WQYrtl7ziwgWZ5/x5ID5eBia2zGagVy/g1CngvvuA4mJrF1EgAYIS6FRWAjffLFtrGhsBnc5636OHvG5dnf3AWYBBChGRFxigUPA4BhhxcdZA5N575c3Zcw8/DGzYYH9sVJS8VVXJIOTCBftrnTkjj7lwAUhIaPs8AGg0wIkTQGIisGcP8Oc/y5aPQLpabLubevUCjh8HunUDunSRLSexsYBWC5w+LYOUs2eBbdvsZxUBDFKIiDxggELB4W5l1bQ04Lvv5C09XbY8/POf8j4nRx47ebK8V469cEF203TtKn/esMH+S/ybb+SXv8EA1NQAjjs2aLUywGlpkWUSQrZubN0K/P3v8py+BgjvvQf07w989BGQmQns3Cm7l3r0ALKzZdCRnCyvbTbL5+LjZbBSXt72fHo90K+ffC02O4Q7fW9DtVMyd2EmojDFAIUC527xsoYG65ezEDJvebn8ubxctkBcuiTHbjQ1yYACkF/08fGyeyQxUQYhtkHK8OHy+XPn2nbtADJNGYNiNstyxMbK/Hv2WFtfvA1S3ntPdhPV1Mj8f/2rDLC6d5flP3FClr22VgZNGo18TeXlsoUlN7ftOVtagMOH5Wu58Ub3762rMTuBCOW5iYgCxACFAuMpOFGm/sbEyJaF5mb747//Xg4ujYuTzynrl0RHy5YJpevEMUhpamrbbeLIbLZvWblwQd6Skqzn8iZIUYITo1GOLzGbZXBy4YL9a1Rm8jQ0yNYbo7Fty46ipUW+d4MGAbNmyZlInt7bYK5Ky12YiSjMMUAh/yhdA88+63xl1aoq2XVRX2/d5ddxsKhCCKC1VX7BNzbKxc2UmTm2QUp8vAwgSkqAf/zDOp3YW2azLENNjWxNsQ1S+vUDPv9cjpOx/ZK2DU6iomTLiKK6WgY2SgAWFSXvL12Sg2MTEmQwVF1t38XjT3DiOGbHcWaUL900vpybiKiDMEAh39l2DezfLweL2q6sWlUl0wEZfDQ0tG05cdTcbO2G0Wisq7ICMkiJiZEBRVSUDGYSEmTg4ziV2BOzWV7r3DlrkPLxx3JMTEWFDKqUL2nH4ESnk61AWpuPTWurPKcSuGg08nmTydp6oix5D/gXnLjbKdnXbhruwkxEKsEAhXzj+AV36pRMz8qSX/AnT1qDE18JIW9Go/2qrC0tMi0mRt7S02WAkZrqugvF3TU0GhlUnDsnz1ddLQe8NjQAffrI1/bTnwLTp9sHJ4A8VvlZYTLJlh+zWZbVYJDjTi5ckMf/13/JsTaNjf4HJwrbQMJxZpSn4IK7MBORijBAIe+56hpQghSDAThyJLBrXLwov+R1Onn++np53ehoYMgQ4LLL5LonCQkyGPKHVmsfpJhM1iBICHndAwes5bANSJQgxFFrq+zq0etl2Vpa5ADa1lYZsGVkAHv3BhacKKKjZZCmzIxKS/PcTcNdmIlIZRigdDS1TPP01DVw+LBsQQmGujrZctLYKLtjzGZ5nauuAkaNkoHKqVO+t54obLuFhJCPlQGup07J1g7bvLazhNx1KSldT5cuyXEzvXrJ25EjspXGZALGjnUenACud0p21NAAHD1qbXFSBva6Cy68PbdynmDt/kxE5CcGKB1JLdM8Pf33ff68nF4bTK2tsnVDCNlaoNfLbhgAGDgQ+MlP7Aes+soxuLl0SV4jK0vuPmyrpcUapDh279hKSbEGJz16yLSTJ2WQUlEB7NgB/Pa3rn/PznZKdqTMGmpslK8/Lk6WWeEqSPHm3Ipg7v5MROQnBigdRS3TPD0FJ7YDYkNBmSGTliZbIZRVWZOTZXowtbTIW3q6XJDN8TmzWXYPOS65D8gxJxqNfXBSUWENHk6d8vx7dtwp2TGQcAxOYmNll1eXLvb5nAUpns6tMBqDu/szEZGfGKB0BDVN8/TUNRDomBNbSouIYyvFwYOylaZrV/lFX14O/N//ye4fT90V3tLpZKvNsWPysbMgRene0Wrty9i3rwwU0tPdByfe/J7dBRKnTlnXfnEVnCicddN4ClIYnBBRGGGA0t7UNs3TU9eAY3eILY3G+24YjUZ2u0RFWQexKtN5zWb5fhw7Jr/0c3OBMWPkuigmU3CCFJNJtoz07m1NS0+3f33KazGZrPkvv1y2aACylQdwHpx4+j3bjkVyFUikpVnfm9xc18EJ4LqbxtW5GZx4TS3DxojUjgFKe1LjNE9P/3Wnpztfxt02MPEUpNgGJxqN7E4RwtqlAsifT5+2bszXqxdwxx2yVUKZ2huoHj1k15HCaJTBx+WXy2DEZJKtLK2t8ne1ciXw4YfW96ax0X1wonD8PSsbJdqORXJ83xsbZXfa4MHyVl3tfzeNs3MzOPFowwb5axs9Wi6REy4fUaJIxQClvah5mqe7IKWhQW7a547tgFTHQEJ5H6KiZD7HKby2M2jMZmDjRtnlA8gN+4YOlTNnhLAPLvxx7Jj1tdh+yX/4oQxGlIXhoqOBt9+WGxw6vjeeghPb1+1so0R340by8oB33pG3QLtpnJ2bwYlTZWVyXPZtt8k/kfPn5Z+98pEOh48oUSRigNJe1D7N01WQcuKErK27dLFvSVGmwNoGJ/37y//+u3SRYzjS0mRAEhvbdlVYx1YXvV6mGY3Ap59aV2S9/nr572xGhhxQm5zc9lhPg2mV/GaznL7r7Et+8mQZlGRnW4MTx/fmrrvkazx+3Lvfc0uLbL2or7eu++IqSLnrLmtZgtVN4+zcnZizrpubbwauuEIuYWOrudm6RA+DFKLQ0Ajh72IS7aeurg5JSUmora1FYmJiRxfHP962oADhPR7A9nX07CnL2dwsW0b69ZP/Xjqb1dO/v5yGa/u6jhyRX/T19TKPN3+KUVHyX1nAftGzr74C7r5bdoMkJ8sl7JXWGGWshrPNBbt0kYFJU5N83K+fzOfve+/t77mhQS4Gd/GiLEP//tZyevv7d/xdnDwZsr8ZNX4GfSmzbaAxYID8M/vHPzxfIyZGNuApsV44fVSJwkEgdQdbUNpLpEzzdHwdAwbIFowBA+RjZTl6W0qa4+saNw54/nnrGBTAOggUsB8oqzw3dqwMiBxXZB09Gnj/fTkm5vx52f3zwgtyF2RlEKvjoFLlsbJ2yRVXyPVcAnnvvfk9uwtOAO+7+dhNExSOMeW//uVdcALIPx22pBCFBgOU9hQp0zwduwbGjZP3WVmyLby11RqkxMTIx3v3yudtX1dZmRwYmpRkDUSUvXKUm23gkpQkW0ZuuMH5cvFKkHL99fJ+7lwZPCUk2AcpWq01IGhslM+vWQOsWxec7g5PY3bcBScKX4MUdtP4xTE4OXLE8zp2jhikEIUGA5T2FinTPAcMAP74R+fl1GjkmJGkJOvYEWeUcTn9+snWC63WOm7F8ecrrpD5jhyRIxVdLRc/ejRQUiLvARk8OQYpCQnyXglO3ntP5gsmT2N24uJcBycKb8ciuftdkEuOwcmBAzL+9celS3KHhj17wmfYGJHaMUDpCJE2zVOp6U+dkoFEbKyssVtb5X1srEw/dcr18usJCfZBitlsH5womwP6s/y6Y5CiDE61DU5Cse2As9+z2SzXb4mLc74irS0uOR8ywQxOFM3NssGQvyqi4GCA0lEiZfyAY02fnCxXOI2NlV+wyoqnycmep9E6Bim2wUmg75FtkNLU5Dw4CcW2A57G7Kh1LJKKOf66y8oCD04A+af+xhv8VREFi18ByrJly5CTk4OYmBjk5+dj27ZtbvN/8MEH6N+/P2JiYjBo0CBs2rTJr8JGnEgYP+Bs+nSXLjIoSU21X47dm+XXlSBFaXUJRnCiUIKUQYNcByeh2HbA1ZgdtY9FUinbP9myMuDCheCc989/Dn5PIVFn5nOAsnbtWhQVFaG4uBg7duzAkCFDUFhYiOrqaqf5v/76a0yaNAn3338/du7ciQkTJmDChAnYs2dPwIWPCGofP+BqKfwuXeQXrO0YC2+XX09IAEaODG5wohg3Dvj2W+fBSSi3HXD8PUfKWCQVsv2TDVZw8sILDE6Igs3ndVDy8/MxYsQILF26FABgNpuRnZ2N2bNnY968eW3yT5w4EQ0NDdiwYYMl7b/+678wdOhQLF++3KtrqnENhk7Fm7U/vPnibcd1PYJW5mCWI9SvOQBq/Ay6K7Pytv/zn4Ff54UX5IQxImqr3dZBMRqN2L59OwoKCqwn0GpRUFCArVu3Oj1m69atdvkBoLCw0GV+AGhubkZdXZ3djcJYsKZPt9e4nHDadiBSxiKFAV/qDeVtd9w421cMTohCx6cA5ezZszCZTEhPT7dLT09PR2VlpdNjKisrfcoPAIsWLUJSUpLllp2d7UsxqSOoafn1cNt2IBLGIoUBX+uNAQPknpP+YnBCFFphOYtn/vz5qK2ttdxOnDjR0UUibwRr+nSox+W4GjfjTHtN9VX7WKQw4E+98eST/l3r3XcZnBCFmk8BSvfu3aHT6VBVVWWXXlVVhYyMDKfHZGRk+JQfAAwGAxITE+1upBJq6LKIlG0HyI4/9cbddwNjxvh2nS+/tN8rkohCw6cAJTo6GsOGDUNpaaklzWw2o7S0FKNGjXJ6zKhRo+zyA8Ann3ziMj9FADV0WUTKtgMUkKgoufDwddd5zqvXy+BEWaSYiELL5y6eoqIirFixAqtXr0ZZWRlmzJiBhoYGTJ8+HQAwZcoUzJ8/35L/0UcfRUlJCX7/+99j//79ePLJJ/HNN99g1qxZwXsVFH7U0GXBqb4EufpraSnw0kuu8yQkAN98w+CEqD35HKBMnDgRixcvxsKFCzF06FDs2rULJSUlloGwx48fx+nTpy35r776arz//vt48803MWTIEKxbtw7r16/HwIEDg/cqiPwVadsOkF+iooA5c+RWSQaD/XPDhslYm1UWUfvyeR2UjqDGNRhIZWy3olWCFgYnFmr8DPpbZrMZ+O47YPt2+XjYMGDwYOuG20TkvUDqjqgQlYlIXZSg5PXXrbN8qFPSaoGhQ+WNiDoOAxQihTJuhoiIOpwqAhSlF4oryhJ1DOWzp4IeYQvWG0QdL5C6QxUBSn19PQBwRVmiDlZfX4+kpKSOLoZXWG8QhQ9/6g5VDJI1m804deoUEhISoNFoOqQMdXV1yM7OxokTJ1Q1SFBtZQbUWW41lhnwvtxCCNTX1yMrKwtalYwWZb3hPzWWW41lBtRZbl/KHEjdoYoWFK1Wi549e3Z0MQBAlSvbqrHMgDrLrcYyA96VWy0tJwrWG4FTY7nVWGZAneX2tsz+1h3q+FeIiIiIOhUGKERERBR2GKB4yWAwoLi4GAbHZSbDmBrLDKiz3GosM6DecquFWt9fNZZbjWUG1Fnu9iqzKgbJEhERUefCFhQiIiIKOwxQiIiIKOwwQCEiIqKwwwCFiIiIwg4DFCIiIgo7nTZAWbZsGXJychATE4P8/Hxs27bNbf4PPvgA/fv3R0xMDAYNGoRNmzbZPS+EwMKFC5GZmYnY2FgUFBTg0KFDHVruFStW4Nprr0VKSgpSUlJQUFDQJv+0adOg0WjsbjfddFOHlXnVqlVtyhMTE2OXJxzf6x//+Mdtyq3RaHDrrbda8oT6vf7nP/+J2267DVlZWdBoNFi/fr3HYz7//HNcddVVMBgM6NevH1atWtUmj6+flUinxrpDjfWGr+UOl7pDbfUGEMZ1h+iE1qxZI6Kjo8Xbb78t9u7dKx544AGRnJwsqqqqnOb/6quvhE6nEy+++KLYt2+fePzxx4Verxe7d++25Hn++edFUlKSWL9+vfj222/F7bffLnJzc0VTU1OHlfvuu+8Wy5YtEzt37hRlZWVi2rRpIikpSZw8edKSZ+rUqeKmm24Sp0+fttxqamo6rMwrV64UiYmJduWprKy0yxOO7/W5c+fsyrxnzx6h0+nEypUrLXlC/V5v2rRJLFiwQPz1r38VAMSHH37oNv/Ro0dFXFycKCoqEvv27ROvvvqq0Ol0oqSkxJLH1/ch0qmx7lBjveFPucOh7lBjvSFE+NYdnTJAGTlypJg5c6blsclkEllZWWLRokVO8//85z8Xt956q11afn6+eOihh4QQQpjNZpGRkSFeeukly/MXLlwQBoNB/O///m+HldtRa2urSEhIEKtXr7akTZ06VYwfPz5oZXTka5lXrlwpkpKSXJ5PLe/1H/7wB5GQkCAuXrxoSQv1e23Lm0pm7ty54sorr7RLmzhxoigsLLQ8DvR9iDRqrDvUWG8Ioc66Q+31hhDhVXd0ui4eo9GI7du3o6CgwJKm1WpRUFCArVu3Oj1m69atdvkBoLCw0JK/vLwclZWVdnmSkpKQn5/v8pztUW5HjY2NaGlpQdeuXe3SP//8c6SlpeHyyy/HjBkzcO7cuQ4t88WLF9G7d29kZ2dj/Pjx2Lt3r+U5tbzXb731Fu666y506dLFLj1U77U/PP1dB+N9iCRqrDvUWG8EUu6OrDs6S70BtF/d0ekClLNnz8JkMiE9Pd0uPT09HZWVlU6PqaysdJtfufflnO1RbkePPfYYsrKy7P5obrrpJvzP//wPSktL8cILL+D//u//cPPNN8NkMnVImS+//HK8/fbb+Oijj/Duu+/CbDbj6quvxsmTJwGo473etm0b9uzZg//3//6fXXoo32t/uPq7rqurQ1NTU1D+5iKJGusONdYb/pa7o+uOzlJvAO1Xd0QFpbQU9p5//nmsWbMGn3/+ud3Asbvuusvy86BBgzB48GD07dsXn3/+OW688cZ2L+eoUaMwatQoy+Orr74aAwYMwBtvvIFnnnmm3cvjj7feeguDBg3CyJEj7dLD7b0m8kQt9Qag/rqD9UZbna4FpXv37tDpdKiqqrJLr6qqQkZGhtNjMjIy3OZX7n05Z3uUW7F48WI8//zz2LJlCwYPHuw2b58+fdC9e3ccPny4Q8us0Ov1+NGPfmQpT7i/1w0NDVizZg3uv/9+j9cJ5nvtD1d/14mJiYiNjQ3K7y+SqLHuUGO9Aaiz7ugs9QbQfnVHpwtQoqOjMWzYMJSWllrSzGYzSktL7aJvW6NGjbLLDwCffPKJJX9ubi4yMjLs8tTV1eHf//63y3O2R7kB4MUXX8QzzzyDkpISDB8+3ON1Tp48iXPnziEzM7PDymzLZDJh9+7dlvKE83sNyCmlzc3NuOeeezxeJ5jvtT88/V0H4/cXSdRYd6ix3gik3Lbau+7oLPUG0I51h9fDaSPImjVrhMFgEKtWrRL79u0TDz74oEhOTrZMSbv33nvFvHnzLPm/+uorERUVJRYvXizKyspEcXGx06mCycnJ4qOPPhLfffedGD9+fEimvvpS7ueff15ER0eLdevW2U1Rq6+vF0IIUV9fL+bMmSO2bt0qysvLxaeffiquuuoqkZeXJy5dutQhZX7qqafE5s2bxZEjR8T27dvFXXfdJWJiYsTevXvtXle4vdeKa665RkycOLFNenu81/X19WLnzp1i586dAoB4+eWXxc6dO8WxY8eEEELMmzdP3HvvvZb8ylTB3/zmN6KsrEwsW7bM6VRBd+9DZ6PGukON9YY/5Q6HukON9YZynXCsOzplgCKEEK+++qro1auXiI6OFiNHjhT/+te/LM+NGTNGTJ061S7/n//8Z3HZZZeJ6OhoceWVV4qNGzfaPW82m8UTTzwh0tPThcFgEDfeeKM4cOBAh5a7d+/eAkCbW3FxsRBCiMbGRjF27FiRmpoq9Hq96N27t3jggQeC/uXjS5l/+ctfWvKmp6eLW265RezYscPufOH4XgshxP79+wUAsWXLljbnao/3+rPPPnP6+1bKOXXqVDFmzJg2xwwdOlRER0eLPn362K2/oHD3PnRGaqw71Fhv+FrucKk71FZvCBG+dYdGCCF8atshIiIiCrFONwaFiIiIwh8DFCIiIgo7DFCIiIgo7DBAISIiorDDAIWIiIjCDgMUIiIiCjsMUIiIiCjsMEAhIiKisMMAhYiIiMIOAxQiIiIKOwxQiIiIKOz8fzCbF37l8oyQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 7.063\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGzCAYAAAAFROyYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABvEElEQVR4nO3deXxU1f0//tfMZDLZN7JDJIEEQdkqSz5IlaopcaFCP1oRUQL6U0sBbVNFKAouVVyoxQqKUgGrWKi0ogUNaL76qVUqBUFZwiZhExIggSQkIZPMnN8fxztLMvuSzJ28no/HPCZz5tx7z0wyZ945q0YIIUBEREQUQrRdXQAiIiKi9higEBERUchhgEJEREQhhwEKERERhRwGKERERBRyGKAQERFRyGGAQkRERCGHAQoRERGFHAYoREREFHIYoJDPHn/8cWg0Gp+OXbVqFTQaDY4cORLYQtk4cuQINBoNVq1aFbRrEBHl5uZi6tSpXV2MsMMApZvas2cP7rzzTvTs2RMGgwHZ2dmYPHky9uzZ09VFI6JOVFlZiZkzZ6Jfv36IiYlBTEwMLrvsMsyYMQPffvttVxcvYD788EM8/vjjXV0M8oKGe/F0P//4xz8wadIkpKSk4J577kFeXh6OHDmCN954AzU1NVizZg1+/vOfuz1PW1sb2traEBUV5XUZTCYTWltbYTAYfG6FcefIkSPIy8vDypUr+d8NkQMbNmzAxIkTERERgcmTJ2PIkCHQarXYt28f/vGPf+Do0aOorKxE7969u7qofps5cyaWLl2KYHzl5ebm4ic/+QlbawMsoqsLQJ3ru+++w1133YU+ffrgX//6F9LS0izPPfjgg7jqqqtw11134dtvv0WfPn0cnqOxsRGxsbGIiIhARIRvf0I6nQ46nc6nY4nIf9999x1uv/129O7dG+Xl5cjKyrJ7/rnnnsMrr7wCrTY0G9qVeojCV2j+5VHQvPDCC2hqasLrr79uF5wAQGpqKl577TU0Njbi+eefB2AdZ7J3717ccccdSE5Oxo9//GO752w1NzfjgQceQGpqKuLj43HzzTfj+++/h0ajsWtedTQGJTc3F+PGjcO///1vjBw5ElFRUejTpw/+8pe/2F2jtrYWDz30EAYNGoS4uDgkJCTghhtuwDfffBPAd4oovD3//PNobGzEypUrOwQnABAREYEHHngAOTk5lrR9+/bh1ltvRUpKCqKiojB8+HB88MEHdscpn+0vvvgCpaWlSEtLQ2xsLH7+85/jzJkzHa7z0Ucf4aqrrkJsbCzi4+Nx0003dehqnjp1KuLi4vDdd9/hxhtvRHx8PCZPngwA+Pzzz/GLX/wCl1xyCQwGA3JycvCb3/wGzc3NdscvXboUAKDRaCw3hdlsxuLFi3H55ZcjKioKGRkZuP/++3Hu3Dm7cggh8Pvf/x69evVCTEwMrrnmGnaLBxFbULqZf/7zn8jNzcVVV13l8Pmrr74aubm52Lhxo136L37xCxQUFOCZZ55x2UQ6depU/O1vf8Ndd92F//mf/8H//d//4aabbvK4fIcOHcKtt96Ke+65ByUlJVixYgWmTp2KYcOG4fLLLwcAHD58GOvXr8cvfvEL5OXlobq6Gq+99hrGjBmDvXv3Ijs72+PrEXVXGzZsQH5+PgoLCz3Kv2fPHowePRo9e/bEnDlzEBsbi7/97W+YMGEC/v73v3foFp41axaSk5OxYMECHDlyBIsXL8bMmTOxdu1aS5633noLJSUlKC4uxnPPPYempia8+uqr+PGPf4wdO3YgNzfXkretrQ3FxcX48Y9/jEWLFiEmJgYA8O6776KpqQnTp09Hjx49sHXrVrz88ss4ceIE3n33XQDA/fffj5MnT+Ljjz/GW2+91eG13X///Vi1ahWmTZuGBx54AJWVlViyZAl27NiBL774Anq9HgAwf/58/P73v8eNN96IG2+8EV9//TXGjh0Lo9Ho1XtPHhLUbZw/f14AEOPHj3eZ7+abbxYARH19vViwYIEAICZNmtQhn/KcYvv27QKA+PWvf22Xb+rUqQKAWLBggSVt5cqVAoCorKy0pPXu3VsAEP/6178saadPnxYGg0H89re/taRdvHhRmEwmu2tUVlYKg8EgnnzySbs0AGLlypUuXy9Rd1NXVycAiAkTJnR47ty5c+LMmTOWW1NTkxBCiOuuu04MGjRIXLx40ZLXbDaLK6+8UhQUFFjSlM92UVGRMJvNlvTf/OY3QqfTifPnzwshhGhoaBBJSUni3nvvtbt+VVWVSExMtEsvKSkRAMScOXM6lFcpn62FCxcKjUYjjh49akmbMWOGcPSV9/nnnwsAYvXq1XbpZWVldumnT58WkZGR4qabbrJ7Xb/73e8EAFFSUtLh3OQfdvF0Iw0NDQCA+Ph4l/mU5+vr6y1pv/zlL92ev6ysDADwq1/9yi591qxZHpfxsssus2vdSUtLw6WXXorDhw9b0gwGg6Vf3GQyoaamBnFxcbj00kvx9ddfe3wtou5K+WzHxcV1eO4nP/kJ0tLSLLelS5eitrYW/+///T/cdtttaGhowNmzZ3H27FnU1NSguLgYBw8exPfff293nvvuu8+uG+Wqq66CyWTC0aNHAQAff/wxzp8/j0mTJlnOd/bsWeh0OhQWFuLTTz/tULbp06d3SIuOjrb83NjYiLNnz+LKK6+EEAI7duxw+168++67SExMxE9/+lO7cgwbNgxxcXGWcnzyyScwGo2YNWuW3ev69a9/7fYa5Bt28XQjSuChBCrOOApk8vLy3J7/6NGj0Gq1HfLm5+d7XMZLLrmkQ1pycrJdX7DZbMZLL72EV155BZWVlTCZTJbnevTo4fG1iLor5bN94cKFDs+99tpraGhoQHV1Ne68804AsutVCIHHHnsMjz32mMNznj59Gj179rQ8bv9ZTk5OBgDLZ/ngwYMAgGuvvdbh+RISEuweR0REoFevXh3yHTt2DPPnz8cHH3zQYcxIXV2dw3PbOnjwIOrq6pCenu7w+dOnTwOAJbAqKCiwez4tLc3y2iiwGKB0I4mJicjKynK7tsG3336Lnj172lUQtv+lBJOzmT3CZtzLM888g8ceewx33303nnrqKaSkpECr1eLXv/41zGZzp5STSM2UumD37t0dnlPGpNgOYFc+Vw899BCKi4sdnrP9PyLuPsvKOd966y1kZmZ2yNd+hqBty6nCZDLhpz/9KWpra/HII4+gf//+iI2Nxffff4+pU6d6VB+YzWakp6dj9erVDp9vP5mAOg8DlG5m3LhxWL58Of79739bZuPY+vzzz3HkyBHcf//9Xp+7d+/eMJvNqKystPsv49ChQ36Vub1169bhmmuuwRtvvGGXfv78eaSmpgb0WkTh6qabbsKf//xnbN26FSNHjnSZV1lyQK/Xo6ioKCDX79u3LwAgPT3d53Pu2rULBw4cwJtvvokpU6ZY0j/++OMOeZ2tt9S3b1988sknGD16tMt/xJS1YA4ePGi3BMOZM2c6tNxQYHAMSjfz8MMPIzo6Gvfffz9qamrsnqutrcUvf/lLxMTE4OGHH/b63Mp/Vq+88opd+ssvv+x7gR3Q6XQdZhK9++67HfrAici52bNnIyYmBnfffTeqq6s7PG/7GUtPT8dPfvITvPbaazh16lSHvI6mD7tTXFyMhIQEPPPMM2htbfXpnEorjW1ZhRB46aWXOuRV1kw5f/68Xfptt90Gk8mEp556qsMxbW1tlvxFRUXQ6/V4+eWX7a63ePFit+Uk37AFpZspKCjAm2++icmTJ2PQoEEdVpI9e/Ys/vrXv1r+u/HGsGHDcMstt2Dx4sWoqamxTDM+cOAAAOf/wXhr3LhxePLJJzFt2jRceeWV2LVrF1avXu10YTki6qigoADvvPMOJk2ahEsvvdSykqwQApWVlXjnnXeg1Wot4z6WLl2KH//4xxg0aBDuvfde9OnTB9XV1diyZQtOnDjh9TpECQkJePXVV3HXXXfhiiuuwO233460tDQcO3YMGzduxOjRo7FkyRKX5+jfvz/69u2Lhx56CN9//z0SEhLw97//3WGLxrBhwwAADzzwAIqLi6HT6XD77bdjzJgxuP/++7Fw4ULs3LkTY8eOhV6vx8GDB/Huu+/ipZdewq233oq0tDQ89NBDWLhwIcaNG4cbb7wRO3bswEcffcSW22DpqulD1LW+/fZbMWnSJJGVlSX0er3IzMwUkyZNErt27bLLp0wlPnPmTIdztJ9mLIQQjY2NYsaMGSIlJUXExcWJCRMmiP379wsA4tlnn7XkczbN+KabbupwnTFjxogxY8ZYHl+8eFH89re/FVlZWSI6OlqMHj1abNmypUM+TjMmcu/QoUNi+vTpIj8/X0RFRYno6GjRv39/8ctf/lLs3LnTLu93330npkyZIjIzM4Verxc9e/YU48aNE+vWrbPkUT7b//3vf+2O/fTTTwUA8emnn3ZILy4uFomJiSIqKkr07dtXTJ06VWzbts2Sp6SkRMTGxjos/969e0VRUZGIi4sTqamp4t577xXffPNNh89+W1ubmDVrlkhLSxMajaZD3fX666+LYcOGiejoaBEfHy8GDRokZs+eLU6ePGnJYzKZxBNPPGGpe37yk5+I3bt3i969e3OacRBwLx4Kup07d+JHP/oR3n77bcvqj0RERK5wDAoFlO3y0orFixdDq9Xi6quv7oISERGRGnEMCgXU888/j+3bt+Oaa65BREQEPvroI3z00Ue477777Pb0ICIicoVdPBRQH3/8MZ544gns3bsXFy5cwCWXXIK77roL8+bN83nnYyIi6n4YoBAREVHI4RgUIiIiCjkMUIiIiCjkqGJQgNlsxsmTJxEfHx+wxb6IyHNCCDQ0NCA7O7vDfiihivUGUdfzp+5QRYBy8uRJzgAhCgHHjx93uKNsKGK9QRQ6fKk7VBGgKFuDHz9+vMMW3EQUfPX19cjJybF8FtWA9QZR1/On7lBFgKI0zyYkJLCiIepCauoqYb1BFDp8qTvU0ZlMRERE3YoqWlBI/dragPXrgRMngF69gAkTAK7bRkREzvArgoKurQ2YPh34+GOgtRXQ64HNm4FXXmGQQkREjrGLh4Ju/XoZnCQmAgUF8n7zZplORETkCAMUCroTJ2TLSXKyfJycLB+fONG15SIiotDFAIWCrlcv2a1z7px8fO6cfKyS5TSIiKgLMEChoJswARg7FqirAw4elPdjx8p0IiIiRzhEkYIuIkIOiOUsHiIi8hS/IqhTREQAt97a1aUgIiK1YBcPERERhRy2oBABMJuB3buB2logJQUYOBBQyaa9RERhiQEKdXtmM/DWW3JtlpYWwGAAiouBO+9kkEJE1FVY/VK3t3u3DE569JAtJz16AJs2yXQiIuoaDFCo26utlS0nKSnycUqKfFxb27XlIiLqzhigULeXkiK7dZSApLZWPlYCFiIi6nwMUKjbGzhQjjmpqZHdOjU18vHAgV1dMiKi7ouDZKnb02rlgNihQzmLh4goVDBAIYIMRgYP7upSEBGRgv8jEhERUchhCwp1GaMRePlloLISyMsDZs0CIiM9O5YLqxERhTcGKNQljEa5o/F//yuDDa0W2LBBrj/iLkjhwmpEROGP1Tl1iZdflsFJVBSQkSHvt26V6e5wYTUiovDHAIW6RGWlbAmJj5eP4+Pl48pK98dyYTUiovDnU4CydOlS5ObmIioqCoWFhdi6davL/OfPn8eMGTOQlZUFg8GAfv364cMPP/SpwBQe8vJkd0xDg3zc0CAf5+W5P5YLqxERhT+vA5S1a9eitLQUCxYswNdff40hQ4aguLgYp0+fdpjfaDTipz/9KY4cOYJ169Zh//79WL58OXr27Ol34Um9Zs0CRo4ELl4Eqqvl/ciRMt0dLqxGRBT+NEII4c0BhYWFGDFiBJYsWQIAMJvNyMnJwaxZszBnzpwO+ZctW4YXXngB+/btg16v96mQ9fX1SExMRF1dHRISEnw6B4UezuJRDzV+BtVYZqJw48/n0KtZPEajEdu3b8fcuXMtaVqtFkVFRdiyZYvDYz744AOMGjUKM2bMwPvvv4+0tDTccccdeOSRR6DT6Rwe09LSgpaWFsvj+vp6b4pJKhEZCfz2t74dy4XVqD3WG0Thxav/Oc+ePQuTyYSMjAy79IyMDFRVVTk85vDhw1i3bh1MJhM+/PBDPPbYY/jDH/6A3//+906vs3DhQiQmJlpuOTk53hSTiLoh1htE4SXo66CYzWakp6fj9ddfh06nw7Bhw/D999/jhRdewIIFCxweM3fuXJSWlloe19fXs7IJkrY2YP164MQJoFcvYMIEIMLJX4U3eT05FvDsfI6O1Wo7dvGYzYG9hj/5qPOx3iAKL15VrampqdDpdKiurrZLr66uRmZmpsNjsrKyoNfr7bpzBgwYgKqqKhiNRkQ6GHRgMBhgMBi8KRr5oK0NmD4d+PhjoLUV0Ovl+iKvvNLxS9ebvJ5cp6wMEAIoL3d9PkfHbtoEjBolj1UWaisqAr74Avjkk8Bcw5981DVYbxCFF6+6eCIjIzFs2DCUl5db0sxmM8rLyzFq1CiHx4wePRqHDh2C2Wy2pB04cABZWVkOgxPqPOvXyy/bxESgoEDeb94s0/3J68mx778PfPCB+/M5OnbjRmDFCvuF2t54A/jww8Bdw598RETkP6/nPZSWlmL58uV48803UVFRgenTp6OxsRHTpk0DAEyZMsVuEO306dNRW1uLBx98EAcOHMDGjRvxzDPPYMaMGYF7FeSTEydkS0BysnycnCwfnzjhX15PjjUa5c3d+Zxdt6HBfqG2hobAX8PXfERE5D+vG6YnTpyIM2fOYP78+aiqqsLQoUNRVlZmGTh77NgxaG3me+bk5GDTpk34zW9+g8GDB6Nnz5548MEH8cgjjwTuVZBPevWS3RTnzskv23Pn5ONevfzL68mxSuOZu/M5u258vHX8SW2tfBzoa/iaj4iI/Of1OihdgesZBEdbG/CrX8luCmVMxdixzsegeJrXk+sUFcnnbMeMODqfo2N/+lPgyivlsbZjUL780n58iD/X8CdfOFLjZ1CNZSYKN/58DhmgdHOcxePda+uus3jU+BlUY5mJwg0DFCIKKjV+BtVYZqJw48/nkIuDExERUcjpBo3T3ZNauyIuXgTmzQMOHwb69AGefhqIigrsNTztbnLUjeRovx+1vtdERKGM1WgYUuuCYhcvAkOHAocOyQXWNBq5tsmOHYELUjxdNM7RYnDFxcCdd9oHKWp9r4mIQh27eMKQWhcUmzdPBic6nZw2rNMBBw/K9EDxdNE4R4vBbdokW1TcnU8N7zURUahjgBKG1Lqg2OHDsiUjOlo+jo6Wjw8fDtw1vFk0rv1icC0tsrvH3fnU8F4TEYU6BihhyHZBMUA9C4r16SO7dZqb5ePmZvm4T5/AXcPRexMZKW/t3y9lMThA3hsM1oDF1fnU8F4TEYU6BihhaMIEuYBYXZ3sIqmrk4+VwaCh6umnZTeJySRbL0wm+fjppwN3DUfvzfjx8mabdtNNwD33ADU1slunpkaOQRk40P351PBeExGFOq6DEqbUOrOEs3hCkxo/g2osM1G44UJtRBRUavwMqrHMROGGC7URERFRWAmzhmgKBGfdLEYj8PLLQGUlkJcHzJol0yZNAo4cAXJzgb/+FYiL8/3anbHvjtnsWdcNERF1HQYoZMfZYmlffQXcfDPw3//KL3itFnjvPWDXLqC+Xh67e7cMDE6c8C1IcbTomaMF04qKgC++sN+l2NFia44WTDObgbfeks+5WoCNiIi6FgMUsmO7WFp0tJzqe/Ag8LOfAdu2yZaU+Hg5y2bLFvmFD8j8JpOcxTJpEvDPf3p/bdtFz5KT5ZTdjRuBigrgiitka0dtLfDGG7J1Jy3Nmu/99+U5srOtacqCabfear3G7t0yvUcP6/k2bZJB2eDBfr55REQUMPyfkew4Wyzt2DEZjMTHy/T4ePvgxPb+yBHfru1s0bP2C6Y1NHi+2Fr7BdNqa2XLibsF2IiIqGsxQCE7zhZLu+QS2QXS0CDTGxqsXSImk/19bq5v13a26Fn7BdPi4z1fbK39gmkpKbJbx90CbERE1LUYoJAdZ4ul/fOfwMiRcoxKdbW8HzUKUGaNKcFJYqIcKOsLR4ueOVow7Z57ZLq7xdYcLZg2cKAcc+JuATYiIupaXAeFOuAsHmpPjZ9BNZaZKNxwoTYiCio1fgbVWGaicOPP55CzeKgDb5Zud9Qa0dbWsaUlMjLw1yYiovDFqp/sOFqLxNF6IoDjNUWuvRb4y1/klGRlvZQNG+RUXndBijfXJiKi8Maed7JjuxZJQYG8V9YTac92TZGBA+X9kiXA1q1yzEpGhrzfulW2qATy2kREFN4YoJAdZ2uRtF9PBHC8pkh9veP1UiorA3ttIiIKbwxQyI6ztUjarycCOF5TJCHB8XopeXmBvTYREYU3Bihkx9FaJI7WEwEcrykycyZQWGi/XsrIkXKgbCCvTURE4Y3TjKkDzuKh9tT4GVRjmYnCDacZU0BFRNhvsOeKVttxk73ISOC3vw3+tYmIKHyxi4eIiIhCDltQwkCgu0WcnY/dL0RE1Fn49aJygV7czNn5/vQnOZaEi6gREVFnYBePygV6cTNn55s3j4uoERFR5/Hpf9+lS5fihRdeQFVVFYYMGYKXX34ZI0eOdHvcmjVrMGnSJIwfPx7rO+GbzWQyobW1NejX6Uo1NUB6utxJGJA/Hzki0y9eDNz56uo8u45er4dOp/P15RB1ObPZDKPR2NXF6FZYb5AjXgcoa9euRWlpKZYtW4bCwkIsXrwYxcXF2L9/P9LT050ed+TIETz00EO46qqr/CqwJ4QQqKqqwvnz54N+ra42fDjQp4+cTaPVymm/ZrOc8uvJ6q2eni82Fmhs9Ow6SUlJyMzMhEajCcyLJOokRqMRlZWVMJvNXV2Ubof1BrXndYDy4osv4t5778W0adMAAMuWLcPGjRuxYsUKzJkzx+ExJpMJkydPxhNPPIHPP/886IGDEpykp6cjJiYmrP/ghQBOngQuXJA/azRAXByQnS1/DtT5srKAU6dcX0cIgaamJpw+fRoAkJWVFcBXShRcQgicOnUKOp0OOTk50GrZA94ZWG+QM14FKEajEdu3b8fcuXMtaVqtFkVFRdiyZYvT45588kmkp6fjnnvuweeff+72Oi0tLWhpabE8rq+v97iMJpPJEpz06NHD4+PUrE8fuSy8Mng1Odm34MTd+Ty5TnR0NADg9OnTSE9PZ7MtdRp/6g0AaGtrQ1NTE7KzsxETExPo4pELrDfIEa8ClLNnz8JkMiEjI8MuPSMjA/v27XN4zL///W+88cYb2Llzp8fXWbhwIZ544glvimahjDnpThWMRmPdsC+Y5/P0Osp739rayoqGOo0/9QYg/7kBgEhPlz2mgGK9Qe0FtQ2zoaEBd911F5YvX47U1FSPj5s7dy7q6uost+PHj3t97XDu1gl1fO+pKwSi3gD499tV+L5Te161oKSmpkKn06G6utouvbq6GpmZmR3yf/fddzhy5Ah+9rOfWdKUwWcRERHYv38/+vbt2+E4g8EAg8HgTdHCkhBAczNgMgE6HRAdLdNOnwaMRrmkfHq6HLQa6Ot62mXkKK8QQFMT8OabQI8ezhd048JvFEisN4jCi1dfB5GRkRg2bBjKy8sx4YctZs1mM8rLyzFz5swO+fv3749du3bZpT366KNoaGjASy+9hJycHN9LHuaEkFN46+utg1Lj42VaU5M1ra5OrksSqCBFCODoUfvr1tcDvXt3DFKc5TWZ5OaBb7whgylHC7oFeoE5IiIKL15/rZWWlmL58uV48803UVFRgenTp6OxsdEyq2fKlCmWQbRRUVEYOHCg3S0pKQnx8fEYOHAg+3pdaG6WX/YREbLlJCICOHPGOtVXr5f3jY0yCHBl1apVSEpK8ui6587J6+p0QFSUvK+vl+me5D1/XqZptXLNFGcLugV6gTkiCjxv6g6iQPM6QJk4cSIWLVqE+fPnY+jQodi5cyfKysosA2ePHTuGU6dOBbygajd16lRoNBrLrUePHrj++uvx7bffOsxvMslWCaU1ISJCpr322uO4/fahAGQQIITs7gmU1lbrdX//+wdw223DMHy4AVdfPdRlXqWMQsib0qKTnCzznThhf+yJEzI9Odl1PqLuztu6w5nHH38cQ4cODU4hbXzzzTeYNGkScnJyEB0djQEDBuCll14K+nUp/PjUMTBz5kwcPXoULS0t+Oqrr1BYWGh57rPPPsOqVaucHrtq1apOWUU2EC5cAF57DbjySqBvX3n/2msy3RfXX389Tp06hVOnTqG8vBwREREYN26cw7w6newyaWuTj9vaZBogAwBALpSm0cixKIGi19tf9+c/vxvFxRMdjkFpn7etTT7WaGTZANnKotfLMSa2evWS6UrLjLN8RKoU4MrDm7qjq23fvh3p6el4++23sWfPHsybNw9z587FkiVLurpopDZCBerq6gQAUVdX5zZvc3Oz2Lt3r2hubvbrmhUVQmRnC6HRyBtg/Tk7Wz7vjZKSEjF+/Hi7tM8//1wAEKdPn7akzZ49WxQUFIjo6GjRu3eemDHjUVFRYRTffSfEn/60UgCwuz3zzEphMglx7tw5cd9994n09HRhMBjE5ZdfLv75z38KIYRYuXKlSExMFGVlZaJ///4iNjZWFBcXi5MnT3Yop9ksRGWlEN98I8TOnfL+wQcXiCFDhniUt7JSiEOHmsXmzXvFiBHNondvIe69V4jWVvtjW1tleu/e8v10lo9CgzefwVDhbZkDVXcEuvLwpe7Iy8sTjz76qDAajUIIWQe0rztWrlwphAhc3eHKr371K3HNNde4zBOw959Cij91B4cjOnDhAnDddUB1tbW1ArD+XF0tn9+/X66m6ts1LuDtt99Gfn6+3YJy8fHxWLVqFbKzs/Htt7tw7733IiMjHr/97Wzcc89EHDmyGxs3luHttz9BZCTQt28iADNuuOEGNDQ04O2330bfvn2xd+9eu7UEmpqasGjRIrz11lvQarW488478dBDD2H16tV25dJo5IBY25k5iYmOX4OjvMnJcm+e8+eBe+5xPosnIkIOiOUsHgornVB5eFJ37Nol6474+HjMnj0bEydOxO7du1FWVoZPPvkEAJCYmAizOXB1hyt1dXVICeRiTdQ9BCFgCrjObkFZtsz6j4+zm0YjxGuveX7OkpISodPpRGxsrIiNjRUARFZWlti+fbvL41544QUxbNgwy+MFCzq2ZmzatElotVqxf/9+h+dQ/ns6dOiQJW3p0qUiIyPDo7I7uqYr/E8o/LAFxUNBqDzUXHcIIcQXX3whIiIixKZNm1zmY70RnvypO7jZhANvvhnYfIprrrkGO3fuxM6dO7F161YUFxfjhhtuwNGjRy151q5di9GjRyMzMxNxcXF49NFHcezYMZfn3blzJ3r16oV+/fo5zRMTE2O35kxWVpZl7wsiCpAgVR5qrTt2796N8ePHY8GCBRg7dqxHxxApGKA40L511hEhgKoq784bGxuL/Px85OfnY8SIEfjzn/+MxsZGLF++HACwZcsWTJ48GTfeeCM2bNiAHTt2YN68eW63flf2sXBFr9fbPdZoNBDuXiQReSdIlYca6469e/fiuuuuw3333YdHH33UbX6i9tjj70BGBlBZ6bqe0WgAB4vnekWj0UCr1aK5uRkA8OWXX6J3796YN2+eJY/tf0iAXCxP2TNEMXjwYJw4cQIHDhxw+Z8QEQVZJ1UeoV537NmzB9deey1KSkrw9NNPB+y81L0wQHGgpAT4z388y+eNlpYWVP3wn9O5c+ewZMkSXLhwwbIVQEFBAY4dO4Y1a9ZgxIgR2LhxI9577z27c+Tm5qKystLSNBsfH48xY8bg6quvxi233IIXX3wR+fn52LdvHzQaDa6//nrvCmnj0KFDuHDhAqqqqtDc3GzZ8PGyyy7jIntEjgSp8lBT3bF7925ce+21KC4uRmlpqaXcOp0OaWlpPp2TuqmAj4gJgs4eJNvQIGcD6nSOx7jpdPL5hgbPz1lSUmI3xS8+Pl6MGDFCrFu3zi7fww8/LHr06CHi4uLExIkTxR//+EeRmJhoef7ixYvilltuEUlJSXZTBWtqasS0adNEjx49RFRUlBg4cKDYsGGDEMI6VdDWe++9J9z9+seMGdNhaiIAUVlZ6fI4DnYLPxwk66EgVB5qqzsWLFjgsN7o3bu3y9fJeiM8+VN3aIQI/YEI9fX1SExMRF1dHRISElzmvXjxIiorK5GXl4eoqCifr7lvn5wNqCyKq+w1AwBZWUB5OdC/v8+nD2uB+h1Q6PDmMxgqvC1zwP5uWXn4hPVGePKn7mAXjxP9+8ulCt55B1i1So59y8yULbN33OH7+idEFOZYeRAFBAMUF+LigPvukzciIo+x8iDyG6cZExERUchhgEJEREQhhwEKERERhRwGKERERBRywjZAUcHs6bDF957UjH+/XYPvO7UXdgGKsm9EU1NTF5ek+1Le+/Z7eBCFMp1OBwBu96+h4GC9Qe2F3TRjnU6HpKQky26bMTEx0CiLJFFQCSHQ1NSE06dPIykpyVLhE6lBREQEYmJicObMGej1emi1Yff/W0hivUHOhF2AAgCZP2zE5emW4BRYSUlJlt8BkVpoNBpkZWWhsrKyw0Z7FHysN6i9sAxQlIomPT0dra2tXV2cbkWv1/M/IFKtyMhIFBQUsJunk7HeIEfCMkBR6HQ6/tETkVe0Wi33giEKAexkJSIiopDDAIWIiIhCDgMUIiIiCjkMUIiIiCjkMEAhIiKikMMARYUqKoAHHpD3RERE4YgBispUVAC//CWwZo28Z5BCREThiAGKiijBycGDQG6uvGeQQkRE4YgBikq0D05iYhikEBFR+GKAogLtg5PISJkeGckghYiIwpNPAcrSpUuRm5uLqKgoFBYWYuvWrU7zLl++HFdddRWSk5ORnJyMoqIil/nJnrPgRMEghYiIwpHXAcratWtRWlqKBQsW4Ouvv8aQIUNQXFzsdOfgzz77DJMmTcKnn36KLVu2ICcnB2PHjsX333/vd+HDnbvgRMEghYiIwo1GCCG8OaCwsBAjRozAkiVLAABmsxk5OTmYNWsW5syZ4/Z4k8mE5ORkLFmyBFOmTPHomvX19UhMTERdXR0SEhK8Ka6qPfCAnK2jjDlxp6kJOHIEuP124E9/CnbpqDtR42dQjWUmCjf+fA69akExGo3Yvn07ioqKrCfQalFUVIQtW7Z4dI6mpia0trYiJSXFaZ6WlhbU19fb3bqj6dOBAQOAEycAd7u/G40y34AB8jii7ob1BlF48SpAOXv2LEwmEzIyMuzSMzIyUFVV5dE5HnnkEWRnZ9sFOe0tXLgQiYmJlltOTo43xQwbAwYAy5YBBQWyZcRZkGI0AocPA4mJwDPPyOOIuhvWG0ThpVNn8Tz77LNYs2YN3nvvPURFRTnNN3fuXNTV1Vlux48f78RShhZ3QYoSnBgMQHo6sHkzcOZMlxSVqEux3iAKL14FKKmpqdDpdKiurrZLr66uRmZmpstjFy1ahGeffRabN2/G4MGDXeY1GAxISEiwu3VnzoIU2+CkoAAoLAR27QKWLGGQQt0P6w2i8OJVgBIZGYlhw4ahvLzckmY2m1FeXo5Ro0Y5Pe7555/HU089hbKyMgwfPtz30nZj7YOUpqaOwUlMjMzHIIWIiNTO6y6e0tJSLF++HG+++SYqKiowffp0NDY2Ytq0aQCAKVOmYO7cuZb8zz33HB577DGsWLECubm5qKqqQlVVFS5cuBC4V9FN2AYp7YMTvV7m0esZpBARkfp5HaBMnDgRixYtwvz58zF06FDs3LkTZWVlloGzx44dw6lTpyz5X331VRiNRtx6663Iysqy3BYtWhS4V9GNDBggB8L26dMxOFEwSCEiIrXzeh2UrsD1DKzOnJFBx65dMghpH5zYam2Vi7YNGgTMnAmkpXVeOSm8qPEzqMYyE4WbTlsHhbpeeTmwbRuQn+86OAHk8/n5Mr/NsCEiIqKQxwBFZa67Dhg+HDh0SLaQuNLaKvMNHy6PIyIiUgsGKCqTlgaMHStXjf3qK2uQcuAA8Mor8h7wrntn9WrgkkvkvS8qKuSy/NwDiIiIAiWiqwtA3qmoAH73OzmLJzZWpiUnAx98INdF+fvfgZtvBkwmz4OTu++Wx959t0ybPNm78igbFH7zjZxlxJVsiYjIX2xBURHb3Y379AFaWmRQ8N57MsCIiJD369fLKcjeBCc6nTVI8bQlpf1uy9xNmYiIAoUBikq0DwZiYmTLydmzsrVEowG0WnlrawM2bpRdQM7YBicREdabp0GKo/IwSCEiokBhgKIC7YOByEgZmCjjTQBACBmYRETIYOHCBdlVs2FDx/O1D050Opmu03kWpDgqDyDvGaQQEVEgMEAJcc6Ck4oKwGy2tpwAMkjR6+UtJgZoaOgYpDgLThTughRnwYmCQQoREQUCA5QQ5mlwotwLATQ3yy4fpSXFNkhxF5wonAUp7oITBYMUIiLyFwOUEPbqq/LLvVcvazBw+LAMTgBrywlgDVLMZjl4FpBBRnS0DFLmzQPmzrUOiHUWnCiUPEajPM5ZeZyJjJT5KirkcURERN5ggBLCpk+XU3ZPnJCBAiBn7yiBiRKoALL1xGyWzxkMMq2tTbaoxMcDTz8NLFwoAweTSd5cUfJERsrjnJXHGaNR5hswQB5HRETkDQYoAeZo0bIzZ4A1a9xv2tc+n+3uxUeOyC/91FSgXz/ZYqIEJco9AERFyZaPtjagqUkGJ6tXA+PGya6eFStk0NHW5jxIMZnk85GRMr+yLoqj8gDy/vRp+8dHjsh8XBeFiIh8wQAlgJQxGmvWWMdeKJv7vfWW652FneVrHxQ0NsrAIyZGPm8bnADAxYsyQGgfnCjcBSnOghOFo/J8/z1QXS3vGxsZnBARkf8YoASIo0XL7r4bWLBA7jx8+eXy3lGQYrtDsaN8SlDQuzewb58cU5KcbF1JVqGMQWlulgFM++BE4SxIcRecKByVRxmQu2+fTGdwQkRE/mCAEgCOFi3r2RPYvRv4299kt0xMjPzCbh982AYnAwY4z5eaCvzoR3J8idEogwllJo/CtiWld2+gb1/nZW4fpCg3d8GJwlF5jEb5+Ec/ks8TERH5igGKnxxNvVXGZOj1sstl0yYZaOj19sFHRYV9cKLXy3M6y1dVBfzv/wI9egDnzsmgICrKviVFqwX695fPu5viaxukKANiPQlOlKDKtjx1dfL+f/9XprvqziIiInJHI4QQXV0Id+rr65GYmIi6ujokJCR0dXEsnAUnyliMmBjZqlFXB6SkyO6WtDS50/DOnXK117g4YOhQa3Biy1m+Awfk5oBCyK4erVYGJM3NcuxHRoZ3A1VXr5ZTiRcu9Dw4sQ2qzpwBtm0Dhg+3vj5Pd1ImdQjVz6AraiwzUbjx53PIFhQfeRKcaLVyLZLERKC2Vi6WduaMzFdXJ4+tr3c+ZddolM8fPCjzG43y+C++kF07ycny/Fqt/DkpSQ6ONRq9Wyxt8mTg2DHfghNABiA33GANRNq3ALElhYiIvMUAxUeOFi07f162dkRH2y+iFhEhZ9ScPStbGior5ayXXr3kfWWl42s4yrdtmzxPfLw8r0Krlde9cEGWAwj8Ymnl5fL6+fmOW3xs6fUy37Zt8jgiIiJvMEDxkaNFy5KSZFdMc7P9gNW2NjnDJTVVdoPk5clumBMn5H1enuNrOMo3fLg8T0ODPK9Cmb0TFyfLAQR+sbTrrpPXP3RIduO40toq8w0fLo8jIiLyBgMUHw0YANx0k2zN2LvX2q3Ss6cctNrUJIOGtjbZxXHhgpxZk5ZmnTnT1CS/yJUWmAMHgFdese5SHBlpnaWj1crHaWkyQLlwQbaqtLXJ69TWyltkpLW7ad8+2Zpy++3WMSiOFpLbsAEYMsR+U8EvvgCuv17eK9LS5JiSQYPk8c6ClNZW4KuvZHA0dizHoBARkfc4SNZHthvvAXKcyWWX2Y9FaWiQgYTtF3lxsQxMvvnGuuDakCGyheSDD6yBzs03y4GvBw/K88THywGvzc3Al19azxcRIfM3NVnT+vaVwUpdnRxIqyzY1revdTyKspbJd9/JsSfKNVavluNZ7rhDzsbJzATeeQcYPdp6fmdjUQBrcHLwoByLc/nlXBMlHITiZ9AdNZaZKNz48zlkgOID2+BEp7MudGYbpDQ2At9+63gArLJXTlKSbOHQauUGf2azDDja2uR5k5Pl/SWXyEGsjY0y4PGURiPHpSgLt+XmysClVy/ZupGSImf6NDVZ80VHWxddU8qXkeFZkGIbnLS0yHKfOMFVZcNBqH0GPaHGMhOFG87i6US2wUlEhPUGyBaLvXvlF/7+/c5n57S0yCBFWcPEdsyKVisDC5NJdh8lJcmAQafzLjgBZNCg18vrNDYCe/YACQnyfAkJ8nFjo3xer5dlamqS142Nlek9esiupDvucN3d09RkH5z06WMNijyZSURERGSLAYoX2gcnOp1M1+nsg5Rvv5UtEArb1V4V9fUyEKittU9vbZXdMoqDB2UgcfKk9+U1GuVCcS0t9uerrJT3ipYWa15Fba0MXvR6z4KU9sGJMq7Gm+nORERECgYoHnIWnChsgxTbgKB9PluNjR3TlOBEaUkxm2Ug4yul68j2fMeOWZfJt92/p72zZz0LUsaOlSvntg9OFAxSqFt4/nn5oVJuer1MIyKfMEDxgLvgRGE7tRiwBgS+jPIRwrfjXJ3P03TbFh93QUpFBfC738mWI0fBiYJBCoW1558HHnnEPq2tTaYxSCHyCQMUD8ydax0Q66pFpH2A4k+QEeihy47K4qp8tkHKuXPyXq+XY2KqqoCnnpJpjhascybQC8cRhQRHwYmtRx4BbrwRWLfOfvEiInKJAYoHFi60bqinzNhxRNvu3VRaen3h63Guztf+nK7KZxu4JCfL+9ZWOasnMxN47DGZ5mjBOmcCvXAcUZdzF5woPvoI+MUvgPvvZ5BC5CEGKB6YPFm2GGi1sm5xFqS0D1CEsI798JY/wY2z83mabhucpKbKGT2trUBNTccpx8p6KgUFcsqyq32FPN28kEgVPA1ObK1YIfuMicgtBigeqKgANm6U02YBx0GKySTTIyOBkhJrsGIyOQ9SYmOdX9PXsSvuzqfVyvVJtFr5WBlAGx3d8Rh3wYnCXZDC4ITCji/BiWLqVDmNj4hcYoDihu2uxQMGyMXYAPsgxTY4WbECWLVKLmLWPkixlZAgA4CUFPv09vm8YTB0DIRsl8sHZJCQlyfvbY+LjJTrnihSUjwLThTOghQGJxR2/AlOFOnp9vP6iagDn74Oly5ditzcXERFRaGwsBBbt251mf/dd99F//79ERUVhUGDBuHDDz/0qbCdzTY4yc2VLSiXXWYfpCg3JTiZPFk+N316xyAFkMFCUpKcknvxolx8zXbgrS+tJkoA0tZmPV5JU1pOdDoZEJ0/LxdVq6+Xy9DHxspytLbKMsXEyHyNjTLdk+BE0T5IaWpicEJh6Mkn/T9HSwswb57/5yEKY14HKGvXrkVpaSkWLFiAr7/+GkOGDEFxcTFOnz7tMP+XX36JSZMm4Z577sGOHTswYcIETJgwAbt37/a78MHUPjixXXjMNkgxmToGJ4r2QYpWCyxdKjfly8iQX/6ADFguvdTa7eKMoxlEjz0GvPWWdRCvVgtccQVwyy3WTQkjI4Gf/1zu+WMwAIcPy6Dh3XeBNWvkHjzNzfJ+7Vpg/XpZvnPnPA9OFO2DFAYnFHbmzw/MeT77LDDnIQpXwksjR44UM2bMsDw2mUwiOztbLFy40GH+2267Tdx00012aYWFheL+++/3+Jp1dXUCgKirq/O2uD7Zu1eIq68WIitLiFGjhBgzpuNt1CghEhOF0OuFeO451+d75RUhUlLkveLtt4VIShKiRw/rNXr2VCb+drxFRAhhMMh7JW38ePtrxMcLccUVQvzud0IsWCDEpElCpKXJ+wULZPp11wkxYoQQ//639dh//lOIwYPlveLf/xaiuNg+n7fv4axZ8p7Ur7M/g4EQ1DI/95zzD6unt9jYwJeLKMT48zmM8CaYMRqN2L59O+bOnWtJ02q1KCoqwpYtWxwes2XLFpSWltqlFRcXY/369U6v09LSghab5VjrO3FAmbOWk/aUlpQjR+QA2p/9zHkrwfTp9tNqKyqA11+XA1OVa1RXyx2QFUoXjdKi0tYm05RWlLY2OXNx9Wq5kmtVFVBUZL+7cL9+8qbQ64HCQnn9zZvlc2lpwLhx8mZr9GigrMyDN8yJAQOAP/3J9+OJvNWp9cbs2fLen7EoL70UmLIQhSmvunjOnj0Lk8mEjIwMu/SMjAxUVVU5PKaqqsqr/ACwcOFCJCYmWm45OTneFNMvnbHwmKNrfPed9XnbQa22PyvjWJQF44xGuYhceTmwbRuQn28NTpzR62W+bdvkcUThotPrjdmzgeee8+3YP/8ZuOeewJaHKMyE5CyeuXPnoq6uznI7fvx4p127MxYec3SNvn2tz9uOQ7H9WWk9URaMi4yUi8hddx0wfDhw6JAc7OpKa6vMN3y4PI4oXHRJveFtkKLVAm+/zeCEyANeBSipqanQ6XSorq62S6+urkZmZqbDYzIzM73KDwAGgwEJCQl2t87SGQuPObpGRgbQv781T/tl6PV6Wbe1n9I8ebL9rsIVFc6DlNZW+fygQTJ/WprnZSYKdV1Wb3gapGi1wF/+0nE0PRE55FWAEhkZiWHDhqHcpm/AbDajvLwco0aNcnjMqFGj7PIDwMcff+w0fyjojIXHPAlSFK6CE4W7IIXBCVEQuQtSGJwQec3rLp7S0lIsX74cb775JioqKjB9+nQ0NjZi2rRpAIApU6bYDaJ98MEHUVZWhj/84Q/Yt28fHn/8cWzbtg0zZ84M3KsIgs5YeMxZkGLb3aPTuQ9OFM6CFAYnRJ1g9mzZ7KksOa1gcELkE68DlIkTJ2LRokWYP38+hg4dip07d6KsrMwyEPbYsWM4deqUJf+VV16Jd955B6+//jqGDBmCdevWYf369Rg4cGDgXkWQdMbCY46u0dQk10XR662BibvgRNE+SGlqYnBC1KkaG2Vril4vFxdicELkE40QgdzxJTjq6+uRmJiIurq6Th2PolCmHldUWAOKQC885ugaX38N3H23bFnxJDixdeaMXCRu2zY5IJbBCfmjqz+DvlBjmYnCjT+fQ6/WQemulIDh1VetM3A64xrKdebOlbN1vPknTGlJKS+Xs3UYnBARkZqwBYWI3FLjZ1CNZSYKN2HfgqLEUJ25oiwRWSmfPRX8P2PBeoOo6/lTd6giQGloaACATl1Rlog6amhoQKKyU2aIY71BFDp8qTtU0cVjNptx8uRJxMfHQ2O79nsnqq+vR05ODo4fP66a5mI1lhlQZ7nVWGbA83ILIdDQ0IDs7GxotSG5AHUHrDd8p8Zyq7HMgDrL7U2Z/ak7VNGCotVq0atXr64uBgB0+sq2gaDGMgPqLLcaywx4Vm61tJwoWG/4T43lVmOZAXWW29My+1p3qONfISIiIupWGKAQERFRyGGA4iGDwYAFCxbAYDB0dVE8psYyA+ostxrLDKi33Gqh1vdXjeVWY5kBdZa7s8qsikGyRERE1L2wBYWIiIhCDgMUIiIiCjkMUIiIiCjkMEAhIiKikMMAhYiIiEIOAxQiIiIKOQxQiIiIKOQwQCEiIqKQwwCFiIiIQg4DFCIiIgo5DFCIiIgo5DBAISIiopDDAIWIiIhCDgMUIiIiCjkMUIiIiCjkMEAhIiKikMMAhYiIiEIOAxQiIiIKOQxQiIiIKOQwQCEiIqKQwwCFiIiIQg4DFCIiIgo5DFCIiIgo5DBAISIiopDDAIWIiIhCTkRXF8ATZrMZJ0+eRHx8PDQaTVcXh6jbEUKgoaEB2dnZ0GrV8X8N6w2irudP3aGKAOXkyZPIycnp6mIQdXvHjx9Hr169uroYHmG9QRQ6fKk7VBGgxMfHA5AvMCEhoYtLQ9T91NfXIycnx/JZVAPWG0Rdz5+6QxUBitI8m5CQwIqGqAupqauE9QZR6PCl7lBHZzIRERF1KwxQiIiIKOQwQCEiIqKQwwCFiIiIQg4DFCIiIgo5qpjFQ0HQ1gasXw+cOAH06gVMmABE8M+BiIhCA7+RuqO2NmD6dODjj4HWVkCvBzZvBl55hUEKERGFBHbxdEfr18vgJDERKCiQ95s3y3QiIqIQwH+Xu6MTJ2TLSXKyfJycDJw9K9MDgd1HRETkJ35rdEe9eslunXPnZHBy7px8HIg9Vth9REREAcAunu5owgRg7Figrg44eFDejx0r0/3F7iMiIgoA/kvbHUVEyBaNYHTDBLv7iIiIugUGKGrmz1iPiAjg1lsDXyZ33Uccn0JERB7gN4NahepYjwkTZDk2b5YtJ3q9tfsoVMtMREQhh98KamU71kNpqVDGegSjZcRTrrqP1q0LzTITEVHIYYCiVqE81sNZ91Eol5mIiEIKAxS1CvZU4WCME/GkzByjQkREYICiXq7GevgjmONE3JWZY1SIiOgHrPXVKlhThYM5tsVdmUN1XA0REXU6BihqFoypwso4Eb0eOH9e3re22o8T8acbRqsF+vUDUlOBlBT5uP2129rkzwaD/bXNZmD3bqC2Vh47cKD98UREFDYYoJC97GygpQU4dMganEREyHTAv24Ysxl46y2Zv6VFBiDFxcCdd8pAIysLqK8HzpwBNBpACJknK8v9sUREFFZYs5O9/HzZxWI2y0DAbJaP8/Pl8/4sZb97t8zbo4ds/ejRA9i0SaYDMiARwv4YJc3dsUREFFbYgkL26uuBIUNka0h9PZCQIFtN6uvl8/5MFa6tlUFPSop8nJICnDwp0wGgqkpeLykJMBqByEjZzVRVBWRmuj6WiIjCCgMUspeSAkRFyZ8zM2WgEBFhDQyUqcInTwIxMUBTk+dThVNSZNeMMoaktlY+tj13ZKQ8X3q6HCQbGSnT3R1LRERhxacunqVLlyI3NxdRUVEoLCzE1q1bXeY/f/48ZsyYgaysLBgMBvTr1w8ffvihTwWmILvsMiAuDvjyS9mV8+WX8vFll8nnb74ZyMsDvv8e2L9f3uflyXTAOkbloYeAF16Q97/6lUwfOFCOG6mpkV0zNTXy8cCB8lhXuyy7O5aIiMKK1y0oa9euRWlpKZYtW4bCwkIsXrwYxcXF2L9/P9LT0zvkNxqN+OlPf4r09HSsW7cOPXv2xNGjR5GUlBSI8lOg7d0LXLgAXHmlbL0wGuXjvXuBwYOBfftky8rVV8uxIRqN7JLZt08+726q8J13AkOHOp6J424asqtjiYgorHgdoLz44ou49957MW3aNADAsmXLsHHjRqxYsQJz5szpkH/FihWora3Fl19+Cb1eDwDIzc31r9RqorapsbW1wMWLMiiorbWOQVHGetTWyqAlNxdobgaio4HTp63Pnzghn6+pka0rUVHyPVDGqGi1MpDxhbtj1fZeExGRU14FKEajEdu3b8fcuXMtaVqtFkVFRdiyZYvDYz744AOMGjUKM2bMwPvvv4+0tDTccccdeOSRR6DT6Rwe09LSgpaWFsvjemWAptqocWpsQgLwzTdyqq8iLU2mA7K15ORJGQjodIDJJIMBpUUsLU0e29ZmPT4iQqa7E8wpzBT2wqbeICIAXo5BOXv2LEwmEzIyMuzSMzIyUFVV5fCYw4cPY926dTCZTPjwww/x2GOP4Q9/+AN+//vfO73OwoULkZiYaLnl5OR4U8zQocapsYcOybEfWq38ktdq5eNDh+zzKdOB208L3rbNGpxoNPK+rU2muxPMKcwU9sKm3iAiAJ2wDorZbEZ6ejpef/11DBs2DBMnTsS8efOwbNkyp8fMnTsXdXV1ltvx48eDXczgcDSttqUltKfGnjwpA5P8fKBnT3lvMMh0QE77zc4GrrsOGDlS3mdny3QAOHJEBibR0fK46Gj5+MgR99d2NIW5/Sq2zqjxvaaACpt6g4gAeNnFk5qaCp1Oh+rqarv06upqZGZmOjwmKysLer3erjtnwIABqKqqgtFoRGRkZIdjDAYDDAaDN0ULTe6mxgZz515fx2Mo04iVQKH9jsPKNGS9HsjIkOePirK+pj595HVMJut5tFqZ7u41+7NDM6chd3thU28QEQAvA5TIyEgMGzYM5eXlmPDDDrRmsxnl5eWYOXOmw2NGjx6Nd955B2azGdofviAPHDiArKwsh8FJWFGmxm7aZG2ZUKbGBnPnXn/GY7jbcdjVawKAp54C3nkHqK6Wg2U1Gjnr56mn3L9mf3ZodlcuIiJSFa+/CUtLS1FSUoLhw4dj5MiRWLx4MRobGy2zeqZMmYKePXti4cKFAIDp06djyZIlePDBBzFr1iwcPHgQzzzzDB544IHAvpJQpNU6nxr7j38Eb+de2/EYSmvCpk2yHO5m0Lib6uvqNQFyrMqYMXKNFGWWz6WXyvQDB1y/Zn92aHZXLiIiUhWvA5SJEyfizJkzmD9/PqqqqjB06FCUlZVZBs4eO3bM0lICADk5Odi0aRN+85vfYPDgwejZsycefPBBPPLII4F7FaHM2dRYf5aMd8fdkvLuuNsl2dV039pa2VIyfrw1Telq8uQ1+7NDsz9TmImIKKT41Jcwc+ZMp106n332WYe0UaNG4T//+Y8vlwpf/oy3cCfY4zEuXgTmzQMOH5ZjS55+2ro8vqtrB/M1ExFRWOFePF3Fn/EW7gRzPMbFi7Ib5dAh60qyH34I7NghgxRX177ssuC9ZiIiCisaIdovZBF66uvrkZiYiLq6OiQoC4aFg1CcxePOb38LvPSSXKQtOlqOMzGZgAcfBP7wB/fXDuZrpqBR42dQjWUmCjf+fA75zdCV/Blv4Y678Ri+BgqHD8uWk8hIeY7ISLmj8eHD9uf++GOgslJuJNi/v8wHBPc1ExFR2GCA0h35M8U5L0/eNzZal7rXaKzpRqPstvnvf2VLilYLbNggu3zCfVo5EREFDOdgdkf+LCl/++1AbKz8WVnSPjZWpgPAyy/L4CQqSi7kFhUFbN0q04mIiDzEFpTuyJ8pzk1NwLXXyoXYlNk4GRkyHZDdOmYzEB8vH8fHy+cqK4PzWoiIKCwxQOmOlOm+J08CMTEygLCd7utqfEpKimwxGTHCOo24psY6hTkvT3brnD8vW08uXpSPlS4gIiIiDzBA6Y5uvhlYulR2vSjjREaOlOnuxqe4m8I8Ywbw5z8DBw8CDQ1yfEpBgUwnIiLyEAOU7mjfPrk/ztVXW9cySUqS6e6Wo3e3pPyBA8CQIXKZfaNRDozt1Uumc5VXIiLyEAOUYHPVXeLvWiWuzu3qudpa2TpSWGg9V/vl6PV62U2j7EhsOz7Fk6Xui4o6npuIiMhDDFCCyVV3iVbr+47D7s4NuO6mcbUcfXa2LM+hQ9bgJCJCpnsi2MvsExFRt8AAJZhsp/O27y7p18/3HYfdnRtw3U3jahxJW5s87swZGagA8nF+vmevOZjL7BMRUbfBACWYXE3nTU31b8dhd1OFXT3nahxJfb0cQxIRIX9OSJBBS329Z+VyN0aFiIjIAwxQgsnV7r3+doX06iWDiMpK+64YZaqwu12DjUbgzTc77kickiL32OnRQ27u134asSfcLbNPRETkBgOUYHK1Y7FW619XyLhxwKOP2u8qXFAg0yMiXO8a7GpHYnbREBFRCGCAEkwREXJgqrPZNP50hWzYIAONnj2tLSjNzTL91ltdX3fePBmc2O5IfPCgTP/DH9hFQ0REXY4BSrC52r3XXVeIq2nIyhiUggJr/oMHreNMXF1X2ZE4Olo+jo6Wi6opOxKzi4aIiLoYA5RQZTa7nobsanyLO336yG6d5mZrC4pGI9OJiIhCANvtQ9Xu3dZpyAMHyvtNm2Q6ILtsxo4F6upky0ldnf04E1eeflq2vJhMsuXEZJKPn346mK+IiIjIY2xBCVW1ta6nIbsb3+JKVJQcEDtvXsdZPERERCGAAUqoSkmRXTZffWW/X47tdF9X40zciYqSA2KJiIhCEAOUUNW/P3DqFPDf/9rvONy/f1eXjIiIKOg4BiVUffABcOSInEZ86aXyvrJSphMREYU5BiihSplGnJ0tu3ayszvuKkxERBSm2MUTqvyZRhxsrtZnISIiCgAGKKHK1TL5Xcnd+ixEREQBwAAlVPkzjTiYbNdnUTY53LRJLo3P1WeJiChAGKB4oq2tawIFf6YRB6sbxt36LERERAHAAMWdtjZg+nTg44/lIFW9XrYgvPJK17dmOBPMbpiUFHk+JfCprZWPbddnISIi8hMHDbizfr0MThIT5XLwiYnyi3/9+q4umXPulsn3x8CBMtipqZHnq6mRjwcO9P/cREREPwjRJoAQokz3TU6Wj5OT5aDVUJ7uG8xuGK1WtsQMHcpZPEREFDQ+BShLly7FCy+8gKqqKgwZMgQvv/wyRo4c6fa4NWvWYNKkSRg/fjzWd0ILhMlkQmtrq38nycsDcnNlN0ZiotyULzdXpl+8GIhiBl5yMpCZKbunkpKA8+fl4+TkwJW5Xz/rz0aj5cfIyEhoGayQipnNZhht/qYp+PR6PXQ6XVcXg0KM1wHK2rVrUVpaimXLlqGwsBCLFy9GcXEx9u/fj/T0dKfHHTlyBA899BCuuuoqvwrsCSEEqqqqcP78ef9PVlAAPPcc0NxsTYuOli0HlZX+nz8Y9HqgpEQGI8o+PlFRMj3IZdZqtcjLy0NkZGRQr0MUDEajEZWVlTCbzV1dlG4nKSkJmZmZ0Gg0XV0UChFeBygvvvgi7r33XkybNg0AsGzZMmzcuBErVqzAnDlzHB5jMpkwefJkPPHEE/j8888DEzi4oAQn6enpiImJ8f8PPi9Ptpy0tcmBsYmJ8ks/lAkhAxRlH5+oqKCX2Ww24+TJkzh16hQuueQSVjSkKkIInDp1CjqdDjk5OWwJ7CRCCDQ1NeH06dMAgKysrC4uEYUKrwIUo9GI7du3Y+7cuZY0rVaLoqIibNmyxelxTz75JNLT03HPPffg888/d3udlpYWtLS0WB7X19d7XEaTyWQJTnr06OHxcW5FRwfuXAoh5Aqxyuyg5GT7IEII2XJjMgE6nSyDN1/6wSizG2lpaTh58iTa2tqg1+s7/frUfflTbwBAW1sbmpqakJ2djZiYmEAXj1yI/qGuOn36NNLT09ndQwC8nMVz9uxZmEwmZGRk2KVnZGSgqqrK4TH//ve/8cYbb2D58uUeX2fhwoVITEy03HJycjw+VhlzEvIVjBDA0aNysG1Vlbw/elSmK8/X1MjnTp+W9zU11udDlNK1YzKZurgk1N34U28A1r9Zdk92DaXO9nvcIIWNoLZhNjQ04K677sLy5cuRmprq8XFz585FXV2d5Xb8+HGvrx3y3QvnzgH19bJlJCpK3tfXy3RAtpzU18supehoeV9fbz8WJgSF/PtOYSsQ9QbAv+Guwved2vOqiyc1NRU6nQ7V1dV26dXV1cjMzOyQ/7vvvsORI0fws5/9zJKmDD6LiIjA/v370bdv3w7HGQwGGAwGb4qmPq2tsjVEWewtIkKOcVH+ezCZOj7f2irTiaiDblFvEHUjXrWgREZGYtiwYSgvL7ekmc1mlJeXY9SoUR3y9+/fH7t27cLOnTstt5tvvhnXXHMNdu7c6XUTbFjR6+V4krY2+bitTT5Wxm3odI6fZ98sERF1A17P4iktLUVJSQmGDx+OkSNHYvHixWhsbLTM6pkyZQp69uyJhQsXIioqCgPbrTCalJQEAB3Su53kZNllU19vDT4SEqwLwkVHy8f19bLlRHm+Cwa+EhERdTavA5SJEyfizJkzmD9/PqqqqjB06FCUlZVZBs4eO3aM0/M8odEAvXs7n8Wj0cgl6mNifJ/F84NVq1bh17/+ddCndxNReGHdQV3Jp0hi5syZOHr0KFpaWvDVV1+hsLDQ8txnn32GVatWOT121apVnbKKbKiZOnUqNBqN5dajRw9cf8MN+PbECSAjQy781j740GhkgBIfL+81Gjz++OMYOnRo0Mv7zTffYNKkScjJyUF0dDQGDBiAl156KejXJSJ7DuuO66/Ht99+69V5OqvuAIAHHngAw4YNg8Fg6LRrUvhhU4crFy4Ar70GXHkl0LevvH/tNZnug+uvvx6nTp3CqVOnUF5ejoiICIwbNy7AhQ6M7du3Iz09HW+//Tb27NmDefPmYe7cuViyZElXF40o5AW46lBV3aG4++67MXHixK4uBqmZUIG6ujoBQNTV1bnN29zcLPbu3Suam5v9u2hFhRDZ2UJoNPIGWH/OzpbPe6GkpESMHz/eLu3zzz8XAMTp06ctabNnzxYFBQUiOjpa5OXliUcffVQYjUYhhBArV64UAOxuK1euFEIIce7cOXHfffeJ9PR0YTAYxOWXXy7++c9/Wo5LTEwUZWVlon///iI2NlYUFxeLkydPevUafvWrX4lrrrnGZZ6Avf8UUrz5DIYKb8scqL/dAFcdqq47FixYIIYMGeJRXtYd4cmfuoO7GTty4QJw3XVAdbX9wmjKz9XV8vn9+4G4OB8vcQFvv/028vPz7Va8jY+Px6pVq5CdnY1du3bh3nvvRXx8PGbPno2JEydi9+7dKCsrwyeffAIASExMhNlsxg033ICGhga8/fbb6Nu3L/bu3Wu3GmNTUxMWLVqEt956C1qtFnfeeSceeughrF692uMy19XVIUXZIZmIOuiEqkOVdQeRLxigOLJ6NXDqlPNVW00m+fw77wD33efxaTds2IC4H2qlxsZGZGVlYcOGDXaDih999FHLz7m5uXjooYewZs0azJ49G9HR0YiLi0NERIRcd+aHpfI3f/ABtm7dioq9e9Hv0ksBAH369LG7dmtrK5YtW2ZZd2bmzJl48sknPS77l19+ibVr12Ljxo0eH0PU3QSp6gh83fGDzZs3y7qjogL9ftihPNB1B5GvOAbFkTffDGy+Hyjrv+zcuRNbt25FcXExbrjhBhw9etSSZ+3atRg9ejQyMzMRFxeHRx99FMeOHet4Mpul8ndu2YJeGRnoZzA4rRljYmLsFsXLysqybM7lzu7duzF+/HgsWLAAY8eO9eo1E3UnQao6Alt32Ni5cyd69eplCU4c8afuIPIHAxRH2rfPOiKE3B/HC7GxscjPz0d+fj5GjBiBP//5z2hsbLTsU7RlyxZMnjwZN954IzZs2IAdO3Zg3rx5MBqNHU9ms1R+tNJWbLtUfjvtN+7TaDQQHuzrs3fvXlx33XW477777P5DI6KOglR1BLbusBHtwbpKvtYdRP5iF48jGRlAZaXrmkajARws7+8NjUYDrVaL5h/21/nyyy/Ru3dvzJs3z5LH9j8kQK7mazKZ7JbKH3zppThRXY0DR46gX7uNHP2xZ88eXHvttSgpKcHTTz8dsPMShatOqjr8qztsDB48GCdOnMCBAwdctqIQdQUGKI6UlAD/+Y9n+bzQ0tJi2fX53LlzWLJkCS5cuGDZq6igoADHjh3DmjVrMGLECGzcuBHvvfee3Tlyc3NRWVmJnfv2oReA+IQEjBk5ElcPG4ZbfvtbvPjss8i/4grs27cPGo0G119/vVdlVOzevRvXXnstiouLUVpaaim3TqdDWlqaT+ckCndBqjoCW3f80K0THx+PMWPG4Oqrr8Ytt9yCF198Efn5+X7XHQBw6NAhXLhwAVVVVWhubsbOnTsBAJdddhl3iybPBXxOURB0+jTjhgY5H1Cnk3ME2990Ovl8Q4PHpywpKbGb4hcfHy9GjBgh1q1bZ5fv4YcfFj169BBxcXFi4sSJ4o9//KNITEy0PH/x4kVxyy23iKSkJDlV8Mknhdi5U9T8619i2i9+IXr06CGioqLEwIEDxYYNG4QQ1qmCtt577z3h6te/YMGCDtMSAYjevXu7fJ2cKhieOM3YM0GoOoJXd/wwzbimpkZMmzYtYHWHEEKMGTPGYf1RWVnp9BjWHeHJn7pDI0TodybW19cjMTERdXV1SEhIcJn34sWLqKysRF5eHqKiony/6L59cj7gqVPysRDWlV6zsoDycqB/f9/PHwg/zOJxuFR+FwnY+08hxZvPYKjwtsyB+ttVQ9URilh3hCd/6g528TjTv79crOCdd4BVq+Tot8xM2TZ7xx2+L2IQSBqNXCKfiEKGGqoOIjVggOJKXJxcrMCbBQuIqNtj1UHkP04zJiIiopDDAIWIiIhCDgMUIiIiCjlhG6CoYHJSWOL7TmrHv+Guwfed2gu7AEVZlrmpqamLS9I9KUtr2+6GSqQGyt+su+XhKTiUOrv90vrUfYXdLB6dToekpCTLZlYxMTHQdPHaIN2F2WzGmTNnEBMTg4iIsPvTojAXERGBmJgYnDlzBnq93m6nYAoeIQSamppw+vRpJCUl8Z8bsgjLbxFlO3HuuNn5tFotLrnkEgaFpDoajQZZWVmorKzssI8NBV9SUpKl7iYCwjRAUSqa9PR0tLa2dnVxupXIyEj+50mqFRkZiYKCAnbzdDK9Xs+WE+ogLAMUhU6n4x89EXlFq9VyqXWiEMB/dYmIiCjkMEAhIiKikMMAhYiIiEIOAxQiIiIKOQxQiIiIKOQwQCEiIqKQwwCFiIiIQg4DFCIiIgo5DFCIiIgo5DBAISIiopDDAIWIiIhCjk8BytKlS5Gbm4uoqCgUFhZi69atTvMuX74cV111FZKTk5GcnIyioiKX+YmIiIi8DlDWrl2L0tJSLFiwAF9//TWGDBmC4uJinD592mH+zz77DJMmTcKnn36KLVu2ICcnB2PHjsX333/vd+GJiIgoPGmEEMKbAwoLCzFixAgsWbIEAGA2m5GTk4NZs2Zhzpw5bo83mUxITk7GkiVLMGXKFI+uWV9fj8TERNTV1SEhIcGb4hJRAKjxM6jGMhOFG38+hxHeZDYajdi+fTvmzp1rSdNqtSgqKsKWLVs8OkdTUxNaW1uRkpLiNE9LSwtaWlosj+vr670pJhF1Q6w3iMKLV108Z8+ehclkQkZGhl16RkYGqqqqPDrHI488guzsbBQVFTnNs3DhQiQmJlpuOTk53hSTiLoh1htE4aVTZ/E8++yzWLNmDd577z1ERUU5zTd37lzU1dVZbsePH+/EUhKRGrHeIAovXnXxpKamQqfTobq62i69uroamZmZLo9dtGgRnn32WXzyyScYPHiwy7wGgwEGg8GbohFRN8d6gyi8eNWCEhkZiWHDhqG8vNySZjabUV5ejlGjRjk97vnnn8dTTz2FsrIyDB8+3PfSErlTUQE88IC87w7XJSIKU161oABAaWkpSkpKMHz4cIwcORKLFy9GY2Mjpk2bBgCYMmUKevbsiYULFwIAnnvuOcyfPx/vvPMOcnNzLWNV4uLiEBcXF8CXQt1eRQXwy1/K+2++AZYtAwYMCN/rEhGFMa/HoEycOBGLFi3C/PnzMXToUOzcuRNlZWWWgbPHjh3DqVOnLPlfffVVGI1G3HrrrcjKyrLcFi1aFLhXQaQECQcPArm58l4JGsLxukREYc7rdVC6AtczIJfaBwmRkYDRCBw5AhQUBK9Fo6uu2wXU+BlUY5mJwo0/n0PuxUPq5ihIAOR9MFs0uuq6RETdBAMUUi9nQYIiWMFCV12XiKgbYYBC6uQuSFAEOljoqusSEXUzDFBIXc6cAdasAV58UX7p9+plHyQ0NsqgoLHRmhYZKfNVVACvvurf9V991fF1jUbg9Gl57+i6L74oy33mjH/XJyLqJhigkHqcOQMsWQK89Rag1wN9+wInTliDgsZG4MABme/AAWuQYjTKfAMGANOn+1eG6dPleWyvazQC338PVFfLe9v0EydkOfV6We4lSxikEBF5gAEKqYMSnOzaBVx+OVBVBfzoR0Dv3nLWzPnzMihpbpYtF83N8vH584GdVTNggDxPQYE8b2OjDEoaG4GYGPvHR47I8v3oR7K8l18uy88ghYjILQYoFPpsg5MBA2QgMGCANUhJSwP27pVBSVQUEBEh75ubZXp2dmCn/CpBSu/ewL59QEODLJNOJ+8bGmR6drY1OLEtN4MUIiK3GKBQcLha+t3dsvC2z7cPTvR6mUevl48PHJBjPwBACMBkkgGCySQft6eMYfE3OEhNlcGHwSC7ctraZKtJW5t8rJTz6FHH5WaQQkTkktdL3RO55Wrpd3fLwts+/9//2rdAKF/yivPngf37gXPngJQUoL4eaGqSzzU1yRaLfv2AkyflOZ95Bti8Gdi2TZ5/5kzZ+uItJWiqqgL+93+Bjz6S4080GhkUpaYCmZnyutHR9gEL0DFI8bUcRERhjC0oFFiuln53tyy87fM9ewK7dwN/+5v8wm8fnJw5A2zYIIOUHj1kd05Li32e1lYZMOTmykDmjjuAL77wbyxI+xadxEQZjEREAGaz7OYRQrbi5OYCZ88CW7fazyoC2JJCROQGAxQKnPYBSEyMNRC56y55O3hQfjlv2ybvlSBlwwb7Y1ta5Jf+xYvApk0dv8C3bZNf/vHxslvlwgUZINhqa5NlamgAtFrZ4lFVBfzf/8mgx9vgYPVqoH9/4P33gfx82TKydau8dm6ufD0pKfJ6Fy/KY1JSgFOngMrKjufT6+V5tm0DbHYId/i+BmunZO7CTEQhil08FBiuln5PTwe+/VY+TkkBjh2TPx87BlxyiTx28mQ5niM/Xx6TlCRbHRoagJoaGcCMG2ftChk+XAYbZ87IYKZ9cALILpfWVjlQVqeT166tlcFCVRVQXOx5N8vq1cDdd8ug5Px5mRYXJ8sWEwMcOiSv1dAg08+fly0p0dFysGxeXsdztrbK44YPB667zvX7GoydkrkLMxGFMLagkP9cra7a2GhtPWhtlWM1bB07Jr/MGxpkN01rq0yPjJTdPPHx8mclSFFaO9LSgGHDnAcngEwXQt63tclbQ4PslqmtlS0znrSk2AYnOp083zffyC4og0EGGc3N8ueLF63jX86elY8HDgRiY+3P2doq37dBg5wHR8HcKZm7MBNRiGOAQv5xF5woa5O40toqv/hbWuwXWHMVpBw7BnzyieOZOo4IIY+Pjpbn8jRIsQ1OIiJkORV1dcCePR2nN1+8KAfsJiXJ4775xn4Mii/BiW13mb+BRDDPTUQUIAxQyDfK2IWnn3a89Ht1tRxb0dAgHystI860tcn7pia5+qqybLxtkKLXywCirEwGJxcudBw86865c7J7p7XVPkhJSgI++0yOk1G+oB0FJ2az7DqyLbdtmkYjx7uYTPLnrCzZwnLwoPV98DY4cbdTsjfjSLgLMxGpBAMU8p7yJbdmjVyQ7JJL7Jd+r66W6YBsuXAXnChaW+WXukZjv2y8Mo5FOY/RKPNERtrvfeMJk0m21Jw9aw1SamqA996TrTfbtsnX9vzzjltOtFr7AEU5Z1OTDFRaW2VXT2qqDM6OHZPBW2urzONrcKJoH0gog4vXrHEfWHAXZiJSEQYo5J32X3InT8r07Gy5tPuJE9bgxBetrXJMSvtl448fl60cmZmy1cRo9D44AWTApNHIYEIJUnQ62SVTUyNbPL75BnjkEcfdOsqYlvba2mRXj14PJCTI4yIjrUFV796yO8if4EShBBLK4OKKCveBBXdhJiKVYYDS1dQ0zdPZ2AUlSDEYgO++8/86zc2yGwaQrRAVFfILv39/4OabgSuukOmejj9pTznObJZdRk1N1kXWamvtx4s4ai1xpq1NBicajTxnfLyclXTsmOyyMpmAsWOdzxZytlOyI0qLzIULslXH3TgSb84dyN2fiYh8xAClK9l2lYT6f6vuxi4cOiRbUAKlrU22aDQ2ykAiMlLOhklKkvdjx8ovZn8JYR3/EhMjW4Ly863Pt7bat5jYtqa016OHNTiJjZXdUtXVsgvsyBHg66+B3/3O+e/Z0U7JjjQ2ylYq5To5OTLdVeuHp+cGArv7MxGRjxigdBU1TfN01z1w7pyc0RIMRqNcV0SvB3bssLZuDB4MjB4duOuYTDI4iY0FMjJka43CNkjRah0PzI2NlTOEbIOT77+X5wRkK5O733P7nZIdBRJKcNLYKN+XSy+1n8LsLEjx5NyATA/k7s9ERD5igNIV1DTN011wYjsg1l/tu1MUNTWy5eL0aeuy8ceOybEizo7x5dqHD1sXYXMXpNi2pOTlydYTd8GJJ79nV4GEu+BE4WuQwuCEiEIIA5TOprZpnu7GLgRizAlgHQMSESFvtsxmuZcOIL/sKyvlcvUXLsgv/ejowFy/tVXuPqxwFKQAsrXFZJItKZdeKtc9SU+X+Z0FJ95MFXYWSJw4IYOTmBjnwYnC2TgSZ+dmcEJEIYYBSmdS4zRPd2MX+vZ1fqwyZdiTVg4lONForGNCbClBisEgWyzGjJGtCBcvOu928Yay0V/v3vbpyclyKrJCWZE2MhJYuVJOTy4okEFJXJzr4EThyVTh9oFEU5MMiuLjZYDi7vW6Gkfi6NwMTogoxDBA6SxqnebprlsgLs5xC4anXS/KF62yvoirNVOEkGuVfP+9HHh6yy3yy7qpSQYuycmeXdMZk8k+OFJaFYYMAZ57Tv5uTCZ5v2KFnOLb/v1xF5woPJkq3P7cAwbIxeMGDPB/HEn7czM4cauiArjzTnnr6o8lUXfAAKWzqHmap6sg5eRJ6wJrzthOB87Lk10TOp3sDmlrkwGOTmcfnDg6n5Lnk0/k46wsYOhQ2apgNMrzKDNpfBmbIoQchwJ0/JKfPVsGJTk51uBEobw/t98uu4SUxdk8nSrc0CBfm6MxKrbnXrZMbpgYqHEk7c/N4MShigrgZz8DCgtlfLh2rf2Cw0QUHBohfF1MovPU19cjMTERdXV1SEhI6Ori+MbTFhQgdMcDOHoN58/L3YIBGTAoOxU7kp8vx1Aor+u77+QXvaM1TZQxKe3p9cCtt8pAR1mVdcQIYMYMOWC3Rw+Zp6FBrmmiHNM++HF0bq1WvtcJCb6//57+nhsbZZfVhQsyYOvf3zqmxJPfv6PrBPHvRo2fwUCUecMG2VDXPg6MiJANa2+9FTofT6JQ5M/nkC0onSUcpnk6Grtw+rSc8jt4sAwCbNcQsdU+OBkwQLYGPPusfWuH8rMSQLRvCRkwwNq6pKzKOm4c8M47cpBqTY0cl9LYKJebj4mRrTRRUdZz2AYnUVHW/XMSE2V+f95/T6cKOwtOAM+6+TiOJOBsxylXVABXXilbThz9Ctva5CQytqQQBQ8DlM4UDtM8HY1deOsteSsokOuhGAz2xxgMMr3966qokANDExOti64pS9ED9i0dSgBx/jzw1Vcdl4wfPdoapJw7J+/Xr5ft8fHxcv8d2yAFkI9bWuTzS5bIcwbi/Xc3VdhVcKLwJUgJ5b+bEGe7ZuKttwKXXQZs2eL6GAYpRMHFAKWzhcM0T0djFwYMAB5+WH7hKxv8Adauh5YW+bzt61LG5eTny2+E9kGKbXBy2WVAv37yCz462vF+NkqQcs018n70aNm6snq1fZCi1doHJ6tXy5kuDz8su6nal9Of96j97/n4cetUYWfBicKTsUgcR+I3296yxERrj6UnGKQQBQ/HoHQV21qxVy85JVQNwYkzyuupqJBdLBcvWoOTqCh5U75MbVtQbMdRNDTIbwez2RqgKMFJfLx/AdyGDdbxLtHRcr8fJTgZN86+/O3LGYj3Rfk9HzkiAyODQQZmKhmLpMbPoCdlbh+c+LrmIMekEDnGMShqFE7N87a1fH6+XEQsOto6s+bSS2W6u5VN4+OtLSmBDE4A+5YUZ8FJMLYdCOZUYfJLoIITQLak7N4dGpPuiMKFTwHK0qVLkZubi6ioKBQWFmLr1q0u87/77rvo378/oqKiMGjQIHz44Yc+FTbshEPzvKPZJLGxsjsmLU3ex8Z6vvy6EqRERwcuOFEoQcqgQc6Dk2BsOxDMqcLkE9tfe3x8YHZrSEjg3opEgeR1gLJ27VqUlpZiwYIF+PrrrzFkyBAUFxfj9OnTDvN/+eWXmDRpEu655x7s2LEDEyZMwIQJE7B7926/Cx8WBgwA/vQn9X4JOVvfJTZWfsG2n53iyfLr8fHAyJGBDU4U48bJQQOOgpNgbjvQ/vccDmORVKp9cHLggP/n1Ovl8jj8dREFjtdjUAoLCzFixAgsWbIEAGA2m5GTk4NZs2Zhzpw5HfJPnDgRjY2N2LBhgyXtf/7nfzB06FAsW7bMo2uqsf+72wjk+i6dOS7Hk3J3RrCgkrFIavwMOivzAw/I2ToZGbJbJhDeftt+7T4ikjptDIrRaMT27dtRVFRkPYFWi6KiImxxMidvy5YtdvkBoLi42Gl+AGhpaUF9fb3djUJUINd36axxOaG07UA4jUXqYp7WG8r2UoHa5/K55xicEAWDVwHK2bNnYTKZkJGRYZeekZGBqqoqh8dUVVV5lR8AFi5ciMTERMstJyfHm2JSZwvk+i6dMS4n1LYdCIexSCHA03pDebsvu8z/aw4aJHdBIKLAC8lZPHPnzkVdXZ3ldvz48a4uErkTyDEVwR6X426HZluudgUOJLWPRQoB3tQbAwbIKcH+bII9aBDw7be+H09ErnkVoKSmpkKn06G6utouvbq6GpmZmQ6PyczM9Co/ABgMBiQkJNjdSAXUsvx6OGw7QB14W28MGAA88YRv12JwQhR8XgUokZGRGDZsGMrLyy1pZrMZ5eXlGDVqlMNjRo0aZZcfAD7++GOn+Unl1DKmIhy2HSC/PfwwMHy4d8cUFjI4IeoMXnfxlJaWYvny5XjzzTdRUVGB6dOno7GxEdOmTQMATJkyBXPnzrXkf/DBB1FWVoY//OEP2LdvHx5//HFs27YNM2fODNyroNCiljEVnOrb7UVEAJ9/LjfE9sS11wL/+U9wy0REktcBysSJE7Fo0SLMnz8fQ4cOxc6dO1FWVmYZCHvs2DGcOnXKkv/KK6/EO++8g9dffx1DhgzBunXrsH79egwcODBwr4JCj1rGVKilW4qCJioK+PJL4Pe/77h5tq3iYqBdYzARBRH34iECgrcXT5hQ42fQlzK3tQF//CPwu9/JnxW33SY3xiYi73AvHiJ/qaVbioIqIkKOS2ltldtBKTcGJ0SdL6KrC0AUMpRuKSIi6nKqCFCUXiiuKEvUNZTPngp6hC1YbxB1PX/qDlUEKA0NDQDAFWWJulhDQwMSExO7uhgeYb1BFDp8qTtUMUjWbDbj5MmTiI+Ph8bVMPsgqq+vR05ODo4fP66qQYJqKzOgznKrscyA5+UWQqChoQHZ2dnQatUxdI31hu/UWG41lhlQZ7m9KbM/dYcqWlC0Wi169erV1cUAAFWubKvGMgPqLLcaywx4Vm61tJwoWG/4T43lVmOZAXWW29My+1p3qONfISIiIupWGKAQERFRyGGA4iGDwYAFCxbAYDB0dVE8psYyA+ostxrLDKi33Gqh1vdXjeVWY5kBdZa7s8qsikGyRERE1L2wBYWIiIhCDgMUIiIiCjkMUIiIiCjkMEAhIiKikMMAhYiIiEJOtw1Qli5ditzcXERFRaGwsBBbt251mf/dd99F//79ERUVhUGDBuHDDz+0e14Igfnz5yMrKwvR0dEoKirCwYMHu7Tcy5cvx1VXXYXk5GQkJyejqKioQ/6pU6dCo9HY3a6//vouK/OqVas6lCcqKsouTyi+1z/5yU86lFuj0eCmm26y5An2e/2vf/0LP/vZz5CdnQ2NRoP169e7Peazzz7DFVdcAYPBgPz8fKxatapDHm8/K+FOjXWHGusNb8sdKnWH2uoNIITrDtENrVmzRkRGRooVK1aIPXv2iHvvvVckJSWJ6upqh/m/+OILodPpxPPPPy/27t0rHn30UaHX68WuXbsseZ599lmRmJgo1q9fL7755htx8803i7y8PNHc3Nxl5b7jjjvE0qVLxY4dO0RFRYWYOnWqSExMFCdOnLDkKSkpEddff704deqU5VZbW9tlZV65cqVISEiwK09VVZVdnlB8r2tqauzKvHv3bqHT6cTKlSsteYL9Xn/44Ydi3rx54h//+IcAIN577z2X+Q8fPixiYmJEaWmp2Lt3r3j55ZeFTqcTZWVlljzevg/hTo11hxrrDV/KHQp1hxrrDSFCt+7olgHKyJEjxYwZMyyPTSaTyM7OFgsXLnSY/7bbbhM33XSTXVphYaG4//77hRBCmM1mkZmZKV544QXL8+fPnxcGg0H89a9/7bJyt9fW1ibi4+PFm2++aUkrKSkR48ePD1gZ2/O2zCtXrhSJiYlOz6eW9/qPf/yjiI+PFxcuXLCkBfu9tuVJJTN79mxx+eWX26VNnDhRFBcXWx77+z6EGzXWHWqsN4RQZ92h9npDiNCqO7pdF4/RaMT27dtRVFRkSdNqtSgqKsKWLVscHrNlyxa7/ABQXFxsyV9ZWYmqqiq7PImJiSgsLHR6zs4od3tNTU1obW1FSkqKXfpnn32G9PR0XHrppZg+fTpqamq6tMwXLlxA7969kZOTg/Hjx2PPnj2W59TyXr/xxhu4/fbbERsba5cerPfaF+7+rgPxPoQTNdYdaqw3/Cl3V9Yd3aXeADqv7uh2AcrZs2dhMpmQkZFhl56RkYGqqiqHx1RVVbnMr9x7c87OKHd7jzzyCLKzs+3+aK6//nr85S9/QXl5OZ577jn83//9H2644QaYTKYuKfOll16KFStW4P3338fbb78Ns9mMK6+8EidOnACgjvd669at2L17N/6//+//s0sP5nvtC2d/1/X19Whubg7I31w4UWPdocZ6w9dyd3Xd0V3qDaDz6o6IgJSWQt6zzz6LNWvW4LPPPrMbOHb77bdbfh40aBAGDx6Mvn374rPPPsN1113X6eUcNWoURo0aZXl85ZVXYsCAAXjttdfw1FNPdXp5fPHGG29g0KBBGDlypF16qL3XRO6opd4A1F93sN7oqNu1oKSmpkKn06G6utouvbq6GpmZmQ6PyczMdJlfuffmnJ1RbsWiRYvw7LPPYvPmzRg8eLDLvH369EFqaioOHTrUpWVW6PV6/OhHP7KUJ9Tf68bGRqxZswb33HOP2+sE8r32hbO/64SEBERHRwfk9xdO1Fh3qLHeANRZd3SXegPovLqj2wUokZGRGDZsGMrLyy1pZrMZ5eXldtG3rVGjRtnlB4CPP/7Ykj8vLw+ZmZl2eerr6/HVV185PWdnlBsAnn/+eTz11FMoKyvD8OHD3V7nxIkTqKmpQVZWVpeV2ZbJZMKuXbss5Qnl9xqQU0pbWlpw5513ur1OIN9rX7j7uw7E7y+cqLHuUGO94U+5bXV23dFd6g2gE+sOj4fThpE1a9YIg8EgVq1aJfbu3Svuu+8+kZSUZJmSdtddd4k5c+ZY8n/xxRciIiJCLFq0SFRUVIgFCxY4nCqYlJQk3n//ffHtt9+K8ePHB2XqqzflfvbZZ0VkZKRYt26d3RS1hoYGIYQQDQ0N4qGHHhJbtmwRlZWV4pNPPhFXXHGFKCgoEBcvXuySMj/xxBNi06ZN4rvvvhPbt28Xt99+u4iKihJ79uyxe12h9l4rfvzjH4uJEyd2SO+M97qhoUHs2LFD7NixQwAQL774otixY4c4evSoEEKIOXPmiLvuusuSX5kq+PDDD4uKigqxdOlSh1MFXb0P3Y0a6w411hu+lDsU6g411hvKdUKx7uiWAYoQQrz88svikksuEZGRkWLkyJHiP//5j+W5MWPGiJKSErv8f/vb30S/fv1EZGSkuPzyy8XGjRvtnjebzeKxxx4TGRkZwmAwiOuuu07s37+/S8vdu3dvAaDDbcGCBUIIIZqamsTYsWNFWlqa0Ov1onfv3uLee+8N+JePN2X+9a9/bcmbkZEhbrzxRvH111/bnS8U32shhNi3b58AIDZv3tzhXJ3xXn/66acOf99KOUtKSsSYMWM6HDN06FARGRkp+vTpY7f+gsLV+9AdqbHuUGO94W25Q6XuUFu9IUTo1h0aIYTwqm2HiIiIKMi63RgUIiIiCn0MUIiIiCjkMEAhIiKikMMAhYiIiEIOAxQiIiIKOQxQiIiIKOQwQCEiIqKQwwCFiIiIQg4DFCIiIgo5DFCIiIgo5DBAISIiopDz/wNgD2JkehxDOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 7.456\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 7.813\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMAGAN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_MAGAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43miris_tma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miris_tma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43miris_tma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/Python_Files/MAGAN.py:422\u001b[0m, in \u001b[0;36mrun_MAGAN\u001b[0;34m(xb1, xb2, labels1)\u001b[0m\n\u001b[1;32m    420\u001b[0m     axes[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mscatter(Gb1[labels2_ \u001b[38;5;241m==\u001b[39m lab, \u001b[38;5;241m0\u001b[39m], Gb1[labels2_ \u001b[38;5;241m==\u001b[39m lab, \u001b[38;5;241m1\u001b[39m], s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.5\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39mmarker)\n\u001b[1;32m    421\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m--> 422\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/pyplot.py:662\u001b[0m, in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m canvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[1;32m    661\u001b[0m         canvas\u001b[38;5;241m.\u001b[39mdraw_idle()\n\u001b[0;32m--> 662\u001b[0m     \u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m     canvas\u001b[38;5;241m.\u001b[39mstart_event_loop(interval)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/backend_bases.py:2193\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2191\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2193\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2195\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2196\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2197\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2198\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2199\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/backend_bases.py:2043\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2041\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2042\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:497\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    447\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    448\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:388\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    387\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3154\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[1;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/axes/_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3070\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/collections.py:1005\u001b[0m, in \u001b[0;36m_CollectionWithSizes.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;129m@artist\u001b[39m\u001b[38;5;241m.\u001b[39mallow_rasterization\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer):\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_sizes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sizes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi)\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/collections.py:391\u001b[0m, in \u001b[0;36mCollection.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     combined_transform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m--> 391\u001b[0m extents \u001b[38;5;241m=\u001b[39m \u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_extents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (extents\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mbbox\u001b[38;5;241m.\u001b[39mwidth\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m extents\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mbbox\u001b[38;5;241m.\u001b[39mheight):\n\u001b[1;32m    394\u001b[0m     do_single_path_optimization \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/matplotlib/path.py:641\u001b[0m, in \u001b[0;36mPath.get_extents\u001b[0;34m(self, transform, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         _, dzeros \u001b[38;5;241m=\u001b[39m curve\u001b[38;5;241m.\u001b[39maxis_aligned_extrema()\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;66;03m# as can the ends of the curve\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m         xys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcurve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdzeros\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    642\u001b[0m     xys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(xys)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xys):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAGAN.run_MAGAN(iris_tma.split_A, iris_tma.split_B, labels1 = iris_tma.labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
