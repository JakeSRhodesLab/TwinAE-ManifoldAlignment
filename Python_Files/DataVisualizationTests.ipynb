{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 13:32:17.166053: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAGAN is running on TensorFlow 2.16.1\n"
     ]
    }
   ],
   "source": [
    "#Import everything\n",
    "import test_manifold_algorithms as tma\n",
    "import MAGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Clear Directory\"\"\"\n",
    "#Careful. This will reset all of the resutls that we have collected\n",
    "#tma.clear_directory()\n",
    "\n",
    "#Converts old way of storing files to the new - if any\n",
    "#tma.change_old_files_to_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "---------------------------       Initalizing class with iris.csv data       ---------------------------\n",
      "\n",
      "Splitting the data randomly\n",
      "Split A features shape: (150, 3)\n",
      "Split B Features shape (150, 1)\n",
      "MDS initialized with 2 components\n",
      "The knn values are: (2, 6, 10, 14, 18, 22, 26, 30, 34, 38)\n",
      "<><><><><>    File /Users/user/Desktop/Work/ManifoldData/iris/DTA(r6739)_AP(0.05-0.1-0.15-0.2-0.3)_38.npy already exists   <><><><><>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Practice Tests to Run\"\"\"\n",
    "test = tma.test_manifold_algorithms(\"iris.csv\", split = \"random\", percent_of_anchors = [0.05, 0.1, 0.15, 0.2, 0.3], random_state=6739, verbose = 2)\n",
    "#print(f\"Anchors : {test.anchors}\")\n",
    "#print(f\"KNN range {test.knn_range}\")\n",
    "#test.run_SPUD_tests(kind = [\"distance\"])\n",
    "#test.run_DIG_tests(predict = True)\n",
    "#test.run_NAMA_tests()\n",
    "test.run_DTA_tests()\n",
    "#test.run_SSMA_tests()\n",
    "#MAGAN.run_MAGAN(test.split_A, test.split_B, labels1 = test.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------    SPUD Tests iris   -------------------------------------\n",
      "\n",
      "Operation average\n",
      "    Kind distance\n",
      "        <><><><><>    File /Users/user/Desktop/Work/ManifoldData/iris/SPUD(r1825)_Ope(average)_Kin(distance)_AP(0.05-0.1-0.15-0.2-0.3)_38.npy already exists   <><><><><>\n",
      "    Kind pure\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.47653333333333325\n",
      "                CE Score: 0.38666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3628888888888889\n",
      "                CE Score: 0.7133333333333334\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3322666666666667\n",
      "                CE Score: 0.6666666666666666\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.30333333333333334\n",
      "                CE Score: 0.6666666666666666\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.24191111111111108\n",
      "                CE Score: 0.8666666666666667\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.43475555555555556\n",
      "                CE Score: 0.4066666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.2902222222222222\n",
      "                CE Score: 0.8133333333333334\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.26168888888888886\n",
      "                CE Score: 0.8866666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2179111111111111\n",
      "                CE Score: 0.8466666666666667\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.19595555555555558\n",
      "                CE Score: 0.8933333333333333\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4728\n",
      "                CE Score: 0.4666666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.2824888888888889\n",
      "                CE Score: 0.72\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.29115555555555556\n",
      "                CE Score: 0.7\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.22857777777777774\n",
      "                CE Score: 0.6866666666666666\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2132\n",
      "                CE Score: 0.8066666666666666\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.39137777777777777\n",
      "                CE Score: 0.52\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3176\n",
      "                CE Score: 0.7066666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3073333333333333\n",
      "                CE Score: 0.6333333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.28453333333333336\n",
      "                CE Score: 0.72\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2601777777777778\n",
      "                CE Score: 0.8066666666666666\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.38964444444444446\n",
      "                CE Score: 0.66\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.33124444444444445\n",
      "                CE Score: 0.7266666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.31333333333333335\n",
      "                CE Score: 0.7933333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.30644444444444446\n",
      "                CE Score: 0.82\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.26942222222222223\n",
      "                CE Score: 0.82\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.33115555555555554\n",
      "                CE Score: 0.7066666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.30066666666666664\n",
      "                CE Score: 0.7266666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.30182222222222227\n",
      "                CE Score: 0.5866666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2864888888888889\n",
      "                CE Score: 0.6066666666666667\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2616888888888889\n",
      "                CE Score: 0.78\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3857777777777778\n",
      "                CE Score: 0.24666666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.33515555555555554\n",
      "                CE Score: 0.7133333333333334\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.31124444444444443\n",
      "                CE Score: 0.6266666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2900444444444444\n",
      "                CE Score: 0.68\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.25653333333333334\n",
      "                CE Score: 0.76\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.42146666666666666\n",
      "                CE Score: 0.38\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.37191111111111114\n",
      "                CE Score: 0.6466666666666666\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3179555555555556\n",
      "                CE Score: 0.8\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.3098666666666666\n",
      "                CE Score: 0.9\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2615111111111111\n",
      "                CE Score: 0.9133333333333333\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.36568888888888884\n",
      "                CE Score: 0.31333333333333335\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.31853333333333333\n",
      "                CE Score: 0.5266666666666666\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.30933333333333335\n",
      "                CE Score: 0.58\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.30417777777777777\n",
      "                CE Score: 0.6733333333333333\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.27848888888888895\n",
      "                CE Score: 0.8266666666666667\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3268444444444445\n",
      "                CE Score: 0.7266666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3238222222222222\n",
      "                CE Score: 0.7733333333333333\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3078666666666667\n",
      "                CE Score: 0.7333333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.3045777777777778\n",
      "                CE Score: 0.7733333333333333\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2764\n",
      "                CE Score: 0.92\n",
      "    Kind similarity\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.47653333333333325\n",
      "                CE Score: 0.38\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3628888888888889\n",
      "                CE Score: 0.66\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3322666666666667\n",
      "                CE Score: 0.64\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.30333333333333334\n",
      "                CE Score: 0.64\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.24191111111111108\n",
      "                CE Score: 0.68\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.43475555555555556\n",
      "                CE Score: 0.44666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.2902222222222222\n",
      "                CE Score: 0.7866666666666666\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.26168888888888886\n",
      "                CE Score: 0.7333333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2179111111111111\n",
      "                CE Score: 0.74\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.19595555555555558\n",
      "                CE Score: 0.8266666666666667\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4728\n",
      "                CE Score: 0.47333333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.2824888888888889\n",
      "                CE Score: 0.6133333333333333\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.29115555555555556\n",
      "                CE Score: 0.64\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.22857777777777774\n",
      "                CE Score: 0.8533333333333334\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2132\n",
      "                CE Score: 0.8266666666666667\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.39137777777777777\n",
      "                CE Score: 0.7133333333333334\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3176\n",
      "                CE Score: 0.7066666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3073333333333333\n",
      "                CE Score: 0.6133333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.28453333333333336\n",
      "                CE Score: 0.56\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2601777777777778\n",
      "                CE Score: 0.6333333333333333\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.38964444444444446\n",
      "                CE Score: 0.66\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.33124444444444445\n",
      "                CE Score: 0.6066666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.31333333333333335\n",
      "                CE Score: 0.6266666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.30644444444444446\n",
      "                CE Score: 0.6666666666666666\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.26942222222222223\n",
      "                CE Score: 0.7133333333333334\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.33115555555555554\n",
      "                CE Score: 0.6133333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.30066666666666664\n",
      "                CE Score: 0.5466666666666666\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.30182222222222227\n",
      "                CE Score: 0.5733333333333334\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2864888888888889\n",
      "                CE Score: 0.5733333333333334\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2616888888888889\n",
      "                CE Score: 0.6333333333333333\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3857777777777778\n",
      "                CE Score: 0.24666666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.33515555555555554\n",
      "                CE Score: 0.5733333333333334\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.31124444444444443\n",
      "                CE Score: 0.5866666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2900444444444444\n",
      "                CE Score: 0.4\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.25653333333333334\n",
      "                CE Score: 0.5266666666666666\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.42146666666666666\n",
      "                CE Score: 0.38666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.37191111111111114\n",
      "                CE Score: 0.49333333333333335\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3179555555555556\n",
      "                CE Score: 0.48\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.3098666666666666\n",
      "                CE Score: 0.6066666666666667\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2615111111111111\n",
      "                CE Score: 0.6533333333333333\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.36568888888888884\n",
      "                CE Score: 0.42\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.31853333333333333\n",
      "                CE Score: 0.54\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.30933333333333335\n",
      "                CE Score: 0.56\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.30417777777777777\n",
      "                CE Score: 0.58\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.27848888888888895\n",
      "                CE Score: 0.88\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3268444444444445\n",
      "                CE Score: 0.5533333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3238222222222222\n",
      "                CE Score: 0.68\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3078666666666667\n",
      "                CE Score: 0.76\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.3045777777777778\n",
      "                CE Score: 0.64\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.2764\n",
      "                CE Score: 0.76\n",
      "Operation abs\n",
      "    Kind distance\n",
      "        <><><><><>    File /Users/user/Desktop/Work/ManifoldData/iris/SPUD(r1825)_Ope(abs)_Kin(distance)_AP(0.05-0.1-0.15-0.2-0.3)_38.npy already exists   <><><><><>\n",
      "    Kind pure\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4521777777777779\n",
      "                CE Score: 0.26666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.39493333333333336\n",
      "                CE Score: 0.19333333333333333\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3175111111111111\n",
      "                CE Score: 0.49333333333333335\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2889777777777778\n",
      "                CE Score: 0.38\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.22826666666666673\n",
      "                CE Score: 0.4533333333333333\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4689777777777779\n",
      "                CE Score: 0.22666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.33048888888888894\n",
      "                CE Score: 0.30666666666666664\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.29715555555555556\n",
      "                CE Score: 0.4866666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2780444444444444\n",
      "                CE Score: 0.6466666666666666\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.24146666666666666\n",
      "                CE Score: 0.6666666666666666\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4403555555555556\n",
      "                CE Score: 0.2866666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.29431111111111113\n",
      "                CE Score: 0.5866666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.28426666666666667\n",
      "                CE Score: 0.8533333333333334\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2190222222222222\n",
      "                CE Score: 0.7666666666666667\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20031111111111108\n",
      "                CE Score: 0.8733333333333333\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3903111111111111\n",
      "                CE Score: 0.58\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.33871111111111113\n",
      "                CE Score: 0.64\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.27884444444444445\n",
      "                CE Score: 0.6333333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.23880000000000004\n",
      "                CE Score: 0.6066666666666667\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.19057777777777776\n",
      "                CE Score: 0.68\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.38208888888888887\n",
      "                CE Score: 0.7466666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3\n",
      "                CE Score: 0.7466666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2679111111111111\n",
      "                CE Score: 0.7733333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.25888888888888884\n",
      "                CE Score: 0.7733333333333333\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20106666666666664\n",
      "                CE Score: 0.8333333333333334\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3276\n",
      "                CE Score: 0.5933333333333334\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.2872\n",
      "                CE Score: 0.6\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2729333333333333\n",
      "                CE Score: 0.7666666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.25551111111111113\n",
      "                CE Score: 0.78\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20200000000000004\n",
      "                CE Score: 0.74\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.37724444444444444\n",
      "                CE Score: 0.6933333333333334\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.29186666666666666\n",
      "                CE Score: 0.6\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2617777777777778\n",
      "                CE Score: 0.68\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.24577777777777773\n",
      "                CE Score: 0.68\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.1968\n",
      "                CE Score: 0.6533333333333333\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3746222222222223\n",
      "                CE Score: 0.36666666666666664\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.31248888888888887\n",
      "                CE Score: 0.8733333333333333\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2622666666666666\n",
      "                CE Score: 0.8066666666666666\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.23351111111111114\n",
      "                CE Score: 0.8266666666666667\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.21582222222222222\n",
      "                CE Score: 0.74\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3853333333333333\n",
      "                CE Score: 0.68\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.31564444444444445\n",
      "                CE Score: 0.6\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.27186666666666665\n",
      "                CE Score: 0.74\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2521777777777778\n",
      "                CE Score: 0.7133333333333334\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20915555555555557\n",
      "                CE Score: 0.7866666666666666\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3581777777777778\n",
      "                CE Score: 0.58\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.27853333333333335\n",
      "                CE Score: 0.7866666666666666\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2816444444444445\n",
      "                CE Score: 0.7666666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2336888888888889\n",
      "                CE Score: 0.78\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20493333333333336\n",
      "                CE Score: 0.9266666666666666\n",
      "    Kind similarity\n",
      "        KNN 2\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4521777777777779\n",
      "                CE Score: 0.22666666666666666\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.39493333333333336\n",
      "                CE Score: 0.3333333333333333\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.3175111111111111\n",
      "                CE Score: 0.64\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2889777777777778\n",
      "                CE Score: 0.34\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.22826666666666673\n",
      "                CE Score: 0.32\n",
      "        KNN 6\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4689777777777779\n",
      "                CE Score: 0.12\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.33048888888888894\n",
      "                CE Score: 0.36\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.29715555555555556\n",
      "                CE Score: 0.28\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2780444444444444\n",
      "                CE Score: 0.54\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.24146666666666666\n",
      "                CE Score: 0.6733333333333333\n",
      "        KNN 10\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.4403555555555556\n",
      "                CE Score: 0.32\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.29431111111111113\n",
      "                CE Score: 0.7133333333333334\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.28426666666666667\n",
      "                CE Score: 0.82\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2190222222222222\n",
      "                CE Score: 0.7933333333333333\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20031111111111108\n",
      "                CE Score: 0.64\n",
      "        KNN 14\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3903111111111111\n",
      "                CE Score: 0.5733333333333334\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.33871111111111113\n",
      "                CE Score: 0.66\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.27884444444444445\n",
      "                CE Score: 0.5266666666666666\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.23880000000000004\n",
      "                CE Score: 0.6066666666666667\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.19057777777777776\n",
      "                CE Score: 0.6733333333333333\n",
      "        KNN 18\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.38208888888888887\n",
      "                CE Score: 0.6733333333333333\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.3\n",
      "                CE Score: 0.6066666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2679111111111111\n",
      "                CE Score: 0.5533333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.25888888888888884\n",
      "                CE Score: 0.6666666666666666\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20106666666666664\n",
      "                CE Score: 0.7133333333333334\n",
      "        KNN 22\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3276\n",
      "                CE Score: 0.5666666666666667\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.2872\n",
      "                CE Score: 0.5666666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2729333333333333\n",
      "                CE Score: 0.7\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.25551111111111113\n",
      "                CE Score: 0.6866666666666666\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20200000000000004\n",
      "                CE Score: 0.7333333333333333\n",
      "        KNN 26\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.37724444444444444\n",
      "                CE Score: 0.37333333333333335\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.29186666666666666\n",
      "                CE Score: 0.4266666666666667\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2617777777777778\n",
      "                CE Score: 0.4666666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.24577777777777773\n",
      "                CE Score: 0.5266666666666666\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.1968\n",
      "                CE Score: 0.54\n",
      "        KNN 30\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3746222222222223\n",
      "                CE Score: 0.42\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.31248888888888887\n",
      "                CE Score: 0.7333333333333333\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2622666666666666\n",
      "                CE Score: 0.6533333333333333\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.23351111111111114\n",
      "                CE Score: 0.72\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.21582222222222222\n",
      "                CE Score: 0.7466666666666667\n",
      "        KNN 34\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3853333333333333\n",
      "                CE Score: 0.38\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.31564444444444445\n",
      "                CE Score: 0.8133333333333334\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.27186666666666665\n",
      "                CE Score: 0.4266666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2521777777777778\n",
      "                CE Score: 0.6\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20915555555555557\n",
      "                CE Score: 0.6266666666666667\n",
      "        KNN 38\n",
      "            Percent of Anchors 0.05\n",
      "                FOSCTTM Score: 0.3581777777777778\n",
      "                CE Score: 0.68\n",
      "            Percent of Anchors 0.1\n",
      "                FOSCTTM Score: 0.27853333333333335\n",
      "                CE Score: 0.6\n",
      "            Percent of Anchors 0.15\n",
      "                FOSCTTM Score: 0.2816444444444445\n",
      "                CE Score: 0.7266666666666667\n",
      "            Percent of Anchors 0.2\n",
      "                FOSCTTM Score: 0.2336888888888889\n",
      "                CE Score: 0.72\n",
      "            Percent of Anchors 0.3\n",
      "                FOSCTTM Score: 0.20493333333333336\n",
      "                CE Score: 0.7066666666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing All functions\"\"\"\n",
    "class_instances = tma.run_all_tests(csv_files = [\"iris.csv\"], test_random = 1, #General function arguments\n",
    "                                split = \"random\", verbose = 0, percent_of_anchors = [0.05, 0.1, 0.15, 0.2, 0.3], #Init Key arguments\n",
    "                                run_DIG = False, page_ranks = (\"None\", \"off-diagonal\", \"full\"), predict = True, #DIG key arguments\n",
    "                                run_DTA = False,\n",
    "                                run_NAMA = False,\n",
    "                                run_SSMA = False,\n",
    "                                run_SPUD = True, operations = (\"average\", \"abs\"), kind = [\"distance\", \"pure\", \"similarity\"]) #SPUD key arguments | SPUDS_Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Visualization\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Veiwing with MatplotLib\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/Python_Files/test_manifold_algorithms.py:782\u001b[0m, in \u001b[0;36mvisualize_results\u001b[0;34m(file_names)\u001b[0m\n\u001b[1;32m    780\u001b[0m             SPUD_avg_data\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mload(file)) \n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m#Its abs \u001b[39;00m\n\u001b[0;32m--> 782\u001b[0m             SPUD_abs_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m#Create graphs. X = KNN values based by percentage (each tick goes up by 1%), and Y = Score\u001b[39;00m\n\u001b[1;32m    785\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/numpy/lib/npyio.py:462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load file containing pickled data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    463\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen allow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(fid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "\"\"\"Visualization\"\"\"\n",
    "#Veiwing with MatplotLib\n",
    "tma.visualize_results(file_names = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------\n",
      "Unable to load heart_failure/.DS_Store. \n",
      "Error Caught: Cannot load file containing pickled data when allow_pickle=False \n",
      "Continuing Loop without uploading file\n",
      "-------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['csv_file', 'method', 'seed', 'split', 'KNN', 'Percent_of_Anchors',\n",
       "       'FOSCTTM', 'Cross_Embedding_KNN', 'Page_Rank', 'Predicted_Feature_MAE',\n",
       "       'Operation', 'SPUDS_Algorithm', 'Combined_Metric'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veiwing with DataFrame\n",
    "df = tma.upload_to_DataFrame()\n",
    "\n",
    "#Add a combined metric to help see (The closer to 1 the better)\n",
    "df[\"Combined_Metric\"] = df[\"Cross_Embedding_KNN\"] - df[\"FOSCTTM\"]\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['csv_file', 'method'])[['FOSCTTM', \"Cross_Embedding_KNN\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Tests\n",
    "\n",
    "1. We want a box & whiskers plot of each method (Make it flexible so we can swicth between which csv files we are using). Show both FOSCTTM and CE\n",
    "2. We also want a box and whiskers plot of different arguments within each method \n",
    "3. Create a line plot of Methods against csv files -> (For each value, we can find the best method arguments for that csv file, and compare best to best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Methods with Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to see only a few csv files at a time, we can sub set it here\n",
    "df_subset = df[df[\"csv_file\"] == \"glass\"]\n",
    "\n",
    "#To see all of it combined\n",
    "#df_subet = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FOSCTTM    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object,\n",
       " Cross_Embedding_KNN    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object,\n",
       " Combined_Metric    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df_subset.plot(column='FOSCTTM', by='method', kind = 'box', cmap='tab10' ),\n",
    "df_subset.plot(column='Cross_Embedding_KNN', by='method', kind = 'box', cmap = \"jet\"),\n",
    "df_subset.plot(column='Combined_Metric', by='method', kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Arguments within the same Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIG\n",
    "\n",
    "We See that Page Rank has little effect on the overall graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to see only a few csv files at a time, we can sub set it here\n",
    "df_subset2 = df[df[\"csv_file\"] == \"glass\"]\n",
    "\n",
    "#To see all of it combined\n",
    "#df_subet2 = df\n",
    "\n",
    "#Change the method to DIG\n",
    "df_subset2 = df[df[\"method\"] == \"DIG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FOSCTTM    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object,\n",
       " Cross_Embedding_KNN    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object,\n",
       " Combined_Metric    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object,\n",
       " Predicted_Feature_MAE    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAH5CAYAAADHrVXSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABTxklEQVR4nO3de5xNZf//8fee8wzmwDAGwzjl0Dg1IiG6GxQKUSI5VNwV3XKqJknljqKkb5HbWXeoCKWcFTlMtwzucDufixmDZgYzzGGv3x9+s5pthmaPsfaMeT0fj/1o77U+a+9rm9be773WdV3LZhiGIQAAAMACbq5uAAAAAIoPwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwDchPDwcHXs2PGWv86xY8dks9k0Z86cv6zt27evwsPDHZbZbDa9+eabt6RtAOAMwicASdLhw4f197//XdWqVZOPj4/8/f3VvHlzffTRR0pNTXV185wyZ84c2Wy2695+/vlnVzex2LLZbBo0aFCO5WPHjpXNZtPTTz8tu91uhm2bzaavv/46R/2bb74pm82ms2fPmsv69u0rm82m+vXrK7crR1/vtQFYy8PVDQDget9//70ee+wxeXt7q3fv3oqIiFBaWpo2bdqkESNGaM+ePZo2bZqrm+m0t99+W1WrVs2xvEaNGi5ojWulpqbKw6NwfuS/++67GjlypPr06aMZM2bIzc3xuMjbb7+tRx99VDabLU/Pt2vXLi1evFhdu3a9Fc0FcJMK5ycRAMscPXpUTzzxhKpUqaIffvhBoaGh5rqBAwfq0KFD+v7773Pd1m63Ky0tTT4+PlY11ykPPfSQGjdu7OpmFAqF9W80YcIERUdHq3fv3po1a1aO4NmwYUPt3LlTS5Ys0aOPPvqXz+fr66uwsDCnAysA63DaHSjmxo8fr4sXL2rmzJkOwTNLjRo1NHjwYEl/nracN2+e7rzzTnl7e2vlypWSpB07duihhx6Sv7+/SpYsqQceeCDH6e309HS99dZbqlmzpnx8fFSmTBm1aNFCa9asMWvi4uLUr18/VapUSd7e3goNDVWnTp107NixAn/vWad233//fU2ePFnVqlWTn5+f2rZtq5MnT8owDI0ZM0aVKlWSr6+vOnXqpPPnz+f6XKtXr1bDhg3l4+OjunXravHixTlqEhMT9dJLLyksLEze3t6qUaOG3nvvPdnt9hx1ffv2VUBAgAIDA9WnTx8lJibm+rpLly5VRESEfHx8FBERoSVLluRad22fz6zT1ocOHVLfvn0VGBiogIAA9evXTykpKQ7bpqam6h//+IeCg4NVqlQpPfLII/r9999vuh/pxIkT9fLLL6tXr16aPXt2juApSU888YTuuOMOvf3227meSr+Wm5ubXn/9df3666/X/bcA4Foc+QSKuWXLlqlatWq6995781T/ww8/6KuvvtKgQYMUHBys8PBw7dmzRy1btpS/v79efvlleXp66l//+pdat26tDRs2qGnTppKuBp5x48bp2WefVZMmTZScnKxt27Zp+/btatOmjSSpa9eu2rNnj1588UWFh4frzJkzWrNmjU6cOJFjEM1fSUpKcugTKF0NYWXKlHFYNm/ePKWlpenFF1/U+fPnNX78eD3++OP629/+pvXr1+uVV17RoUOH9PHHH2v48OGaNWuWw/YHDx5U9+7d9dxzz6lPnz6aPXu2HnvsMa1cudJ8XykpKWrVqpV+//13/f3vf1flypW1ZcsWRUdH6/Tp05o0aZIkyTAMderUSZs2bdJzzz2nOnXqaMmSJerTp0+O97d69Wp17dpVdevW1bhx43Tu3DkzuOfV448/rqpVq2rcuHHavn27ZsyYoXLlyum9994za/r27auvvvpKTz31lO655x5t2LBBHTp0yPNr5Oajjz7SsGHD1LNnT82ZMyfX4ClJ7u7uev3119W7d+88H/3s2bOnxowZo7fffltdunTh6CdQ2BgAiq2kpCRDktGpU6c81Usy3NzcjD179jgs79y5s+Hl5WUcPnzYXHbq1CmjVKlSxn333Wcua9CggdGhQ4frPv8ff/xhSDImTJjg3Bu5xuzZsw1Jud68vb3NuqNHjxqSjLJlyxqJiYnm8ujoaEOS0aBBAyM9Pd1c3qNHD8PLy8u4fPmyuaxKlSqGJOPrr782lyUlJRmhoaFGo0aNzGVjxowxSpQoYRw4cMChra+++qrh7u5unDhxwjAMw1i6dKkhyRg/frxZk5GRYbRs2dKQZMyePdtc3rBhQyM0NNSh7atXrzYkGVWqVHF4HUnG6NGjzcejR482JBlPP/20Q12XLl2MMmXKmI9jY2MNScZLL73kUNe3b98cz5kXWW2TZPTo0cPIyMjItS7rbzNhwgQjIyPDqFmzptGgQQPDbrc7tD8hIcHcpk+fPkaJEiUMwzCMuXPnGpKMxYsXO7z2wIEDnWovgILHaXegGEtOTpYklSpVKs/btGrVSnXr1jUfZ2ZmavXq1ercubOqVatmLg8NDVXPnj21adMm83UCAwO1Z88eHTx4MNfn9vX1lZeXl9avX68//vgjP2/JweTJk7VmzRqH24oVK3LUPfbYYwoICDAfZx2p7dWrl8MgnaZNmyotLU2///67w/YVKlRQly5dzMf+/v7q3bu3duzYobi4OEnSwoUL1bJlSwUFBens2bPmLSoqSpmZmfrpp58kScuXL5eHh4eef/558/nc3d314osvOrzm6dOntXPnTvXp08eh7W3atHH4+/yV5557zuFxy5Ytde7cOfNvltWt4oUXXnCou7Y9zoiPj5ckVa1aVe7u7n9Zn3X087///a+WLl2ap9d48sknVbNmzTyfrgdgHcInUIz5+/tLki5cuJDnba4dPZ6QkKCUlBTVqlUrR22dOnVkt9t18uRJSVdHLScmJuqOO+5QvXr1NGLECP36669mvbe3t9577z2tWLFCISEhuu+++zR+/HgzwDmrSZMmioqKcrjdf//9OeoqV67s8DgrzIWFheW6/NpgXKNGjRyndu+44w5JMvuqHjx4UCtXrlTZsmUdblFRUZKkM2fOSJKOHz+u0NBQlSxZ0uH5rv33PX78uCSpZs2aOd5Pbn+L67n2vQcFBTm8x+PHj8vNzS3H3/1mZgzo06ePHn74YY0dO1YffvhhnrZ58sknVaNGjTyHyazAunPnzjwHVgDWIHwCxZi/v78qVKig3bt353kbX1/ffL/efffdp8OHD2vWrFmKiIjQjBkzdNddd2nGjBlmzUsvvaQDBw5o3Lhx8vHx0ahRo1SnTh3t2LEj36/7V6539O16y/NzJM1ut6tNmzY5jsRm3Vw1LVBBvse88vDw0FdffaVWrVpp2LBhmj179l9ukz1MfvPNN3l6HWcDKwBrED6BYq5jx446fPiwYmJi8rV92bJl5efnp/379+dYt2/fPrm5uTkcQSxdurT69eunBQsW6OTJk6pfv36OEdPVq1fXsGHDtHr1au3evVtpaWn64IMP8tU+Kxw6dChHuDlw4IAkmYOkqlevrosXL+Y4Ept1yzoCWaVKFZ0+fVoXL150eL5r/32rVKkiSbl2Ycjtb5FfVapUkd1u19GjRx2WHzp06Kae18fHR99++60aNWqk/v3752lkeq9evVSjRg299dZbTh/9zGtgBXDrET6BYu7ll19WiRIl9Oyzz5p98bI7fPiwPvroo+tu7+7urrZt2+qbb75xmA4pPj5e8+fPV4sWLczT++fOnXPYtmTJkqpRo4auXLki6eqI8MuXLzvUVK9eXaVKlTJrCqNTp045hKfk5GR99tlnatiwocqXLy/p6qjymJgYrVq1Ksf2iYmJysjIkCS1b99eGRkZ+vTTT831mZmZ+vjjjx22CQ0NVcOGDTV37lwlJSWZy9esWaP//e9/Bfbe2rVrJ0maMmWKw/Jr25Mf/v7+WrlypWrUqKEePXpo3bp1N6zPHia//fbbPL1G9sAKoHBgqiWgmKtevbrmz5+v7t27q06dOg5XONqyZYsWLlyovn373vA5/vnPf2rNmjVq0aKFXnjhBXl4eOhf//qXrly5ovHjx5t1devWVevWrRUZGanSpUtr27ZtWrRokXnJwwMHDuiBBx7Q448/rrp168rDw0NLlixRfHy8nnjiCaff24oVK7Rv374cy++9916HwVE364477tAzzzyjX375RSEhIZo1a5bi4+MdTiePGDFC3377rTp27Ki+ffsqMjJSly5d0q5du7Ro0SIdO3ZMwcHBevjhh9W8eXO9+uqrOnbsmDlnaPaAmWXcuHHq0KGDWrRooaefflrnz5/Xxx9/rDvvvDPHkdP8ioyMVNeuXTVp0iSdO3fOnGop68juzU5jVLZsWa1Zs0bNmzdX586dtW7dOjVp0uS69U8++aTGjBmjnTt35un53d3dNXLkSPXr1++m2gmgALlwpD2AQuTAgQNG//79jfDwcMPLy8soVaqU0bx5c+Pjjz82pxbSDaaq2b59u9GuXTujZMmShp+fn3H//fcbW7Zscaj55z//aTRp0sQIDAw0fH19jdq1axvvvPOOkZaWZhiGYZw9e9YYOHCgUbt2baNEiRJGQECA0bRpU+Orr75y6r3caKolZZuuKPt0Ptn9+OOPhiRj4cKFuT7vL7/8Yi6rUqWK0aFDB2PVqlVG/fr1DW9vb6N27do5tjUMw7hw4YIRHR1t1KhRw/Dy8jKCg4ONe++913j//ffNfwPDMIxz584ZTz31lOHv728EBAQYTz31lLFjx44cUy0ZhmF8/fXXRp06dQxvb2+jbt26xuLFi40+ffrkeaql7FMVZX+PR48eNZddunTJGDhwoFG6dGmjZMmSRufOnY39+/cbkox33333en+GXF3v/6G9e/cawcHBRunSpY3du3df92+TvY3Xtj/7VEvZpaenG9WrV2eqJaCQsBkGvbABAM7ZuXOnGjVqpM8//1xPPvmkq5sDoAihzycA4IZSU1NzLJs0aZLc3Nx03333uaBFAIoy+nwCKDIuXrz4l30Zy5Ytm6eJy5F348ePV2xsrO6//355eHhoxYoVWrFihQYMGKCwsDBlZmYqISHhhs9RsmTJHHOXAiieOO0OoMh48803/3LU8tGjR52+BjxubM2aNXrrrbf0v//9TxcvXlTlypX11FNPaeTIkfLw8NCxY8dyTEJ/rdGjR+eYUgtA8UT4BFBkHDlyREeOHLlhTYsWLeTj42NRiyBJly9f1qZNm25YU61atQKdYQBA0UX4BAAAgGUYcAQAAADLFIkBR3a7XadOnVKpUqVuekJjAAAAFDzDMHThwgVVqFBBbm7XP75ZJMLnqVOnHK4NDQAAgMLp5MmTqlSp0nXXF4nwWapUKUlX30zWNaIBAABQeCQnJyssLMzMbddTJMJn1ql2f39/wicAAEAh9lddJJ0ecPTTTz/p4YcfVoUKFWSz2bR06dK/3Gb9+vW666675O3trRo1amjOnDnOviwAAABuA06Hz0uXLqlBgwaaPHlynuqPHj2qDh066P7779fOnTv10ksv6dlnn9WqVaucbiwAAACKNqdPuz/00EN66KGH8lw/depUVa1aVR988IEkqU6dOtq0aZM+/PBDtWvXztmXBwAAQBF2y+f5jImJUVRUlMOydu3aKSYm5rrbXLlyRcnJyQ43AAAAFH23PHzGxcUpJCTEYVlISIiSk5OVmpqa6zbjxo1TQECAeWOaJQAAgNtDobzCUXR0tJKSkszbyZMnXd0kAAAAFIBbPtVS+fLlFR8f77AsPj5e/v7+8vX1zXUbb29veXt73+qmAQAAwGK3/Mhns2bNtG7dOodla9asUbNmzW71SwMAAKCQcTp8Xrx4UTt37tTOnTslXZ1KaefOnTpx4oSkq6fMe/fubdY/99xzOnLkiF5++WXt27dPU6ZM0VdffaUhQ4YUzDsAAABAkeF0+Ny2bZsaNWqkRo0aSZKGDh2qRo0a6Y033pAknT592gyiklS1alV9//33WrNmjRo0aKAPPvhAM2bMYJolAACAYshmGIbh6kb8leTkZAUEBCgpKYnLawIAABRCec1rhXK0OwAAAG5PhE8AAABY5pZPtQQAAJAlJSVd+/adzde2qakZOnYsUeHhgfL1zX+EqV07WH5+nvneHjeH8AkA+XAzX6BSwXyJ8gWKomjfvrOKjJzm0jbExg7QXXeFurQNxRnhEwDygS9QIH9q1w5WbOyAfG27d+9Z9eq1WJ9//qjq1Am+qTbAdQif4BQIkA838wUqFcyXKF+gKIr8/Dxv+kdTnTrB/PAqwgif4AgOkA8F8QUq8SUKoPghfIJTIAAAwDKET3AKBAAAWIZ5PgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDKETwAAAFiG8AkAAADLED4BAABgGcInAAAALEP4BAAAgGUInwAAALAM4RMAAACWIXwCAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDKETwAAAFiG8AkAAADLED4BAABgGcInAAAALEP4BAAAgGUInwAAALAM4RMAAACWIXwCAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJbJV/icPHmywsPD5ePjo6ZNm2rr1q03rJ80aZJq1aolX19fhYWFaciQIbp8+XK+GgwAAICiy+nw+eWXX2ro0KEaPXq0tm/frgYNGqhdu3Y6c+ZMrvXz58/Xq6++qtGjR2vv3r2aOXOmvvzyS7322ms33XgAAAAULU6Hz4kTJ6p///7q16+f6tatq6lTp8rPz0+zZs3KtX7Lli1q3ry5evbsqfDwcLVt21Y9evT4y6OlAAAAuP04FT7T0tIUGxurqKioP5/AzU1RUVGKiYnJdZt7771XsbGxZtg8cuSIli9frvbt21/3da5cuaLk5GSHGwAAAIo+D2eKz549q8zMTIWEhDgsDwkJ0b59+3LdpmfPnjp79qxatGghwzCUkZGh55577oan3ceNG6e33nrLmaYBAACgCLjlo93Xr1+vsWPHasqUKdq+fbsWL16s77//XmPGjLnuNtHR0UpKSjJvJ0+evNXNBAAAgAWcOvIZHBwsd3d3xcfHOyyPj49X+fLlc91m1KhReuqpp/Tss89KkurVq6dLly5pwIABGjlypNzccuZfb29veXt7O9M0AAAAFAFOHfn08vJSZGSk1q1bZy6z2+1at26dmjVrlus2KSkpOQKmu7u7JMkwDGfbCwAAgCLMqSOfkjR06FD16dNHjRs3VpMmTTRp0iRdunRJ/fr1kyT17t1bFStW1Lhx4yRJDz/8sCZOnKhGjRqpadOmOnTokEaNGqWHH37YDKEAAAAoHpwOn927d1dCQoLeeOMNxcXFqWHDhlq5cqU5COnEiRMORzpff/112Ww2vf766/r9999VtmxZPfzww3rnnXcK7l0AAACgSHA6fErSoEGDNGjQoFzXrV+/3vEFPDw0evRojR49Oj8vBQAAgNsI13YHAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDKETwAAAFjGw9UNAAAARcvBg+d04UKa5a+7d+9Zh/9arVQpL9WsWcYlr307IXzeJvggAPKHfQdwzsGD53THHZ+4tA29ei122WsfODCIfecmET5vA3wQ8EGA/GHfYd+B87J+rH3+eRfVqVPW0tdOTc3QsWOJCg8PlK+vtRFm794E9eq1xCU/Vm83hM/bAB8EfBAgf9h32HeQf3XqlNVdd4Va/rrNm4dZ/pooWITP2wgfBED+sO8AgHUY7Q4AAADLED4BAABgGcInAAAALEP4BAAAgGUInwAAALAM4RMAAACWIXwCAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDKETwAAAFiG8AkAAADLED4BAABgGcInAAAALEP4BAAAgGUInwAAALAM4RMAAACWIXwCAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZD1c3AAWjpC4oce+vOq3Trm6KZRL3JqikLri6GQAAwAmEz9tEY23Txl4faKOrG2Kxxmrl6iagiOOHG+A89hvcDMLnbWKbGmvU59GqU6esq5timb17E/R+rzWubgaKOH64Ac5jv8HNIHzeJi6qlALr1FfoXaGuboplTuu0LupnVzcDRRw/3ADnsd/gZhA+ARRr/HADnMd+g5vBaHcAAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBl8hU+J0+erPDwcPn4+Khp06baunXrDesTExM1cOBAhYaGytvbW3fccYeWL1+erwYDAACg6HJ6qqUvv/xSQ4cO1dSpU9W0aVNNmjRJ7dq10/79+1WuXLkc9WlpaWrTpo3KlSunRYsWqWLFijp+/LgCAwMLov0AAAAoQpwOnxMnTlT//v3Vr18/SdLUqVP1/fffa9asWXr11Vdz1M+aNUvnz5/Xli1b5OnpKUkKDw+/uVYDAACgSHLqtHtaWppiY2MVFRX15xO4uSkqKkoxMTG5bvPtt9+qWbNmGjhwoEJCQhQREaGxY8cqMzPzuq9z5coVJScnO9wAAABQ9DkVPs+ePavMzEyFhIQ4LA8JCVFcXFyu2xw5ckSLFi1SZmamli9frlGjRumDDz7QP//5z+u+zrhx4xQQEGDewsLCnGkmAAAACqlbPtrdbrerXLlymjZtmiIjI9W9e3eNHDlSU6dOve420dHRSkpKMm8nT5681c0EAACABZzq8xkcHCx3d3fFx8c7LI+Pj1f58uVz3SY0NFSenp5yd3c3l9WpU0dxcXFKS0uTl5dXjm28vb3l7e3tTNMAAABQBDh15NPLy0uRkZFat26ducxut2vdunVq1qxZrts0b95chw4dkt1uN5cdOHBAoaGhuQZPAAAA3L6cPu0+dOhQTZ8+XXPnztXevXv1/PPP69KlS+bo9969eys6Otqsf/7553X+/HkNHjxYBw4c0Pfff6+xY8dq4MCBBfcuAAAAUCQ4PdVS9+7dlZCQoDfeeENxcXFq2LChVq5caQ5COnHihNzc/sy0YWFhWrVqlYYMGaL69eurYsWKGjx4sF555ZWCexcAAAAoEpwOn5I0aNAgDRo0KNd169evz7GsWbNm+vnnn/PzUgAAALiNcG13AAAAWIbwCQAAAMsQPgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlPFzdANy8lJR0SdL27actf+3U1AwdO5ao8PBA+fpa+7/T3r0Jlr4ebj/sOwBgPcLnbWDfvrOSpP79l7m4Ja5RqpSXq5uAIop9h30HzuNHG24W4fM20LlzbUlS7drB8vPztPS19+49q169Fuvzzx9VnTrBlr62dPXLs2bNMpa/Lm4P7DvsO3AeP9r40XazCJ+3geBgPz377F0ubUOdOsG6665Ql7YBcBb7DuA8frTxo+1mET4BAECe8aMNN4vR7gAAALAM4RMAAACWIXwCAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDKETwAAAFiG8AkAAADLED4BAABgGcInAAAALEP4BAAAgGUInwAAALAM4RMAAACWIXwCAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDL5Cp+TJ09WeHi4fHx81LRpU23dujVP233xxRey2Wzq3Llzfl4WAAAARZzT4fPLL7/U0KFDNXr0aG3fvl0NGjRQu3btdObMmRtud+zYMQ0fPlwtW7bMd2MBAABQtDkdPidOnKj+/furX79+qlu3rqZOnSo/Pz/NmjXruttkZmbqySef1FtvvaVq1ardVIMBAABQdDkVPtPS0hQbG6uoqKg/n8DNTVFRUYqJibnudm+//bbKlSunZ555Jk+vc+XKFSUnJzvcAAAAUPQ5FT7Pnj2rzMxMhYSEOCwPCQlRXFxcrtts2rRJM2fO1PTp0/P8OuPGjVNAQIB5CwsLc6aZAAAAKKRu6Wj3Cxcu6KmnntL06dMVHByc5+2io6OVlJRk3k6ePHkLWwkAAACreDhTHBwcLHd3d8XHxzssj4+PV/ny5XPUHz58WMeOHdPDDz9sLrPb7Vdf2MND+/fvV/Xq1XNs5+3tLW9vb2eaBgAAgCLAqSOfXl5eioyM1Lp168xldrtd69atU7NmzXLU165dW7t27dLOnTvN2yOPPKL7779fO3fu5HQ6AABAMePUkU9JGjp0qPr06aPGjRurSZMmmjRpki5duqR+/fpJknr37q2KFStq3Lhx8vHxUUREhMP2gYGBkpRjOQAAAG5/TofP7t27KyEhQW+88Ybi4uLUsGFDrVy50hyEdOLECbm5ceEkAAAA5OR0+JSkQYMGadCgQbmuW79+/Q23nTNnTn5eEgAAALcBDlECAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDKETwAAAFiG8AkAAADLED4BAABgGcInAAAALEP4BAAAgGUInwAAALAM4RMAAACWIXwCAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZwicAAAAsQ/gEAACAZQifAAAAsAzhEwAAAJYhfAIAAMAyhE8AAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDKETwAAAFiG8AkAAADLED4BAABgGcInAAAALEP4BAAAgGUIn8i3tLQ0zZs3TdJyzZs3TWlpaa5uElAksO8AKM4In8iXl19+WSVKlNDEiW9K2qqJE99UiRIl9PLLL7u6aUChxr4DoLjzcHUD4HopKenat+9snus/+miMPvvsU5UuHax77umg5cvPqn37YP388/eaMGGC4uMvavDgUU61oXbtYPn5eTrbdMBlnN1vpD/3naCgMmrWrKOWL09Q+/ZlFRPzXb72HfYbAEWRzTAMw9WN+CvJyckKCAhQUlKS/P39Xd2c28727acVGTktj9UZksZK8pTkJelCtnWlJKVJSpf0mpz5bRMbO0B33RWa53rA1ZzbbyTHfcdXUmK2dYGSUuXsvsN+g+Ima7/j//3CKa95jSOfUO3awYqNHZCn2nnzpmniRLukK/LykrJ3VfPySlNa2hVJ0tChHnryybw9Z1YbgKLEmf1Gyr7vpKlFi5YKDa2ss2eTFBwcoNOnT2jTpnWSDKf2HfYbFCepqal6991oSZv07rtHNXfup/L19XV1s5APhE/Iz88zz78gZ848Y95PT3ccJJH98eXLZ/hVituaM/uN9Oe+U6VKZW3Z8oPsdru5zs3NTVWqVNbx48fZd4BcdO7cWd988435eOHCw1q4cK46deqkpUuXuq5hyBfCJ5ySvZeGzWa77uMi0JsDsJTNZpMkHT9+PMc6u91uLs+qA25XzvaXHjq0nzZsWJXrum+++UatWz+oiRNnO9UG+ku7FuETTilZsqR5v127dnrjjTcUERGh3bt36+2339aKFSty1AGQIiMjC7QOKKr27TvrRH/pNEnZg2d9Sc0kxUj6VZK0YcMqRUZ+oqvjEPKGPqOuRfiEU3bs2GHej42N1cKFC7V9+3YdPnxYsbGxudYBkP7zn/+Y9202mxo1aqQaNWro0KFD2rFjh3m24D//+Y/69evnqmYCt5wz/aXHjBmhrLPqP/10UDt3bte+fUdVu/bf1LDhXbrvvpqSpM6dj2vUqAlOtQGuw2h3OKVFixbavHmzSpYsqYsXL+ZYn7W8efPm2rRpkwtaCBROzZo1088///yXdffcc49iYmIsaBFQ+JUrV04JCQm6++67lZCQoGPHjpnrwsPDVaZMGcXGxqps2bI6c+bM9Z8IlmC0O26J8PBwbd68WRcvXlTZsmVVoUIFXblyRd7e3jp16pQSEhLMOgB/iouLM+97eXmpcuXKcnNzk91u14kTJ8yrHGWvA4q7jIwMSdIvv/yijh07asSIEfL19VVqaqpWrFih7777zqEORQPhE0558sknNW/ePElSQkKCGTZzqwPwp/Lly5tHbdLS0nTo0KHr1gG46t5779X3338vSdq+fbsZNiWpQoUKDnUoOri8Jpzi5ZW3Dt15rQOKi7Jly5r3bTaboqKiNHbsWEVFRTmMcM9eBxR3AwcONO+fOnXKYV32x9nrUPhx5BNOuXbnv9k6oLgIDf1zZK1hGFq7dq3Wrl17wzqguDt//nyB1qFw4MgnnJI1YjcwMDDX9VnLs4/sBaA8D4Zg0ATwp6wDGW5uuceVrOUc8ChaCJ9wStbkCImJibLZbKpUqZJq1KihSpUqyWazKTEx0aEOwFV57ctJn0/gTzt37pQklS5dOscFGGw2m0qXLu1Qh6IhX+Fz8uTJCg8Pl4+Pj5o2baqtW7det3b69Olq2bKlgoKCFBQUpKioqBvWo3CrVKmSed8wDP322286dOiQfvvtN4fAmb0OgFS9evUCrQOKg5SUFEnS2bNn5enpqZ49e2rixInq2bOnPD09dfbsWYc6FA1Oh88vv/xSQ4cO1ejRo7V9+3Y1aNBA7dq1u+6povXr16tHjx768ccfFRMTo7CwMLVt21a///77TTce1tuyZUuB1gEAcD3NmjWTdPUoZ2ZmpubPn6+hQ4dq/vz5yszMNI+GZtWhaHA6fE6cOFH9+/dXv379VLduXU2dOlV+fn6aNWtWrvXz5s3TCy+8oIYNG6p27dqaMWOG7Ha71q1bd9ONh/WOHj1aoHVAcXG9qZXyWwcUB1l9Og3DUGZmpsO6zMxM84zb9fqEonBy6q+Vlpam2NhYRUVF/fkEbm6KiorK8xU5UlJSlJ6ebvbTyM2VK1eUnJzscEPhkNtVjW6mDigudu/eXaB1QHHAAY/bk1Ph8+zZs8rMzFRISIjD8pCQkDxfleOVV15RhQoVHALstcaNG6eAgADzFhYW5kwzcQtlv1zWtf06sz/mMqiAI09PzwKtA4qDrCObHh65zwyZtZxBrkWLpfN8vvvuu/riiy+0fv16+fj4XLcuOjpaQ4cONR8nJycTQAuJ7HOp/fbbb6pVq5bq1q2r//3vf9q/f3+udQBkDozIEhkZqRo1aujQoUOKjY29bh1QnGVN35eRkSFPT09VqVJF7u7uyszM1PHjx5Wenu5Qh6LBqfAZHBwsd3d3xcfHOyyPj4//y+lB3n//fb377rtau3at6tevf8Nab29veXt7O9M0WKRs2bIOg8X279/vEDqz1wH407X7RGxsrEPovF4dUJxl7+eZnp5+3T7R1/YHReHm1Gl3Ly8vRUZGOgwWyho8dKORZuPHj9eYMWO0cuVKNW7cOP+thctdewTa399f5cqVy3GanSPVgKO0tLQCrQOKg7179xZoHQoHp4eHDR06VNOnT9fcuXO1d+9ePf/887p06ZL69esnSerdu7eio6PN+vfee0+jRo3SrFmzFB4erri4OMXFxTEgpYjq1KmTw+Pk5GSdOXMmx6Cwa+uA4q5WrVoFWgcUB5cuXSrQOhQOTvf57N69uxISEvTGG28oLi5ODRs21MqVK81BSCdOnHCY8uDTTz9VWlqaunXr5vA8o0eP1ptvvnlzrYflduzYUaB1QHFxbXelm60DioPU1NQCrUPhkK8BR4MGDdKgQYNyXbd+/XqHx8eOHcvPS6CQymu/GvrfAI7y+lnIZybwp+zfJW5ubrLb7bk+5junaLF0tDtuL+3bt5evr6/++OMPBQUFKTU1VcuXL3d1s4BCKXtfzjJlyigiIkKGYchms2n37t06d+5cjjqguMt+9UTDMBQZGanq1avr8OHD2r59e651KPwIn3BK1nQWJUqU0J49e3T8+HFzXXh4uPz8/JSSksK0F8A1goODdfDgQbm5uencuXPasGGDuc5ms5lHcYKDg13YSqBwKV++vHk2wDCM684S8Vcz7qBw4XpUcErWhL6XLl3SiRMnHNYdP35cKSkpDnUArmrQoIEkOZw2zGIYhrk8qw6A1LBhwwKtQ+FA+IRTWrdubd6/9ooS2R9nrwPAaHcgP+65554CrUPhQPiEU1q2bCmbzSbp6mTYFSpUUGBgoCpUqGBOjm2z2dSyZUtXNhModJ599tkCrQOKg7xe8YsrgxUthE84ZePGjeYRzoSEBJ06dUqJiYk6deqUEhISJF09Arpx40ZXNhModGbMmFGgdUBxQPi8PRE+4ZRrp9K62TqguDh8+HCB1gHFwW+//ebwODAwUOHh4TkGtV5bh8KNUSFwyuXLlwu0Diguso/GPXfunD777DMdPnxY1atXV+/evVWmTJkcdUBxl9WdK0tiYqISExP/sg6FG+ETTtm8ebPD41q1aikiIkK7d+/W/v37r1sHFHcLFiyQdHUmCH9/f7300kvmuoyMDHl4eCgjI0MLFizQyJEjXdRKoHBZvXp1gdahcCB8winX/uLcv3+/Q+i8Xh1Q3J0+fVrS1aBZsWJF9erVy5ws+/PPP1dGRoZDHQApKSnJvH+jKxxlr0PhR/iEU+Li4gq0DiguKlSooPPnzyswMFBnzpzRxIkTHdYHBgYqMTFRFSpUcFELgcIn+5zR186Rm/0xc0sXLfy14BQfHx/zfqVKlRw6eYeFhenkyZM56gBIGzZsUJkyZZSYmKh27dqpdu3aSk1Nla+vr/bt26dVq1aZdQCuuvPOO80rHHl7e+vKlSvmuuyP77zzTlc0D/nEaHc4xdvb27z/+++/KyoqSu+8846ioqIcgmj2OgBSQECA3NyufuSuWrVKMTExevTRRxUTE2MGTzc3NwUEBLiymUChkn1U+5UrV9S4cWO98cYbaty4sUMQ5ZLORQtHPuGUqKgocx5CwzC0du1arV27Ntc6AH/auHGj7Ha7SpcurfPnz2vr1q168MEHzfVZyzdu3MgVwoD/r0GDBpo3b55sNpsMw9C2bdu0bds2c33Wci5LW7QQPuGUa09tBAcHq1SpUrpw4YLDJL+cAgEcZQ0kOn78uNLS0tSqVSudOnVKFSpU0IYNG+Tp6Sl/f38GHAHZZPWBNgxDZcqUUWBgoNldJTExUefOnXOoQ9FA+IRTXnjhBY0YMUJ2u112u11nz551CJ1ubm5yc3PTCy+84MJWAoVPaGioJGn37t265557tGvXLof1MTExDnUApIoVK5r3z58/b4ZNSealnq+tQ+FHn084xcvLS0OGDJHdblfZsmVVvXp1hYaGqnr16ipbtqzsdruGDBkiLy8vVzcVKFRatmyp8PBwjR07Vunp6Vq/fr0WLFig9evXKz09XePGjVPVqlXVsmVLVzcVKDSy9pvGjRurcuXKDuuqVKmixo0bs98UQRz5hNPGjx8vSfrwww/N67lLV6e6GDFihLkewJ/c3d31wQcfqFu3bgoICFBqaqq5ztfXV5cvX9aiRYvk7u7uwlYChUv2/aZDhw4aMWKEfH19lZqaqpUrV+r7779nvymCCJ/Il/Hjx+utt97SiBEjdPDgQdWsWVMTJkyQr6+vq5sGFGqGYeRYljVoAkBOjz76qBYtWqRhw4bpu+++M5dXrVpVixYt0qOPPurC1iE/bEYR+MRLTk5WQECAkpKS5O/v7+rmQNLixYs1bNgwc/41SQoPD9cHH3zABwGQi8zMTNWoUUP16tXT119/rc2bN+v06dMKDQ1V8+bN1bVrV+3evVsHDx7kKA6Qi8zMTG3cuNHcb1q2bMm+UsjkNa9x5BNOW7x4sbp166aOHTtqwYIF5rXdx44dq27duvFLFMjFxo0bdezYMS1YsECenp45plOKjo7Wvffey1RLwHW4u7uzb9wmGHAEp2RmZmrYsGHq2LGjvv76a12+fFnLli3T5cuX9fXXX6tjx44aPny4MjMzXd1UoFDJmkIpIiJCaWlpmjRpkl588UVNmjRJaWlpioiIcKgD4CgzM9NhoB7fM0UXRz7hlKyjN3//+991xx135DjtPmDAAC1btoyjN8A1sqZQeu655/Tll18qIyPDXDdixAg9/vjjDnUA/kRXr9sLRz7hlKyjMq+99prq1aunmJgYXbhwQTExMapXr55GjhzpUAfgqpYtW8rf31/z5s1T6dKlNXz4cE2ZMkXDhw9X6dKlNX/+fPn7+zNlDHCNrK5eERERmjx5smbNmqXJkycrIiJC3bp10+LFi13dRDiJAUdwyrp16xQVFaUWLVpow4YN5rWqJclut6tVq1batGmT1q5dqwceeMCFLQUKl7S0NPn6+sput5tTxWTJeuzm5qbU1FTmyQX+v6yBesHBwTp79myOI5/BwcE6d+4cA/UKibzmNY58It9y67dWBH7LAC4xZcoU2e32XNdlXanFbrdrypQpVjYLKNSyunrFxsbmerYtNjZWR48e1caNG13dVDiBPp9wypkzZyRJmzZtkp+fn0PYHDp0qPk4qw7AVQcPHpQktW3bVt99912OqZY6dOigNWvWmHUApN9//12S9OCDD2rp0qXm2bZ77rlHS5cuVceOHbVixQqzDkUD4RNOyT4Y4tqJsd3c3MzRhwyaABxlHd286667cp1qqVGjRlqzZo3D9aqB4i7rKnqPPvqoQzcv6ep3TufOnbVixQqHq+2h8OO0O5zStGlTSVev8X7x4kX9+OOPmj9/vn788UdduHDB7KuWVQfgqqx9YubMmQ4j3SUpIyNDs2fPdqgDIJUtW1bS1UFH6enpDlMtpaena+nSpQ51KBo48gmn/Otf/5Ikpaenq1u3bvL19dUff/yhoKAgTZgwQenp6WbdSy+95MKWAoVLWFiYpKtHcipUqKDWrVurZMmSunjxotavX28eucmqAyBVrFhRkrRixQoFBATkOlAvex2KBsInnHL48GFJUoMGDbR8+fIc6xs2bKidO3eadQCuatmypcLDw5WYmKiEhAQtXLjQYX1gYKCCgoKYagnIpmXLlipXrpzOnDnjEDwlmY/LlSvHflPEcNodTqlevbokaefOnfL09FSPHj304YcfqkePHvL09NTOnTsd6gBc5e7urgYNGigxMTHX9YmJiapfvz7TxQDXyNpnbDab2rRpo7Fjx6pNmzZm/+jr7VMovJjnE05JSkpSYGCgJCk+Pl5///vfdfjwYVWvXl3/+te/FBISIunqh0FAQIALWwoULszzCThv1apVevDBB+Xm5qawsDAdP37cXBceHq4TJ07Ibrdr5cqVateunQtbCol5PnGLZF3BSJJCQkK0dOlS7dq1S0uXLjWD57V1AKRPPvlEdrtd/v7+uZ4+9Pf3l91u1yeffOKiFgKFzwcffCDp6mwQv/32m8O6kydPqlGjRg51KBoIn3BKXucgZK5CwFHWJNjJycm5dllJTk52qAMg/fHHH5Kk2NhYBQcHa/r06Tp9+rSmT5+u4OBgxcbGOtShaGDAEZySfSRuUlKSZs2aZZ52f/rpp81T7YzYBRz5+PhIutpvrUKFClqwYIEWLFggSapSpYpOnDghwzDMOgBXB7Fu27ZN7u7uOnHihNkl5dlnn1Xv3r3l5+enzMxMNWzY0LUNhVMIn3BKfHy8pD8nmD906JAOHjwowzBkGIa5PKsOwFWXLl2SJBmGodq1aysgIEDnzp1TmTJlFBoaavZly6oDINWoUUPS1Wu8d+zYUbt27VJycrL8/f1Vr14988ImWXUoGgifcErWF6RhGObAI0lavXq1Jk+enKMOwFXZ+3muWrXKvP/777/r119/zbUOKO6y9/Ncs2aNeT8lJUVxcXG51qHwo88nnJLXKZSYaglwVLJkyQKtA4oDvnNuT4RPOGXatGnm/djYWHl6ekqSPD09zY7f19YBkNq2bWver1ChgsO67I+z1wHF3WOPPWbeX716tcO67I+z16HwY55POGXQoEEOp9evZ+DAgUwZA2RTr1497d69+y/rIiIitGvXLgtaBBR+VatW1bFjx/6yLjw8XEePHr31DcINMc8nbgmmWgLyJ69XYeFqLcCfEhISCrQOhQMDjuCU7BPJHz9+XIMHDzanWvroo49UpUqVHHUArl5/OmtQRFRUlAICAvTHH38oKChISUlJWrt2rVkH4Cp/f39zBojDhw/r22+/Nb9zHnnkEbOvJ2dFixbCJ5yybNky835cXJyWLl0qSdq1a5eio6NzrQMg7du3z7y/Z88enT592nycvc9n9jqguMu+n+zZs0dDhgwxH2cfZJS9DoUffT7hFE9PT2VkZPxlnYeHh9LT0y1oEVA0uLu7y263/2Wdm5ubOXchUNzZbLY81xaBOHPbo88nbolSpUoVaB1QXPj5+RVoHVAcuLnlLabktQ6FA38tOOXf//63eX/Tpk0aOHCg2rZtq4EDB2rTpk251gGQ5s2bZ95fu3atmjdvrrCwMDVv3tzs73ltHVDcZZ+27/PPP1d4eLhKlCih8PBwff7557nWofDjtDucwikQIH/YdwDnsd8ULZx2BwAAQKFD+AQAAIBlCJ9wyvvvv2/eHzFihMO67I+z1wGQZs2aZd4fNmyYw7rsj7PXAcXdu+++a95//fXXHdZlf5y9DoUffT7hFPrfAPnDvgM4j/2maKHPJwAAAAodwify7bPPPrvhYwC5u3ZaGKaJAf4a3zm3D8In8s3Dw0Oenp6Srl75yMODq7UCeREUFHTDxwByKlu2rEJCQuTt7a2QkBCVLVvW1U1CPtHnE06h/w2QP+w7gPPYb4oW+nwCAACg0CF8wikzZsww7w8ePNhhXfbH2esASOPHjzfv32jKmOx1QHG3YsUK8/610yllf5y9DoUfp93hFC8vL6Wnp/9lnaenp9LS0ixoEVA05Hb6sHHjxtq2bVuO5UXgYxmwRPny5RUfH/+XdSEhIYqLi7OgRbgRTrvjlshL8HSmDijOcgueAP6UmJhYoHUoHAifcErW6HZJ+u677xzWZX+cvQ7An9zc3LRw4UKHZQsXLpSbGx/HwLUCAgLM+zExMQ7rsj/OXofCj087OKVTp07m/cjISBmGYd4iIyNzrQMg7dixQ5Jkt9vVuHFjh32ncePGstvtDnUApIYNG5r3a9eu7bDf1K5dO9c6FH75Cp+TJ09WeHi4fHx81LRpU23duvWG9QsXLlTt2rXl4+OjevXqafny5flqLFwvOTnZvB8aGqoSJUronXfeUYkSJRQaGpprHQDHL8eqVavK3d1dL7zwgtzd3VW1atVc64Di7vTp0+b9oKAghYeHa/78+QoPD3eYHzd7HQo/p8Pnl19+qaFDh2r06NHavn27GjRooHbt2unMmTO51m/ZskU9evTQM888ox07dqhz587q3Lmzdu/efdONh/Vq1qzp8DglJUWvv/66UlJSblgHwHEgkd1u16effmoe8bx2PQCpevXqkiR3d3dJ0vHjx/Xkk0/q+PHjDsuz6lA0OD3avWnTprr77rv1ySefSLr6ARoWFqYXX3xRr776ao767t2769KlSw79Ae+55x41bNhQU6dOzdNrMtq98EhNTZWfn5+8vLy0Y8cONWzYUOnp6fL09NTOnTvVqFEjpaWlKSUlRb6+vq5uLlAoZe0rWbL2JQCOLl68qFKlSslms+nIkSO65557lJiYqMDAQP3888+qVq2aDMPQhQsXVLJkSVc3t9i7JaPd09LSFBsbq6ioqD+fwM1NUVFROToCZ4mJiXGol6R27dpdt16Srly5ouTkZIcbCgdfX1916tRJaWlpatSokYYMGaL9+/dryJAhZvDs1KkTwRO4gYYNGzr0XSN4ArkrWbKk7r77bhmGoWrVqikqKkpbtmxRVFSUGTzvvvtugmcR41T4PHv2rDIzMxUSEuKw/Ebza8XFxTlVL0njxo1TQECAeQsLC3OmmbjFli5dagbQ8ePHq1atWho/frwZPJcuXerqJgIAbhNbt241A+i8efMUGRmpefPmmcHzr8adoPAplKPdo6OjlZSUZN5Onjzp6ibhGkuXLlVKSooGDhyotm3bauDAgUpJSSF4AgAK3NatW3XhwgV17txZ9erVU+fOnXXhwgWCZxHl4UxxcHCw3N3dc1xtID4+XuXLl891m9yuTnCjekny9vaWt7e3M02DC/j6+pp9fwEAuJVKliypJUuWuLoZKABOHfn08vJSZGSk1q1bZy6z2+1at26dmjVrlus2zZo1c6iXpDVr1ly3HgAAALcvp458StLQoUPVp08fNW7cWE2aNNGkSZN06dIl9evXT5LUu3dvVaxYUePGjZMkDR48WK1atdIHH3ygDh066IsvvtC2bds0bdq0gn0nAAAAKPScDp/du3dXQkKC3njjDcXFxalhw4ZauXKlOajoxIkTDpeJu/feezV//ny9/vrreu2111SzZk0tXbpUERERBfcuAAAAUCQ4Pc+nKzDPJwAAQOF2S+b5BAAAAG4G4RMAAACWIXwCAADAMoRPAAAAWIbwCQAAAMsQPgEAAGAZp+f5dIWs2aCSk5Nd3BIAAADkJiun/dUsnkUifF64cEGSFBYW5uKWAAAA4EYuXLiggICA664vEpPM2+12nTp1SqVKlZLNZnN1c5BNcnKywsLCdPLkSS4AADiBfQdwHvtN4WYYhi5cuKAKFSo4XO3yWkXiyKebm5sqVark6mbgBvz9/fkgAPKBfQdwHvtN4XWjI55ZGHAEAAAAyxA+AQAAYBnCJ26Kt7e3Ro8eLW9vb1c3BShS2HcA57Hf3B6KxIAjAAAA3B448gkAAADLED4BAABgGcInAAAALEP4BAAAgGUInwDgIpmZma5uAoBs9u3bJ7vd7upm3PYInwDgAuPHj1e/fv10+fJlVzcFgKRXX31VTZo00c8//0wAvcUInwDgAnfccYfmz5+v4cOHE0CBQuDdd9/VnXfeqX79+ikmJoYAegsRPnFLMH0skLtjx44pPT1dnTt31rJlyzRz5kwNGTKEAAq4UEZGhiQpJiZGgYGB6tu3LwH0FiJ8osAZhiGbzab169dr1KhRevLJJ/XFF18oISHB1U0DXGrBggWqVauW1q9fr4yMDD300EP6+uuvNWfOHAIo4EIeHh5mAP3Pf/6j0qVLE0BvIcInCpzNZtPixYvVpUsXHT58WCEhIerVq5deffVVxcXFubp5gMv06NFDLVq00DPPPKP169crPT1d7du3J4ACLpI9WHp4eJj3//Of/ygoKIgAeosQPlHgjh49qujoaL333nuaP3++Jk6cKG9vb5UrV07ly5d3dfMAl8g6qrJu3TrVrl1bvXv31oYNGwiggIvY7Xa5uV2NQTt27NDGjRt18uRJcxaKrVu3mgGUQUgFi/CJApeWlqagoCANGDBABw8eVKVKlfTkk09q3LhxkqQ9e/a4uIWA9bIfVVm9erXq1q173QA6YsQIpaamurC1wO3NMAwzeL7++uvq3LmzevfurYiICH300Uc6cuSIpKsBtHTp0nr66ae1YcMGxjMUEMInClxSUpJ+//13bd68WQ899JDat2+vTz/9VNLVHXnUqFE6cOCAi1sJWG/Pnj365ZdfJElr167NNYAuWbJEkydP1uuvv+7i1gK3L5vNJkl65513NHv2bM2aNUtHjx5V165d9c4772jmzJlmAP3Pf/6jK1euaOrUqeZ2uDmET9yUrF+B2X8NNmnSRPfcc49atWqlyMhITZs2Te7u7pKkpUuXKj4+XgEBAS5pL+AKhmHozJkzevTRR/Xhhx8qNjZWUs4AmpGRoQcffFCrVq1S//79Xdxq4PZ2+PBhbdq0SR9//LEeeOABLVu2TEuWLFHr1q314Ycfatq0aTp06JCkq93J5s+f7+IW3z5sBseQkU9Zo9p/+uknrV+/Xr6+vurevbsqV66slStX6q233pKvr6/effddXbhwQStWrND06dO1ceNG1a9f39XNB26ZCxcuqFSpUjmWf/HFFxo7dqzuvvtuPf/882rcuLEkKSoqSgcPHtSnn36qtm3bOpyiB3BrnDt3Tj/++KPat2+vnTt36rHHHlN0dLQGDRqkp59+Wt9//726d++ul19+WZUqVZJ09apkWQdTkH98wiHfbDabli9frkceeURRUVFav369vvnmG7388st65JFHlJqaqhkzZqhFixaqVauWAgIC9NNPPxE8cVsbMGCAMjIyNHXqVHl5eSk1NVW+vr6SpCeeeEKenp4aNWqUbDabnn/+eUVGRmrt2rW6++67NXz4cG3bto3wCRSw7IOLspQpU0YPPPCA/Pz8tGDBAt1///0aMGCAJCkwMFAVKlTQqVOnVLFiRXMbgmfB4BMOTss64hkfH6+FCxdq6tSpevbZZ3Xu3Dn16NFD7733ngzDUJcuXdSlSxft2rVLFSpUkLu7uwIDA13dfOCW+eKLL7R06VKtXr1aXl5e2rJli1asWKF+/fqpWrVqkqSuXbvKMAwNGTJEV65c0dChQ9WoUSP98ssvOnHihPz8/Fz8LoDbS/bBRYsWLdKlS5fk5+enxx57TEFBQcrIyNCZM2fk7e2ttLQ0eXl56cSJE5o0aZLuu+8+2Ww283sPBYPwCafZbDZt3rxZY8eOVXJysl588UVJV39Ffv755+rdu7fGjx+vK1euqFu3bqpXr56LWwxY4+TJkypTpowaNmyoVatW6emnn9aVK1dkt9s1YMAAValSRZLUrVs3xcXF6bXXXlNGRoaGDx+uyMhIVa5c2cXvALi9ZA+Nw4YN05w5cxQcHKyUlBQtWbJE8+fPl4eHh+rXr6/33ntPiYmJOnHihNLS0tS8eXPZbLZcj5ri5vCviXwpX768jhw5oi1btmjXrl3m8nLlyunzzz9XUFCQxowZo6VLl7qukYDFWrduLcMw9Le//U3t27c3+3jOnTtXU6dO1bFjx8zacuXKqWrVqvrtt99UoUIF1zUauI1lBc+EhAT9+uuv2rBhg3744Qf93//9n9auXauHH35YkjRy5EiNHDlSlStXVqtWrfTrr7/Kw8NDmZmZBM9bgAFHyLdjx46pS5cuCgwM1OjRo9W6dWtz3ZkzZzRw4EBNmDBB4eHhLmsjYLWBAwfq008/VZMmTfTzzz9Lkj766CNNmDBBTz31lHr27Kl69erp9ddfV8WKFdWzZ09mfwBuoY8++kgLFy5UWFiYZs6cKT8/P6Wnp2vt2rXq06ePmjRpou+++06SY9/QjIwM+l/fIoRP/KWs0xb79+/XyZMnFRgYqPLly6tSpUo6cOCAunXrptDQUEVHRzsEUE5VoLhJTU1Vx44dVa1aNW3ZskX169fXggULJEmffPKJpk6dqitXrqhcuXL69ddfFRMTo4iICBe3Grh9paWlafr06Ro/frwCAgL066+/muuyAujTTz+tatWqafPmzS5safFC+MQNZQXPr7/+WoMHD5anp6cMw5CPj4+mTZum++67zwygYWFhGjx4sNq2bevqZgMuk5KSIj8/P82aNUvjx49Xo0aNzAC6Zs0a/e9//1NCQoKeeuop1apVy8WtBW4vuR30OHfunL799lsNGjRITz31lKZOnWquy8jI0LJlyzRjxgwtW7aMAyYWIXziurJOOWzdulVRUVGaMGGCOnbsqEOHDmnGjBlatGiRVq9erZYtW+rQoUP629/+prvvvlv//ve/GbGLYu/ixYtauHChGUCZoBq4tbIHz4MHD+rKlSsKCwtTQECAMjIyNGfOHL366qvq3r27Jk+ebG6Xfe5OzthZg84MyOH48eOqXLmy2dl6165daty4sfr37y83NzdVrFhRtWrVkt1u1+DBg7V8+XLVqFFDP/30k+x2O8ETkFSyZEk9/vjjkqSJEyfqkUce0bfffuviVgG3p+zTKb322mv66quvdOnSJaWlpWnIkCHq06ePnnnmGdlsNr322muy2Wz65JNPJDnO3UnwtAbhEw6uXLmiJ554QnFxcTpy5Ijc3d2VnJysnTt3Kjk5WYGBgTIMQ+XLl1fPnj31/PPP648//lD58uUZWARco0SJEnr88cd1+fJlzZkzR6dOnWJkO3ALZI1qnzhxoqZPn665c+eqcuXK+u677zR37lwlJCRo5MiR6tmzp9zc3PTMM88oPDxcw4cPd3HLiyciPhx4eXlpwoQJKlmypO666y4ZhqFOnTopNDRUs2fPVmJiormT16xZU56enrpw4YKLWw0UXiVKlFCfPn20evVqgidwC2UNIHruuefUvn17RURE6NVXX9WwYcO0aNEirVq1Sr6+vurcubO+/fZbDRkyxNVNLrYIn3Bgs9l07733avr06UpNTVXTpk1VrVo1denSRbNnz9b06dMVHx+vixcvatasWXJzc+OIJ/AX/Pz8mE4JKGDXDlnJzMzUxYsXzeVXrlyRJD377LNq166dJk2aJLvdrqCgIHXs2FHu7u7KzMy0vN0gfEJSXFycOR+hdLXPS2RkpD777DOdPXtWrVq10j//+U917txZn332mcLDw9WmTRvNmjVLX331lcqVK+fC1gMAiqOss3AHDx6UJPn4+CgiIkKzZ8/WpUuX5O3trYyMDElStWrVFBISkqNPJ9dqdw1GuxdzJ0+eVKNGjXT+/Hm1atVKzZo1U1RUlBo3bix/f3/98ssveuaZZ+Tv769NmzYpLi5Oy5cvV1BQkO666y7zcoEAAFgh+4j0r776SlOmTNHQoUP1yCOP6Ny5c2rTpo3sdrtWr16tUqVKydPTU23btlVYWJjmzp3r4tZDInwWe8ePH1fnzp2VmpqqUqVK6c4779SXX36p2rVrq169eurYsaNsNpuio6NVrVo1rVq1yvy1CQCAlbIHz1WrVumbb77R/Pnz1bBhQ7322mtq27atduzYoeeff14HDhxQjRo1lJ6ervT0dO3YscOcq5rvMdcifEKHDh3Syy+/LLvdrujoaIWGhmrLli365JNPlJ6ert27d6t69eravXu3OnXqpCVLlrDzAgBcZsSIEZo/f76ef/55Xbx4UXPmzFFERIRGjBihdu3aSZKmTJmilJQUeXt76/nnn5eHhweXzCwkCJ+QJO3fv1+DBw+W3W7XO++8o7vvvluSlJiYqGXLlmnfvn1asWKFZs6cqUaNGrm4tQCA4uq///2v2rdvr7lz5yoqKkqStHXrVr300kvy9PTUa6+9ZgbQ7LJPJg/XInzCdPDgQb344ouSpOjoaLVq1cphPb8YAQCudvDgQbVu3Vpz5sxRmzZtzDNxv/zyi1q1aqXmzZtr8ODB6tixoyRxpq4QYrQ7TDVr1tTHH38sm82mcePGacuWLQ7rCZ4AAFfL6vO5Z88eSVf7gRqGobvvvluNGjXS6dOnNXfuXO3bt0+SCJ6FEOETDmrWrKn/+7//k6enp4YNG+YwBRMAAFax2+3m/ewnaatXr66XXnpJI0aM0KJFi+Tu7i6bzaaUlBRVr15dw4cP1w8//KBVq1a5otnIA067I1f79u3TqFGj9MEHH6hy5cqubg4AoBjJPqp9+vTp+vXXX3X58mV16tRJbdu2lZeXl4YPH66JEyfq73//u4KCghQTE6Pk5GTFxsbqkUcekbe3txYuXOjid4LccOQTuapdu7bmzZtH8AQAWC4reL7yyisaOXKk3N3ddfLkSY0ZM0bvvPOO0tLS9P7772vWrFk6fvy4Nm/erNDQUMXExEiSUlJSVKtWLVe+BdwAnfhwXV5eXq5uAgCgmJo1a5YWLVqkFStWKDIyUkuWLNFjjz2mixcvKjU1VW+//bb69u2rrl27qlSpUpKky5cva+TIkdq9e7cmT57s4neA6+HIJwAAcKmWLVvqhx9+MB8bhqFLly6pT58+ZvB8+umnNWHCBN1///2aPXu2xowZo8uXL5vB8/Dhw4qOjtbcuXO1cuVKjnwWYvT5BAAALpOSkqLJkyfrH//4h7y9vc3lf/zxhy5fvqzMzEy1b99effr00bBhw3T48GHde++98vb21vDhw/WPf/xDkpSamqq9e/cqODiYLmOFHKfdAQCAS6SkpMjPz08jRoyQJL3zzjuqXr26nnjiCQUEBCgoKEjr1q1TSkqKOnXqJEk6d+6c7rvvPkVFRal///7mc/n6+uquu+5yyfuAczjtDgAALPf000+rTZs2+uOPPyRJaWlpOnbsmHr27KlvvvnGHHTk5uYmT09Pfffddzpy5IjGjBmjoKAgDRgwQG5ubsrMzHTl20A+cNodAABYbuvWrerUqZPuuecezZ49W4GBgUpOTtZbb72ljz76SAsXLlSXLl30xx9/aMiQIfrpp590+fJlVapUSZs3b5anpydXLyqiCJ8AAMBSWZdr/u9//6uHHnpIzZo107Rp01SmTBlduHBBb7zxhj7++GN98cUX6tatmxITE3X48GElJiaqdevWcnd355LPRRh/NQAAYBm73W6GxosXL2rIkCF65ZVX5Ofnp48//liBgYF66623JEk9evSQm5ubHn30UUVGRprPkZmZSfAswujzCQAALJN9AvmePXvq/Pnz6tixo7755hv16dNHiYmJ8vf319tvv61//OMf6tatm3766SeH53B3d3dF01FAOO0OAAAstXXrVj344INatGiR/va3vykzM1ObN29W165d1aJFC82aNUtBQUFKSkrS3Llz9cILL3Ck8zbCkU8AAHDL5HaMKyUlRb6+vrrzzjslXT0aet9992nOnDn67rvv9PLLL+vs2bMKCAjQP/7xD3l4eCgjI8PqpuMWIXwCAIBb4vLly7mORq9Ro4aSkpK0fPlySTJr7rzzToWGhmrmzJkaP368wzYc+bx9ED4BAECB69Chgz755JMcyzMzMxUcHKxnnnlGn376qRYtWmSuCwgIUNu2bbV161aNGzfOyubCQvT5BAAABeq5557Tjz/+qP3790uSOR+n3W6Xm5ubUlNTlZSUpOHDh+uXX35Rly5dVLt2bf373//WpUuXFBMTI5vNpszMTAYX3YY48gkAAApUamqq2rdvL0maMmWKfvzxRzN4fvnllypfvrxKlSql6OhoDRgwQAsWLNCnn34qT09Pbdy4UTabTYZhEDxvU3SgAAAABWLatGnq16+fQkJCtGjRIh09elTLli3TsWPH5ObmpqVLl+rZZ5/VO++8oxIlSujOO+/UnXfeqYEDByojI0MlSpSQzWZjAvnbHKfdAQDATWvdurV8fHy0cuVKSVLlypWVkJCgMWPGaPjw4UpKStJTTz2lhx9+WP379ze3yzoimoVLZt7++FkBAABuypo1a3To0CH9/PPPkqQtW7YoPT1d9957r6ZMmaIqVaroscce05w5c1S6dGmHbbMHT0kEz2KA8AkAAG6KzWaTj4+PDh48qDfffFMlSpTQwYMHVbJkSXXt2lXDhg2TzWZThw4dXN1UFAKcdgcAADftscce0+bNm3Xu3Dn99NNPatq0qbmuW7du2rZtm95//3117NhRPj4+LmwpXI3R7gAAIN8yMzMlXe3jGRcXp4oVK+rSpUu6fPmyWbNo0SLdfffdeuWVV7Rw4UKlpaW5qrkoBAifAADAaXa7XZLM6ZDuv/9+/frrr4qIiNCAAQO0du1ah5C5cOFCValSRd988428vLxc0mYUDpx2BwAATsk+Qv2bb75RXFycDMNQr169VLJkSXXp0kW7du3SpEmT1LZtW4ewee3odhQ/hE8AAJAvw4cP19y5c1W7dm3t3LlTd9xxh1588UX17dtXnTt31t69ezVx4kS1adOGAAoTf3kAAOC0RYsWaf78+Vq5cqV++uknnTx5UpGRkZo2bZoWLlyopUuXqmrVqurVq5e2bdvmsC3Bs3jjrw8AAJx25MgRVa5cWfXr15dhGAoMDNSYMWMUGhqqKVOmSJJWrlypvn37Oox8BwifAAAgz7J663l4eOjy5ctKS0uTm5ubMjIyFBISoujoaG3YsEFbt26VJH344Ydyd3c3R8UDhE8AAJBnWVcgevDBB7V79269//77kmReiz0zM1MREREKDg522C5rVDzAFY4AAIDT6tatq5kzZ6p///5KTk5W165dFRQUpLfeekuBgYEKDw93dRNRSDHaHQAA5NvixYs1aNAg2Ww2+fn5qVy5clq/fr08PT0Z1Y5cET4BAMBNiYuLU3x8vNLS0hQZGWn2Ac06FQ9kR/gEAAAFiiOeuBHCJwAAACzDzxIAAABYhvAJAAAAyxA+AQAAYBnCJwAAACxD+AQAAIBlCJ8AAACwDOETAAAAliF8AgAAwDKETwAAAFiG8AkAAADLED4BAABgmf8HcL6jjuyxULwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To make it easier to add edits\n",
    "key_words = {\"figsize\": (8, 5),\n",
    "            \"kind\": \"box\",\n",
    "            \"by\": \"Page_Rank\",\n",
    "            \"rot\": 45}\n",
    "\n",
    "(df_subset2.plot(column='FOSCTTM', cmap='tab10', **key_words),\n",
    "df_subset2.plot(column='Cross_Embedding_KNN', cmap = \"jet\", **key_words),\n",
    "df_subset2.plot(column='Combined_Metric', **key_words),\n",
    "df_subset2.plot(column='Predicted_Feature_MAE', cmap = \"jet\", **key_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPUD\n",
    "\n",
    "Notes:\n",
    "1. Distance seems to be the best metric (This note was made when we only have iris data tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/6x5k_xzn7rg11nhcgfgp3g740000gn/T/ipykernel_1142/426300760.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset3[\"Combined_Arguments\"] = df_subset3[\"Operation\"]+ \" and \" + df_subset3[\"SPUDS_Algorithm\"]\n"
     ]
    }
   ],
   "source": [
    "#If we want to see only a few csv files at a time, we can sub set it here\n",
    "#df_subset3 = df[df[\"csv_file\"] == \"iris\"]\n",
    "\n",
    "#To see all of it combined\n",
    "df_subet3 = df\n",
    "\n",
    "#Change the method to DIG\n",
    "df_subset3 = df[df[\"method\"] == \"SPUD\"]\n",
    "\n",
    "#Combine DIG argumenst\n",
    "df_subset3[\"Combined_Arguments\"] = df_subset3[\"Operation\"]+ \" and \" + df_subset3[\"SPUDS_Algorithm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FOSCTTM    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object,\n",
       " Cross_Embedding_KNN    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object,\n",
       " Combined_Metric    Axes(0.125,0.11;0.775x0.77)\n",
       " dtype: object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To make it easier to add edits\n",
    "key_words = {\"figsize\": (10, 6),\n",
    "            \"kind\": \"box\",\n",
    "            \"by\": \"Combined_Arguments\",\n",
    "            \"rot\": 15}\n",
    "\n",
    "(df_subset3.plot(column='FOSCTTM', cmap='tab10', **key_words),\n",
    "df_subset3.plot(column='Cross_Embedding_KNN', cmap = \"jet\", **key_words),\n",
    "df_subset3.plot(column='Combined_Metric', **key_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Methods against CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort out by methods\n",
    "import pandas as pd\n",
    "\n",
    "agregate_df = pd.DataFrame({\n",
    "    'SSMA': df[df[\"method\"] == \"SSMA\"].groupby(\"csv_file\")[\"Combined_Metric\"].max(),\n",
    "    'DTA': df[df[\"method\"] == \"DTA\"].groupby(\"csv_file\")[\"Combined_Metric\"].max(),\n",
    "    'SPUD': df[df[\"method\"] == \"SPUD\"].groupby(\"csv_file\")[\"Combined_Metric\"].max(),\n",
    "    'DIG': df[df[\"method\"] == \"DIG\"].groupby(\"csv_file\")[\"Combined_Metric\"].max(),\n",
    "    'NAMA': df[df[\"method\"] == \"NAMA\"].groupby(\"csv_file\")[\"Combined_Metric\"].max()\n",
    "})\n",
    "\n",
    "agregate_df = agregate_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15c9aa690>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To make it easier to add edits\n",
    "key_words = {\"x\" : agregate_df.index\n",
    "            }\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "ax = plt.scatter(y = agregate_df[\"SPUD\"], label = \"SPUD\", **key_words)\n",
    "ax = plt.scatter(y = agregate_df[\"DIG\"], label = \"DIG\", **key_words)\n",
    "ax = plt.scatter(y = agregate_df[\"SSMA\"], label = \"SSMA\", **key_words)\n",
    "ax = plt.scatter(y = agregate_df[\"DTA\"], label = \"DTA\", **key_words)\n",
    "ax = plt.scatter(y = agregate_df[\"NAMA\"], label = \"NAMA\", **key_words)\n",
    "\n",
    "#Show Legend\n",
    "plt.xticks(ticks= agregate_df.index,labels=agregate_df[\"csv_file\"], rotation = 65)\n",
    "plt.title(\"Combined Metric Scores vs. CSV Files\")\n",
    "plt.ylabel(\"CE - FOSCTTM\")\n",
    "plt.grid(visible=True, axis = \"x\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Tests Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "---------------------------       Initalizing class with glass.csv data       ---------------------------\n",
      "\n",
      "Spliting the data evenly\n",
      "Split A features shape: (214, 5)\n",
      "Split B Features shape (214, 4)\n",
      "MDS initialized with 4 components\n",
      "The knn values are: (2, 7, 12, 17, 22, 27, 32, 37, 42, 47)\n"
     ]
    }
   ],
   "source": [
    "iris_tma = tma.test_manifold_algorithms(\"glass.csv\", split = \"even\", percent_of_anchors= [0.1], verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_data(n_batches=2, n_pts_per_cluster=500):\n",
    "    \"\"\"Return the artificial data.\"\"\"\n",
    "    make = lambda x,y,s: np.concatenate([np.random.normal(x,s, (n_pts_per_cluster, 1)), np.random.normal(y,s, (n_pts_per_cluster, 1))], axis=1)\n",
    "    # batch 1\n",
    "    xb1 = np.concatenate([make(-1.3, 2.2, .1), make(.1, 1.8, .1), make(.8, 2, .1)], axis=0)\n",
    "    labels1 = np.concatenate([0 * np.ones(n_pts_per_cluster), 1 * np.ones(n_pts_per_cluster), 2 * np.ones(n_pts_per_cluster)], axis=0)\n",
    "\n",
    "    # batch 2\n",
    "    xb2 = np.concatenate([make(-.9, -2, .1), make(0, -2.3, .1), make(1.5, -1.5, .1)], axis=0)\n",
    "    labels2 = np.concatenate([0 * np.ones(n_pts_per_cluster), 1 * np.ones(n_pts_per_cluster), 2 * np.ones(n_pts_per_cluster)], axis=0)\n",
    "\n",
    "    return xb1, xb2, labels1, labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb1, xb2, labels1, labels2 = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/user/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/util/decorator_utils.py:153: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
      "Help on package tensorflow.compat.v1 in tensorflow.compat:\n",
      "\n",
      "NAME\n",
      "    tensorflow.compat.v1 - Bring in all of the public TensorFlow interface into this module.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __internal__ (package)\n",
      "    app (package)\n",
      "    audio (package)\n",
      "    autograph (package)\n",
      "    bitwise (package)\n",
      "    compat (package)\n",
      "    config (package)\n",
      "    data (package)\n",
      "    debugging (package)\n",
      "    distribute (package)\n",
      "    distributions (package)\n",
      "    dtypes (package)\n",
      "    errors (package)\n",
      "    experimental (package)\n",
      "    feature_column (package)\n",
      "    gfile (package)\n",
      "    graph_util (package)\n",
      "    image (package)\n",
      "    initializers (package)\n",
      "    io (package)\n",
      "    layers (package)\n",
      "    linalg (package)\n",
      "    lite (package)\n",
      "    logging (package)\n",
      "    lookup (package)\n",
      "    losses (package)\n",
      "    manip (package)\n",
      "    math (package)\n",
      "    metrics (package)\n",
      "    mixed_precision (package)\n",
      "    mlir (package)\n",
      "    nest (package)\n",
      "    nn (package)\n",
      "    profiler (package)\n",
      "    python_io (package)\n",
      "    quantization (package)\n",
      "    queue (package)\n",
      "    ragged (package)\n",
      "    random (package)\n",
      "    raw_ops (package)\n",
      "    resource_loader (package)\n",
      "    saved_model (package)\n",
      "    sets (package)\n",
      "    signal (package)\n",
      "    sparse (package)\n",
      "    spectral (package)\n",
      "    strings (package)\n",
      "    summary (package)\n",
      "    sysconfig (package)\n",
      "    test (package)\n",
      "    tpu (package)\n",
      "    train (package)\n",
      "    types (package)\n",
      "    user_ops (package)\n",
      "    version (package)\n",
      "    xla (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        tensorflow.python.framework.errors_impl.OpError\n",
      "    builtins.object\n",
      "        tensorflow.python.eager.backprop.GradientTape\n",
      "        tensorflow.python.framework.ops.GraphKeys\n",
      "        tensorflow.python.framework.ops.RegisterGradient\n",
      "        tensorflow.python.framework.tensor_shape.Dimension\n",
      "        tensorflow.python.ops.critical_section_ops.CriticalSection\n",
      "        tensorflow.python.ops.data_flow_ops.ConditionalAccumulatorBase\n",
      "            tensorflow.python.ops.data_flow_ops.ConditionalAccumulator\n",
      "            tensorflow.python.ops.data_flow_ops.SparseConditionalAccumulator\n",
      "        tensorflow.python.ops.data_flow_ops.QueueBase\n",
      "            tensorflow.python.ops.data_flow_ops.FIFOQueue\n",
      "            tensorflow.python.ops.data_flow_ops.PaddingFIFOQueue\n",
      "            tensorflow.python.ops.data_flow_ops.PriorityQueue\n",
      "            tensorflow.python.ops.data_flow_ops.RandomShuffleQueue\n",
      "        tensorflow.python.ops.gradients_util.AggregationMethod\n",
      "        tensorflow.python.ops.io_ops.ReaderBase\n",
      "            tensorflow.python.ops.io_ops.FixedLengthRecordReader\n",
      "            tensorflow.python.ops.io_ops.IdentityReader\n",
      "            tensorflow.python.ops.io_ops.LMDBReader\n",
      "            tensorflow.python.ops.io_ops.TFRecordReader\n",
      "            tensorflow.python.ops.io_ops.TextLineReader\n",
      "            tensorflow.python.ops.io_ops.WholeFileReader\n",
      "        tensorflow.python.ops.tensor_array_ops.TensorArray\n",
      "        tensorflow.python.ops.variable_scope.VariableScope\n",
      "        tensorflow.python.ops.variable_scope.variable_scope\n",
      "    builtins.tuple(builtins.object)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensorValue\n",
      "    contextlib.AbstractContextManager(abc.ABC)\n",
      "        tensorflow.python.framework.ops.name_scope_v1\n",
      "    enum.Enum(builtins.object)\n",
      "        tensorflow.python.ops.unconnected_gradients.UnconnectedGradients\n",
      "        tensorflow.python.ops.variables.VariableAggregation\n",
      "        tensorflow.python.ops.variables.VariableSynchronization\n",
      "    google._upb._message.Message(builtins.object)\n",
      "        tensorflow.core.framework.attr_value_pb2.AttrValue(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.attr_value_pb2.NameAttrList(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.graph_pb2.GraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.node_def_pb2.NodeDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.SummaryMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.ConfigProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GPUOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GraphOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.OptimizerOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.MetaGraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.TensorInfo(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.LogMessage(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tsl.protobuf.histogram_pb2.HistogramProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "    google.protobuf.message.Message(builtins.object)\n",
      "        tensorflow.core.framework.attr_value_pb2.AttrValue(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.attr_value_pb2.NameAttrList(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.graph_pb2.GraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.node_def_pb2.NodeDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.SummaryMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.ConfigProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GPUOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GraphOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.OptimizerOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.MetaGraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.TensorInfo(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.LogMessage(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "        tsl.protobuf.histogram_pb2.HistogramProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "    tensorflow.core.function.trace_type.serialization.Serializable(builtins.object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "        tensorflow.python.framework.tensor_shape.TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    tensorflow.python.client._pywrap_tf_session.PyGraph(builtins.object)\n",
      "        tensorflow.python.framework.ops.Graph\n",
      "    tensorflow.python.client._pywrap_tf_session.PyOperation(builtins.object)\n",
      "        tensorflow.python.framework.ops.Operation\n",
      "    tensorflow.python.client.session.BaseSession(tensorflow.python.client.session.SessionInterface)\n",
      "        tensorflow.python.client.session.InteractiveSession\n",
      "        tensorflow.python.client.session.Session\n",
      "    tensorflow.python.framework._dtypes.DType(pybind11_builtins.pybind11_object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "    tensorflow.python.framework.composite_tensor.CompositeTensor(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.internal.RaggedTensor)\n",
      "    tensorflow.python.framework.device_spec.DeviceSpecV2(builtins.object)\n",
      "        tensorflow.python.framework.device_spec.DeviceSpecV1\n",
      "    tensorflow.python.framework.tensor.DenseSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "    tensorflow.python.framework.type_spec.BatchableTypeSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensorSpec\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.python.types.internal.RaggedTensorSpec)\n",
      "    tensorflow.python.ops.init_ops.Initializer(builtins.object)\n",
      "        tensorflow.python.ops.init_ops.Constant\n",
      "        tensorflow.python.ops.init_ops.Ones\n",
      "        tensorflow.python.ops.init_ops.Orthogonal\n",
      "        tensorflow.python.ops.init_ops.RandomNormal\n",
      "        tensorflow.python.ops.init_ops.RandomUniform\n",
      "        tensorflow.python.ops.init_ops.TruncatedNormal\n",
      "        tensorflow.python.ops.init_ops.UniformUnitScaling\n",
      "        tensorflow.python.ops.init_ops.VarianceScaling\n",
      "            tensorflow.python.ops.init_ops.GlorotNormal\n",
      "            tensorflow.python.ops.init_ops.GlorotUniform\n",
      "        tensorflow.python.ops.init_ops.Zeros\n",
      "    tensorflow.python.ops.parsing_config.FixedLenFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_config.FixedLenFeature\n",
      "    tensorflow.python.ops.parsing_config.FixedLenSequenceFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_config.FixedLenSequenceFeature\n",
      "    tensorflow.python.ops.parsing_config.SparseFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_config.SparseFeature\n",
      "    tensorflow.python.ops.parsing_config.VarLenFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_config.VarLenFeature\n",
      "    tensorflow.python.ops.variables.Variable(tensorflow.python.trackable.base.Trackable)\n",
      "        tensorflow.python.ops.variable_v1.VariableV1\n",
      "    tensorflow.python.trackable.autotrackable.AutoTrackable(tensorflow.python.trackable.base.Trackable)\n",
      "        tensorflow.python.module.module.Module\n",
      "    tensorflow.python.types.core.Symbol(tensorflow.python.types.core.Tensor)\n",
      "        tensorflow.python.framework.tensor.Tensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "    tensorflow.python.types.internal.IndexedSlices(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "    tensorflow.python.types.internal.NativeObject(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.tensor.Tensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.internal.RaggedTensor)\n",
      "    tensorflow.python.types.internal.RaggedTensor(builtins.object)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.internal.RaggedTensor)\n",
      "    tensorflow.python.types.internal.RaggedTensorSpec(builtins.object)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.python.types.internal.RaggedTensorSpec)\n",
      "    tensorflow.python.types.internal.TensorSpec(builtins.object)\n",
      "        tensorflow.python.framework.tensor.TensorSpec(tensorflow.python.framework.tensor.DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "    tensorflow.python.types.internal.TypeSpec(builtins.object)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    tensorflow.python.types.trace.TraceType(builtins.object)\n",
      "        tensorflow.python.framework.dtypes.DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.tensor_shape.TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "        tensorflow.python.framework.type_spec.TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "    \n",
      "    class AggregationMethod(builtins.object)\n",
      "     |  A class listing aggregation methods used to combine gradients.\n",
      "     |  \n",
      "     |  Computing partial derivatives can require aggregating gradient\n",
      "     |  contributions. This class lists the various methods that can\n",
      "     |  be used to combine gradients in the graph.\n",
      "     |  \n",
      "     |  The following aggregation methods are part of the stable API for\n",
      "     |  aggregating gradients:\n",
      "     |  \n",
      "     |  *  `ADD_N`: All of the gradient terms are summed as part of one\n",
      "     |     operation using the \"AddN\" op (see `tf.add_n`). This\n",
      "     |     method has the property that all gradients must be ready and\n",
      "     |     buffered separately in memory before any aggregation is performed.\n",
      "     |  *  `DEFAULT`: The system-chosen default aggregation method.\n",
      "     |  \n",
      "     |  The following aggregation methods are experimental and may not\n",
      "     |  be supported in future releases:\n",
      "     |  \n",
      "     |  * `EXPERIMENTAL_TREE`: Gradient terms are summed in pairs using\n",
      "     |    the \"AddN\" op. This method of summing gradients may reduce\n",
      "     |    performance, but it can improve memory utilization because the\n",
      "     |    gradients can be released earlier.\n",
      "     |  * `EXPERIMENTAL_ACCUMULATE_N`: Same as `EXPERIMENTAL_TREE`.\n",
      "     |  \n",
      "     |  Example usage when computing gradient:\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def example():\n",
      "     |  ...   x = tf.constant(1.0)\n",
      "     |  ...   y = x * 2.0\n",
      "     |  ...   z = y + y + y + y\n",
      "     |  ...   return tf.gradients(z, [x, y],\n",
      "     |  ...     aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)\n",
      "     |  >>> example()\n",
      "     |  [<tf.Tensor: shape=(), dtype=float32, numpy=8.0>,\n",
      "     |   <tf.Tensor: shape=(), dtype=float32, numpy=4.0>]\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ADD_N = 0\n",
      "     |  \n",
      "     |  DEFAULT = 0\n",
      "     |  \n",
      "     |  EXPERIMENTAL_ACCUMULATE_N = 2\n",
      "     |  \n",
      "     |  EXPERIMENTAL_TREE = 1\n",
      "    \n",
      "    class AttrValue(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      AttrValue\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ListValue = <class 'tensorflow.core.framework.attr_value_pb2.ListValue...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class ConditionalAccumulator(ConditionalAccumulatorBase)\n",
      "     |  ConditionalAccumulator(dtype, shape=None, shared_name=None, name='conditional_accumulator', reduction_type='MEAN')\n",
      "     |  \n",
      "     |  A conditional accumulator for aggregating gradients.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConditionalAccumulator\n",
      "     |      ConditionalAccumulatorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape=None, shared_name=None, name='conditional_accumulator', reduction_type='MEAN')\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        shared_name: Optional. If non-empty, this accumulator will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the accumulator.\n",
      "     |        reduction_type: Reduction type to use when taking the gradient.\n",
      "     |  \n",
      "     |  apply_grad(self, grad, local_step=0, name=None)\n",
      "     |      Attempts to apply a gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., local_step\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad: The gradient tensor to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  take_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      \n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tensor holding the value of the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If num_required < 1\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class ConditionalAccumulatorBase(builtins.object)\n",
      "     |  ConditionalAccumulatorBase(dtype, shape, accumulator_ref)\n",
      "     |  \n",
      "     |  A conditional accumulator for aggregating gradients.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape, accumulator_ref)\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        accumulator_ref: A handle to the conditional accumulator, created by sub-\n",
      "     |          classes\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class ConfigProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      ConfigProto\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  DeviceCountEntry = <class 'tensorflow.core.protobuf.config_pb2.DeviceC...\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class CriticalSection(builtins.object)\n",
      "     |  CriticalSection(name=None, shared_name=None, critical_section_def=None, import_scope=None)\n",
      "     |  \n",
      "     |  Critical section.\n",
      "     |  \n",
      "     |  A `CriticalSection` object is a resource in the graph which executes subgraphs\n",
      "     |  in **serial** order.  A common example of a subgraph one may wish to run\n",
      "     |  exclusively is the one given by the following function:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  v = resource_variable_ops.ResourceVariable(0.0, name=\"v\")\n",
      "     |  \n",
      "     |  def count():\n",
      "     |    value = v.read_value()\n",
      "     |    with tf.control_dependencies([value]):\n",
      "     |      with tf.control_dependencies([v.assign_add(1)]):\n",
      "     |        return tf.identity(value)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Here, a snapshot of `v` is captured in `value`; and then `v` is updated.\n",
      "     |  The snapshot value is returned.\n",
      "     |  \n",
      "     |  If multiple workers or threads all execute `count` in parallel, there is no\n",
      "     |  guarantee that access to the variable `v` is atomic at any point within\n",
      "     |  any thread's calculation of `count`.  In fact, even implementing an atomic\n",
      "     |  counter that guarantees that the user will see each value `0, 1, ...,` is\n",
      "     |  currently impossible.\n",
      "     |  \n",
      "     |  The solution is to ensure any access to the underlying resource `v` is\n",
      "     |  only processed through a critical section:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  cs = CriticalSection()\n",
      "     |  f1 = cs.execute(count)\n",
      "     |  f2 = cs.execute(count)\n",
      "     |  output = f1 + f2\n",
      "     |  session.run(output)\n",
      "     |  ```\n",
      "     |  The functions `f1` and `f2` will be executed serially, and updates to `v`\n",
      "     |  will be atomic.\n",
      "     |  \n",
      "     |  **NOTES**\n",
      "     |  \n",
      "     |  All resource objects, including the critical section and any captured\n",
      "     |  variables of functions executed on that critical section, will be\n",
      "     |  colocated to the same device (host and cpu/gpu).\n",
      "     |  \n",
      "     |  When using multiple critical sections on the same resources, there is no\n",
      "     |  guarantee of exclusive access to those resources.  This behavior is disallowed\n",
      "     |  by default (but see the kwarg `exclusive_resource_access`).\n",
      "     |  \n",
      "     |  For example, running the same function in two separate critical sections\n",
      "     |  will not ensure serial execution:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  v = tf.compat.v1.get_variable(\"v\", initializer=0.0, use_resource=True)\n",
      "     |  def accumulate(up):\n",
      "     |    x = v.read_value()\n",
      "     |    with tf.control_dependencies([x]):\n",
      "     |      with tf.control_dependencies([v.assign_add(up)]):\n",
      "     |        return tf.identity(x)\n",
      "     |  ex1 = CriticalSection().execute(\n",
      "     |    accumulate, 1.0, exclusive_resource_access=False)\n",
      "     |  ex2 = CriticalSection().execute(\n",
      "     |    accumulate, 1.0, exclusive_resource_access=False)\n",
      "     |  bad_sum = ex1 + ex2\n",
      "     |  sess.run(v.initializer)\n",
      "     |  sess.run(bad_sum)  # May return 0.0\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, shared_name=None, critical_section_def=None, import_scope=None)\n",
      "     |      Creates a critical section.\n",
      "     |  \n",
      "     |  execute(self, fn, exclusive_resource_access=True, name=None)\n",
      "     |      Execute function `fn()` inside the critical section.\n",
      "     |      \n",
      "     |      `fn` should not accept any arguments.  To add extra arguments to when\n",
      "     |      calling `fn` in the critical section, create a lambda:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      critical_section.execute(lambda: fn(*my_args, **my_kwargs))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fn: The function to execute.  Must return at least one tensor.\n",
      "     |        exclusive_resource_access: Whether the resources required by\n",
      "     |          `fn` should be exclusive to this `CriticalSection`.  Default: `True`.\n",
      "     |          You may want to set this to `False` if you will be accessing a\n",
      "     |          resource in read-only mode in two different CriticalSections.\n",
      "     |        name: The name to use when creating the execute operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensors returned from `fn()`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `fn` attempts to lock this `CriticalSection` in any nested\n",
      "     |          or lazy way that may cause a deadlock.\n",
      "     |        ValueError: If `exclusive_resource_access == True` and\n",
      "     |          another `CriticalSection` has an execution requesting the same\n",
      "     |          resources as `fn``.  Note, even if `exclusive_resource_access` is\n",
      "     |          `True`, if another execution in another `CriticalSection` was created\n",
      "     |          without `exclusive_resource_access=True`, a `ValueError` will be raised.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class DType(tensorflow.python.framework._dtypes.DType, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  DType(type_enum, handle_data=None)\n",
      "     |  \n",
      "     |  Represents the type of the elements in a `Tensor`.\n",
      "     |  \n",
      "     |  `DType`'s are used to specify the output data type for operations which\n",
      "     |  require it, or to inspect the data type of existing `Tensor`'s.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |  >>> tf.constant(1, dtype=tf.int64)\n",
      "     |  <tf.Tensor: shape=(), dtype=int64, numpy=1>\n",
      "     |  >>> tf.constant(1.0).dtype\n",
      "     |  tf.float32\n",
      "     |  \n",
      "     |  See `tf.dtypes` for a complete list of `DType`'s defined.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DType\n",
      "     |      tensorflow.python.framework._dtypes.DType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns True iff this DType refers to the same type as `other`.\n",
      "     |  \n",
      "     |  __hash__(...)\n",
      "     |      __hash__(self: tensorflow.python.framework._dtypes.DType) -> int\n",
      "     |  \n",
      "     |  __init__(self, type_enum, handle_data=None)\n",
      "     |      __init__(self: tensorflow.python.framework._dtypes.DType, arg0: object) -> None\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns True iff self != other.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  cast(self, value, cast_context)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.framework.types_pb2.SerializedDType\n",
      "     |      Returns a proto representation of the Dtype instance.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns True if the `other` DType will be converted to this DType (TF1).\n",
      "     |      \n",
      "     |      Programs written for TensorFlow 2.x do not need this function.\n",
      "     |      Instead, they can do equality comparison on `DType` objects directly:\n",
      "     |      `tf.as_dtype(this) == tf.as_dtype(other)`.\n",
      "     |      \n",
      "     |      This function exists only for compatibility with TensorFlow 1.x, where it\n",
      "     |      additionally allows conversion from a reference type (used by\n",
      "     |      `tf.compat.v1.Variable`) to its base type.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `DType` (or object that may be converted to a `DType`).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if a Tensor of the `other` `DType` will be implicitly converted to\n",
      "     |        this `DType`.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, types: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('DType')]\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.framework.types_pb2.SerializedDType) -> 'DType' from tensorflow.python.framework.dtypes.DTypeMeta\n",
      "     |      Returns a Dtype instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.framework.types_pb2.SerializedDType] from tensorflow.python.framework.dtypes.DTypeMeta\n",
      "     |      Returns the type of proto associated with DType serialization.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  as_numpy_dtype\n",
      "     |      Returns a Python `type` object based on this `DType`.\n",
      "     |  \n",
      "     |  base_dtype\n",
      "     |      Returns a non-reference `DType` based on this `DType` (for TF1).\n",
      "     |      \n",
      "     |      Programs written for TensorFlow 2.x do not need this attribute.\n",
      "     |      It exists only for compatibility with TensorFlow 1.x, which used\n",
      "     |      reference `DType`s in the implementation of `tf.compat.v1.Variable`.\n",
      "     |      In TensorFlow 2.x, `tf.Variable` is implemented without reference types.\n",
      "     |  \n",
      "     |  limits\n",
      "     |      Return intensity limits, i.e.\n",
      "     |      \n",
      "     |      (min, max) tuple, of the dtype.\n",
      "     |      Args:\n",
      "     |        clip_negative : bool, optional If True, clip the negative range (i.e.\n",
      "     |          return 0 for min intensity) even if the image dtype allows negative\n",
      "     |          values. Returns\n",
      "     |        min, max : tuple Lower and upper intensity limits.\n",
      "     |  \n",
      "     |  max\n",
      "     |      Returns the maximum representable value in this data type.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if this is a non-numeric, unordered, or quantized type.\n",
      "     |  \n",
      "     |  min\n",
      "     |      Returns the minimum representable value in this data type.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if this is a non-numeric, unordered, or quantized type.\n",
      "     |  \n",
      "     |  real_dtype\n",
      "     |      Returns the `DType` corresponding to this `DType`'s real part.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework._dtypes.DType:\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |      __int__(self: tensorflow.python.framework._dtypes.DType) -> int\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: tensorflow.python.framework._dtypes.DType) -> str\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: tensorflow.python.framework._dtypes.DType) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.framework._dtypes.DType:\n",
      "     |  \n",
      "     |  as_datatype_enum\n",
      "     |      Returns a `types_pb2.DataType` enum value based on this data type.\n",
      "     |  \n",
      "     |  is_bool\n",
      "     |      Returns whether this is a boolean data type.\n",
      "     |  \n",
      "     |  is_complex\n",
      "     |      Returns whether this is a complex floating point type.\n",
      "     |  \n",
      "     |  is_floating\n",
      "     |      Returns whether this is a (non-quantized, real) floating point type.\n",
      "     |  \n",
      "     |  is_integer\n",
      "     |      Returns whether this is a (non-quantized) integer type.\n",
      "     |  \n",
      "     |  is_numeric\n",
      "     |      Returns whether this is a numeric data type.\n",
      "     |  \n",
      "     |  is_numpy_compatible\n",
      "     |      Returns whether this data type has a compatible NumPy data type.\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Returns whether this is a quantized data type.\n",
      "     |  \n",
      "     |  is_unsigned\n",
      "     |      Returns whether this type is unsigned.\n",
      "     |      \n",
      "     |      Non-numeric, unordered, and quantized types are not considered unsigned, and\n",
      "     |      this function returns `False`.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.trace.TraceType:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    DeviceSpec = class DeviceSpecV1(DeviceSpecV2)\n",
      "     |  DeviceSpec(job=None, replica=None, task=None, device_type=None, device_index=None)\n",
      "     |  \n",
      "     |  Represents a (possibly partial) specification for a TensorFlow device.\n",
      "     |  \n",
      "     |  `DeviceSpec`s are used throughout TensorFlow to describe where state is stored\n",
      "     |  and computations occur. Using `DeviceSpec` allows you to parse device spec\n",
      "     |  strings to verify their validity, merge them or compose them programmatically.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Place the operations on device \"GPU:0\" in the \"ps\" job.\n",
      "     |  device_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  with tf.device(device_spec.to_string()):\n",
      "     |    # Both my_var and squared_var will be placed on /job:ps/device:GPU:0.\n",
      "     |    my_var = tf.Variable(..., name=\"my_variable\")\n",
      "     |    squared_var = tf.square(my_var)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  With eager execution disabled (by default in TensorFlow 1.x and by calling\n",
      "     |  disable_eager_execution() in TensorFlow 2.x), the following syntax\n",
      "     |  can be used:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.compat.v1.disable_eager_execution()\n",
      "     |  \n",
      "     |  # Same as previous\n",
      "     |  device_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  # No need of .to_string() method.\n",
      "     |  with tf.device(device_spec):\n",
      "     |    my_var = tf.Variable(..., name=\"my_variable\")\n",
      "     |    squared_var = tf.square(my_var)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If a `DeviceSpec` is partially specified, it will be merged with other\n",
      "     |  `DeviceSpec`s according to the scope in which it is defined. `DeviceSpec`\n",
      "     |  components defined in inner scopes take precedence over those defined in\n",
      "     |  outer scopes.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  gpu0_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  with tf.device(DeviceSpec(job=\"train\").to_string()):\n",
      "     |    with tf.device(gpu0_spec.to_string()):\n",
      "     |      # Nodes created here will be assigned to /job:ps/device:GPU:0.\n",
      "     |    with tf.device(DeviceSpec(device_type=\"GPU\", device_index=1).to_string()):\n",
      "     |      # Nodes created here will be assigned to /job:train/device:GPU:1.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  A `DeviceSpec` consists of 5 components -- each of\n",
      "     |  which is optionally specified:\n",
      "     |  \n",
      "     |  * Job: The job name.\n",
      "     |  * Replica: The replica index.\n",
      "     |  * Task: The task index.\n",
      "     |  * Device type: The device type string (e.g. \"CPU\" or \"GPU\").\n",
      "     |  * Device index: The device index.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DeviceSpecV1\n",
      "     |      DeviceSpecV2\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  merge_from(self, dev)\n",
      "     |      Merge the properties of \"dev\" into this `DeviceSpec`.\n",
      "     |      \n",
      "     |      Note: Will be removed in TensorFlow 2.x since DeviceSpecs will become\n",
      "     |            immutable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dev: a `DeviceSpec`.\n",
      "     |  \n",
      "     |  parse_from_string(self, spec)\n",
      "     |      Parse a `DeviceSpec` name into its components.\n",
      "     |      \n",
      "     |      **2.x behavior change**:\n",
      "     |      \n",
      "     |      In TensorFlow 1.x, this function mutates its own state and returns itself.\n",
      "     |      In 2.x, DeviceSpecs are immutable, and this function will return a\n",
      "     |        DeviceSpec which contains the spec.\n",
      "     |      \n",
      "     |      * Recommended:\n",
      "     |      \n",
      "     |        ```\n",
      "     |        # my_spec and my_updated_spec are unrelated.\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_updated_spec = tf.DeviceSpec.from_string(\"/GPU:0\")\n",
      "     |        with tf.device(my_updated_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      * Will work in 1.x and 2.x (though deprecated in 2.x):\n",
      "     |      \n",
      "     |        ```\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_updated_spec = my_spec.parse_from_string(\"/GPU:0\")\n",
      "     |        with tf.device(my_updated_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      * Will NOT work in 2.x:\n",
      "     |      \n",
      "     |        ```\n",
      "     |        my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |        my_spec.parse_from_string(\"/GPU:0\")  # <== Will not update my_spec\n",
      "     |        with tf.device(my_spec):\n",
      "     |          ...\n",
      "     |        ```\n",
      "     |      \n",
      "     |      In general, `DeviceSpec.from_string` should completely replace\n",
      "     |      `DeviceSpec.parse_from_string`, and `DeviceSpec.replace` should\n",
      "     |      completely replace setting attributes directly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: an optional string of the form\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:CPU:<id> or\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:GPU:<id> as cpu and gpu are\n",
      "     |           mutually exclusive. All entries are optional.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `DeviceSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the spec was not valid.\n",
      "     |  \n",
      "     |  to_string(self)\n",
      "     |      Return a string representation of this `DeviceSpec`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        a string of the form\n",
      "     |        /job:<name>/replica:<id>/task:<id>/device:<device_type>:<id>.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  device_index\n",
      "     |  \n",
      "     |  device_type\n",
      "     |  \n",
      "     |  job\n",
      "     |  \n",
      "     |  replica\n",
      "     |  \n",
      "     |  task\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DeviceSpecV2:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Checks if the `other` DeviceSpec is same as the current instance, eg have\n",
      "     |      \n",
      "     |         same value for all the internal fields.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another DeviceSpec\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Return `True` if `other` is also a DeviceSpec instance and has same value\n",
      "     |        as the current instance.\n",
      "     |        Return `False` otherwise.\n",
      "     |  \n",
      "     |  __init__(self, job=None, replica=None, task=None, device_type=None, device_index=None)\n",
      "     |      Create a new `DeviceSpec` object.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        job: string.  Optional job name.\n",
      "     |        replica: int.  Optional replica index.\n",
      "     |        task: int.  Optional task index.\n",
      "     |        device_type: Optional device type string (e.g. \"CPU\" or \"GPU\")\n",
      "     |        device_index: int.  Optional device index.  If left unspecified, device\n",
      "     |          represents 'any' device_index.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  make_merged_spec(self, dev)\n",
      "     |      Returns a new DeviceSpec which incorporates `dev`.\n",
      "     |      \n",
      "     |      When combining specs, `dev` will take precedence over the current spec.\n",
      "     |      So for instance:\n",
      "     |      ```\n",
      "     |      first_spec = tf.DeviceSpec(job=0, device_type=\"CPU\")\n",
      "     |      second_spec = tf.DeviceSpec(device_type=\"GPU\")\n",
      "     |      combined_spec = first_spec.make_merged_spec(second_spec)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      is equivalent to:\n",
      "     |      ```\n",
      "     |      combined_spec = tf.DeviceSpec(job=0, device_type=\"GPU\")\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dev: a `DeviceSpec`\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new `DeviceSpec` which combines `self` and `dev`\n",
      "     |  \n",
      "     |  replace(self, **kwargs)\n",
      "     |      Convenience method for making a new DeviceSpec by overriding fields.\n",
      "     |      \n",
      "     |      For instance:\n",
      "     |      ```\n",
      "     |      my_spec = DeviceSpec=(job=\"my_job\", device=\"CPU\")\n",
      "     |      my_updated_spec = my_spec.replace(device=\"GPU\")\n",
      "     |      my_other_spec = my_spec.replace(device=None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        **kwargs: This method takes the same args as the DeviceSpec constructor\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A DeviceSpec with the fields specified in kwargs overridden.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from DeviceSpecV2:\n",
      "     |  \n",
      "     |  from_string(spec) from builtins.type\n",
      "     |      Construct a `DeviceSpec` from a string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: a string of the form\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:CPU:<id> or\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:GPU:<id> as cpu and gpu are\n",
      "     |           mutually exclusive. All entries are optional.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A DeviceSpec.\n",
      "    \n",
      "    class Dimension(builtins.object)\n",
      "     |  Dimension(value)\n",
      "     |  \n",
      "     |  Represents the value of one dimension in a TensorShape.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  In TF2, members of a `TensorShape` object are integers. The `Dimension` class\n",
      "     |  is not part of TF2's data model.\n",
      "     |  \n",
      "     |  Please refer to the [TensorShape section of the migration guide]\n",
      "     |  (https://www.tensorflow.org/guide/migrate/index#tensorshape) on common code\n",
      "     |  patterns adapting Dimension objects to a TF2 syntax.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |      Returns the sum of `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are summed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    + tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m + n)\n",
      "     |      tf.compat.v1.Dimension(m)    + tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) + tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) + tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the sum of `self` and `other`.\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Equivalent to `bool(self.value)`.\n",
      "     |  \n",
      "     |  __div__(self, other)\n",
      "     |      DEPRECATED: Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only for backwards compatibility purposes; new code\n",
      "     |      should use `__floordiv__` via the syntax `x // y`.  Using `x // y`\n",
      "     |      communicates clearly that the result rounds down, and is forward compatible\n",
      "     |      to Python 3.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns true if `other` has the same known value as this Dimension.\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |      Returns the quotient of `self` and `other` rounded down.\n",
      "     |      \n",
      "     |      Dimensions are divided as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    // tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m // n)\n",
      "     |      tf.compat.v1.Dimension(m)    // tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) // tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) // tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Returns True if `self` is known to be greater than or equal to `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    >= tf.compat.v1.Dimension(n))    == (m >= n)\n",
      "     |      (tf.compat.v1.Dimension(m)    >= tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) >= tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) >= tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value >= other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Returns True if `self` is known to be greater than `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    > tf.compat.v1.Dimension(n))    == (m > n)\n",
      "     |      (tf.compat.v1.Dimension(m)    > tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) > tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) > tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value > other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __index__(self)\n",
      "     |  \n",
      "     |  __init__(self, value)\n",
      "     |      Creates a new Dimension with the given value.\n",
      "     |  \n",
      "     |  __int__(self)\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Returns True if `self` is known to be less than or equal to `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    <= tf.compat.v1.Dimension(n))    == (m <= n)\n",
      "     |      (tf.compat.v1.Dimension(m)    <= tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) <= tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) <= tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value <= other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __long__(self)\n",
      "     |      # This is needed for Windows.\n",
      "     |      # See https://github.com/tensorflow/tensorflow/pull/9780\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Returns True if `self` is known to be less than `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    < tf.compat.v1.Dimension(n))    == (m < n)\n",
      "     |      (tf.compat.v1.Dimension(m)    < tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) < tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) < tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value < other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __mod__(self, other)\n",
      "     |      Returns `self` modulo `other`.\n",
      "     |      \n",
      "     |      Dimension modulo are computed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    % tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m % n)\n",
      "     |      tf.compat.v1.Dimension(m)    % tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) % tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) % tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is `self` modulo `other`.\n",
      "     |  \n",
      "     |  __mul__(self, other)\n",
      "     |      Returns the product of `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are summed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    * tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m * n)\n",
      "     |      tf.compat.v1.Dimension(m)    * tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) * tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) * tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the product of `self` and `other`.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns true if `other` has a different known value from `self`.\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |      Returns the sum of `other` and `self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the sum of `self` and `other`.\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |      Returns the quotient of `other` and `self` rounded down.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __rmod__(self, other)\n",
      "     |      Returns `other` modulo `self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is `other` modulo `self`.\n",
      "     |  \n",
      "     |  __rmul__(self, other)\n",
      "     |      Returns the product of `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the product of `self` and `other`.\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |      Returns the subtraction of `self` from `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the subtraction of `self` from `other`.\n",
      "     |  \n",
      "     |  __rtruediv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__(self, other)\n",
      "     |      Returns the subtraction of `other` from `self`.\n",
      "     |      \n",
      "     |      Dimensions are subtracted as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    - tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m - n)\n",
      "     |      tf.compat.v1.Dimension(m)    - tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) - tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) - tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the subtraction of `other` from `self`.\n",
      "     |  \n",
      "     |  __truediv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'Dimension' and 'int'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  assert_is_compatible_with(self, other)\n",
      "     |      Raises an exception if `other` is not compatible with this Dimension.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible (see\n",
      "     |          is_compatible_with).\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns true if `other` is compatible with this Dimension.\n",
      "     |      \n",
      "     |      Two known Dimensions are compatible if they have the same value.\n",
      "     |      An unknown Dimension is compatible with all other Dimensions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if this Dimension and `other` are compatible.\n",
      "     |  \n",
      "     |  merge_with(self, other)\n",
      "     |      Returns a Dimension that combines the information in `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are combined as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(n))     ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(None))  ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      tf.compat.v1.Dimension(None).merge_with(tf.compat.v1.Dimension(n))     ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      # equivalent to tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None).merge_with(tf.compat.v1.Dimension(None))\n",
      "     |      \n",
      "     |      # raises ValueError for n != m\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(m))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension containing the combined information of `self` and\n",
      "     |        `other`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible (see\n",
      "     |          is_compatible_with).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of this dimension, or None if it is unknown.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class Event(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      Event\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class FIFOQueue(QueueBase)\n",
      "     |  FIFOQueue(capacity, dtypes, shapes=None, names=None, shared_name=None, name='fifo_queue')\n",
      "     |  \n",
      "     |  A queue implementation that dequeues elements in first-in first-out order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FIFOQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, dtypes, shapes=None, names=None, shared_name=None, name='fifo_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `FIFOQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `FIFOQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `dtypes`, and whose shapes are optionally described\n",
      "     |      by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects\n",
      "     |          with the same length as `dtypes`, or `None`.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from QueueBase:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class FixedLenFeature(FixedLenFeature)\n",
      "     |  FixedLenFeature(shape, dtype, default_value=None)\n",
      "     |  \n",
      "     |  Configuration for parsing a fixed-length input feature.\n",
      "     |  \n",
      "     |  To treat sparse input as dense, provide a `default_value`; otherwise,\n",
      "     |  the parse functions will fail on any examples missing this feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    shape: Shape of input data.\n",
      "     |    dtype: Data type of input.\n",
      "     |    default_value: Value to be used if an example is missing this feature. It\n",
      "     |        must be compatible with `dtype` and of the specified `shape`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLenFeature\n",
      "     |      FixedLenFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, shape, dtype, default_value=None)\n",
      "     |      Create new instance of FixedLenFeature(shape, dtype, default_value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.FixedLenFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.FixedLenFeature', 'FixedLenFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new FixedLenFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new FixedLenFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  default_value\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  __match_args__ = ('shape', 'dtype', 'default_value')\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('shape', 'dtype', 'default_value')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    class FixedLenSequenceFeature(FixedLenSequenceFeature)\n",
      "     |  FixedLenSequenceFeature(shape, dtype, allow_missing=False, default_value=None)\n",
      "     |  \n",
      "     |  Configuration for parsing a variable-length input feature into a `Tensor`.\n",
      "     |  \n",
      "     |  The resulting `Tensor` of parsing a single `SequenceExample` or `Example` has\n",
      "     |  a static `shape` of `[None] + shape` and the specified `dtype`.\n",
      "     |  The resulting `Tensor` of parsing a `batch_size` many `Example`s has\n",
      "     |  a static `shape` of `[batch_size, None] + shape` and the specified `dtype`.\n",
      "     |  The entries in the `batch` from different `Examples` will be padded with\n",
      "     |  `default_value` to the maximum length present in the `batch`.\n",
      "     |  \n",
      "     |  To treat a sparse input as dense, provide `allow_missing=True`; otherwise,\n",
      "     |  the parse functions will fail on any examples missing this feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    shape: Shape of input data for dimension 2 and higher. First dimension is\n",
      "     |      of variable length `None`.\n",
      "     |    dtype: Data type of input.\n",
      "     |    allow_missing: Whether to allow this feature to be missing from a feature\n",
      "     |      list item. Is available only for parsing `SequenceExample` not for\n",
      "     |      parsing `Examples`.\n",
      "     |    default_value: Scalar value to be used to pad multiple `Example`s to their\n",
      "     |      maximum length. Irrelevant for parsing a single `Example` or\n",
      "     |      `SequenceExample`. Defaults to \"\" for dtype string and 0 otherwise\n",
      "     |      (optional).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLenSequenceFeature\n",
      "     |      FixedLenSequenceFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, shape, dtype, allow_missing=False, default_value=None)\n",
      "     |      Create new instance of FixedLenSequenceFeature(shape, dtype, allow_missing, default_value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.FixedLenSequenceFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.FixedLenSequenceFeature', 'FixedLenSequenceFea...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new FixedLenSequenceFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new FixedLenSequenceFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  allow_missing\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  default_value\n",
      "     |      Alias for field number 3\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  __match_args__ = ('shape', 'dtype', 'allow_missing', 'default_value')\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('shape', 'dtype', 'allow_missing', 'default_value')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    class FixedLengthRecordReader(ReaderBase)\n",
      "     |  FixedLengthRecordReader(record_bytes, header_bytes=None, footer_bytes=None, hop_bytes=None, name=None, encoding=None)\n",
      "     |  \n",
      "     |  A Reader that outputs fixed-length records from a file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLengthRecordReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, record_bytes, header_bytes=None, footer_bytes=None, hop_bytes=None, name=None, encoding=None)\n",
      "     |      Create a FixedLengthRecordReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        record_bytes: An int.\n",
      "     |        header_bytes: An optional int. Defaults to 0.\n",
      "     |        footer_bytes: An optional int. Defaults to 0.\n",
      "     |        hop_bytes: An optional int. Defaults to 0.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        encoding: The type of encoding for the file. Defaults to none.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class GPUOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      GPUOptions\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class GradientTape(builtins.object)\n",
      "     |  GradientTape(persistent=False, watch_accessed_variables=True)\n",
      "     |  \n",
      "     |  Record operations for automatic differentiation.\n",
      "     |  \n",
      "     |  Operations are recorded if they are executed within this context manager and\n",
      "     |  at least one of their inputs is being \"watched\".\n",
      "     |  \n",
      "     |  Trainable variables (created by `tf.Variable` or `tf.compat.v1.get_variable`,\n",
      "     |  where `trainable=True` is default in both cases) are automatically watched.\n",
      "     |  Tensors can be manually watched by invoking the `watch` method on this context\n",
      "     |  manager.\n",
      "     |  \n",
      "     |  For example, consider the function `y = x * x`. The gradient at `x = 3.0` can\n",
      "     |  be computed as:\n",
      "     |  \n",
      "     |  >>> x = tf.constant(3.0)\n",
      "     |  >>> with tf.GradientTape() as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   y = x * x\n",
      "     |  >>> dy_dx = g.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  GradientTapes can be nested to compute higher-order derivatives. For example,\n",
      "     |  \n",
      "     |  >>> x = tf.constant(5.0)\n",
      "     |  >>> with tf.GradientTape() as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   with tf.GradientTape() as gg:\n",
      "     |  ...     gg.watch(x)\n",
      "     |  ...     y = x * x\n",
      "     |  ...   dy_dx = gg.gradient(y, x)  # dy_dx = 2 * x\n",
      "     |  >>> d2y_dx2 = g.gradient(dy_dx, x)  # d2y_dx2 = 2\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "     |  >>> print(d2y_dx2)\n",
      "     |  tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  By default, the resources held by a GradientTape are released as soon as\n",
      "     |  GradientTape.gradient() method is called. To compute multiple gradients over\n",
      "     |  the same computation, create a persistent gradient tape. This allows multiple\n",
      "     |  calls to the gradient() method as resources are released when the tape object\n",
      "     |  is garbage collected. For example:\n",
      "     |  \n",
      "     |  >>> x = tf.constant(3.0)\n",
      "     |  >>> with tf.GradientTape(persistent=True) as g:\n",
      "     |  ...   g.watch(x)\n",
      "     |  ...   y = x * x\n",
      "     |  ...   z = y * y\n",
      "     |  >>> dz_dx = g.gradient(z, x)  # (4*x^3 at x = 3)\n",
      "     |  >>> print(dz_dx)\n",
      "     |  tf.Tensor(108.0, shape=(), dtype=float32)\n",
      "     |  >>> dy_dx = g.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "     |  \n",
      "     |  By default GradientTape will automatically watch any trainable variables that\n",
      "     |  are accessed inside the context. If you want fine grained control over which\n",
      "     |  variables are watched you can disable automatic tracking by passing\n",
      "     |  `watch_accessed_variables=False` to the tape constructor:\n",
      "     |  \n",
      "     |  >>> x = tf.Variable(2.0)\n",
      "     |  >>> w = tf.Variable(5.0)\n",
      "     |  >>> with tf.GradientTape(\n",
      "     |  ...     watch_accessed_variables=False, persistent=True) as tape:\n",
      "     |  ...   tape.watch(x)\n",
      "     |  ...   y = x ** 2  # Gradients will be available for `x`.\n",
      "     |  ...   z = w ** 3  # No gradients will be available as `w` isn't being watched.\n",
      "     |  >>> dy_dx = tape.gradient(y, x)\n",
      "     |  >>> print(dy_dx)\n",
      "     |  tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "     |  >>> # No gradients will be available as `w` isn't being watched.\n",
      "     |  >>> dz_dw = tape.gradient(z, w)\n",
      "     |  >>> print(dz_dw)\n",
      "     |  None\n",
      "     |  \n",
      "     |  Note that when using models you should ensure that your variables exist when\n",
      "     |  using `watch_accessed_variables=False`. Otherwise it's quite easy to make your\n",
      "     |  first iteration not have any gradients:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = tf.keras.layers.Dense(32)\n",
      "     |  b = tf.keras.layers.Dense(32)\n",
      "     |  \n",
      "     |  with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
      "     |    tape.watch(a.variables)  # Since `a.build` has not been called at this point\n",
      "     |                             # `a.variables` will return an empty list and the\n",
      "     |                             # tape will not be watching anything.\n",
      "     |    result = b(a(inputs))\n",
      "     |    tape.gradient(result, a.variables)  # The result of this computation will be\n",
      "     |                                        # a list of `None`s since a's variables\n",
      "     |                                        # are not being watched.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that only tensors with real or complex dtypes are differentiable.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      Enters a context inside which operations are recorded on this tape.\n",
      "     |  \n",
      "     |  __exit__(self, typ, value, traceback)\n",
      "     |      Exits the recording context, no further operations are traced.\n",
      "     |  \n",
      "     |  __init__(self, persistent=False, watch_accessed_variables=True)\n",
      "     |      Creates a new GradientTape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        persistent: Boolean controlling whether a persistent gradient tape\n",
      "     |          is created. False by default, which means at most one call can\n",
      "     |          be made to the gradient() method on this object.\n",
      "     |        watch_accessed_variables: Boolean controlling whether the tape will\n",
      "     |          automatically `watch` any (trainable) variables accessed while the tape\n",
      "     |          is active. Defaults to True meaning gradients can be requested from any\n",
      "     |          result computed in the tape derived from reading a trainable `Variable`.\n",
      "     |          If False users must explicitly `watch` any `Variable`s they want to\n",
      "     |          request gradients from.\n",
      "     |  \n",
      "     |  batch_jacobian(self, target, source, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      "     |      Computes and stacks per-example jacobians.\n",
      "     |      \n",
      "     |      See [wikipedia article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant)\n",
      "     |      for the definition of a Jacobian. This function is essentially an efficient\n",
      "     |      implementation of the following:\n",
      "     |      \n",
      "     |      `tf.stack([self.jacobian(y[i], x[i]) for i in range(x.shape[0])])`.\n",
      "     |      \n",
      "     |      Note that compared to `GradientTape.jacobian` which computes gradient of\n",
      "     |      each output value w.r.t each input value, this function is useful when\n",
      "     |      `target[i,...]` is independent of `source[j,...]` for `j != i`. This\n",
      "     |      assumption allows more efficient computation as compared to\n",
      "     |      `GradientTape.jacobian`. The output, as well as intermediate activations,\n",
      "     |      are lower dimensional and avoid a bunch of redundant zeros which would\n",
      "     |      result in the jacobian computation given the independence assumption.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      Note: By default the batch_jacobian implementation uses parallel for (pfor),\n",
      "     |      which creates a tf.function under the hood for each batch_jacobian call.\n",
      "     |      For better performance, and to avoid recompilation and vectorization\n",
      "     |      rewrites on each call, enclose GradientTape code in @tf.function.\n",
      "     |      \n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.GradientTape() as g:\n",
      "     |        x = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float32)\n",
      "     |        g.watch(x)\n",
      "     |        y = x * x\n",
      "     |      batch_jacobian = g.batch_jacobian(y, x)\n",
      "     |      # batch_jacobian is [[[2,  0], [0,  4]], [[6,  0], [0,  8]]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: A tensor with rank 2 or higher and with shape [b, y1, ..., y_n].\n",
      "     |          `target[i,...]` should only depend on `source[i,...]`.\n",
      "     |        source: A tensor with rank 2 or higher and with shape [b, x1, ..., x_m].\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      "     |          in parallel. This knob can be used to control the total memory usage.\n",
      "     |        experimental_use_pfor: If true, uses pfor for computing the Jacobian. Else\n",
      "     |          uses a tf.while_loop.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tensor `t` with shape [b, y_1, ..., y_n, x1, ..., x_m] where `t[i, ...]`\n",
      "     |        is the jacobian of `target[i, ...]` w.r.t. `source[i, ...]`, i.e. stacked\n",
      "     |        per-example jacobians.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      "     |          enabled and without enabling experimental_use_pfor.\n",
      "     |        ValueError: If vectorization of jacobian computation fails or if first\n",
      "     |          dimension of `target` and `source` do not match.\n",
      "     |  \n",
      "     |  gradient(self, target, sources, output_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      "     |      Computes the gradient using operations recorded in context of this tape.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      In addition to Tensors, gradient also supports RaggedTensors. For example,\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1.0, 2.0], [3.0]])\n",
      "     |      >>> with tf.GradientTape() as g:\n",
      "     |      ...   g.watch(x)\n",
      "     |      ...   y = x * x\n",
      "     |      >>> g.gradient(y, x)\n",
      "     |      <tf.RaggedTensor [[2.0, 4.0], [6.0]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: a list or nested structure of Tensors or Variables or\n",
      "     |          CompositeTensors to be differentiated.\n",
      "     |        sources: a list or nested structure of Tensors or Variables or\n",
      "     |          CompositeTensors. `target` will be differentiated against elements in\n",
      "     |          `sources`.\n",
      "     |        output_gradients: a list of gradients, one for each differentiable\n",
      "     |          element of target. Defaults to None.\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        a list or nested structure of Tensors (or IndexedSlices, or None, or\n",
      "     |        CompositeTensor), one for each element in `sources`. Returned structure\n",
      "     |        is the same as the structure of `sources`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called inside the context of the tape.\n",
      "     |        TypeError: If the target is a None object.\n",
      "     |        ValueError: If the target is a variable or if unconnected gradients is\n",
      "     |         called with an unknown value.\n",
      "     |  \n",
      "     |  jacobian(self, target, sources, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      "     |      Computes the jacobian using operations recorded in context of this tape.\n",
      "     |      \n",
      "     |      Note: Unless you set `persistent=True` a GradientTape can only be used to\n",
      "     |      compute one set of gradients (or jacobians).\n",
      "     |      \n",
      "     |      Note: By default the jacobian implementation uses parallel for (pfor), which\n",
      "     |      creates a tf.function under the hood for each jacobian call. For better\n",
      "     |      performance, and to avoid recompilation and vectorization rewrites on each\n",
      "     |      call, enclose GradientTape code in @tf.function.\n",
      "     |      \n",
      "     |      See[wikipedia\n",
      "     |      article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant)\n",
      "     |      for the definition of a Jacobian.\n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.GradientTape() as g:\n",
      "     |        x  = tf.constant([1.0, 2.0])\n",
      "     |        g.watch(x)\n",
      "     |        y = x * x\n",
      "     |      jacobian = g.jacobian(y, x)\n",
      "     |      # jacobian value is [[2., 0.], [0., 4.]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: Tensor to be differentiated.\n",
      "     |        sources: a list or nested structure of Tensors or Variables. `target`\n",
      "     |          will be differentiated against elements in `sources`.\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      "     |          in parallel. This knob can be used to control the total memory usage.\n",
      "     |        experimental_use_pfor: If true, vectorizes the jacobian computation. Else\n",
      "     |          falls back to a sequential while_loop. Vectorization can sometimes fail\n",
      "     |          or lead to excessive memory usage. This option can be used to disable\n",
      "     |          vectorization in such cases.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list or nested structure of Tensors (or None), one for each element in\n",
      "     |        `sources`. Returned structure is the same as the structure of `sources`.\n",
      "     |        Note if any gradient is sparse (IndexedSlices), jacobian function\n",
      "     |        currently makes it dense and returns a Tensor instead. This may change in\n",
      "     |        the future.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a used, non-persistent tape.\n",
      "     |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      "     |          enabled and without enabling experimental_use_pfor.\n",
      "     |        ValueError: If vectorization of jacobian computation fails.\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |      Clears all information stored in this tape.\n",
      "     |      \n",
      "     |      Equivalent to exiting and reentering the tape context manager with a new\n",
      "     |      tape. For example, the two following code blocks are equivalent:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = loss_fn()\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss += other_loss_fn()\n",
      "     |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      "     |      \n",
      "     |      \n",
      "     |      # The following is equivalent to the above\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = loss_fn()\n",
      "     |        t.reset()\n",
      "     |        loss += other_loss_fn()\n",
      "     |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This is useful if you don't want to exit the context manager for the tape,\n",
      "     |      or can't because the desired reset point is inside a control flow construct:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = ...\n",
      "     |        if loss > k:\n",
      "     |          t.reset()\n",
      "     |      ```\n",
      "     |  \n",
      "     |  stop_recording(self)\n",
      "     |      Temporarily stops recording operations on this tape.\n",
      "     |      \n",
      "     |      Operations executed while this context manager is active will not be\n",
      "     |      recorded on the tape. This is useful for reducing the memory used by tracing\n",
      "     |      all computations.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(4.0)\n",
      "     |      >>> with tf.GradientTape() as tape:\n",
      "     |      ...   with tape.stop_recording():\n",
      "     |      ...     y = x ** 2\n",
      "     |      >>> dy_dx = tape.gradient(y, x)\n",
      "     |      >>> print(dy_dx)\n",
      "     |      None\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        None\n",
      "     |      Raises:\n",
      "     |        RuntimeError: if the tape is not currently recording.\n",
      "     |  \n",
      "     |  watch(self, tensor)\n",
      "     |      Ensures that `tensor` is being traced by this tape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: a Tensor/Variable or list of Tensors/Variables.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if it encounters something that is not a tensor.\n",
      "     |  \n",
      "     |  watched_variables(self)\n",
      "     |      Returns variables watched by this tape in order of construction.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class Graph(tensorflow.python.client._pywrap_tf_session.PyGraph)\n",
      "     |  Graph() -> None\n",
      "     |  \n",
      "     |  A TensorFlow computation, represented as a dataflow graph.\n",
      "     |  \n",
      "     |  Graphs are used by `tf.function`s to represent the function's computations.\n",
      "     |  Each graph contains a set of `tf.Operation` objects, which represent units of\n",
      "     |  computation; and `tf.Tensor` objects, which represent the units of data that\n",
      "     |  flow between operations.\n",
      "     |  \n",
      "     |  ### Using graphs directly (deprecated)\n",
      "     |  \n",
      "     |  A `tf.Graph` can be constructed and used directly without a `tf.function`, as\n",
      "     |  was required in TensorFlow 1, but this is deprecated and it is recommended to\n",
      "     |  use a `tf.function` instead. If a graph is directly used, other deprecated\n",
      "     |  TensorFlow 1 classes are also required to execute the graph, such as a\n",
      "     |  `tf.compat.v1.Session`.\n",
      "     |  \n",
      "     |  A default graph can be registered with the `tf.Graph.as_default` context\n",
      "     |  manager. Then, operations will be added to the graph instead of being executed\n",
      "     |  eagerly. For example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  g = tf.Graph()\n",
      "     |  with g.as_default():\n",
      "     |    # Define operations and tensors in `g`.\n",
      "     |    c = tf.constant(30.0)\n",
      "     |    assert c.graph is g\n",
      "     |  ```\n",
      "     |  \n",
      "     |  `tf.compat.v1.get_default_graph()` can be used to obtain the default graph.\n",
      "     |  \n",
      "     |  Important note: This class *is not* thread-safe for graph construction. All\n",
      "     |  operations should be created from a single thread, or external\n",
      "     |  synchronization must be provided. Unless otherwise specified, all methods\n",
      "     |  are not thread-safe.\n",
      "     |  \n",
      "     |  A `Graph` instance supports an arbitrary number of \"collections\"\n",
      "     |  that are identified by name. For convenience when building a large\n",
      "     |  graph, collections can store groups of related objects: for\n",
      "     |  example, the `tf.Variable` uses a collection (named\n",
      "     |  `tf.GraphKeys.GLOBAL_VARIABLES`) for\n",
      "     |  all variables that are created during the construction of a graph. The caller\n",
      "     |  may define additional collections by specifying a new name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Graph\n",
      "     |      tensorflow.python.client._pywrap_tf_session.PyGraph\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self: ~GraphType) -> ~GraphType\n",
      "     |  \n",
      "     |  __exit__(self, *args) -> None\n",
      "     |  \n",
      "     |  __init__(self) -> None\n",
      "     |      Creates a new, empty Graph.\n",
      "     |  \n",
      "     |  add_to_collection(self, name, value) -> None\n",
      "     |      Stores `value` in the collection with the given `name`.\n",
      "     |      \n",
      "     |      Note that collections are not sets, so it is possible to add a value to\n",
      "     |      a collection several times.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. The `GraphKeys` class contains many\n",
      "     |          standard names for collections.\n",
      "     |        value: The value to add to the collection.\n",
      "     |  \n",
      "     |  add_to_collections(self, names, value) -> None\n",
      "     |      Stores `value` in the collections given by `names`.\n",
      "     |      \n",
      "     |      Note that collections are not sets, so it is possible to add a value to\n",
      "     |      a collection several times. This function makes sure that duplicates in\n",
      "     |      `names` are ignored, but it will not check for pre-existing membership of\n",
      "     |      `value` in any of the collections in `names`.\n",
      "     |      \n",
      "     |      `names` can be any iterable, but if `names` is a string, it is treated as a\n",
      "     |      single collection name.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        names: The keys for the collections to add to. The `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |        value: The value to add to the collections.\n",
      "     |  \n",
      "     |  as_default(self) -> ContextManager[ForwardRef('Graph')]\n",
      "     |      Returns a context manager that makes this `Graph` the default graph.\n",
      "     |      \n",
      "     |      This method should be used if you want to create multiple graphs\n",
      "     |      in the same process. For convenience, a global default graph is\n",
      "     |      provided, and all ops will be added to this graph if you do not\n",
      "     |      create a new graph explicitly.\n",
      "     |      \n",
      "     |      Use this method with the `with` keyword to specify that ops created within\n",
      "     |      the scope of a block should be added to this graph. In this case, once\n",
      "     |      the scope of the `with` is exited, the previous default graph is set again\n",
      "     |      as default. There is a stack, so it's ok to have multiple nested levels\n",
      "     |      of `as_default` calls.\n",
      "     |      \n",
      "     |      The default graph is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default graph in that\n",
      "     |      thread, you must explicitly add a `with g.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      The following code examples are equivalent:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # 1. Using Graph.as_default():\n",
      "     |      g = tf.Graph()\n",
      "     |      with g.as_default():\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        assert c.graph is g\n",
      "     |      \n",
      "     |      # 2. Constructing and making default:\n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        assert c.graph is g\n",
      "     |      ```\n",
      "     |      \n",
      "     |      If eager execution is enabled ops created under this context manager will be\n",
      "     |      added to the graph instead of executed eagerly.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager for using this graph as the default graph.\n",
      "     |  \n",
      "     |  as_graph_def(self, from_version=None, add_shapes=False, use_pybind11_proto=False) -> tensorflow.core.framework.graph_pb2.GraphDef\n",
      "     |      Returns a serialized `GraphDef` representation of this graph.\n",
      "     |      \n",
      "     |      The serialized `GraphDef` can be imported into another `Graph`\n",
      "     |      (using `tf.import_graph_def`) or used with the\n",
      "     |      [C++ Session API](../../api_docs/cc/index.md).\n",
      "     |      \n",
      "     |      This method is thread-safe.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        from_version: Optional.  If this is set, returns a `GraphDef` containing\n",
      "     |          only the nodes that were added to this graph since its `version`\n",
      "     |          property had the given value.\n",
      "     |        add_shapes: If true, adds an \"_output_shapes\" list attr to each node with\n",
      "     |          the inferred shapes of each of its outputs.\n",
      "     |        use_pybind11_proto: If true, If true, uses the c++ pybind11_proto api to\n",
      "     |          get the GraphDef proto directly from c++, instead of through a TF\n",
      "     |          buffer. See https://github.com/pybind/pybind11_protobuf for reference.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A\n",
      "     |        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      "     |        protocol buffer.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If the `graph_def` would be too large.\n",
      "     |  \n",
      "     |  as_graph_element(self, obj, allow_tensor=True, allow_operation=True) -> Union[tensorflow.python.framework.tensor.Tensor, ForwardRef('Operation')]\n",
      "     |      Returns the object referred to by `obj`, as an `Operation` or `Tensor`.\n",
      "     |      \n",
      "     |      This function validates that `obj` represents an element of this\n",
      "     |      graph, and gives an informative error message if it is not.\n",
      "     |      \n",
      "     |      This function is the canonical way to get/validate an object of\n",
      "     |      one of the allowed types from an external argument reference in the\n",
      "     |      Session API.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        obj: A `Tensor`, an `Operation`, or the name of a tensor or operation. Can\n",
      "     |          also be any object with an `_as_graph_element()` method that returns a\n",
      "     |          value of one of these types. Note: `_as_graph_element` will be called\n",
      "     |          inside the graph's lock and so may not modify the graph.\n",
      "     |        allow_tensor: If true, `obj` may refer to a `Tensor`.\n",
      "     |        allow_operation: If true, `obj` may refer to an `Operation`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Tensor` or `Operation` in the Graph corresponding to `obj`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `obj` is not a type we support attempting to convert\n",
      "     |          to types.\n",
      "     |        ValueError: If `obj` is of an appropriate type but invalid. For\n",
      "     |          example, an invalid string.\n",
      "     |        KeyError: If `obj` is not an object in the graph.\n",
      "     |  \n",
      "     |  clear_collection(self, name) -> None\n",
      "     |      Clears all values in a collection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. The `GraphKeys` class contains many\n",
      "     |          standard names for collections.\n",
      "     |  \n",
      "     |  colocate_with(self, op, ignore_existing=False) -> collections.abc.Iterator[None]\n",
      "     |      Returns a context manager that specifies an op to colocate with.\n",
      "     |      \n",
      "     |      Note: this function is not for public use, only for internal libraries.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = tf.Variable([1.0])\n",
      "     |      with g.colocate_with(a):\n",
      "     |        b = tf.constant(1.0)\n",
      "     |        c = tf.add(a, b)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      `b` and `c` will always be colocated with `a`, no matter where `a`\n",
      "     |      is eventually placed.\n",
      "     |      \n",
      "     |      **NOTE** Using a colocation scope resets any existing device constraints.\n",
      "     |      \n",
      "     |      If `op` is `None` then `ignore_existing` must be `True` and the new\n",
      "     |      scope resets all colocation and device constraints.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op: The op to colocate all created ops with, or `None`.\n",
      "     |        ignore_existing: If true, only applies colocation of this op within the\n",
      "     |          context, rather than applying all colocation properties on the stack.\n",
      "     |          If `op` is `None`, this value must be `True`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if op is None but ignore_existing is False.\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        A context manager that specifies the op with which to colocate\n",
      "     |        newly created ops.\n",
      "     |  \n",
      "     |  container(self, container_name) -> collections.abc.Iterator[str]\n",
      "     |      Returns a context manager that specifies the resource container to use.\n",
      "     |      \n",
      "     |      Stateful operations, such as variables and queues, can maintain their\n",
      "     |      states on devices so that they can be shared by multiple processes.\n",
      "     |      A resource container is a string name under which these stateful\n",
      "     |      operations are tracked. These resources can be released or cleared\n",
      "     |      with `tf.Session.reset()`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.container('experiment0'):\n",
      "     |        # All stateful Operations constructed in this context will be placed\n",
      "     |        # in resource container \"experiment0\".\n",
      "     |        v1 = tf.Variable([1.0])\n",
      "     |        v2 = tf.Variable([2.0])\n",
      "     |        with g.container(\"experiment1\"):\n",
      "     |          # All stateful Operations constructed in this context will be\n",
      "     |          # placed in resource container \"experiment1\".\n",
      "     |          v3 = tf.Variable([3.0])\n",
      "     |          q1 = tf.queue.FIFOQueue(10, tf.float32)\n",
      "     |        # All stateful Operations constructed in this context will be\n",
      "     |        # be created in the \"experiment0\".\n",
      "     |        v4 = tf.Variable([4.0])\n",
      "     |        q1 = tf.queue.FIFOQueue(20, tf.float32)\n",
      "     |        with g.container(\"\"):\n",
      "     |          # All stateful Operations constructed in this context will be\n",
      "     |          # be placed in the default resource container.\n",
      "     |          v5 = tf.Variable([5.0])\n",
      "     |          q3 = tf.queue.FIFOQueue(30, tf.float32)\n",
      "     |      \n",
      "     |      # Resets container \"experiment0\", after which the state of v1, v2, v4, q1\n",
      "     |      # will become undefined (such as uninitialized).\n",
      "     |      tf.Session.reset(target, [\"experiment0\"])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        container_name: container name string.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager for defining resource containers for stateful ops,\n",
      "     |          yields the container name.\n",
      "     |  \n",
      "     |  control_dependencies(self, control_inputs) -> tensorflow.python.framework.ops.Graph._ControlDependenciesController\n",
      "     |      Returns a context manager that specifies control dependencies.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that all operations constructed\n",
      "     |      within the context should have control dependencies on\n",
      "     |      `control_inputs`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b, c]):\n",
      "     |        # `d` and `e` will only run after `a`, `b`, and `c` have executed.\n",
      "     |        d = ...\n",
      "     |        e = ...\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Multiple calls to `control_dependencies()` can be nested, and in\n",
      "     |      that case a new `Operation` will have control dependencies on the union\n",
      "     |      of `control_inputs` from all active contexts.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b]):\n",
      "     |        # Ops constructed here run after `a` and `b`.\n",
      "     |        with g.control_dependencies([c, d]):\n",
      "     |          # Ops constructed here run after `a`, `b`, `c`, and `d`.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      You can pass None to clear the control dependencies:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b]):\n",
      "     |        # Ops constructed here run after `a` and `b`.\n",
      "     |        with g.control_dependencies(None):\n",
      "     |          # Ops constructed here run normally, not waiting for either `a` or `b`.\n",
      "     |          with g.control_dependencies([c, d]):\n",
      "     |            # Ops constructed here run after `c` and `d`, also not waiting\n",
      "     |            # for either `a` or `b`.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      *N.B.* The control dependencies context applies *only* to ops that\n",
      "     |      are constructed within the context. Merely using an op or tensor\n",
      "     |      in the context does not add a control dependency. The following\n",
      "     |      example illustrates this point:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # WRONG\n",
      "     |      def my_func(pred, tensor):\n",
      "     |        t = tf.matmul(tensor, tensor)\n",
      "     |        with tf.control_dependencies([pred]):\n",
      "     |          # The matmul op is created outside the context, so no control\n",
      "     |          # dependency will be added.\n",
      "     |          return t\n",
      "     |      \n",
      "     |      # RIGHT\n",
      "     |      def my_func(pred, tensor):\n",
      "     |        with tf.control_dependencies([pred]):\n",
      "     |          # The matmul op is created in the context, so a control dependency\n",
      "     |          # will be added.\n",
      "     |          return tf.matmul(tensor, tensor)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Also note that though execution of ops created under this scope will trigger\n",
      "     |      execution of the dependencies, the ops created under this scope might still\n",
      "     |      be pruned from a normal tensorflow graph. For example, in the following\n",
      "     |      snippet of code the dependencies are never executed:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |        loss = model.loss()\n",
      "     |        with tf.control_dependencies(dependencies):\n",
      "     |          loss = loss + tf.constant(1)  # note: dependencies ignored in the\n",
      "     |                                        # backward pass\n",
      "     |        return tf.gradients(loss, model.variables)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This is because evaluating the gradient graph does not require evaluating\n",
      "     |      the constant(1) op created in the forward pass.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      "     |          executed or computed before running the operations defined in the\n",
      "     |          context.  Can also be `None` to clear the control dependencies.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |       A context manager that specifies control dependencies for all\n",
      "     |       operations constructed within the context.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `control_inputs` is not a list of `Operation` or\n",
      "     |          `Tensor` objects.\n",
      "     |  \n",
      "     |  create_op(self, op_type, inputs, dtypes=None, input_types=None, name=None, attrs=None, op_def=None, compute_shapes=True, compute_device=True) -> 'Operation'\n",
      "     |      Creates an `Operation` in this graph. (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(compute_shapes)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "     |      \n",
      "     |      This is a low-level interface for creating an `Operation`. Most\n",
      "     |      programs will not call this method directly, and instead use the\n",
      "     |      Python op constructors, such as `tf.constant()`, which add ops to\n",
      "     |      the default graph.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type: The `Operation` type to create. This corresponds to the\n",
      "     |          `OpDef.name` field for the proto that defines the operation.\n",
      "     |        inputs: A list of `Tensor` objects that will be inputs to the `Operation`.\n",
      "     |        dtypes: (Optional) A list of `DType` objects that will be the types of the\n",
      "     |          tensors that the operation produces.\n",
      "     |        input_types: (Optional.) A list of `DType`s that will be the types of the\n",
      "     |          tensors that the operation consumes. By default, uses the base `DType`\n",
      "     |          of each input in `inputs`. Operations that expect reference-typed inputs\n",
      "     |          must specify `input_types` explicitly.\n",
      "     |        name: (Optional.) A string name for the operation. If not specified, a\n",
      "     |          name is generated based on `op_type`.\n",
      "     |        attrs: (Optional.) A dictionary where the key is the attribute name (a\n",
      "     |          string) and the value is the respective `attr` attribute of the\n",
      "     |          `NodeDef` proto that will represent the operation (an `AttrValue`\n",
      "     |          proto).\n",
      "     |        op_def: (Optional.) The `OpDef` proto that describes the `op_type` that\n",
      "     |          the operation will have.\n",
      "     |        compute_shapes: (Optional.) Deprecated. Has no effect (shapes are always\n",
      "     |          computed).\n",
      "     |        compute_device: (Optional.) If True, device functions will be executed to\n",
      "     |          compute the device property of the Operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if any of the inputs is not a `Tensor`.\n",
      "     |        ValueError: if colocation conflicts with existing device assignment.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An `Operation` object.\n",
      "     |  \n",
      "     |  device(self, device_name_or_function) -> collections.abc.Iterator[None]\n",
      "     |      Returns a context manager that specifies the default device to use.\n",
      "     |      \n",
      "     |      The `device_name_or_function` argument may either be a device name\n",
      "     |      string, a device function, or None:\n",
      "     |      \n",
      "     |      * If it is a device name string, all operations constructed in\n",
      "     |        this context will be assigned to the device with that name, unless\n",
      "     |        overridden by a nested `device()` context.\n",
      "     |      * If it is a function, it will be treated as a function from\n",
      "     |        Operation objects to device name strings, and invoked each time\n",
      "     |        a new Operation is created. The Operation will be assigned to\n",
      "     |        the device with the returned name.\n",
      "     |      * If it is None, all `device()` invocations from the enclosing context\n",
      "     |        will be ignored.\n",
      "     |      \n",
      "     |      For information about the valid syntax of device name strings, see\n",
      "     |      the documentation in\n",
      "     |      [`DeviceNameUtils`](https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.device('/device:GPU:0'):\n",
      "     |        # All operations constructed in this context will be placed\n",
      "     |        # on GPU 0.\n",
      "     |        with g.device(None):\n",
      "     |          # All operations constructed in this context will have no\n",
      "     |          # assigned device.\n",
      "     |      \n",
      "     |      # Defines a function from `Operation` to device string.\n",
      "     |      def matmul_on_gpu(n):\n",
      "     |        if n.type == \"MatMul\":\n",
      "     |          return \"/device:GPU:0\"\n",
      "     |        else:\n",
      "     |          return \"/cpu:0\"\n",
      "     |      \n",
      "     |      with g.device(matmul_on_gpu):\n",
      "     |        # All operations of type \"MatMul\" constructed in this context\n",
      "     |        # will be placed on GPU 0; all other operations will be placed\n",
      "     |        # on CPU 0.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      **N.B.** The device scope may be overridden by op wrappers or\n",
      "     |      other library code. For example, a variable assignment op\n",
      "     |      `v.assign()` must be colocated with the `tf.Variable` `v`, and\n",
      "     |      incompatible device scopes will be ignored.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        device_name_or_function: The device name or function to use in the\n",
      "     |          context.\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        A context manager that specifies the default device to use for newly\n",
      "     |        created ops.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If device scopes are not properly nested.\n",
      "     |  \n",
      "     |  finalize(self) -> None\n",
      "     |      Finalizes this graph, making it read-only.\n",
      "     |      \n",
      "     |      After calling `g.finalize()`, no new operations can be added to\n",
      "     |      `g`.  This method is used to ensure that no operations are added\n",
      "     |      to a graph when it is shared between multiple threads, for example\n",
      "     |      when using a `tf.compat.v1.train.QueueRunner`.\n",
      "     |  \n",
      "     |  get(self: ~GraphType) -> ~GraphType\n",
      "     |  \n",
      "     |  get_all_collection_keys(self) -> list[str]\n",
      "     |      Returns a list of collections used in this graph.\n",
      "     |  \n",
      "     |  get_collection(self, name, scope=None) -> list[typing.Any]\n",
      "     |      Returns a list of values in the collection with the given `name`.\n",
      "     |      \n",
      "     |      This is different from `get_collection_ref()` which always returns the\n",
      "     |      actual collection list if it exists in that it returns a new list each time\n",
      "     |      it is called.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. For example, the `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |        scope: (Optional.) A string. If supplied, the resulting list is filtered\n",
      "     |          to include only items whose `name` attribute matches `scope` using\n",
      "     |          `re.match`. Items without a `name` attribute are never returned if a\n",
      "     |          scope is supplied. The choice of `re.match` means that a `scope` without\n",
      "     |          special tokens filters by prefix.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of values in the collection with the given `name`, or\n",
      "     |        an empty list if no value has been added to that collection. The\n",
      "     |        list contains the values in the order under which they were\n",
      "     |        collected.\n",
      "     |  \n",
      "     |  get_collection_ref(self, name) -> list[typing.Any]\n",
      "     |      Returns a list of values in the collection with the given `name`.\n",
      "     |      \n",
      "     |      If the collection exists, this returns the list itself, which can\n",
      "     |      be modified in place to change the collection.  If the collection does\n",
      "     |      not exist, it is created as an empty list and the list is returned.\n",
      "     |      \n",
      "     |      This is different from `get_collection()` which always returns a copy of\n",
      "     |      the collection list if it exists and never creates an empty collection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. For example, the `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of values in the collection with the given `name`, or an empty\n",
      "     |        list if no value has been added to that collection.\n",
      "     |  \n",
      "     |  get_name_scope(self) -> str\n",
      "     |      Returns the current name scope.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.name_scope('scope1'):\n",
      "     |        with tf.name_scope('scope2'):\n",
      "     |          print(tf.compat.v1.get_default_graph().get_name_scope())\n",
      "     |      ```\n",
      "     |      would print the string `scope1/scope2`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string representing the current name scope.\n",
      "     |  \n",
      "     |  get_operation_by_name(self, name) -> 'Operation'\n",
      "     |      Returns the `Operation` with the given `name`.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the `Operation` to return.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Operation` with the given `name`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `name` is not a string.\n",
      "     |        KeyError: If `name` does not correspond to an operation in this graph.\n",
      "     |  \n",
      "     |  get_tensor_by_name(self, name) -> tensorflow.python.framework.tensor.Tensor\n",
      "     |      Returns the `Tensor` with the given `name`.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the `Tensor` to return.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Tensor` with the given `name`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `name` is not a string.\n",
      "     |        KeyError: If `name` does not correspond to a tensor in this graph.\n",
      "     |  \n",
      "     |  gradient_override_map(self, op_type_map) -> collections.abc.Iterator[None]\n",
      "     |      EXPERIMENTAL: A context manager for overriding gradient functions.\n",
      "     |      \n",
      "     |      This context manager can be used to override the gradient function\n",
      "     |      that will be used for ops within the scope of the context.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      @tf.RegisterGradient(\"CustomSquare\")\n",
      "     |      def _custom_square_grad(op, grad):\n",
      "     |        # ...\n",
      "     |      \n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        s_1 = tf.square(c)  # Uses the default gradient for tf.square.\n",
      "     |        with g.gradient_override_map({\"Square\": \"CustomSquare\"}):\n",
      "     |          s_2 = tf.square(s_2)  # Uses _custom_square_grad to compute the\n",
      "     |                                # gradient of s_2.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type_map: A dictionary mapping op type strings to alternative op type\n",
      "     |          strings.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager that sets the alternative op type to be used for one\n",
      "     |        or more ops created in that context.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `op_type_map` is not a dictionary mapping strings to\n",
      "     |          strings.\n",
      "     |  \n",
      "     |  is_feedable(self, tensor) -> bool\n",
      "     |      Returns `True` if and only if `tensor` is feedable.\n",
      "     |  \n",
      "     |  is_fetchable(self, tensor_or_op) -> bool\n",
      "     |      Returns `True` if and only if `tensor_or_op` is fetchable.\n",
      "     |  \n",
      "     |  name_scope(self, name) -> collections.abc.Iterator[str]\n",
      "     |      Returns a context manager that creates hierarchical names for operations.\n",
      "     |      \n",
      "     |      A graph maintains a stack of name scopes. A `with name_scope(...):`\n",
      "     |      statement pushes a new name onto the stack for the lifetime of the context.\n",
      "     |      \n",
      "     |      The `name` argument will be interpreted as follows:\n",
      "     |      \n",
      "     |      * A string (not ending with '/') will create a new name scope, in which\n",
      "     |        `name` is appended to the prefix of all operations created in the\n",
      "     |        context. If `name` has been used before, it will be made unique by\n",
      "     |        calling `self.unique_name(name)`.\n",
      "     |      * A scope previously captured from a `with g.name_scope(...) as\n",
      "     |        scope:` statement will be treated as an \"absolute\" name scope, which\n",
      "     |        makes it possible to re-enter existing scopes.\n",
      "     |      * A value of `None` or the empty string will reset the current name scope\n",
      "     |        to the top-level (empty) name scope.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0, name=\"c\")\n",
      "     |        assert c.op.name == \"c\"\n",
      "     |        c_1 = tf.constant(6.0, name=\"c\")\n",
      "     |        assert c_1.op.name == \"c_1\"\n",
      "     |      \n",
      "     |        # Creates a scope called \"nested\"\n",
      "     |        with g.name_scope(\"nested\") as scope:\n",
      "     |          nested_c = tf.constant(10.0, name=\"c\")\n",
      "     |          assert nested_c.op.name == \"nested/c\"\n",
      "     |      \n",
      "     |          # Creates a nested scope called \"inner\".\n",
      "     |          with g.name_scope(\"inner\"):\n",
      "     |            nested_inner_c = tf.constant(20.0, name=\"c\")\n",
      "     |            assert nested_inner_c.op.name == \"nested/inner/c\"\n",
      "     |      \n",
      "     |          # Create a nested scope called \"inner_1\".\n",
      "     |          with g.name_scope(\"inner\"):\n",
      "     |            nested_inner_1_c = tf.constant(30.0, name=\"c\")\n",
      "     |            assert nested_inner_1_c.op.name == \"nested/inner_1/c\"\n",
      "     |      \n",
      "     |            # Treats `scope` as an absolute name scope, and\n",
      "     |            # switches to the \"nested/\" scope.\n",
      "     |            with g.name_scope(scope):\n",
      "     |              nested_d = tf.constant(40.0, name=\"d\")\n",
      "     |              assert nested_d.op.name == \"nested/d\"\n",
      "     |      \n",
      "     |              with g.name_scope(\"\"):\n",
      "     |                e = tf.constant(50.0, name=\"e\")\n",
      "     |                assert e.op.name == \"e\"\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The name of the scope itself can be captured by `with\n",
      "     |      g.name_scope(...) as scope:`, which stores the name of the scope\n",
      "     |      in the variable `scope`. This value can be used to name an\n",
      "     |      operation that represents the overall result of executing the ops\n",
      "     |      in a scope. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      inputs = tf.constant(...)\n",
      "     |      with g.name_scope('my_layer') as scope:\n",
      "     |        weights = tf.Variable(..., name=\"weights\")\n",
      "     |        biases = tf.Variable(..., name=\"biases\")\n",
      "     |        affine = tf.matmul(inputs, weights) + biases\n",
      "     |        output = tf.nn.relu(affine, name=scope)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      NOTE: This constructor validates the given `name`. Valid scope\n",
      "     |      names match one of the following regular expressions:\n",
      "     |      \n",
      "     |          [A-Za-z0-9.][A-Za-z0-9_.\\-/]* (for scopes at the root)\n",
      "     |          [A-Za-z0-9_.\\-/]* (for other scopes)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the scope.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager that installs `name` as a new name scope.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `name` is not a valid scope name, according to the rules\n",
      "     |          above.\n",
      "     |  \n",
      "     |  op_def_for_type(self, type) -> tensorflow.core.framework.op_def_pb2.OpDef\n",
      "     |      Returns the `OpDef` proto for `type`. `type` is a string.\n",
      "     |  \n",
      "     |  prevent_feeding(self, tensor) -> None\n",
      "     |      Marks the given `tensor` as unfeedable in this graph.\n",
      "     |  \n",
      "     |  prevent_fetching(self, op) -> None\n",
      "     |      Marks the given `op` as unfetchable in this graph.\n",
      "     |  \n",
      "     |  switch_to_thread_local(self) -> None\n",
      "     |      Make device, colocation and dependencies stacks thread-local.\n",
      "     |      \n",
      "     |      Device, colocation and dependencies stacks are not thread-local be default.\n",
      "     |      If multiple threads access them, then the state is shared.  This means that\n",
      "     |      one thread may affect the behavior of another thread.\n",
      "     |      \n",
      "     |      After this method is called, the stacks become thread-local.  If multiple\n",
      "     |      threads access them, then the state is not shared.  Each thread uses its own\n",
      "     |      value; a thread doesn't affect other threads by mutating such a stack.\n",
      "     |      \n",
      "     |      The initial value for every thread's stack is set to the current value\n",
      "     |      of the stack when `switch_to_thread_local()` was first called.\n",
      "     |  \n",
      "     |  unique_name(self, name, mark_as_used=True) -> str\n",
      "     |      Return a unique operation name for `name`.\n",
      "     |      \n",
      "     |      Note: You rarely need to call `unique_name()` directly.  Most of\n",
      "     |      the time you just need to create `with g.name_scope()` blocks to\n",
      "     |      generate structured names.\n",
      "     |      \n",
      "     |      `unique_name` is used to generate structured names, separated by\n",
      "     |      `\"/\"`, to help identify operations when debugging a graph.\n",
      "     |      Operation names are displayed in error messages reported by the\n",
      "     |      TensorFlow runtime, and in various visualization tools such as\n",
      "     |      TensorBoard.\n",
      "     |      \n",
      "     |      If `mark_as_used` is set to `True`, which is the default, a new\n",
      "     |      unique name is created and marked as in use. If it's set to `False`,\n",
      "     |      the unique name is returned without actually being marked as used.\n",
      "     |      This is useful when the caller simply wants to know what the name\n",
      "     |      to be created will be.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name for an operation.\n",
      "     |        mark_as_used: Whether to mark this name as being used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string to be passed to `create_op()` that will be used\n",
      "     |        to name the operation being created.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  building_function\n",
      "     |      Returns True iff this graph represents a function.\n",
      "     |  \n",
      "     |  collections\n",
      "     |      Returns the names of the collections known to this graph.\n",
      "     |  \n",
      "     |  finalized\n",
      "     |      True if this graph has been finalized.\n",
      "     |  \n",
      "     |  graph_def_versions\n",
      "     |      The GraphDef version information of this graph.\n",
      "     |      \n",
      "     |      For details on the meaning of each version, see\n",
      "     |      [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `VersionDef`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  seed\n",
      "     |      The graph-level random seed of this graph.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  Dismantle = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> None\n",
      "     |  \n",
      "     |  get_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> list\n",
      "     |  \n",
      "     |  new_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> List[TF_Operation]\n",
      "     |  \n",
      "     |  num_operations = (...) from builtins.PyCapsule\n",
      "     |      (self: handle) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.client._pywrap_tf_session.PyGraph:\n",
      "     |  \n",
      "     |  operations\n",
      "     |  \n",
      "     |  version\n",
      "    \n",
      "    class GraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  A protobuf containing the graph of operations.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  This API is not available in TensorFlow 2.x.\n",
      "     |  \n",
      "     |  You should not need to use `GraphDef`s directly in TF2. To load `GraphDef`s in\n",
      "     |  TF2, use SavedModel. The SavedModel contains the `GraphDef`.\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.io.gfile.GFile('/tmp/graph.pb', 'rb') as f:\n",
      "     |    graph_def = tf.compat.v1.GraphDef()\n",
      "     |    graph_def.ParseFromString(f.read())\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.saved_model.load('/tmp/saved_model')\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If you would like to create a `GraphDef` in TF2, use `tf.function` and\n",
      "     |  `get_concrete_function`.\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  >>> def f(x):\n",
      "     |  >>>   return x\n",
      "     |  >>>\n",
      "     |  >>> graph_def = f.get_concrete_function(1.).graph.as_graph_def()\n",
      "     |  >>> print(graph_def)\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphDef\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class GraphKeys(builtins.object)\n",
      "     |  Standard names to use for graph collections.\n",
      "     |  \n",
      "     |  The standard library uses various well-known names to collect and\n",
      "     |  retrieve values associated with a graph. For example, the\n",
      "     |  `tf.Optimizer` subclasses default to optimizing the variables\n",
      "     |  collected under `tf.GraphKeys.TRAINABLE_VARIABLES` if none is\n",
      "     |  specified, but it is also possible to pass an explicit list of\n",
      "     |  variables.\n",
      "     |  \n",
      "     |  The following standard keys are defined:\n",
      "     |  \n",
      "     |  * `GLOBAL_VARIABLES`: the default collection of `Variable` objects, shared\n",
      "     |    across distributed environment (model variables are subset of these). See\n",
      "     |    `tf.compat.v1.global_variables`\n",
      "     |    for more details.\n",
      "     |    Commonly, all `TRAINABLE_VARIABLES` variables will be in `MODEL_VARIABLES`,\n",
      "     |    and all `MODEL_VARIABLES` variables will be in `GLOBAL_VARIABLES`.\n",
      "     |  * `LOCAL_VARIABLES`: the subset of `Variable` objects that are local to each\n",
      "     |    machine. Usually used for temporarily variables, like counters.\n",
      "     |  * `MODEL_VARIABLES`: the subset of `Variable` objects that are used in the\n",
      "     |    model for inference (feed forward).\n",
      "     |  * `TRAINABLE_VARIABLES`: the subset of `Variable` objects that will\n",
      "     |    be trained by an optimizer. See\n",
      "     |    `tf.compat.v1.trainable_variables`\n",
      "     |    for more details.\n",
      "     |  * `SUMMARIES`: the summary `Tensor` objects that have been created in the\n",
      "     |    graph. See\n",
      "     |    `tf.compat.v1.summary.merge_all`\n",
      "     |    for more details.\n",
      "     |  * `QUEUE_RUNNERS`: the `QueueRunner` objects that are used to\n",
      "     |    produce input for a computation. See\n",
      "     |    `tf.compat.v1.train.start_queue_runners`\n",
      "     |    for more details.\n",
      "     |  * `MOVING_AVERAGE_VARIABLES`: the subset of `Variable` objects that will also\n",
      "     |    keep moving averages.  See\n",
      "     |    `tf.compat.v1.moving_average_variables`\n",
      "     |    for more details.\n",
      "     |  * `REGULARIZATION_LOSSES`: regularization losses collected during graph\n",
      "     |    construction.\n",
      "     |  \n",
      "     |  The following standard keys are _defined_, but their collections are **not**\n",
      "     |  automatically populated as many of the others are:\n",
      "     |  \n",
      "     |  * `WEIGHTS`\n",
      "     |  * `BIASES`\n",
      "     |  * `ACTIVATIONS`\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ACTIVATIONS = 'activations'\n",
      "     |  \n",
      "     |  ASSET_FILEPATHS = 'asset_filepaths'\n",
      "     |  \n",
      "     |  BIASES = 'biases'\n",
      "     |  \n",
      "     |  CONCATENATED_VARIABLES = 'concatenated_variables'\n",
      "     |  \n",
      "     |  COND_CONTEXT = 'cond_context'\n",
      "     |  \n",
      "     |  EVAL_STEP = 'eval_step'\n",
      "     |  \n",
      "     |  GLOBAL_STEP = 'global_step'\n",
      "     |  \n",
      "     |  GLOBAL_VARIABLES = 'variables'\n",
      "     |  \n",
      "     |  INIT_OP = 'init_op'\n",
      "     |  \n",
      "     |  LOCAL_INIT_OP = 'local_init_op'\n",
      "     |  \n",
      "     |  LOCAL_RESOURCES = 'local_resources'\n",
      "     |  \n",
      "     |  LOCAL_VARIABLES = 'local_variables'\n",
      "     |  \n",
      "     |  LOSSES = 'losses'\n",
      "     |  \n",
      "     |  METRIC_VARIABLES = 'metric_variables'\n",
      "     |  \n",
      "     |  MODEL_VARIABLES = 'model_variables'\n",
      "     |  \n",
      "     |  MOVING_AVERAGE_VARIABLES = 'moving_average_variables'\n",
      "     |  \n",
      "     |  QUEUE_RUNNERS = 'queue_runners'\n",
      "     |  \n",
      "     |  READY_FOR_LOCAL_INIT_OP = 'ready_for_local_init_op'\n",
      "     |  \n",
      "     |  READY_OP = 'ready_op'\n",
      "     |  \n",
      "     |  REGULARIZATION_LOSSES = 'regularization_losses'\n",
      "     |  \n",
      "     |  RESOURCES = 'resources'\n",
      "     |  \n",
      "     |  SAVEABLE_OBJECTS = 'saveable_objects'\n",
      "     |  \n",
      "     |  SAVERS = 'savers'\n",
      "     |  \n",
      "     |  SUMMARIES = 'summaries'\n",
      "     |  \n",
      "     |  SUMMARY_OP = 'summary_op'\n",
      "     |  \n",
      "     |  TABLE_INITIALIZERS = 'table_initializer'\n",
      "     |  \n",
      "     |  TRAINABLE_RESOURCE_VARIABLES = 'trainable_resource_variables'\n",
      "     |  \n",
      "     |  TRAINABLE_VARIABLES = 'trainable_variables'\n",
      "     |  \n",
      "     |  TRAIN_OP = 'train_op'\n",
      "     |  \n",
      "     |  UPDATE_OPS = 'update_ops'\n",
      "     |  \n",
      "     |  VARIABLES = 'variables'\n",
      "     |  \n",
      "     |  WEIGHTS = 'weights'\n",
      "     |  \n",
      "     |  WHILE_CONTEXT = 'while_context'\n",
      "    \n",
      "    class GraphOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      GraphOptions\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class HistogramProto(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      HistogramProto\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class IdentityReader(ReaderBase)\n",
      "     |  IdentityReader(name=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the queued work as both the key and value.\n",
      "     |  \n",
      "     |  To use, enqueue strings in a Queue.  Read will take the front\n",
      "     |  work string and output (work, work).\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IdentityReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Create a IdentityReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(...)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class IndexedSlices(tensorflow.python.types.internal.IndexedSlices, tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  IndexedSlices(values, indices, dense_shape=None)\n",
      "     |  \n",
      "     |  A sparse representation of a set of tensor slices at given indices.\n",
      "     |  \n",
      "     |  This class is a simple wrapper for a pair of `Tensor` objects:\n",
      "     |  \n",
      "     |  * `values`: A `Tensor` of any dtype with shape `[D0, D1, ..., Dn]`.\n",
      "     |  * `indices`: A 1-D integer `Tensor` with shape `[D0]`.\n",
      "     |  \n",
      "     |  An `IndexedSlices` is typically used to represent a subset of a larger\n",
      "     |  tensor `dense` of shape `[LARGE0, D1, .. , DN]` where `LARGE0 >> D0`.\n",
      "     |  The values in `indices` are the indices in the first dimension of\n",
      "     |  the slices that have been extracted from the larger tensor.\n",
      "     |  \n",
      "     |  The dense tensor `dense` represented by an `IndexedSlices` `slices` has\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dense[slices.indices[i], :, :, :, ...] = slices.values[i, :, :, :, ...]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The `IndexedSlices` class is used principally in the definition of\n",
      "     |  gradients for operations that have sparse gradients\n",
      "     |  (e.g. `tf.gather`).\n",
      "     |  \n",
      "     |  >>> v = tf.Variable([[0.,1, 2], [2, 3, 4], [4, 5, 6], [6, 7, 8]])\n",
      "     |  >>> with tf.GradientTape() as tape:\n",
      "     |  ...   r = tf.gather(v, [1,3])\n",
      "     |  >>> index_slices = tape.gradient(r,v)\n",
      "     |  >>> index_slices\n",
      "     |  <...IndexedSlices object ...>\n",
      "     |  >>> index_slices.indices.numpy()\n",
      "     |  array([1, 3], dtype=int32)\n",
      "     |  >>> index_slices.values.numpy()\n",
      "     |  array([[1., 1., 1.],\n",
      "     |         [1., 1., 1.]], dtype=float32)\n",
      "     |  \n",
      "     |  Contrast this representation with\n",
      "     |  `tf.sparse.SparseTensor`,\n",
      "     |  which uses multi-dimensional indices and scalar values.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexedSlices\n",
      "     |      tensorflow.python.types.internal.IndexedSlices\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, values, indices, dense_shape=None)\n",
      "     |      Creates an `IndexedSlices`.\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      A 1-D `Tensor` containing the shape of the corresponding dense tensor.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device on which `values` will be produced, or `None`.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains the values, indices, and shape tensors.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      A 1-D `Tensor` containing the indices of the slices.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of this `IndexedSlices`.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces `values` as an output.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Gets the `tf.TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` object.\n",
      "     |  \n",
      "     |  values\n",
      "     |      A `Tensor` containing the values of the slices.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __composite_gradient__ = <tensorflow.python.framework.indexed_slices.I...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.IndexedSlices:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "    \n",
      "    class IndexedSlicesSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  IndexedSlicesSpec(shape=None, dtype=tf.float32, indices_dtype=tf.int64, dense_shape_dtype=None, indices_shape=None)\n",
      "     |  \n",
      "     |  Type specification for a `tf.IndexedSlices`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexedSlicesSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32, indices_dtype=tf.int64, dense_shape_dtype=None, indices_shape=None)\n",
      "     |      Constructs a type specification for a `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The dense shape of the `IndexedSlices`, or `None` to allow any\n",
      "     |          dense shape.\n",
      "     |        dtype: `tf.DType` of values in the `IndexedSlices`.\n",
      "     |        indices_dtype: `tf.DType` of the `indices` in the `IndexedSlices`.  One\n",
      "     |          of `tf.int32` or `tf.int64`.\n",
      "     |        dense_shape_dtype: `tf.DType` of the `dense_shape` in the `IndexedSlices`.\n",
      "     |          One of `tf.int32`, `tf.int64`, or `None` (if the `IndexedSlices` has\n",
      "     |          no `dense_shape` tensor).\n",
      "     |        indices_shape: The shape of the `indices` component, which indicates\n",
      "     |          how many slices are in the `IndexedSlices`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class InteractiveSession(BaseSession)\n",
      "     |  InteractiveSession(target='', graph=None, config=None)\n",
      "     |  \n",
      "     |  A TensorFlow `Session` for use in interactive contexts, such as a shell.\n",
      "     |  \n",
      "     |  The only difference with a regular `Session` is that an `InteractiveSession`\n",
      "     |  installs itself as the default session on construction.\n",
      "     |  The methods `tf.Tensor.eval`\n",
      "     |  and `tf.Operation.run`\n",
      "     |  will use that session to run ops.\n",
      "     |  \n",
      "     |  This is convenient in interactive shells and [IPython\n",
      "     |  notebooks](http://ipython.org), as it avoids having to pass an explicit\n",
      "     |  `Session` object to run ops.\n",
      "     |  \n",
      "     |  For example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  sess = tf.compat.v1.InteractiveSession()\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  # We can just use 'c.eval()' without passing 'sess'\n",
      "     |  print(c.eval())\n",
      "     |  sess.close()\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that a regular session installs itself as the default session when it\n",
      "     |  is created in a `with` statement.  The common usage in non-interactive\n",
      "     |  programs is to follow that pattern:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  with tf.compat.v1.Session():\n",
      "     |    # We can also use 'c.eval()' here.\n",
      "     |    print(c.eval())\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InteractiveSession\n",
      "     |      BaseSession\n",
      "     |      SessionInterface\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, target='', graph=None, config=None)\n",
      "     |      Creates a new interactive TensorFlow session.\n",
      "     |      \n",
      "     |      If no `graph` argument is specified when constructing the session,\n",
      "     |      the default graph will be launched in the session. If you are\n",
      "     |      using more than one graph (created with `tf.Graph()`) in the same\n",
      "     |      process, you will have to use different sessions for each graph,\n",
      "     |      but each graph can be used in multiple sessions. In this case, it\n",
      "     |      is often clearer to pass the graph to be launched explicitly to\n",
      "     |      the session constructor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: (Optional.) The execution engine to connect to. Defaults to using\n",
      "     |          an in-process engine.\n",
      "     |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      "     |        config: (Optional) `ConfigProto` proto used to configure the session.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes an `InteractiveSession`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSession:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  as_default(self)\n",
      "     |      Returns a context manager that makes this object the default session.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that calls to\n",
      "     |      `tf.Operation.run` or `tf.Tensor.eval` should be executed in\n",
      "     |      this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(..)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      \n",
      "     |      with sess.as_default():\n",
      "     |        assert tf.compat.v1.get_default_session() is sess\n",
      "     |        print(c.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      To get the current default session, use `tf.compat.v1.get_default_session`.\n",
      "     |      \n",
      "     |      *N.B.* The `as_default` context manager *does not* close the\n",
      "     |      session when you exit the context, and you must close the session\n",
      "     |      explicitly.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(...)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      # ...\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      \n",
      "     |      sess.close()\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Alternatively, you can use `with tf.compat.v1.Session():` to create a\n",
      "     |      session that is automatically closed on exiting the context,\n",
      "     |      including when an uncaught exception is raised.\n",
      "     |      \n",
      "     |      *N.B.* The default session is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default session in that\n",
      "     |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      "     |      the current default graph. If you are using multiple graphs, and\n",
      "     |      `sess.graph` is different from the value of\n",
      "     |      `tf.compat.v1.get_default_graph`, you must explicitly enter a\n",
      "     |      `with sess.graph.as_default():` block to make `sess.graph` the default\n",
      "     |      graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager using this session as the default session.\n",
      "     |  \n",
      "     |  list_devices(self)\n",
      "     |      Lists available devices in this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      devices = sess.list_devices()\n",
      "     |      for d in devices:\n",
      "     |        print(d.name)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Where:\n",
      "     |        Each element in the list has the following properties\n",
      "     |        name: A string with the full name of the device. ex:\n",
      "     |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      "     |        device_type: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      "     |        memory_limit: The maximum amount of memory available on the device.\n",
      "     |            Note: depending on the device, it is possible the usable memory could\n",
      "     |            be substantially less.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      "     |        invalid state, or network errors occur).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of devices in the session.\n",
      "     |  \n",
      "     |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      "     |      Returns a Python callable that runs a particular step.\n",
      "     |      \n",
      "     |      The returned callable will take `len(feed_list)` arguments whose types\n",
      "     |      must be compatible feed values for the respective elements of `feed_list`.\n",
      "     |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      "     |      argument to the returned callable must be a numpy ndarray (or something\n",
      "     |      convertible to an ndarray) with matching element type and shape. See\n",
      "     |      `tf.Session.run` for details of the allowable feed key and value types.\n",
      "     |      \n",
      "     |      The returned callable will have the same return type as\n",
      "     |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      "     |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      "     |      it will return `None`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A value or list of values to fetch. See `tf.Session.run` for\n",
      "     |          details of the allowable fetch types.\n",
      "     |        feed_list: (Optional.) A list of `feed_dict` keys. See `tf.Session.run`\n",
      "     |          for details of the allowable feed key types.\n",
      "     |        accept_options: (Optional.) If `True`, the returned `Callable` will be\n",
      "     |          able to accept `tf.compat.v1.RunOptions` and `tf.compat.v1.RunMetadata`\n",
      "     |          as optional keyword arguments `options` and `run_metadata`,\n",
      "     |          respectively, with the same syntax and semantics as `tf.Session.run`,\n",
      "     |          which is useful for certain use cases (profiling and debugging) but will\n",
      "     |          result in measurable slowdown of the `Callable`'s\n",
      "     |          performance. Default: `False`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A function that when called will execute the step defined by\n",
      "     |        `feed_list` and `fetches` in this session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      "     |          as arguments to `tf.Session.run`.\n",
      "     |  \n",
      "     |  partial_run(self, handle, fetches, feed_dict=None)\n",
      "     |      Continues the execution with more feeds and fetches. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2023-06-01.\n",
      "     |      Instructions for updating:\n",
      "     |      This function is deprecated and we do not expect adding newfunctionality to it. Please do not have your code dependingon this function.\n",
      "     |      \n",
      "     |      NOTE: This function is deprecated and we do not expect adding new\n",
      "     |      functionality to it. Please do not have your code depending on this\n",
      "     |      function.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      "     |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      "     |      list of feeds and fetches that will be used in the subsequent\n",
      "     |      `partial_run` calls.\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. See run() for more information.\n",
      "     |      \n",
      "     |      Below is a simple example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      r1 = math_ops.add(a, b)\n",
      "     |      r2 = math_ops.multiply(r1, c)\n",
      "     |      \n",
      "     |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      "     |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      "     |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        handle: A handle for a sequence of partial runs.\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (see\n",
      "     |          documentation for `run`).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary\n",
      "     |        (see documentation for `run`).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses on error.\n",
      "     |  \n",
      "     |  partial_run_setup(self, fetches, feeds=None)\n",
      "     |      Sets up a graph with feeds and fetches for partial run. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2023-06-01.\n",
      "     |      Instructions for updating:\n",
      "     |      This function is deprecated and we do not expect adding newfunctionality to it. Please do not have your code dependingon this function.\n",
      "     |      \n",
      "     |      NOTE: This function is deprecated and we do not expect adding new\n",
      "     |      functionality to it. Please do not have your code depending on this\n",
      "     |      function.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      "     |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, or a list of graph elements.\n",
      "     |        feeds: A single graph element, or a list of graph elements.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A handle for partial run.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      "     |  \n",
      "     |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      "     |      Runs operations and evaluates tensors in `fetches`.\n",
      "     |      \n",
      "     |      This method runs one \"step\" of TensorFlow computation, by\n",
      "     |      running the necessary graph fragment to execute every `Operation`\n",
      "     |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      "     |      `feed_dict` for the corresponding input values.\n",
      "     |      \n",
      "     |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      "     |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      "     |      elements at its leaves.  A graph element can be one of the following types:\n",
      "     |      \n",
      "     |      * A `tf.Operation`.\n",
      "     |        The corresponding fetched value will be `None`.\n",
      "     |      * A `tf.Tensor`.\n",
      "     |        The corresponding fetched value will be a numpy ndarray containing the\n",
      "     |        value of that tensor.\n",
      "     |      * A `tf.sparse.SparseTensor`.\n",
      "     |        The corresponding fetched value will be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`\n",
      "     |        containing the value of that sparse tensor.\n",
      "     |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      "     |        numpy ndarray containing the handle of that tensor.\n",
      "     |      * A `string` which is the name of a tensor or operation in the graph.\n",
      "     |      \n",
      "     |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      "     |      where the leaves are replaced by the corresponding values returned by\n",
      "     |      TensorFlow.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |         a = tf.constant([10, 20])\n",
      "     |         b = tf.constant([1.0, 2.0])\n",
      "     |         # 'fetches' can be a singleton\n",
      "     |         v = session.run(a)\n",
      "     |         # v is the numpy array [10, 20]\n",
      "     |         # 'fetches' can be a list.\n",
      "     |         v = session.run([a, b])\n",
      "     |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      "     |         # 1-D array [1.0, 2.0]\n",
      "     |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      "     |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      "     |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      "     |         # v is a dict with\n",
      "     |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      "     |         # 'b' (the numpy array [1.0, 2.0])\n",
      "     |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      "     |         # [10, 20].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      "     |      one of the following types:\n",
      "     |      \n",
      "     |      * If the key is a `tf.Tensor`, the\n",
      "     |        value may be a Python scalar, string, list, or numpy ndarray\n",
      "     |        that can be converted to the same `dtype` as that\n",
      "     |        tensor. Additionally, if the key is a\n",
      "     |        `tf.compat.v1.placeholder`, the shape of\n",
      "     |        the value will be checked for compatibility with the placeholder.\n",
      "     |      * If the key is a\n",
      "     |        `tf.sparse.SparseTensor`,\n",
      "     |        the value should be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`.\n",
      "     |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      "     |        should be a nested tuple with the same structure that maps to their\n",
      "     |        corresponding values as above.\n",
      "     |      \n",
      "     |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      "     |      of the corresponding key.\n",
      "     |      \n",
      "     |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      "     |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      "     |      on).\n",
      "     |      \n",
      "     |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      "     |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      "     |      example, when users turn on tracing in `options`, the profiled info will be\n",
      "     |      collected into this argument and passed back.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (described\n",
      "     |          above).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |        options: A [`RunOptions`] protocol buffer\n",
      "     |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary (described above).\n",
      "     |        Order in which `fetches` operations are evaluated inside the call\n",
      "     |        is undefined.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      "     |          `Tensor` that doesn't exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSession:\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The graph that was launched in this session.\n",
      "     |  \n",
      "     |  graph_def\n",
      "     |      A serializable version of the underlying TensorFlow graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      "     |        the underlying TensorFlow graph.\n",
      "     |  \n",
      "     |  sess_str\n",
      "     |      The TensorFlow process to which this session will connect.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SessionInterface:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class LMDBReader(ReaderBase)\n",
      "     |  LMDBReader(name=None, options=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the records from a LMDB file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LMDBReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, options=None)\n",
      "     |      Create a LMDBReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.contrib.data.LMDBDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        options: A LMDBRecordOptions object (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class LogMessage(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      LogMessage\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class MetaGraphDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      MetaGraphDef\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CollectionDefEntry = <class 'tensorflow.core.protobuf.meta_graph_pb2.C...\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  MetaInfoDef = <class 'tensorflow.core.protobuf.meta_graph_pb2.MetaInfo...\n",
      "     |  \n",
      "     |  SignatureDefEntry = <class 'tensorflow.core.protobuf.meta_graph_pb2.Si...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class Module(tensorflow.python.trackable.autotrackable.AutoTrackable)\n",
      "     |  Module(name=None)\n",
      "     |  \n",
      "     |  Base neural network module class.\n",
      "     |  \n",
      "     |  A module is a named container for `tf.Variable`s, other `tf.Module`s and\n",
      "     |  functions which apply to user input. For example a dense layer in a neural\n",
      "     |  network might be implemented as a `tf.Module`:\n",
      "     |  \n",
      "     |  >>> class Dense(tf.Module):\n",
      "     |  ...   def __init__(self, input_dim, output_size, name=None):\n",
      "     |  ...     super().__init__(name=name)\n",
      "     |  ...     self.w = tf.Variable(\n",
      "     |  ...       tf.random.normal([input_dim, output_size]), name='w')\n",
      "     |  ...     self.b = tf.Variable(tf.zeros([output_size]), name='b')\n",
      "     |  ...   def __call__(self, x):\n",
      "     |  ...     y = tf.matmul(x, self.w) + self.b\n",
      "     |  ...     return tf.nn.relu(y)\n",
      "     |  \n",
      "     |  You can use the Dense layer as you would expect:\n",
      "     |  \n",
      "     |  >>> d = Dense(input_dim=3, output_size=2)\n",
      "     |  >>> d(tf.ones([1, 3]))\n",
      "     |  <tf.Tensor: shape=(1, 2), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |  \n",
      "     |  \n",
      "     |  By subclassing `tf.Module` instead of `object` any `tf.Variable` or\n",
      "     |  `tf.Module` instances assigned to object properties can be collected using\n",
      "     |  the `variables`, `trainable_variables` or `submodules` property:\n",
      "     |  \n",
      "     |  >>> d.variables\n",
      "     |      (<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=...,\n",
      "     |      dtype=float32)>,\n",
      "     |      <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=..., dtype=float32)>)\n",
      "     |  \n",
      "     |  \n",
      "     |  Subclasses of `tf.Module` can also take advantage of the `_flatten` method\n",
      "     |  which can be used to implement tracking of any other types.\n",
      "     |  \n",
      "     |  All `tf.Module` classes have an associated `tf.name_scope` which can be used\n",
      "     |  to group operations in TensorBoard and create hierarchies for variable names\n",
      "     |  which can help with debugging. We suggest using the name scope when creating\n",
      "     |  nested submodules/parameters or for forward methods whose graph you might want\n",
      "     |  to inspect in TensorBoard. You can enter the name scope explicitly using\n",
      "     |  `with self.name_scope:` or you can annotate methods (apart from `__init__`)\n",
      "     |  with `@tf.Module.with_name_scope`.\n",
      "     |  \n",
      "     |  >>> class MLP(tf.Module):\n",
      "     |  ...   def __init__(self, input_size, sizes, name=None):\n",
      "     |  ...     super().__init__(name=name)\n",
      "     |  ...     self.layers = []\n",
      "     |  ...     with self.name_scope:\n",
      "     |  ...       for size in sizes:\n",
      "     |  ...         self.layers.append(Dense(input_dim=input_size, output_size=size))\n",
      "     |  ...         input_size = size\n",
      "     |  ...   @tf.Module.with_name_scope\n",
      "     |  ...   def __call__(self, x):\n",
      "     |  ...     for layer in self.layers:\n",
      "     |  ...       x = layer(x)\n",
      "     |  ...     return x\n",
      "     |  \n",
      "     |  >>> module = MLP(input_size=5, sizes=[5, 5])\n",
      "     |  >>> module.variables\n",
      "     |  (<tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,\n",
      "     |     dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)>,\n",
      "     |  <tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,\n",
      "     |     dtype=float32)>)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Module\n",
      "     |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      "     |      tensorflow.python.trackable.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  with_name_scope(method) from builtins.type\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      >>> class MyModule(tf.Module):\n",
      "     |      ...   @tf.Module.with_name_scope\n",
      "     |      ...   def __call__(self, x):\n",
      "     |      ...     if not hasattr(self, 'w'):\n",
      "     |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      "     |      ...     return tf.matmul(x, self.w)\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      >>> mod = MyModule()\n",
      "     |      >>> mod(tf.ones([1, 2]))\n",
      "     |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      "     |      >>> mod.w\n",
      "     |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      "     |      numpy=..., dtype=float32)>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  non_trainable_variables\n",
      "     |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      >>> a = tf.Module()\n",
      "     |      >>> b = tf.Module()\n",
      "     |      >>> c = tf.Module()\n",
      "     |      >>> a.b = b\n",
      "     |      >>> b.c = c\n",
      "     |      >>> list(a.submodules) == [b, c]\n",
      "     |      True\n",
      "     |      >>> list(b.submodules) == [c]\n",
      "     |      True\n",
      "     |      >>> list(c.submodules) == []\n",
      "     |      True\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of trainable variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of variables owned by this module and its submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class NameAttrList(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      NameAttrList\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AttrEntry = <class 'tensorflow.core.framework.attr_value_pb2.AttrEntry...\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class NodeDef(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      NodeDef\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AttrEntry = <class 'tensorflow.core.framework.node_def_pb2.AttrEntry'>\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ExperimentalDebugInfo = <class 'tensorflow.core.framework.node_def_pb2...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class OpError(builtins.Exception)\n",
      "     |  OpError(node_def, op, message, error_code, *args)\n",
      "     |  \n",
      "     |  The base class for TensorFlow exceptions.\n",
      "     |  \n",
      "     |  Usually, TensorFlow will raise a more specific subclass of `OpError` from the\n",
      "     |  `tf.errors` module.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, node_def, op, message, error_code, *args)\n",
      "     |      Creates a new `OpError` indicating that a particular op failed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        node_def: The `node_def_pb2.NodeDef` proto representing the op that\n",
      "     |          failed, if known; otherwise None.\n",
      "     |        op: The `ops.Operation` that failed, if known; otherwise None. During\n",
      "     |          eager execution, this field is always `None`.\n",
      "     |        message: The message string describing the failure.\n",
      "     |        error_code: The `error_codes_pb2.Code` describing the error.\n",
      "     |        *args: If not empty, it should contain a dictionary describing details\n",
      "     |          about the error. This argument is inspired by Abseil payloads:\n",
      "     |          https://github.com/abseil/abseil-cpp/blob/master/absl/status/status.h\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  error_code\n",
      "     |      The integer error code that describes the error.\n",
      "     |  \n",
      "     |  experimental_payloads\n",
      "     |      A dictionary describing the details of the error.\n",
      "     |  \n",
      "     |  message\n",
      "     |      The error message that describes the error.\n",
      "     |  \n",
      "     |  node_def\n",
      "     |      The `NodeDef` proto representing the op that failed.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The operation that failed, if known.\n",
      "     |      \n",
      "     |      *N.B.* If the failed op was synthesized at runtime, e.g. a `Send`\n",
      "     |      or `Recv` op, there will be no corresponding\n",
      "     |      `tf.Operation`\n",
      "     |      object.  In that case, this will return `None`, and you should\n",
      "     |      instead use the `tf.errors.OpError.node_def` to\n",
      "     |      discover information about the op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Operation` that failed, or None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  add_note(...)\n",
      "     |      Exception.add_note(note) --\n",
      "     |      add a note to the exception\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class Operation(tensorflow.python.client._pywrap_tf_session.PyOperation)\n",
      "     |  Represents a graph node that performs computation on tensors.\n",
      "     |  \n",
      "     |  An `Operation` is a node in a `tf.Graph` that takes zero or more `Tensor`\n",
      "     |  objects as input, and produces zero or more `Tensor` objects as output.\n",
      "     |  Objects of type `Operation` are created by calling a Python op constructor\n",
      "     |  (such as `tf.matmul`) within a `tf.function` or under a `tf.Graph.as_default`\n",
      "     |  context manager.\n",
      "     |  \n",
      "     |  For example, within a `tf.function`, `c = tf.matmul(a, b)` creates an\n",
      "     |  `Operation` of type \"MatMul\" that takes tensors `a` and `b` as input, and\n",
      "     |  produces `c` as output.\n",
      "     |  \n",
      "     |  If a `tf.compat.v1.Session` is used, an `Operation` of a `tf.Graph` can be\n",
      "     |  executed by passing it to `tf.Session.run`. `op.run()` is a shortcut for\n",
      "     |  calling `tf.compat.v1.get_default_session().run(op)`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Operation\n",
      "     |      tensorflow.python.client._pywrap_tf_session.PyOperation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self) -> str\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __tf_tensor__(self, dtype=None, name=None) -> NoReturn\n",
      "     |      Raises a helpful error.\n",
      "     |  \n",
      "     |  colocation_groups(self) -> list[bytes]\n",
      "     |      Returns the list of colocation groups of the op.\n",
      "     |  \n",
      "     |  experimental_set_type(self, type_proto) -> None\n",
      "     |      Sets the corresponding node's `experimental_type` field.\n",
      "     |      \n",
      "     |      See the description of `NodeDef.experimental_type` for more info.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        type_proto: A FullTypeDef proto message. The root type_if of this object\n",
      "     |          must be `TFT_PRODUCT`, even for ops which only have a singlre return\n",
      "     |          value.\n",
      "     |  \n",
      "     |  get_attr(self, name)\n",
      "     |      Returns the value of the attr of this op with the given `name`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the attr to fetch.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of the attr, as a Python object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If this op does not have an attr with the given `name`.\n",
      "     |  \n",
      "     |  run(self, feed_dict=None, session=None) -> None\n",
      "     |      Runs this operation in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for this operation.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `Operation.run()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to run to this operation. If\n",
      "     |          none, the default session will be used.\n",
      "     |  \n",
      "     |  values(self) -> tuple[typing.Any, ...]\n",
      "     |      DEPRECATED: Use outputs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_node_def(node_def, g, inputs=None, output_types=None, control_inputs=None, input_types=None, original_op=None, op_def=None) -> ~OperationType from builtins.type\n",
      "     |      Creates an `Operation`.\n",
      "     |      \n",
      "     |      NOTE: This constructor validates the name of the `Operation` (passed\n",
      "     |      as `node_def.name`). Valid `Operation` names match the following\n",
      "     |      regular expression:\n",
      "     |      \n",
      "     |          [A-Za-z0-9.][A-Za-z0-9_.\\\\-/]*\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        node_def: `node_def_pb2.NodeDef`.  `NodeDef` for the `Operation`. Used for\n",
      "     |          attributes of `node_def_pb2.NodeDef`, typically `name`, `op`, and\n",
      "     |          `device`.  The `input` attribute is irrelevant here as it will be\n",
      "     |          computed when generating the model.\n",
      "     |        g: `Graph`. The parent graph.\n",
      "     |        inputs: list of `Tensor` objects. The inputs to this `Operation`.\n",
      "     |        output_types: list of `DType` objects.  List of the types of the `Tensors`\n",
      "     |          computed by this operation.  The length of this list indicates the\n",
      "     |          number of output endpoints of the `Operation`.\n",
      "     |        control_inputs: list of operations or tensors from which to have a control\n",
      "     |          dependency.\n",
      "     |        input_types: List of `DType` objects representing the types of the tensors\n",
      "     |          accepted by the `Operation`.  By default uses `[x.dtype.base_dtype for x\n",
      "     |          in inputs]`.  Operations that expect reference-typed inputs must specify\n",
      "     |          these explicitly.\n",
      "     |        original_op: Optional. Used to associate the new `Operation` with an\n",
      "     |          existing `Operation` (for example, a replica with the op that was\n",
      "     |          replicated).\n",
      "     |        op_def: Optional. The `op_def_pb2.OpDef` proto that describes the op type\n",
      "     |          that this `Operation` represents.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if control inputs are not Operations or Tensors,\n",
      "     |          or if `node_def` is not a `NodeDef`,\n",
      "     |          or if `g` is not a `Graph`,\n",
      "     |          or if `inputs` are not tensors,\n",
      "     |          or if `inputs` and `input_types` are incompatible.\n",
      "     |        ValueError: if the `node_def` name is not valid.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device to which this op has been assigned, if any.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The string name of the device to which this op has been\n",
      "     |        assigned, or an empty string if it has not been assigned to a\n",
      "     |        device.\n",
      "     |  \n",
      "     |  inputs\n",
      "     |      The sequence of `Tensor` objects representing the data inputs of this op.\n",
      "     |  \n",
      "     |  node_def\n",
      "     |  \n",
      "     |  op_def\n",
      "     |  \n",
      "     |  traceback\n",
      "     |      Returns the call stack from when this operation was constructed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  control_inputs\n",
      "     |      The `Operation` objects on which this op has a control dependency.\n",
      "     |      \n",
      "     |      Before this op is executed, TensorFlow will ensure that the\n",
      "     |      operations in `self.control_inputs` have finished executing. This\n",
      "     |      mechanism can be used to run ops sequentially for performance\n",
      "     |      reasons, or to ensure that the side effects of an op are observed\n",
      "     |      in the correct order.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of `Operation` objects.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  outputs\n",
      "     |  \n",
      "     |  type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.client._pywrap_tf_session.PyOperation:\n",
      "     |  \n",
      "     |  graph\n",
      "    \n",
      "    class OptimizerOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      OptimizerOptions\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class OptionalSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  OptionalSpec(element_spec)\n",
      "     |  \n",
      "     |  Type specification for `tf.experimental.Optional`.\n",
      "     |  \n",
      "     |  For instance, `tf.OptionalSpec` can be used to define a tf.function that takes\n",
      "     |  `tf.experimental.Optional` as an input argument:\n",
      "     |  \n",
      "     |  >>> @tf.function(input_signature=[tf.OptionalSpec(\n",
      "     |  ...   tf.TensorSpec(shape=(), dtype=tf.int32, name=None))])\n",
      "     |  ... def maybe_square(optional):\n",
      "     |  ...   if optional.has_value():\n",
      "     |  ...     x = optional.get_value()\n",
      "     |  ...     return x * x\n",
      "     |  ...   return -1\n",
      "     |  >>> optional = tf.experimental.Optional.from_value(5)\n",
      "     |  >>> print(maybe_square(optional))\n",
      "     |  tf.Tensor(25, shape=(), dtype=int32)\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |    element_spec: A (nested) structure of `TypeSpec` objects that represents the\n",
      "     |      type specification of the optional element.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OptionalSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, element_spec)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_value(value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class PaddingFIFOQueue(QueueBase)\n",
      "     |  PaddingFIFOQueue(capacity, dtypes, shapes, names=None, shared_name=None, name='padding_fifo_queue')\n",
      "     |  \n",
      "     |  A FIFOQueue that supports batching variable-sized tensors by padding.\n",
      "     |  \n",
      "     |  A `PaddingFIFOQueue` may contain components with dynamic shape, while also\n",
      "     |  supporting `dequeue_many`.  See the constructor for more details.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PaddingFIFOQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, dtypes, shapes, names=None, shared_name=None, name='padding_fifo_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `PaddingFIFOQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `PaddingFIFOQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `dtypes`, and whose shapes are described by the `shapes`\n",
      "     |      argument.\n",
      "     |      \n",
      "     |      The `shapes` argument must be specified; each component of a queue\n",
      "     |      element must have the respective shape.  Shapes of fixed\n",
      "     |      rank but variable size are allowed by setting any shape dimension to None.\n",
      "     |      In this case, the inputs' shape may vary along the given dimension, and\n",
      "     |      `dequeue_many` will pad the given dimension with zeros up to the maximum\n",
      "     |      shape of all elements in the given batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: A list of `TensorShape` objects, with the same length as\n",
      "     |          `dtypes`.  Any dimension in the `TensorShape` containing value\n",
      "     |          `None` is dynamic and allows values to be enqueued with\n",
      "     |           variable size in that dimension.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If shapes is not a list of shapes, or the lengths of dtypes\n",
      "     |          and shapes do not match, or if names is specified and the lengths of\n",
      "     |          dtypes and names do not match.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from QueueBase:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class PriorityQueue(QueueBase)\n",
      "     |  PriorityQueue(capacity, types, shapes=None, names=None, shared_name=None, name='priority_queue')\n",
      "     |  \n",
      "     |  A queue implementation that dequeues elements in prioritized order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PriorityQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, types, shapes=None, names=None, shared_name=None, name='priority_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `PriorityQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `PriorityQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `types`, and whose shapes are optionally described\n",
      "     |      by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      Enqueues and Dequeues to the `PriorityQueue` must include an additional\n",
      "     |      tuple entry at the beginning: the `priority`.  The priority must be\n",
      "     |      an int64 scalar (for `enqueue`) or an int64 vector (for `enqueue_many`).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        types:  A list of `DType` objects. The length of `types` must equal\n",
      "     |          the number of tensors in each queue element, except the first priority\n",
      "     |          element.  The first tensor in each element is the priority,\n",
      "     |          which must be type int64.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects,\n",
      "     |          with the same length as `types`, or `None`.\n",
      "     |        names: (Optional.) A list of strings naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified, the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from QueueBase:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class QueueBase(builtins.object)\n",
      "     |  QueueBase(dtypes, shapes, names, queue_ref)\n",
      "     |  \n",
      "     |  Base class for queue implementations.\n",
      "     |  \n",
      "     |  A queue is a TensorFlow data structure that stores tensors across\n",
      "     |  multiple steps, and exposes operations that enqueue and dequeue\n",
      "     |  tensors.\n",
      "     |  \n",
      "     |  Each queue element is a tuple of one or more tensors, where each\n",
      "     |  tuple component has a static dtype, and may have a static shape. The\n",
      "     |  queue implementations support versions of enqueue and dequeue that\n",
      "     |  handle single elements, versions that support enqueuing and\n",
      "     |  dequeuing a batch of elements at once.\n",
      "     |  \n",
      "     |  See `tf.queue.FIFOQueue` and\n",
      "     |  `tf.queue.RandomShuffleQueue` for concrete\n",
      "     |  implementations of this class, and instructions on how to create\n",
      "     |  them.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtypes, shapes, names, queue_ref)\n",
      "     |      Constructs a queue object from a queue reference.\n",
      "     |      \n",
      "     |      The two optional lists, `shapes` and `names`, must be of the same length\n",
      "     |      as `dtypes` if provided.  The values at a given index `i` indicate the\n",
      "     |      shape and name to use for the corresponding queue component in `dtypes`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtypes:  A list of types.  The length of dtypes must equal the number\n",
      "     |          of tensors in each element.\n",
      "     |        shapes: Constraints on the shapes of tensors in an element:\n",
      "     |          A list of shape tuples or None. This list is the same length\n",
      "     |          as dtypes.  If the shape of any tensors in the element are constrained,\n",
      "     |          all must be; shapes can be None if the shapes should not be constrained.\n",
      "     |        names: Optional list of names.  If provided, the `enqueue()` and\n",
      "     |          `dequeue()` methods will use dictionaries with these names as keys.\n",
      "     |          Must be None or a list or tuple of the same length as `dtypes`.\n",
      "     |        queue_ref: The queue reference, i.e. the output of the queue op.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If one of the arguments is invalid.\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor, tensorflow.python.types.internal.NativeObject, tensorflow.python.types.internal.RaggedTensor)\n",
      "     |  RaggedTensor(values, row_partition, internal=False)\n",
      "     |  \n",
      "     |  Represents a ragged tensor.\n",
      "     |  \n",
      "     |  A `RaggedTensor` is a tensor with one or more *ragged dimensions*, which are\n",
      "     |  dimensions whose slices may have different lengths.  For example, the inner\n",
      "     |  (column) dimension of `rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is ragged,\n",
      "     |  since the column slices (`rt[0, :]`, ..., `rt[4, :]`) have different lengths.\n",
      "     |  Dimensions whose slices all have the same length are called *uniform\n",
      "     |  dimensions*.  The outermost dimension of a `RaggedTensor` is always uniform,\n",
      "     |  since it consists of a single slice (and so there is no possibility for\n",
      "     |  differing slice lengths).\n",
      "     |  \n",
      "     |  The total number of dimensions in a `RaggedTensor` is called its *rank*,\n",
      "     |  and the number of ragged dimensions in a `RaggedTensor` is called its\n",
      "     |  *ragged-rank*.  A `RaggedTensor`'s ragged-rank is fixed at graph creation\n",
      "     |  time: it can't depend on the runtime values of `Tensor`s, and can't vary\n",
      "     |  dynamically for different session runs.\n",
      "     |  \n",
      "     |  Note that the `__init__` constructor is private. Please use one of the\n",
      "     |  following methods to construct a `RaggedTensor`:\n",
      "     |  \n",
      "     |  * `tf.RaggedTensor.from_row_lengths`\n",
      "     |  * `tf.RaggedTensor.from_value_rowids`\n",
      "     |  * `tf.RaggedTensor.from_row_splits`\n",
      "     |  * `tf.RaggedTensor.from_row_starts`\n",
      "     |  * `tf.RaggedTensor.from_row_limits`\n",
      "     |  * `tf.RaggedTensor.from_nested_row_splits`\n",
      "     |  * `tf.RaggedTensor.from_nested_row_lengths`\n",
      "     |  * `tf.RaggedTensor.from_nested_value_rowids`\n",
      "     |  \n",
      "     |  ### Potentially Ragged Tensors\n",
      "     |  \n",
      "     |  Many ops support both `Tensor`s and `RaggedTensor`s\n",
      "     |  (see [tf.ragged](https://www.tensorflow.org/api_docs/python/tf/ragged) for a\n",
      "     |  full listing). The term \"potentially ragged tensor\" may be used to refer to a\n",
      "     |  tensor that might be either a `Tensor` or a `RaggedTensor`.  The ragged-rank\n",
      "     |  of a `Tensor` is zero.\n",
      "     |  \n",
      "     |  ### Documenting RaggedTensor Shapes\n",
      "     |  \n",
      "     |  When documenting the shape of a RaggedTensor, ragged dimensions can be\n",
      "     |  indicated by enclosing them in parentheses.  For example, the shape of\n",
      "     |  a 3-D `RaggedTensor` that stores the fixed-size word embedding for each\n",
      "     |  word in a sentence, for each sentence in a batch, could be written as\n",
      "     |  `[num_sentences, (num_words), embedding_size]`.  The parentheses around\n",
      "     |  `(num_words)` indicate that dimension is ragged, and that the length\n",
      "     |  of each element list in that dimension may vary for each item.\n",
      "     |  \n",
      "     |  ### Component Tensors\n",
      "     |  \n",
      "     |  Internally, a `RaggedTensor` consists of a concatenated list of values that\n",
      "     |  are partitioned into variable-length rows.  In particular, each `RaggedTensor`\n",
      "     |  consists of:\n",
      "     |  \n",
      "     |    * A `values` tensor, which concatenates the variable-length rows into a\n",
      "     |      flattened list.  For example, the `values` tensor for\n",
      "     |      `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is `[3, 1, 4, 1, 5, 9, 2, 6]`.\n",
      "     |  \n",
      "     |    * A `row_splits` vector, which indicates how those flattened values are\n",
      "     |      divided into rows.  In particular, the values for row `rt[i]` are stored\n",
      "     |      in the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  >>> print(tf.RaggedTensor.from_row_splits(\n",
      "     |  ...       values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |  ...       row_splits=[0, 4, 4, 7, 8, 8]))\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  ### Alternative Row-Partitioning Schemes\n",
      "     |  \n",
      "     |  In addition to `row_splits`, ragged tensors provide support for five other\n",
      "     |  row-partitioning schemes:\n",
      "     |  \n",
      "     |    * `row_lengths`: a vector with shape `[nrows]`, which specifies the length\n",
      "     |      of each row.\n",
      "     |  \n",
      "     |    * `value_rowids` and `nrows`: `value_rowids` is a vector with shape\n",
      "     |      `[nvals]`, corresponding one-to-one with `values`, which specifies\n",
      "     |      each value's row index.  In particular, the row `rt[row]` consists of the\n",
      "     |      values `rt.values[j]` where `value_rowids[j]==row`.  `nrows` is an\n",
      "     |      integer scalar that specifies the number of rows in the\n",
      "     |      `RaggedTensor`. (`nrows` is used to indicate trailing empty rows.)\n",
      "     |  \n",
      "     |    * `row_starts`: a vector with shape `[nrows]`, which specifies the start\n",
      "     |      offset of each row.  Equivalent to `row_splits[:-1]`.\n",
      "     |  \n",
      "     |    * `row_limits`: a vector with shape `[nrows]`, which specifies the stop\n",
      "     |      offset of each row.  Equivalent to `row_splits[1:]`.\n",
      "     |  \n",
      "     |    * `uniform_row_length`: A scalar tensor, specifying the length of every\n",
      "     |      row.  This row-partitioning scheme may only be used if all rows have\n",
      "     |      the same length.\n",
      "     |  \n",
      "     |  Example: The following ragged tensors are equivalent, and all represent the\n",
      "     |  nested list `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]`.\n",
      "     |  \n",
      "     |  >>> values = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "     |  >>> RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_value_rowids(\n",
      "     |  ...     values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  >>> RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)\n",
      "     |  <tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>\n",
      "     |  \n",
      "     |  ### Multiple Ragged Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with multiple ragged dimensions can be defined by using\n",
      "     |  a nested `RaggedTensor` for the `values` tensor.  Each nested `RaggedTensor`\n",
      "     |  adds a single ragged dimension.\n",
      "     |  \n",
      "     |  >>> inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above\n",
      "     |  ...     values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])\n",
      "     |  >>> outer_rt = RaggedTensor.from_row_splits(\n",
      "     |  ...     values=inner_rt, row_splits=[0, 3, 3, 5])\n",
      "     |  >>> print(outer_rt.to_list())\n",
      "     |  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]\n",
      "     |  >>> print(outer_rt.ragged_rank)\n",
      "     |  2\n",
      "     |  \n",
      "     |  The factory function `RaggedTensor.from_nested_row_splits` may be used to\n",
      "     |  construct a `RaggedTensor` with multiple ragged dimensions directly, by\n",
      "     |  providing a list of `row_splits` tensors:\n",
      "     |  \n",
      "     |  >>> RaggedTensor.from_nested_row_splits(\n",
      "     |  ...     flat_values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |  ...     nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()\n",
      "     |  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]\n",
      "     |  \n",
      "     |  ### Uniform Inner Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with uniform inner dimensions can be defined\n",
      "     |  by using a multidimensional `Tensor` for `values`.\n",
      "     |  \n",
      "     |  >>> rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),\n",
      "     |  ...                                   row_splits=[0, 2, 5])\n",
      "     |  >>> print(rt.to_list())\n",
      "     |  [[[1, 1, 1], [1, 1, 1]],\n",
      "     |   [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]\n",
      "     |  >>> print(rt.shape)\n",
      "     |  (2, None, 3)\n",
      "     |  \n",
      "     |  ### Uniform Outer Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with uniform outer dimensions can be defined by using\n",
      "     |  one or more `RaggedTensor` with a `uniform_row_length` row-partitioning\n",
      "     |  tensor.  For example, a `RaggedTensor` with shape `[2, 2, None]` can be\n",
      "     |  constructed with this method from a `RaggedTensor` values with shape\n",
      "     |  `[4, None]`:\n",
      "     |  \n",
      "     |  >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |  >>> print(values.shape)\n",
      "     |  (4, None)\n",
      "     |  >>> rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |  >>> print(rt6)\n",
      "     |  <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |  >>> print(rt6.shape)\n",
      "     |  (2, 2, None)\n",
      "     |  \n",
      "     |  Note that `rt6` only contains one ragged dimension (the innermost\n",
      "     |  dimension). In contrast, if `from_row_splits` is used to construct a similar\n",
      "     |  `RaggedTensor`, then that `RaggedTensor` will have two ragged dimensions:\n",
      "     |  \n",
      "     |  >>> rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])\n",
      "     |  >>> print(rt7.shape)\n",
      "     |  (2, None, None)\n",
      "     |  \n",
      "     |  Uniform and ragged outer dimensions may be interleaved, meaning that a\n",
      "     |  tensor with any combination of ragged and uniform dimensions may be created.\n",
      "     |  For example, a RaggedTensor `t4` with shape `[3, None, 4, 8, None, 2]` could\n",
      "     |  be constructed as follows:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]\n",
      "     |  t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]\n",
      "     |  t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]\n",
      "     |  t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]\n",
      "     |  t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RaggedTensor\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.types.internal.RaggedTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = ragged_abs(self, name=None)\n",
      "     |      Computes the absolute value of a ragged tensor.\n",
      "     |      \n",
      "     |      Given a ragged tensor of integer or floating-point values, this operation\n",
      "     |      returns a ragged tensor of the same type, where each element contains the\n",
      "     |      absolute value of the corresponding element in the input.\n",
      "     |      \n",
      "     |      Given a ragged tensor `x` of complex numbers, this operation returns a tensor\n",
      "     |      of type `float32` or `float64` that is the absolute value of each element in\n",
      "     |      `x`. For a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
      "     |      \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # real number\n",
      "     |      >>> x = tf.ragged.constant([[-2.2, 3.2], [-4.2]])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.RaggedTensor [[2.2, 3.2], [4.2]]>\n",
      "     |      \n",
      "     |      >>> # complex number\n",
      "     |      >>> x = tf.ragged.constant([[-2.2 + 4.7j], [-3.2 + 5.7j], [-4.2 + 6.7j]])\n",
      "     |      >>> tf.abs(x)\n",
      "     |      <tf.RaggedTensor [[5.189412298131649],\n",
      "     |       [6.536818798161687],\n",
      "     |       [7.907591289387685]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` of the same size and type as `x`, with absolute values.\n",
      "     |        Note, for `complex64` or `complex128` input, the returned `RaggedTensor`\n",
      "     |        will be of type `float32` or `float64`, respectively.\n",
      "     |  \n",
      "     |  __add__ = add(x, y, name=None)\n",
      "     |      Returns x + y element-wise.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Add a scalar and a list:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `+` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x + y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Add a tensor and a list of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**7 + 1, 2**7 + 2]\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "     |      \n",
      "     |      When adding two input values of different shapes, `Add` follows NumPy\n",
      "     |      broadcasting rules. The two input array shapes are compared element-wise.\n",
      "     |      Starting with the trailing dimensions, the two dimensions either have to be\n",
      "     |      equal or one of them needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [2, 2, 3, 3]\n",
      "     |      \n",
      "     |      Another example with two arrays of different dimension.\n",
      "     |      \n",
      "     |      >>> x = np.ones([1, 2, 1, 4])\n",
      "     |      >>> y = np.ones([3, 4])\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [1, 2, 3, 4]\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "     |          float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "     |          int32, int64, complex64, complex128, string.\n",
      "     |        y: A `tf.Tensor`. Must have the same type as x.\n",
      "     |        name: A name for the operation (optional)\n",
      "     |  \n",
      "     |  __and__ = ragged_and(self, y, name=None)\n",
      "     |      Returns the truth value of elementwise `x & y`.\n",
      "     |      \n",
      "     |      Logical AND function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `y` can be:\n",
      "     |      \n",
      "     |        - A single Python boolean, where the result will be calculated by applying\n",
      "     |          logical AND with the single element to each element in `x`.\n",
      "     |        - A `tf.Tensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |        - A `tf.RaggedTensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # `y` is a Python boolean\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = True\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.logical_and(x, y)  # Equivalent of x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> y & x\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.reduce_all(x & y)  # Reduce to a scalar bool Tensor.\n",
      "     |      <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True, False]])\n",
      "     |      >>> y = tf.constant([[True, False], [False, True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False, False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.constant([[True], [False]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.ragged.constant([[False, True], [True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[False, False], [True]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[[True, True, False]], [[]], [[True, False]]])\n",
      "     |      >>> y = tf.ragged.constant([[[True]], [[True]], [[False]]], ragged_rank=1)\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[[True, True, False]], [[]], [[False, False]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        y: A Python boolean or a `tf.Tensor` or `tf.RaggedTensor` of dtype\n",
      "     |          `tf.bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `x` and `y`\n",
      "     |        broadcast to.\n",
      "     |  \n",
      "     |  __bool__ = ragged_bool(self)\n",
      "     |      Raises TypeError when a RaggedTensor is used as a Python bool.\n",
      "     |      \n",
      "     |      To prevent RaggedTensor from being used as a bool, this function always raise\n",
      "     |      TypeError when being called.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> result = True if x else False  # Evaluate x as a bool value.\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1]])\n",
      "     |      >>> r = (x == 1)  # tf.RaggedTensor [[True]]\n",
      "     |      >>> if r:  # Evaluate r as a bool value.\n",
      "     |      ...   pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |  \n",
      "     |  __div__ = div(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __eq__ = ragged_eq(self, other)\n",
      "     |      Returns result of elementwise `==` or False if not broadcast-compatible.\n",
      "     |      \n",
      "     |      Compares two ragged tensors elemewise for equality if they are\n",
      "     |      broadcast-compatible; or returns False if they are not\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).\n",
      "     |      \n",
      "     |      Note that this behavior differs from `tf.math.equal`, which raises an\n",
      "     |      exception if the two ragged tensors are not broadcast-compatible.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> rt1 == rt1\n",
      "     |      <tf.RaggedTensor [[True, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt2 = tf.ragged.constant([[1, 2], [4]])\n",
      "     |      >>> rt1 == rt2\n",
      "     |      <tf.RaggedTensor [[True, True], [False]]>\n",
      "     |      \n",
      "     |      >>> rt3 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> # rt1 and rt3 are not broadcast-compatible.\n",
      "     |      >>> rt1 == rt3\n",
      "     |      False\n",
      "     |      \n",
      "     |      >>> # You can also compare a `tf.RaggedTensor` to a `tf.Tensor`.\n",
      "     |      >>> t = tf.constant([[1, 2], [3, 4]])\n",
      "     |      >>> rt1 == t\n",
      "     |      False\n",
      "     |      >>> t == rt1\n",
      "     |      False\n",
      "     |      >>> rt4 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> rt4 == t\n",
      "     |      <tf.RaggedTensor [[True, True], [True, True]]>\n",
      "     |      >>> t == rt4\n",
      "     |      <tf.RaggedTensor [[True, True], [True, True]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: The right-hand side of the `==` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The ragged tensor result of the elementwise `==` operation, or `False` if\n",
      "     |        the arguments are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __floordiv__ = floordiv(x, y, name=None)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __ge__ = ragged_ge(self, other)\n",
      "     |      Elementwise `>=` comparison of two convertible-to-ragged-tensor values.\n",
      "     |      \n",
      "     |      Computes the elemewise `>=` comparison of two values that are convertible to\n",
      "     |      ragged tenors, with [broadcasting]\n",
      "     |      (http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) support.\n",
      "     |      Raises an exception if two values are not broadcast-compatible.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> rt1 >= rt1\n",
      "     |      <tf.RaggedTensor [[True, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt2 = tf.ragged.constant([[2, 1], [3]])\n",
      "     |      >>> rt1 >= rt2\n",
      "     |      <tf.RaggedTensor [[False, True], [True]]>\n",
      "     |      \n",
      "     |      >>> rt3 = tf.ragged.constant([[1, 2], [3, 4]])\n",
      "     |      >>> # rt1 and rt3 are not broadcast-compatible.\n",
      "     |      >>> rt1 >= rt3\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      InvalidArgumentError: ...\n",
      "     |      \n",
      "     |      >>> # You can also compare a `tf.RaggedTensor` to a `tf.Tensor`.\n",
      "     |      >>> rt4 = tf.ragged.constant([[1, 2],[3, 4]])\n",
      "     |      >>> t1 = tf.constant([[2, 1], [4, 3]])\n",
      "     |      >>> rt4 >= t1\n",
      "     |      <tf.RaggedTensor [[False, True],\n",
      "     |       [False, True]]>\n",
      "     |      >>> t1 >= rt4\n",
      "     |      <tf.RaggedTensor [[True, False],\n",
      "     |       [True, False]]>\n",
      "     |      \n",
      "     |      >>> # Compares a `tf.RaggedTensor` to a `tf.Tensor` with broadcasting.\n",
      "     |      >>> t2 = tf.constant([[2]])\n",
      "     |      >>> rt4 >= t2\n",
      "     |      <tf.RaggedTensor [[False, True],\n",
      "     |       [True, True]]>\n",
      "     |      >>> t2 >= rt4\n",
      "     |      <tf.RaggedTensor [[True, True],\n",
      "     |       [False, False]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: The right-hand side of the `>=` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `self` and\n",
      "     |        `other` broadcast to.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `self` and `other` are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __getitem__ = ragged_tensor_getitem(rt_input, key)\n",
      "     |      Returns the specified piece of this RaggedTensor.\n",
      "     |      \n",
      "     |      Supports multidimensional indexing and slicing, with one restriction:\n",
      "     |      indexing into a ragged inner dimension is not allowed.  This case is\n",
      "     |      problematic because the indicated value may exist in some rows but not\n",
      "     |      others.  In such cases, it's not obvious whether we should (1) report an\n",
      "     |      IndexError; (2) use a default value; or (3) skip that value and return a\n",
      "     |      tensor with fewer rows than we started with.  Following the guiding\n",
      "     |      principles of Python (\"In the face of ambiguity, refuse the temptation to\n",
      "     |      guess\"), we simply disallow this operation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rt_input: The RaggedTensor to slice.\n",
      "     |        key: Indicates which piece of the RaggedTensor to return, using standard\n",
      "     |          Python semantics (e.g., negative values index from the end).  `key`\n",
      "     |          may have any of the following types:\n",
      "     |      \n",
      "     |          * `int` constant\n",
      "     |          * Scalar integer `Tensor`\n",
      "     |          * `slice` containing integer constants and/or scalar integer\n",
      "     |            `Tensor`s\n",
      "     |          * `Ellipsis`\n",
      "     |          * `tf.newaxis`\n",
      "     |          * `tuple` containing any of the above (for multidimensional indexing)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `RaggedTensor` object.  Values that include at least one\n",
      "     |        ragged dimension are returned as `RaggedTensor`.  Values that include no\n",
      "     |        ragged dimensions are returned as `Tensor`.  See above for examples of\n",
      "     |        expressions that return `Tensor`s vs `RaggedTensor`s.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `key` is out of bounds.\n",
      "     |        ValueError: If `key` is not supported.\n",
      "     |        TypeError: If the indices in `key` have an unsupported type.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> # A 2-D ragged tensor with 1 ragged dimension.\n",
      "     |      >>> rt = tf.ragged.constant([['a', 'b', 'c'], ['d', 'e'], ['f'], ['g']])\n",
      "     |      >>> rt[0].numpy()                 # First row (1-D `Tensor`)\n",
      "     |      array([b'a', b'b', b'c'], dtype=object)\n",
      "     |      >>> rt[:3].to_list()              # First three rows (2-D RaggedTensor)\n",
      "     |      [[b'a', b'b', b'c'], [b'd', b'e'], [b'f']]\n",
      "     |      >>> rt[3, 0].numpy()              # 1st element of 4th row (scalar)\n",
      "     |      b'g'\n",
      "     |      \n",
      "     |      >>> # A 3-D ragged tensor with 2 ragged dimensions.\n",
      "     |      >>> rt = tf.ragged.constant([[[1, 2, 3], [4]],\n",
      "     |      ...                          [[5], [], [6]],\n",
      "     |      ...                          [[7]],\n",
      "     |      ...                          [[8, 9], [10]]])\n",
      "     |      >>> rt[1].to_list()               # Second row (2-D RaggedTensor)\n",
      "     |      [[5], [], [6]]\n",
      "     |      >>> rt[3, 0].numpy()              # First element of fourth row (1-D Tensor)\n",
      "     |      array([8, 9], dtype=int32)\n",
      "     |      >>> rt[:, 1:3].to_list()          # Items 1-3 of each row (3-D RaggedTensor)\n",
      "     |      [[[4]], [[], [6]], [], [[10]]]\n",
      "     |      >>> rt[:, -1:].to_list()          # Last item of each row (3-D RaggedTensor)\n",
      "     |      [[[4]], [[6]], [[7]], [[10]]]\n",
      "     |  \n",
      "     |  __gt__ = greater(x: typing.Annotated[_any, ~TV_Greater_T], y: typing.Annotated[_any, ~TV_Greater_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__ = ragged_hash(self)\n",
      "     |      The operation invoked by the `RaggedTensor.__hash__` operator.\n",
      "     |  \n",
      "     |  __init__(self, values, row_partition, internal=False)\n",
      "     |      Creates a `RaggedTensor` with a specified partitioning for `values`.\n",
      "     |      \n",
      "     |      This constructor is private -- please use one of the following ops to\n",
      "     |      build `RaggedTensor`s:\n",
      "     |      \n",
      "     |        * `tf.RaggedTensor.from_row_lengths`\n",
      "     |        * `tf.RaggedTensor.from_value_rowids`\n",
      "     |        * `tf.RaggedTensor.from_row_splits`\n",
      "     |        * `tf.RaggedTensor.from_row_starts`\n",
      "     |        * `tf.RaggedTensor.from_row_limits`\n",
      "     |        * `tf.RaggedTensor.from_nested_row_splits`\n",
      "     |        * `tf.RaggedTensor.from_nested_row_lengths`\n",
      "     |        * `tf.RaggedTensor.from_nested_value_rowids`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor of any dtype and shape `[nvals, ...]`.\n",
      "     |        row_partition: A `RowPartition` object, representing the arrangement of\n",
      "     |          the lists at the top level.\n",
      "     |        internal: True if the constructor is being called by one of the factory\n",
      "     |          methods.  If false, an exception will be raised.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If internal = False. Note that this method is intended only\n",
      "     |                   for internal use.\n",
      "     |        TypeError: If values is not a `RaggedTensor` or `Tensor`, or\n",
      "     |                   row_partition is not a `RowPartition`.\n",
      "     |  \n",
      "     |  __invert__ = logical_not(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of `NOT x` element-wise.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> tf.math.logical_not(tf.constant([True, False]))\n",
      "     |      <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`. A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __le__ = less_equal(x: typing.Annotated[_any, ~TV_LessEqual_T], y: typing.Annotated[_any, ~TV_LessEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __lt__ = less(x: typing.Annotated[_any, ~TV_Less_T], y: typing.Annotated[_any, ~TV_Less_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __mod__ = floor_mod(x: typing.Annotated[_any, ~TV_FloorMod_T], y: typing.Annotated[_any, ~TV_FloorMod_T], name=None) -> typing.Annotated[_any, ~TV_FloorMod_T]\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __mul__ = multiply(x, y, name=None)\n",
      "     |      Returns an element-wise x * y.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "     |      >>> tf.math.multiply(x, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "     |      \n",
      "     |      Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "     |      pass in non-`Tensor` arguments:\n",
      "     |      \n",
      "     |      >>> tf.math.multiply(7,6)\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "     |      \n",
      "     |      If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "     |      compatible shape. (More about broadcasting\n",
      "     |      [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ones([1, 2]);\n",
      "     |      >>> y = tf.ones([2, 1]);\n",
      "     |      >>> x * y  # Taking advantage of operator overriding\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "     |      array([[1., 1.],\n",
      "     |           [1., 1.]], dtype=float32)>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "     |          `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "     |          `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      \n",
      "     |      A `Tensor`.  Has the same type as `x`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |      \n",
      "     |       * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "     |  \n",
      "     |  __ne__ = tensor_not_equals(self, other)\n",
      "     |      The operation invoked by the `Tensor.__ne__` operator.\n",
      "     |      \n",
      "     |      Compares two tensors element-wise for inequality if they are\n",
      "     |      broadcast-compatible; or returns True if they are not broadcast-compatible.\n",
      "     |      (Note that this behavior differs from `tf.math.not_equal`, which raises an\n",
      "     |      exception if the two tensors are not broadcast-compatible.)\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__ne__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The left-hand side of the `!=` operator.\n",
      "     |        other: The right-hand side of the `!=` operator.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The result of the elementwise `!=` operation, or `True` if the arguments\n",
      "     |        are not broadcast-compatible.\n",
      "     |  \n",
      "     |  __neg__ = neg(x: typing.Annotated[_any, ~TV_Neg_T], name=None) -> typing.Annotated[_any, ~TV_Neg_T]\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __nonzero__ = ragged_bool(self)\n",
      "     |      Raises TypeError when a RaggedTensor is used as a Python bool.\n",
      "     |      \n",
      "     |      To prevent RaggedTensor from being used as a bool, this function always raise\n",
      "     |      TypeError when being called.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1, 2], [3]])\n",
      "     |      >>> result = True if x else False  # Evaluate x as a bool value.\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |      \n",
      "     |      >>> x = tf.ragged.constant([[1]])\n",
      "     |      >>> r = (x == 1)  # tf.RaggedTensor [[True]]\n",
      "     |      >>> if r:  # Evaluate r as a bool value.\n",
      "     |      ...   pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      TypeError: RaggedTensor may not be used as a boolean.\n",
      "     |  \n",
      "     |  __or__ = logical_or(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], y: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      Logical OR function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`.\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical OR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical OR of the two input tensors.\n",
      "     |      \n",
      "     |      You can also use the `|` operator instead.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |        >>> a = tf.constant([True])\n",
      "     |        >>> b = tf.constant([False])\n",
      "     |        >>> tf.math.logical_or(a, b)\n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |        >>> a | b\n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |        >>> c = tf.constant([False])\n",
      "     |        >>> x = tf.constant([False, True, True, False])\n",
      "     |        >>> tf.math.logical_or(c, x)\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |        >>> c | x\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |      \n",
      "     |        >>> y = tf.constant([False, False, True, True])\n",
      "     |        >>> z = tf.constant([False, True, False, True])\n",
      "     |        >>> tf.math.logical_or(y, z)\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |        >>> y | z\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |      \n",
      "     |        This op also supports broadcasting\n",
      "     |      \n",
      "     |        >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "     |        <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "     |        array([[ True,  True],\n",
      "     |             [ True, False]])>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` of type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __pow__ = pow(x, y, name=None)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __radd__ = add(x, y, name=None)\n",
      "     |      Returns x + y element-wise.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Add a scalar and a list:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `+` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x + y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "     |      dtype=int32)>\n",
      "     |      \n",
      "     |      Add a tensor and a list of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**7 + 1, 2**7 + 2]\n",
      "     |      >>> tf.add(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "     |      \n",
      "     |      When adding two input values of different shapes, `Add` follows NumPy\n",
      "     |      broadcasting rules. The two input array shapes are compared element-wise.\n",
      "     |      Starting with the trailing dimensions, the two dimensions either have to be\n",
      "     |      equal or one of them needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [2, 2, 3, 3]\n",
      "     |      \n",
      "     |      Another example with two arrays of different dimension.\n",
      "     |      \n",
      "     |      >>> x = np.ones([1, 2, 1, 4])\n",
      "     |      >>> y = np.ones([3, 4])\n",
      "     |      >>> tf.add(x, y).shape.as_list()\n",
      "     |      [1, 2, 3, 4]\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "     |          float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "     |          int32, int64, complex64, complex128, string.\n",
      "     |        y: A `tf.Tensor`. Must have the same type as x.\n",
      "     |        name: A name for the operation (optional)\n",
      "     |  \n",
      "     |  __rand__ = ragged_and(self, y, name=None)\n",
      "     |      Returns the truth value of elementwise `x & y`.\n",
      "     |      \n",
      "     |      Logical AND function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `y` can be:\n",
      "     |      \n",
      "     |        - A single Python boolean, where the result will be calculated by applying\n",
      "     |          logical AND with the single element to each element in `x`.\n",
      "     |        - A `tf.Tensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |        - A `tf.RaggedTensor` object of dtype `tf.bool` of the same shape or\n",
      "     |          [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |          shape. In this case, the result will be the element-wise logical AND of\n",
      "     |          `x` and `y`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> # `y` is a Python boolean\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = True\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.logical_and(x, y)  # Equivalent of x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> y & x\n",
      "     |      <tf.RaggedTensor [[True, False], [True]]>\n",
      "     |      >>> tf.math.reduce_all(x & y)  # Reduce to a scalar bool Tensor.\n",
      "     |      <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True, False]])\n",
      "     |      >>> y = tf.constant([[True, False], [False, True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False, False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a tf.Tensor of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.constant([[True], [False]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[True, False], [False]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of the same shape.\n",
      "     |      >>> x = tf.ragged.constant([[True, False], [True]])\n",
      "     |      >>> y = tf.ragged.constant([[False, True], [True]])\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[False, False], [True]]>\n",
      "     |      \n",
      "     |      >>> # `y` is a `tf.RaggedTensor` of a broadcast-compatible shape.\n",
      "     |      >>> x = tf.ragged.constant([[[True, True, False]], [[]], [[True, False]]])\n",
      "     |      >>> y = tf.ragged.constant([[[True]], [[True]], [[False]]], ragged_rank=1)\n",
      "     |      >>> x & y\n",
      "     |      <tf.RaggedTensor [[[True, True, False]], [[]], [[False, False]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        y: A Python boolean or a `tf.Tensor` or `tf.RaggedTensor` of dtype\n",
      "     |          `tf.bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.RaggedTensor` of dtype `tf.bool` with the shape that `x` and `y`\n",
      "     |        broadcast to.\n",
      "     |  \n",
      "     |  __rdiv__ = div(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      @compatibility(TF2)\n",
      "     |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "     |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "     |      semantics.\n",
      "     |      @end_compatibility\n",
      "     |      \n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = floordiv(x, y, name=None)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      Mathematically, this is equivalent to floor(x / y). For example:\n",
      "     |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "     |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "     |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "     |      \n",
      "     |      Note: `x` and `y` must have the same type, and the result will have the same\n",
      "     |      type as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded toward -infinity.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __rmod__ = floor_mod(x: typing.Annotated[_any, ~TV_FloorMod_T], y: typing.Annotated[_any, ~TV_FloorMod_T], name=None) -> typing.Annotated[_any, ~TV_FloorMod_T]\n",
      "     |      Returns element-wise remainder of division.\n",
      "     |      \n",
      "     |      This follows Python semantics in that the\n",
      "     |      result here is consistent with a flooring divide. E.g.\n",
      "     |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rmul__ = multiply(x, y, name=None)\n",
      "     |      Returns an element-wise x * y.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "     |      >>> tf.math.multiply(x, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "     |      \n",
      "     |      Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "     |      pass in non-`Tensor` arguments:\n",
      "     |      \n",
      "     |      >>> tf.math.multiply(7,6)\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "     |      \n",
      "     |      If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "     |      compatible shape. (More about broadcasting\n",
      "     |      [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      >>> x = tf.ones([1, 2]);\n",
      "     |      >>> y = tf.ones([2, 1]);\n",
      "     |      >>> x * y  # Taking advantage of operator overriding\n",
      "     |      <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "     |      array([[1., 1.],\n",
      "     |           [1., 1.]], dtype=float32)>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "     |          `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "     |          `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |      \n",
      "     |      A `Tensor`.  Has the same type as `x`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |      \n",
      "     |       * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "     |  \n",
      "     |  __ror__ = logical_or(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], y: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      Logical OR function.\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`.\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical OR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical OR of the two input tensors.\n",
      "     |      \n",
      "     |      You can also use the `|` operator instead.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |        >>> a = tf.constant([True])\n",
      "     |        >>> b = tf.constant([False])\n",
      "     |        >>> tf.math.logical_or(a, b)\n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |        >>> a | b\n",
      "     |        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |        >>> c = tf.constant([False])\n",
      "     |        >>> x = tf.constant([False, True, True, False])\n",
      "     |        >>> tf.math.logical_or(c, x)\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |        >>> c | x\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "     |      \n",
      "     |        >>> y = tf.constant([False, False, True, True])\n",
      "     |        >>> z = tf.constant([False, True, False, True])\n",
      "     |        >>> tf.math.logical_or(y, z)\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |        >>> y | z\n",
      "     |        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "     |      \n",
      "     |        This op also supports broadcasting\n",
      "     |      \n",
      "     |        >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "     |        <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "     |        array([[ True,  True],\n",
      "     |             [ True, False]])>\n",
      "     |      \n",
      "     |      The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` of type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rpow__ = pow(x, y, name=None)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __rsub__ = subtract(x, y, name=None)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x - y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      array([[[0., 0., 0.],\n",
      "     |              [0., 0., 0.],\n",
      "     |              [0., 0., 0.]],\n",
      "     |             [[0., 0., 0.],\n",
      "     |              [0., 0., 0.],\n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rtruediv__ = truediv(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __rxor__ = logical_xor(x, y, name='LogicalXor')\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical XOR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical XOR of the two input tensors.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([True])\n",
      "     |      >>> b = tf.constant([False])\n",
      "     |      >>> tf.math.logical_xor(a, b)\n",
      "     |      <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |      >>> c = tf.constant([True])\n",
      "     |      >>> x = tf.constant([False, True, True, False])\n",
      "     |      >>> tf.math.logical_xor(c, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>\n",
      "     |      \n",
      "     |      >>> y = tf.constant([False, False, True, True])\n",
      "     |      >>> z = tf.constant([False, True, False, True])\n",
      "     |      >>> tf.math.logical_xor(y, z)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  __sub__ = subtract(x, y, name=None)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Both input and output have a range `(-inf, inf)`.\n",
      "     |      \n",
      "     |      Example usages below.\n",
      "     |      \n",
      "     |      Subtract operation between an array and a scalar:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = 1\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      Note that binary `-` operator can be used instead:\n",
      "     |      \n",
      "     |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "     |      >>> y = tf.convert_to_tensor(1)\n",
      "     |      >>> x - y\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "     |      \n",
      "     |      Subtract operation between an array and a tensor of same shape:\n",
      "     |      \n",
      "     |      >>> x = [1, 2, 3, 4, 5]\n",
      "     |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "     |      >>> tf.subtract(y, x)\n",
      "     |      <tf.Tensor: shape=(5,), dtype=int32,\n",
      "     |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "     |      \n",
      "     |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "     |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "     |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "     |      conversion.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "     |      >>> y = [2**8 + 1, 2**8 + 2]\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "     |      \n",
      "     |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "     |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "     |      . The two input array shapes are compared element-wise. Starting with the\n",
      "     |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "     |      needs to be `1`.\n",
      "     |      \n",
      "     |      For example,\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "     |      array([[[0., 0., 0.],\n",
      "     |              [0., 0., 0.],\n",
      "     |              [0., 0., 0.]],\n",
      "     |             [[0., 0., 0.],\n",
      "     |              [0., 0., 0.],\n",
      "     |              [0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Example with inputs of different dimensions:\n",
      "     |      \n",
      "     |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "     |      >>> y = np.ones(6).reshape(1, 6)\n",
      "     |      >>> tf.subtract(x, y)\n",
      "     |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "     |      array([[[0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.]],\n",
      "     |             [[0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.],\n",
      "     |              [0., 0., 0., 0., 0., 0.]]])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __truediv__ = truediv(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __xor__ = logical_xor(x, y, name='LogicalXor')\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Requires that `x` and `y` have the same shape or have\n",
      "     |      [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      shapes. For example, `x` and `y` can be:\n",
      "     |      \n",
      "     |      - Two single elements of type `bool`\n",
      "     |      - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "     |        be calculated by applying logical XOR with the single element to each\n",
      "     |        element in the larger Tensor.\n",
      "     |      - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "     |        the result will be the element-wise logical XOR of the two input tensors.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      >>> a = tf.constant([True])\n",
      "     |      >>> b = tf.constant([False])\n",
      "     |      >>> tf.math.logical_xor(a, b)\n",
      "     |      <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "     |      \n",
      "     |      >>> c = tf.constant([True])\n",
      "     |      >>> x = tf.constant([False, True, True, False])\n",
      "     |      >>> tf.math.logical_xor(c, x)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>\n",
      "     |      \n",
      "     |      >>> y = tf.constant([False, False, True, True])\n",
      "     |      >>> z = tf.constant([False, True, False, True])\n",
      "     |      >>> tf.math.logical_xor(y, z)\n",
      "     |      <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `tf.Tensor` type bool.\n",
      "     |          y: A `tf.Tensor` of type bool.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  bounding_shape(self, axis=None, name=None, out_type=None)\n",
      "     |      Returns the tight bounding box shape for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        axis: An integer scalar or vector indicating which axes to return the\n",
      "     |          bounding box for.  If not specified, then the full bounding box is\n",
      "     |          returned.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |        out_type: `dtype` for the returned tensor.  Defaults to\n",
      "     |          `self.row_splits.dtype`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An integer `Tensor` (`dtype=self.row_splits.dtype`).  If `axis` is not\n",
      "     |        specified, then `output` is a vector with\n",
      "     |        `output.shape=[self.shape.ndims]`.  If `axis` is a scalar, then the\n",
      "     |        `output` is a scalar.  If `axis` is a vector, then `output` is a vector,\n",
      "     |        where `output[i]` is the bounding size for dimension `axis[i]`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])\n",
      "     |      >>> rt.bounding_shape().numpy()\n",
      "     |      array([5, 4])\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  get_shape(self) -> tensorflow.python.framework.tensor_shape.TensorShape\n",
      "     |      The statically known shape of this ragged tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the statically known shape of this ragged\n",
      "     |        tensor.  Ragged dimensions have a size of `None`.\n",
      "     |      \n",
      "     |      Alias for `shape` property.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[0], [1, 2]]).get_shape()\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant(\n",
      "     |      ...    [[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).get_shape()\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |  \n",
      "     |  merge_dims(self, outer_axis, inner_axis)\n",
      "     |      Merges outer_axis...inner_axis into a single dimension.\n",
      "     |      \n",
      "     |      Returns a copy of this RaggedTensor with the specified range of dimensions\n",
      "     |      flattened into a single dimension, with elements in row-major order.\n",
      "     |      \n",
      "     |      #### Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[1, 2], [3]], [[4, 5, 6]]])\n",
      "     |      >>> print(rt.merge_dims(0, 1))\n",
      "     |      <tf.RaggedTensor [[1, 2], [3], [4, 5, 6]]>\n",
      "     |      >>> print(rt.merge_dims(1, 2))\n",
      "     |      <tf.RaggedTensor [[1, 2, 3], [4, 5, 6]]>\n",
      "     |      >>> print(rt.merge_dims(0, 2))\n",
      "     |      tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n",
      "     |      \n",
      "     |      To mimic the behavior of `np.flatten` (which flattens all dimensions), use\n",
      "     |      `rt.merge_dims(0, -1).  To mimic the behavior of `tf.layers.Flatten` (which\n",
      "     |      flattens all dimensions except the outermost batch dimension), use\n",
      "     |      `rt.merge_dims(1, -1)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        outer_axis: `int`: The first dimension in the range of dimensions to\n",
      "     |          merge. May be negative if `self.shape.rank` is statically known.\n",
      "     |        inner_axis: `int`: The last dimension in the range of dimensions to merge.\n",
      "     |          May be negative if `self.shape.rank` is statically known.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A copy of this tensor, with the specified dimensions merged into a\n",
      "     |        single dimension.  The shape of the returned tensor will be\n",
      "     |        `self.shape[:outer_axis] + [N] + self.shape[inner_axis + 1:]`, where `N`\n",
      "     |        is the total number of slices in the merged dimensions.\n",
      "     |  \n",
      "     |  nested_row_lengths(self, name=None)\n",
      "     |      Returns a tuple containing the row_lengths for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_row_lengths()` is a tuple containing the `row_lengths` tensors\n",
      "     |      for all ragged dimensions in `rt`, ordered from outermost to innermost.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensors`.  The length of the tuple is equal to\n",
      "     |        `self.ragged_rank`.\n",
      "     |  \n",
      "     |  nested_value_rowids(self, name=None)\n",
      "     |      Returns a tuple containing the value_rowids for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_value_rowids` is a tuple containing the `value_rowids` tensors\n",
      "     |      for\n",
      "     |      all ragged dimensions in `rt`, ordered from outermost to innermost.  In\n",
      "     |      particular, `rt.nested_value_rowids = (rt.value_rowids(),) + value_ids`\n",
      "     |      where:\n",
      "     |      \n",
      "     |      * `value_ids = ()` if `rt.values` is a `Tensor`.\n",
      "     |      * `value_ids = rt.values.nested_value_rowids` otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensor`s.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])\n",
      "     |      >>> for i, ids in enumerate(rt.nested_value_rowids()):\n",
      "     |      ...   print('row ids for dimension %d: %s' % (i+1, ids.numpy()))\n",
      "     |      row ids for dimension 1: [0 0 0]\n",
      "     |      row ids for dimension 2: [0 0 0 2 2]\n",
      "     |      row ids for dimension 3: [0 0 0 0 2 2 2 3]\n",
      "     |  \n",
      "     |  nrows(self, out_type=None, name=None)\n",
      "     |      Returns the number of rows in this ragged tensor.\n",
      "     |      \n",
      "     |      I.e., the size of the outermost dimension of the tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        out_type: `dtype` for the returned tensor.  Defaults to\n",
      "     |          `self.row_splits.dtype`.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar `Tensor` with dtype `out_type`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.nrows())  # rt has 5 rows.\n",
      "     |      tf.Tensor(5, shape=(), dtype=int64)\n",
      "     |  \n",
      "     |  numpy(self)\n",
      "     |      Returns a numpy `array` with the values for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Requires that this `RaggedTensor` was constructed in eager execution mode.\n",
      "     |      \n",
      "     |      Ragged dimensions are encoded using numpy `arrays` with `dtype=object` and\n",
      "     |      `rank=1`, where each element is a single row.\n",
      "     |      \n",
      "     |      #### Examples\n",
      "     |      \n",
      "     |      In the following example, the value returned by `RaggedTensor.numpy()`\n",
      "     |      contains three numpy `array` objects: one for each row (with `rank=1` and\n",
      "     |      `dtype=int64`), and one to combine them (with `rank=1` and `dtype=object`):\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[1, 2, 3], [4, 5]], dtype=tf.int64).numpy()\n",
      "     |      array([array([1, 2, 3]), array([4, 5])], dtype=object)\n",
      "     |      \n",
      "     |      Uniform dimensions are encoded using multidimensional numpy `array`s.  In\n",
      "     |      the following example, the value returned by `RaggedTensor.numpy()` contains\n",
      "     |      a single numpy `array` object, with `rank=2` and `dtype=int64`:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.int64).numpy()\n",
      "     |      array([[1, 2, 3], [4, 5, 6]])\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy `array`.\n",
      "     |  \n",
      "     |  row_lengths(self, axis=1, name=None)\n",
      "     |      Returns the lengths of the rows in this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.row_lengths()[i]` indicates the number of values in the\n",
      "     |      `i`th row of `rt`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        axis: An integer constant indicating the axis whose row lengths should be\n",
      "     |          returned.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A potentially ragged integer Tensor with shape `self.shape[:axis]`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `axis` is out of bounds.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []])\n",
      "     |      >>> print(rt.row_lengths())  # lengths of rows in rt\n",
      "     |      tf.Tensor([2 0 2 1 0], shape=(5,), dtype=int64)\n",
      "     |      >>> print(rt.row_lengths(axis=2))  # lengths of axis=2 rows.\n",
      "     |      <tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]>\n",
      "     |  \n",
      "     |  row_limits(self, name=None)\n",
      "     |      Returns the limit indices for rows in this ragged tensor.\n",
      "     |      \n",
      "     |      These indices specify where the values for each row end in\n",
      "     |      `self.values`.  `rt.row_limits(self)` is equal to `rt.row_splits[:-1]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer Tensor with shape `[nrows]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.row_limits())  # indices of row limits in rt.values\n",
      "     |      tf.Tensor([4 4 7 8 8], shape=(5,), dtype=int64)\n",
      "     |  \n",
      "     |  row_starts(self, name=None)\n",
      "     |      Returns the start indices for rows in this ragged tensor.\n",
      "     |      \n",
      "     |      These indices specify where the values for each row begin in\n",
      "     |      `self.values`.  `rt.row_starts()` is equal to `rt.row_splits[:-1]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer Tensor with shape `[nrows]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.row_starts())  # indices of row starts in rt.values\n",
      "     |      tf.Tensor([0 4 4 7 8], shape=(5,), dtype=int64)\n",
      "     |  \n",
      "     |  to_list(self)\n",
      "     |      Returns a nested Python `list` with the values for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Requires that `rt` was constructed in eager execution mode.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A nested Python `list`.\n",
      "     |  \n",
      "     |  to_sparse(self, name=None)\n",
      "     |      Converts this `RaggedTensor` into a `tf.sparse.SparseTensor`.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3], [4], [], [5, 6]])\n",
      "     |      >>> print(rt.to_sparse())\n",
      "     |      SparseTensor(indices=tf.Tensor(\n",
      "     |                       [[0 0] [0 1] [0 2] [1 0] [3 0] [3 1]],\n",
      "     |                       shape=(6, 2), dtype=int64),\n",
      "     |                   values=tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32),\n",
      "     |                   dense_shape=tf.Tensor([4 3], shape=(2,), dtype=int64))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A SparseTensor with the same values as `self`.\n",
      "     |  \n",
      "     |  to_tensor(self, default_value=None, name=None, shape=None)\n",
      "     |      Converts this `RaggedTensor` into a `tf.Tensor`.\n",
      "     |      \n",
      "     |      If `shape` is specified, then the result is padded and/or truncated to\n",
      "     |      the specified shape.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]])\n",
      "     |      >>> print(rt.to_tensor())\n",
      "     |      tf.Tensor(\n",
      "     |          [[9 8 7] [0 0 0] [6 5 0] [4 0 0]], shape=(4, 3), dtype=int32)\n",
      "     |      >>> print(rt.to_tensor(shape=[5, 2]))\n",
      "     |      tf.Tensor(\n",
      "     |          [[9 8] [0 0] [6 5] [4 0] [0 0]], shape=(5, 2), dtype=int32)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        default_value: Value to set for indices not specified in `self`. Defaults\n",
      "     |          to zero.  `default_value` must be broadcastable to\n",
      "     |          `self.shape[self.ragged_rank + 1:]`.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        shape: The shape of the resulting dense tensor.  In particular,\n",
      "     |          `result.shape[i]` is `shape[i]` (if `shape[i]` is not None), or\n",
      "     |          `self.bounding_shape(i)` (otherwise).`shape.rank` must be `None` or\n",
      "     |          equal to `self.rank`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` with shape `ragged.bounding_shape(self)` and the\n",
      "     |        values specified by the non-empty values in `self`.  Empty values are\n",
      "     |        assigned `default_value`.\n",
      "     |  \n",
      "     |  value_rowids(self, name=None)\n",
      "     |      Returns the row indices for the `values` in this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.value_rowids()` corresponds one-to-one with the outermost dimension of\n",
      "     |      `rt.values`, and specifies the row containing each value.  In particular,\n",
      "     |      the row `rt[row]` consists of the values `rt.values[j]` where\n",
      "     |      `rt.value_rowids()[j] == row`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer `Tensor` with shape `self.values.shape[:1]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |      >>> print(rt.value_rowids())  # corresponds 1:1 with rt.values\n",
      "     |      tf.Tensor([0 0 0 0 2 2 2 3], shape=(8,), dtype=int64)\n",
      "     |  \n",
      "     |  with_flat_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `flat_values` replaced by `new_value`.\n",
      "     |      \n",
      "     |      Preserves cached row-partitioning tensors such as `self.cached_nrows` and\n",
      "     |      `self.cached_value_rowids` if they have values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: Potentially ragged tensor that should replace\n",
      "     |          `self.flat_values`.  Must have `rank > 0`, and must have the same number\n",
      "     |          of rows as `self.flat_values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.\n",
      "     |        `result.rank = self.ragged_rank + new_values.rank`.\n",
      "     |        `result.ragged_rank = self.ragged_rank + new_values.ragged_rank`.\n",
      "     |  \n",
      "     |  with_row_splits_dtype(self, dtype)\n",
      "     |      Returns a copy of this RaggedTensor with the given `row_splits` dtype.\n",
      "     |      \n",
      "     |      For RaggedTensors with multiple ragged dimensions, the `row_splits` for all\n",
      "     |      nested `RaggedTensor` objects are cast to the given dtype.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: The dtype for `row_splits`.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A copy of this RaggedTensor, with the `row_splits` cast to the given\n",
      "     |        type.\n",
      "     |  \n",
      "     |  with_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `values` replaced by `new_value`.\n",
      "     |      \n",
      "     |      Preserves cached row-partitioning tensors such as `self.cached_nrows` and\n",
      "     |      `self.cached_value_rowids` if they have values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: Potentially ragged tensor to use as the `values` for the\n",
      "     |          returned `RaggedTensor`.  Must have `rank > 0`, and must have the same\n",
      "     |          number of rows as `self.values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = 1 + new_values.rank`.\n",
      "     |        `result.ragged_rank = 1 + new_values.ragged_rank`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_nested_row_lengths(flat_values, nested_row_lengths, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `row_lengths` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for row_lengths in reversed(nested_row_lengths):\n",
      "     |        result = from_row_lengths(result, row_lengths)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_row_lengths: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `row_lengths` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_row_lengths` is empty).\n",
      "     |  \n",
      "     |  from_nested_row_splits(flat_values, nested_row_splits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `row_splits` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for row_splits in reversed(nested_row_splits):\n",
      "     |        result = from_row_splits(result, row_splits)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_row_splits: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `row_splits` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_row_splits` is empty).\n",
      "     |  \n",
      "     |  from_nested_value_rowids(flat_values, nested_value_rowids, nested_nrows=None, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `value_rowids` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):\n",
      "     |        result = from_value_rowids(result, rowids, nrows)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_value_rowids: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `value_rowids` for the `i`th ragged dimension.\n",
      "     |        nested_nrows: A list of integer scalars.  The `i`th scalar is used as the\n",
      "     |          `nrows` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_value_rowids` is empty).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `len(nested_values_rowids) != len(nested_nrows)`.\n",
      "     |  \n",
      "     |  from_row_lengths(values, row_lengths, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_lengths`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [[values.pop(0) for i in range(length)]\n",
      "     |                for length in row_lengths]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_lengths: A 1-D integer tensor with shape `[nrows]`.  Must be\n",
      "     |          nonnegative.  `sum(row_lengths)` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_lengths(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_lengths=[4, 0, 3, 1, 0]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_limits(values, row_limits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_limits`.\n",
      "     |      \n",
      "     |      Equivalent to: `from_row_splits(values, concat([0, row_limits]))`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_limits: A 1-D integer tensor with shape `[nrows]`.  Must be sorted in\n",
      "     |          ascending order.  If `nrows>0`, then `row_limits[-1]` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_limits(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_limits=[4, 4, 7, 8, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_splits(values, row_splits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_splits`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [values[row_splits[i]:row_splits[i + 1]]\n",
      "     |                for i in range(len(row_splits) - 1)]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_splits: A 1-D integer tensor with shape `[nrows+1]`.  Must not be\n",
      "     |          empty, and must be sorted in ascending order.  `row_splits[0]` must be\n",
      "     |          zero and `row_splits[-1]` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `row_splits` is an empty list.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_splits(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_splits=[0, 4, 4, 7, 8, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_row_starts(values, row_starts, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_starts`.\n",
      "     |      \n",
      "     |      Equivalent to: `from_row_splits(values, concat([row_starts, nvals]))`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_starts: A 1-D integer tensor with shape `[nrows]`.  Must be\n",
      "     |          nonnegative and sorted in ascending order.  If `nrows>0`, then\n",
      "     |          `row_starts[0]` must be zero.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_row_starts(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     row_starts=[0, 4, 4, 7, 8]))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  from_sparse(st_input, name=None, row_splits_dtype=tf.int64) from abc.ABCMeta\n",
      "     |      Converts a 2D `tf.sparse.SparseTensor` to a `RaggedTensor`.\n",
      "     |      \n",
      "     |      Each row of the `output` `RaggedTensor` will contain the explicit values\n",
      "     |      from the same row in `st_input`.  `st_input` must be ragged-right.  If not\n",
      "     |      it is not ragged-right, then an error will be generated.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      >>> indices = [[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]]\n",
      "     |      >>> st = tf.sparse.SparseTensor(indices=indices,\n",
      "     |      ...                             values=[1, 2, 3, 4, 5],\n",
      "     |      ...                             dense_shape=[4, 3])\n",
      "     |      >>> tf.RaggedTensor.from_sparse(st).to_list()\n",
      "     |      [[1, 2, 3], [4], [], [5]]\n",
      "     |      \n",
      "     |      Currently, only two-dimensional `SparseTensors` are supported.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        st_input: The sparse tensor to convert.  Must have rank 2.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        row_splits_dtype: `dtype` for the returned `RaggedTensor`'s `row_splits`\n",
      "     |          tensor.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` with the same values as `st_input`.\n",
      "     |        `output.ragged_rank = rank(st_input) - 1`.\n",
      "     |        `output.shape = [st_input.dense_shape[0], None]`.\n",
      "     |      Raises:\n",
      "     |        ValueError: If the number of dimensions in `st_input` is not known\n",
      "     |          statically, or is not two.\n",
      "     |  \n",
      "     |  from_tensor(tensor, lengths=None, padding=None, ragged_rank=1, name=None, row_splits_dtype=tf.int64) from abc.ABCMeta\n",
      "     |      Converts a `tf.Tensor` into a `RaggedTensor`.\n",
      "     |      \n",
      "     |      The set of absent/default values may be specified using a vector of lengths\n",
      "     |      or a padding value (but not both).  If `lengths` is specified, then the\n",
      "     |      output tensor will satisfy `output[row] = tensor[row][:lengths[row]]`. If\n",
      "     |      'lengths' is a list of lists or tuple of lists, those lists will be used\n",
      "     |      as nested row lengths. If `padding` is specified, then any row *suffix*\n",
      "     |      consisting entirely of `padding` will be excluded from the returned\n",
      "     |      `RaggedTensor`.  If neither `lengths` nor `padding` is specified, then the\n",
      "     |      returned `RaggedTensor` will have no absent/default values.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt)\n",
      "     |      <tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]>\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])\n",
      "     |      <tf.RaggedTensor [[5], [], [6, 0, 0]]>\n",
      "     |      \n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, padding=0)\n",
      "     |      <tf.RaggedTensor [[5, 7], [0, 3], [6]]>\n",
      "     |      \n",
      "     |      >>> dt = tf.constant([[[5, 0], [7, 0], [0, 0]],\n",
      "     |      ...                   [[0, 0], [3, 0], [0, 0]],\n",
      "     |      ...                   [[6, 0], [0, 0], [0, 0]]])\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))\n",
      "     |      <tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]>\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: The `Tensor` to convert.  Must have rank `ragged_rank + 1` or\n",
      "     |          higher.\n",
      "     |        lengths: An optional set of row lengths, specified using a 1-D integer\n",
      "     |          `Tensor` whose length is equal to `tensor.shape[0]` (the number of rows\n",
      "     |          in `tensor`).  If specified, then `output[row]` will contain\n",
      "     |          `tensor[row][:lengths[row]]`.  Negative lengths are treated as zero. You\n",
      "     |            may optionally pass a list or tuple of lengths to this argument, which\n",
      "     |            will be used as nested row lengths to construct a ragged tensor with\n",
      "     |            multiple ragged dimensions.\n",
      "     |        padding: An optional padding value.  If specified, then any row suffix\n",
      "     |          consisting entirely of `padding` will be excluded from the returned\n",
      "     |          RaggedTensor.  `padding` is a `Tensor` with the same dtype as `tensor`\n",
      "     |          and with `shape=tensor.shape[ragged_rank + 1:]`.\n",
      "     |        ragged_rank: Integer specifying the ragged rank for the returned\n",
      "     |          `RaggedTensor`.  Must be greater than zero.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        row_splits_dtype: `dtype` for the returned `RaggedTensor`'s `row_splits`\n",
      "     |          tensor.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` with the specified `ragged_rank`.  The shape of the\n",
      "     |        returned ragged tensor is compatible with the shape of `tensor`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If both `lengths` and `padding` are specified.\n",
      "     |        ValueError: If the rank of `tensor` is 0 or 1.\n",
      "     |  \n",
      "     |  from_uniform_row_length(values, uniform_row_length, nrows=None, validate=True, name=None) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `uniform_row_length`.\n",
      "     |      \n",
      "     |      This method can be used to create `RaggedTensor`s with multiple uniform\n",
      "     |      outer dimensions.  For example, a `RaggedTensor` with shape `[2, 2, None]`\n",
      "     |      can be constructed with this method from a `RaggedTensor` values with shape\n",
      "     |      `[4, None]`:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> print(values.shape)\n",
      "     |      (4, None)\n",
      "     |      >>> rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> print(rt1)\n",
      "     |      <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |      >>> print(rt1.shape)\n",
      "     |      (2, 2, None)\n",
      "     |      \n",
      "     |      Note that `rt1` only contains one ragged dimension (the innermost\n",
      "     |      dimension). In contrast, if `from_row_splits` is used to construct a similar\n",
      "     |      `RaggedTensor`, then that `RaggedTensor` will have two ragged dimensions:\n",
      "     |      \n",
      "     |      >>> rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])\n",
      "     |      >>> print(rt2.shape)\n",
      "     |      (2, None, None)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        uniform_row_length: A scalar integer tensor.  Must be nonnegative. The\n",
      "     |          size of the outer axis of `values` must be evenly divisible by\n",
      "     |          `uniform_row_length`.\n",
      "     |        nrows: The number of rows in the constructed RaggedTensor.  If not\n",
      "     |          specified, then it defaults to `nvals/uniform_row_length` (or `0` if\n",
      "     |          `uniform_row_length==0`).  `nrows` only needs to be specified if\n",
      "     |          `uniform_row_length` might be zero.  `uniform_row_length*nrows` must be\n",
      "     |          `nvals`.\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` that corresponds with the python list defined by:\n",
      "     |      \n",
      "     |        ```python\n",
      "     |        result = [[values.pop(0) for i in range(uniform_row_length)]\n",
      "     |                  for _ in range(nrows)]\n",
      "     |        ```\n",
      "     |      \n",
      "     |        `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |  \n",
      "     |  from_value_rowids(values, value_rowids, nrows=None, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `value_rowids`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]\n",
      "     |                for row in range(nrows)]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        value_rowids: A 1-D integer tensor with shape `[nvals]`, which corresponds\n",
      "     |          one-to-one with `values`, and specifies each value's row index.  Must be\n",
      "     |          nonnegative, and must be sorted in ascending order.\n",
      "     |        nrows: An integer scalar specifying the number of rows.  This should be\n",
      "     |          specified if the `RaggedTensor` may containing empty training rows. Must\n",
      "     |          be greater than `value_rowids[-1]` (or zero if `value_rowids` is empty).\n",
      "     |          Defaults to `value_rowids[-1] + 1` (or zero if `value_rowids` is empty).\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,\n",
      "     |            since they must be checked for each tensor value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `nrows` is incompatible with `value_rowids`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> print(tf.RaggedTensor.from_value_rowids(\n",
      "     |      ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |      ...     value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],\n",
      "     |      ...     nrows=5))\n",
      "     |      <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of values in this tensor.\n",
      "     |  \n",
      "     |  flat_values\n",
      "     |      The innermost `values` tensor for this ragged tensor.\n",
      "     |      \n",
      "     |      Concretely, if `rt.values` is a `Tensor`, then `rt.flat_values` is\n",
      "     |      `rt.values`; otherwise, `rt.flat_values` is `rt.values.flat_values`.\n",
      "     |      \n",
      "     |      Conceptually, `flat_values` is the tensor formed by flattening the\n",
      "     |      outermost dimension and all of the ragged dimensions into a single\n",
      "     |      dimension.\n",
      "     |      \n",
      "     |      `rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]`\n",
      "     |      (where `nvals` is the number of items in the flattened dimensions).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])\n",
      "     |      >>> print(rt.flat_values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |  \n",
      "     |  nested_row_splits\n",
      "     |      A tuple containing the row_splits for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_row_splits` is a tuple containing the `row_splits` tensors for\n",
      "     |      all ragged dimensions in `rt`, ordered from outermost to innermost.  In\n",
      "     |      particular, `rt.nested_row_splits = (rt.row_splits,) + value_splits` where:\n",
      "     |      \n",
      "     |          * `value_splits = ()` if `rt.values` is a `Tensor`.\n",
      "     |          * `value_splits = rt.values.nested_row_splits` otherwise.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensor`s.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant(\n",
      "     |      ...     [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])\n",
      "     |      >>> for i, splits in enumerate(rt.nested_row_splits):\n",
      "     |      ...   print('Splits for dimension %d: %s' % (i+1, splits.numpy()))\n",
      "     |      Splits for dimension 1: [0 3]\n",
      "     |      Splits for dimension 2: [0 3 3 5]\n",
      "     |      Splits for dimension 3: [0 4 4 7 8 8]\n",
      "     |  \n",
      "     |  ragged_rank\n",
      "     |      The number of times the RaggedTensor's flat_values is partitioned.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> values.ragged_rank\n",
      "     |      1\n",
      "     |      \n",
      "     |      >>> rt = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> rt.ragged_rank\n",
      "     |      2\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Python `int` indicating the number of times the underlying `flat_values`\n",
      "     |        Tensor has been partitioned to add a new dimension.\n",
      "     |        I.e., `tf.rank(rt) = tf.rank(rt.flat_values) + rt.ragged_rank`.\n",
      "     |  \n",
      "     |  row_splits\n",
      "     |      The row-split indices for this ragged tensor's `values`.\n",
      "     |      \n",
      "     |      `rt.row_splits` specifies where the values for each row begin and end in\n",
      "     |      `rt.values`.  In particular, the values for row `rt[i]` are stored in\n",
      "     |      the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer `Tensor` with shape `[self.nrows+1]`.\n",
      "     |        The returned tensor is non-empty, and is sorted in ascending order.\n",
      "     |        `self.row_splits[0]` is zero, and `self.row_splits[-1]` is equal to\n",
      "     |        `self.values.shape[0]`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.row_splits)  # indices of row splits in rt.values\n",
      "     |      tf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The statically known shape of this ragged tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the statically known shape of this ragged\n",
      "     |        tensor.  Ragged dimensions have a size of `None`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[0], [1, 2]]).shape\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |  \n",
      "     |  uniform_row_length\n",
      "     |      The length of each row in this ragged tensor, or None if rows are ragged.\n",
      "     |      \n",
      "     |      >>> rt1 = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> print(rt1.uniform_row_length)  # rows are ragged.\n",
      "     |      None\n",
      "     |      \n",
      "     |      >>> rt2 = tf.RaggedTensor.from_uniform_row_length(\n",
      "     |      ...     values=rt1, uniform_row_length=2)\n",
      "     |      >>> print(rt2)\n",
      "     |      <tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>\n",
      "     |      >>> print(rt2.uniform_row_length)  # rows are not ragged (all have size 2).\n",
      "     |      tf.Tensor(2, shape=(), dtype=int64)\n",
      "     |      \n",
      "     |      A RaggedTensor's rows are only considered to be uniform (i.e. non-ragged)\n",
      "     |      if it can be determined statically (at graph construction time) that the\n",
      "     |      rows all have the same length.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar integer `Tensor`, specifying the length of every row in this\n",
      "     |        ragged tensor (for ragged tensors whose rows are uniform); or `None`\n",
      "     |        (for ragged tensors whose rows are ragged).\n",
      "     |  \n",
      "     |  values\n",
      "     |      The concatenated rows for this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.values` is a potentially ragged tensor formed by flattening the two\n",
      "     |      outermost dimensions of `rt` into a single dimension.\n",
      "     |      \n",
      "     |      `rt.values.shape = [nvals] + rt.shape[2:]` (where `nvals` is the\n",
      "     |      number of items in the outer two dimensions of `rt`).\n",
      "     |      \n",
      "     |      `rt.ragged_rank = self.ragged_rank - 1`\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A potentially ragged tensor.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |      >>> print(rt.values)\n",
      "     |      tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __composite_gradient__ = <tensorflow.python.framework.composite_tensor...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class RaggedTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.python.types.internal.RaggedTensorSpec)\n",
      "     |  RaggedTensorSpec(shape=None, dtype=tf.float32, ragged_rank=None, row_splits_dtype=tf.int64, flat_values_spec=None)\n",
      "     |  \n",
      "     |  Type specification for a `tf.RaggedTensor`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RaggedTensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      tensorflow.python.types.internal.RaggedTensorSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32, ragged_rank=None, row_splits_dtype=tf.int64, flat_values_spec=None)\n",
      "     |      Constructs a type specification for a `tf.RaggedTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The shape of the RaggedTensor, or `None` to allow any shape.  If a\n",
      "     |          shape is specified, then all ragged dimensions must have size `None`.\n",
      "     |        dtype: `tf.DType` of values in the RaggedTensor.\n",
      "     |        ragged_rank: Python integer, the number of times the RaggedTensor's\n",
      "     |          flat_values is partitioned.  Defaults to `shape.ndims - 1`.\n",
      "     |        row_splits_dtype: `dtype` for the RaggedTensor's `row_splits` tensor. One\n",
      "     |          of `tf.int32` or `tf.int64`.\n",
      "     |        flat_values_spec: TypeSpec for flat_value of the RaggedTensor. It shall be\n",
      "     |          provided when the flat_values is a CompositeTensor rather then Tensor.\n",
      "     |          If both `dtype` and `flat_values_spec` and  are provided, `dtype` must\n",
      "     |          be the same as `flat_values_spec.dtype`. (experimental)\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `tf.dtypes.DType` specified by this type for the RaggedTensor.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[\"a\"], [\"b\", \"c\"]], dtype=tf.string)\n",
      "     |      >>> tf.type_spec_from_value(rt).dtype\n",
      "     |      tf.string\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.dtypes.DType` of the values in the RaggedTensor.\n",
      "     |  \n",
      "     |  flat_values_spec\n",
      "     |      The `TypeSpec` of the flat_values of RaggedTensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        - The TypeSpec of flat_values.\n",
      "     |        - None when the flat_values is a Tensor.\n",
      "     |  \n",
      "     |  ragged_rank\n",
      "     |      The number of times the RaggedTensor's flat_values is partitioned.\n",
      "     |      \n",
      "     |      Defaults to `shape.ndims - 1`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])\n",
      "     |      >>> tf.type_spec_from_value(values).ragged_rank\n",
      "     |      1\n",
      "     |      \n",
      "     |      >>> rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)\n",
      "     |      >>> tf.type_spec_from_value(rt1).ragged_rank\n",
      "     |      2\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Python `int` indicating the number of times the underlying `flat_values`\n",
      "     |        Tensor has been partitioned to add a new dimension.\n",
      "     |        I.e., `tf.rank(rt) = tf.rank(rt.flat_values) + rt.ragged_rank`.\n",
      "     |  \n",
      "     |  row_splits_dtype\n",
      "     |      The `tf.dtypes.DType` of the RaggedTensor's `row_splits`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[1, 2, 3], [4]], row_splits_dtype=tf.int64)\n",
      "     |      >>> tf.type_spec_from_value(rt).row_splits_dtype\n",
      "     |      tf.int64\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.dtypes.DType` for the RaggedTensor's `row_splits` tensor. One\n",
      "     |        of `tf.int32` or `tf.int64`.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The statically known shape of the RaggedTensor.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[0], [1, 2]])\n",
      "     |      >>> tf.type_spec_from_value(rt).shape\n",
      "     |      TensorShape([2, None])\n",
      "     |      \n",
      "     |      >>> rt = tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1)\n",
      "     |      >>> tf.type_spec_from_value(rt).shape\n",
      "     |      TensorShape([2, None, 2])\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` containing the statically known shape of the\n",
      "     |        RaggedTensor. Ragged dimensions have a size of `None`.\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class RandomShuffleQueue(QueueBase)\n",
      "     |  RandomShuffleQueue(capacity, min_after_dequeue, dtypes, shapes=None, names=None, seed=None, shared_name=None, name='random_shuffle_queue')\n",
      "     |  \n",
      "     |  A queue implementation that dequeues elements in a random order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomShuffleQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, min_after_dequeue, dtypes, shapes=None, names=None, seed=None, shared_name=None, name='random_shuffle_queue')\n",
      "     |      Create a queue that dequeues elements in a random order.\n",
      "     |      \n",
      "     |      A `RandomShuffleQueue` has bounded capacity; supports multiple\n",
      "     |      concurrent producers and consumers; and provides exactly-once\n",
      "     |      delivery.\n",
      "     |      \n",
      "     |      A `RandomShuffleQueue` holds a list of up to `capacity`\n",
      "     |      elements. Each element is a fixed-length tuple of tensors whose\n",
      "     |      dtypes are described by `dtypes`, and whose shapes are optionally\n",
      "     |      described by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      The `min_after_dequeue` argument allows the caller to specify a\n",
      "     |      minimum number of elements that will remain in the queue after a\n",
      "     |      `dequeue` or `dequeue_many` operation completes, to ensure a\n",
      "     |      minimum level of mixing of elements. This invariant is maintained\n",
      "     |      by blocking those operations until sufficient elements have been\n",
      "     |      enqueued. The `min_after_dequeue` argument is ignored after the\n",
      "     |      queue has been closed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        min_after_dequeue: An integer (described above).\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects\n",
      "     |          with the same length as `dtypes`, or `None`.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        seed: A Python integer. Used to create a random seed. See\n",
      "     |          `tf.compat.v1.set_random_seed`\n",
      "     |          for behavior.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from QueueBase:\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class ReaderBase(builtins.object)\n",
      "     |  ReaderBase(reader_ref, supports_serialize=False)\n",
      "     |  \n",
      "     |  Base class for different Reader types, that produce a record every step.\n",
      "     |  \n",
      "     |  Conceptually, Readers convert string 'work units' into records (key,\n",
      "     |  value pairs).  Typically the 'work units' are filenames and the\n",
      "     |  records are extracted from the contents of those files.  We want a\n",
      "     |  single record produced per step, but a work unit can correspond to\n",
      "     |  many records.\n",
      "     |  \n",
      "     |  Therefore we introduce some decoupling using a queue.  The queue\n",
      "     |  contains the work units and the Reader dequeues from the queue when\n",
      "     |  it is asked to produce a record (via Read()) but it has finished the\n",
      "     |  last work unit.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, reader_ref, supports_serialize=False)\n",
      "     |      Creates a new ReaderBase.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reader_ref: The operation that implements the reader.\n",
      "     |        supports_serialize: True if the reader implementation can\n",
      "     |          serialize its state.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If eager execution is enabled.\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class RegisterGradient(builtins.object)\n",
      "     |  RegisterGradient(op_type)\n",
      "     |  \n",
      "     |  A decorator for registering the gradient function for an op type.\n",
      "     |  \n",
      "     |  This decorator is only used when defining a new op type. For an op\n",
      "     |  with `m` inputs and `n` outputs, the gradient function is a function\n",
      "     |  that takes the original `Operation` and `n` `Tensor` objects\n",
      "     |  (representing the gradients with respect to each output of the op),\n",
      "     |  and returns `m` `Tensor` objects (representing the partial gradients\n",
      "     |  with respect to each input of the op).\n",
      "     |  \n",
      "     |  For example, assuming that operations of type `\"Sub\"` take two\n",
      "     |  inputs `x` and `y`, and return a single output `x - y`, the\n",
      "     |  following gradient function would be registered:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  @tf.RegisterGradient(\"Sub\")\n",
      "     |  def _sub_grad(unused_op, grad):\n",
      "     |    return grad, tf.negative(grad)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The decorator argument `op_type` is the string type of an\n",
      "     |  operation. This corresponds to the `OpDef.name` field for the proto\n",
      "     |  that defines the operation.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, f: ~_T) -> ~_T\n",
      "     |      Registers the function `f` as gradient function for `op_type`.\n",
      "     |  \n",
      "     |  __init__(self, op_type)\n",
      "     |      Creates a new decorator with `op_type` as the Operation type.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type: The string type of an operation. This corresponds to the\n",
      "     |          `OpDef.name` field for the proto that defines the operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `op_type` is not string.\n",
      "    \n",
      "    class RunMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      RunMetadata\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  FunctionGraphs = <class 'tensorflow.core.protobuf.config_pb2.FunctionG...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class RunOptions(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      RunOptions\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class Session(BaseSession)\n",
      "     |  Session(target='', graph=None, config=None)\n",
      "     |  \n",
      "     |  A class for running TensorFlow operations.\n",
      "     |  \n",
      "     |  A `Session` object encapsulates the environment in which `Operation`\n",
      "     |  objects are executed, and `Tensor` objects are evaluated. For\n",
      "     |  example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
      "     |  # Build a graph.\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  \n",
      "     |  # Launch the graph in a session.\n",
      "     |  sess = tf.compat.v1.Session()\n",
      "     |  \n",
      "     |  # Evaluate the tensor `c`.\n",
      "     |  print(sess.run(c)) # prints 30.0\n",
      "     |  ```\n",
      "     |  \n",
      "     |  A session may own resources, such as\n",
      "     |  `tf.Variable`, `tf.queue.QueueBase`,\n",
      "     |  and `tf.compat.v1.ReaderBase`. It is important to release\n",
      "     |  these resources when they are no longer required. To do this, either\n",
      "     |  invoke the `tf.Session.close` method on the session, or use\n",
      "     |  the session as a context manager. The following two examples are\n",
      "     |  equivalent:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Using the `close()` method.\n",
      "     |  sess = tf.compat.v1.Session()\n",
      "     |  sess.run(...)\n",
      "     |  sess.close()\n",
      "     |  \n",
      "     |  # Using the context manager.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |    sess.run(...)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The\n",
      "     |  [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      "     |  protocol buffer exposes various configuration options for a\n",
      "     |  session. For example, to create a session that uses soft constraints\n",
      "     |  for device placement, and log the resulting placement decisions,\n",
      "     |  create a session as follows:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Launch the graph in a session that allows soft device placement and\n",
      "     |  # logs the placement decisions.\n",
      "     |  sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\n",
      "     |      allow_soft_placement=True,\n",
      "     |      log_device_placement=True))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  `Session` does not work with either eager execution or `tf.function`, and you\n",
      "     |  should not invoke it directly. To migrate code that uses sessions to TF2,\n",
      "     |  rewrite the code without it. See the\n",
      "     |  [migration\n",
      "     |  guide](https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls)\n",
      "     |  on replacing `Session.run` calls.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Session\n",
      "     |      BaseSession\n",
      "     |      SessionInterface\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self) -> 'Session'\n",
      "     |  \n",
      "     |  __exit__(self, exec_type, exec_value, exec_tb)\n",
      "     |  \n",
      "     |  __init__(self, target='', graph=None, config=None)\n",
      "     |      Creates a new TensorFlow session.\n",
      "     |      \n",
      "     |      If no `graph` argument is specified when constructing the session,\n",
      "     |      the default graph will be launched in the session. If you are\n",
      "     |      using more than one graph (created with `tf.Graph()`) in the same\n",
      "     |      process, you will have to use different sessions for each graph,\n",
      "     |      but each graph can be used in multiple sessions. In this case, it\n",
      "     |      is often clearer to pass the graph to be launched explicitly to\n",
      "     |      the session constructor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: (Optional.) The execution engine to connect to. Defaults to using\n",
      "     |          an in-process engine. See\n",
      "     |          [Distributed TensorFlow](https://tensorflow.org/deploy/distributed) for\n",
      "     |            more examples.\n",
      "     |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      "     |        config: (Optional.) A\n",
      "     |          [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      "     |            protocol buffer with configuration options for the session.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  reset(target, containers=None, config=None)\n",
      "     |      Resets resource containers on `target`, and close all connected sessions.\n",
      "     |      \n",
      "     |      A resource container is distributed across all workers in the\n",
      "     |      same cluster as `target`.  When a resource container on `target`\n",
      "     |      is reset, resources associated with that container will be cleared.\n",
      "     |      In particular, all Variables in the container will become undefined:\n",
      "     |      they lose their values and shapes.\n",
      "     |      \n",
      "     |      NOTE:\n",
      "     |      (i) reset() is currently only implemented for distributed sessions.\n",
      "     |      (ii) Any sessions on the master named by `target` will be closed.\n",
      "     |      \n",
      "     |      If no resource containers are provided, all containers are reset.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: The execution engine to connect to.\n",
      "     |        containers: A list of resource container name strings, or `None` if all of\n",
      "     |          all the containers are to be reset.\n",
      "     |        config: (Optional.) Protocol buffer with configuration options.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      "     |          resetting containers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSession:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  as_default(self)\n",
      "     |      Returns a context manager that makes this object the default session.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that calls to\n",
      "     |      `tf.Operation.run` or `tf.Tensor.eval` should be executed in\n",
      "     |      this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(..)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      \n",
      "     |      with sess.as_default():\n",
      "     |        assert tf.compat.v1.get_default_session() is sess\n",
      "     |        print(c.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      To get the current default session, use `tf.compat.v1.get_default_session`.\n",
      "     |      \n",
      "     |      *N.B.* The `as_default` context manager *does not* close the\n",
      "     |      session when you exit the context, and you must close the session\n",
      "     |      explicitly.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(...)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      # ...\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      \n",
      "     |      sess.close()\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Alternatively, you can use `with tf.compat.v1.Session():` to create a\n",
      "     |      session that is automatically closed on exiting the context,\n",
      "     |      including when an uncaught exception is raised.\n",
      "     |      \n",
      "     |      *N.B.* The default session is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default session in that\n",
      "     |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      "     |      the current default graph. If you are using multiple graphs, and\n",
      "     |      `sess.graph` is different from the value of\n",
      "     |      `tf.compat.v1.get_default_graph`, you must explicitly enter a\n",
      "     |      `with sess.graph.as_default():` block to make `sess.graph` the default\n",
      "     |      graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager using this session as the default session.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes this session.\n",
      "     |      \n",
      "     |      Calling this method frees all resources associated with the session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      "     |          closing the TensorFlow session.\n",
      "     |  \n",
      "     |  list_devices(self)\n",
      "     |      Lists available devices in this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      devices = sess.list_devices()\n",
      "     |      for d in devices:\n",
      "     |        print(d.name)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Where:\n",
      "     |        Each element in the list has the following properties\n",
      "     |        name: A string with the full name of the device. ex:\n",
      "     |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      "     |        device_type: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      "     |        memory_limit: The maximum amount of memory available on the device.\n",
      "     |            Note: depending on the device, it is possible the usable memory could\n",
      "     |            be substantially less.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      "     |        invalid state, or network errors occur).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of devices in the session.\n",
      "     |  \n",
      "     |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      "     |      Returns a Python callable that runs a particular step.\n",
      "     |      \n",
      "     |      The returned callable will take `len(feed_list)` arguments whose types\n",
      "     |      must be compatible feed values for the respective elements of `feed_list`.\n",
      "     |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      "     |      argument to the returned callable must be a numpy ndarray (or something\n",
      "     |      convertible to an ndarray) with matching element type and shape. See\n",
      "     |      `tf.Session.run` for details of the allowable feed key and value types.\n",
      "     |      \n",
      "     |      The returned callable will have the same return type as\n",
      "     |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      "     |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      "     |      it will return `None`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A value or list of values to fetch. See `tf.Session.run` for\n",
      "     |          details of the allowable fetch types.\n",
      "     |        feed_list: (Optional.) A list of `feed_dict` keys. See `tf.Session.run`\n",
      "     |          for details of the allowable feed key types.\n",
      "     |        accept_options: (Optional.) If `True`, the returned `Callable` will be\n",
      "     |          able to accept `tf.compat.v1.RunOptions` and `tf.compat.v1.RunMetadata`\n",
      "     |          as optional keyword arguments `options` and `run_metadata`,\n",
      "     |          respectively, with the same syntax and semantics as `tf.Session.run`,\n",
      "     |          which is useful for certain use cases (profiling and debugging) but will\n",
      "     |          result in measurable slowdown of the `Callable`'s\n",
      "     |          performance. Default: `False`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A function that when called will execute the step defined by\n",
      "     |        `feed_list` and `fetches` in this session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      "     |          as arguments to `tf.Session.run`.\n",
      "     |  \n",
      "     |  partial_run(self, handle, fetches, feed_dict=None)\n",
      "     |      Continues the execution with more feeds and fetches. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2023-06-01.\n",
      "     |      Instructions for updating:\n",
      "     |      This function is deprecated and we do not expect adding newfunctionality to it. Please do not have your code dependingon this function.\n",
      "     |      \n",
      "     |      NOTE: This function is deprecated and we do not expect adding new\n",
      "     |      functionality to it. Please do not have your code depending on this\n",
      "     |      function.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      "     |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      "     |      list of feeds and fetches that will be used in the subsequent\n",
      "     |      `partial_run` calls.\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. See run() for more information.\n",
      "     |      \n",
      "     |      Below is a simple example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      r1 = math_ops.add(a, b)\n",
      "     |      r2 = math_ops.multiply(r1, c)\n",
      "     |      \n",
      "     |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      "     |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      "     |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        handle: A handle for a sequence of partial runs.\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (see\n",
      "     |          documentation for `run`).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary\n",
      "     |        (see documentation for `run`).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses on error.\n",
      "     |  \n",
      "     |  partial_run_setup(self, fetches, feeds=None)\n",
      "     |      Sets up a graph with feeds and fetches for partial run. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2023-06-01.\n",
      "     |      Instructions for updating:\n",
      "     |      This function is deprecated and we do not expect adding newfunctionality to it. Please do not have your code dependingon this function.\n",
      "     |      \n",
      "     |      NOTE: This function is deprecated and we do not expect adding new\n",
      "     |      functionality to it. Please do not have your code depending on this\n",
      "     |      function.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      "     |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, or a list of graph elements.\n",
      "     |        feeds: A single graph element, or a list of graph elements.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A handle for partial run.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      "     |  \n",
      "     |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      "     |      Runs operations and evaluates tensors in `fetches`.\n",
      "     |      \n",
      "     |      This method runs one \"step\" of TensorFlow computation, by\n",
      "     |      running the necessary graph fragment to execute every `Operation`\n",
      "     |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      "     |      `feed_dict` for the corresponding input values.\n",
      "     |      \n",
      "     |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      "     |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      "     |      elements at its leaves.  A graph element can be one of the following types:\n",
      "     |      \n",
      "     |      * A `tf.Operation`.\n",
      "     |        The corresponding fetched value will be `None`.\n",
      "     |      * A `tf.Tensor`.\n",
      "     |        The corresponding fetched value will be a numpy ndarray containing the\n",
      "     |        value of that tensor.\n",
      "     |      * A `tf.sparse.SparseTensor`.\n",
      "     |        The corresponding fetched value will be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`\n",
      "     |        containing the value of that sparse tensor.\n",
      "     |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      "     |        numpy ndarray containing the handle of that tensor.\n",
      "     |      * A `string` which is the name of a tensor or operation in the graph.\n",
      "     |      \n",
      "     |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      "     |      where the leaves are replaced by the corresponding values returned by\n",
      "     |      TensorFlow.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |         a = tf.constant([10, 20])\n",
      "     |         b = tf.constant([1.0, 2.0])\n",
      "     |         # 'fetches' can be a singleton\n",
      "     |         v = session.run(a)\n",
      "     |         # v is the numpy array [10, 20]\n",
      "     |         # 'fetches' can be a list.\n",
      "     |         v = session.run([a, b])\n",
      "     |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      "     |         # 1-D array [1.0, 2.0]\n",
      "     |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      "     |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      "     |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      "     |         # v is a dict with\n",
      "     |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      "     |         # 'b' (the numpy array [1.0, 2.0])\n",
      "     |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      "     |         # [10, 20].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      "     |      one of the following types:\n",
      "     |      \n",
      "     |      * If the key is a `tf.Tensor`, the\n",
      "     |        value may be a Python scalar, string, list, or numpy ndarray\n",
      "     |        that can be converted to the same `dtype` as that\n",
      "     |        tensor. Additionally, if the key is a\n",
      "     |        `tf.compat.v1.placeholder`, the shape of\n",
      "     |        the value will be checked for compatibility with the placeholder.\n",
      "     |      * If the key is a\n",
      "     |        `tf.sparse.SparseTensor`,\n",
      "     |        the value should be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`.\n",
      "     |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      "     |        should be a nested tuple with the same structure that maps to their\n",
      "     |        corresponding values as above.\n",
      "     |      \n",
      "     |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      "     |      of the corresponding key.\n",
      "     |      \n",
      "     |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      "     |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      "     |      on).\n",
      "     |      \n",
      "     |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      "     |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      "     |      example, when users turn on tracing in `options`, the profiled info will be\n",
      "     |      collected into this argument and passed back.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (described\n",
      "     |          above).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |        options: A [`RunOptions`] protocol buffer\n",
      "     |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary (described above).\n",
      "     |        Order in which `fetches` operations are evaluated inside the call\n",
      "     |        is undefined.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      "     |          `Tensor` that doesn't exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSession:\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The graph that was launched in this session.\n",
      "     |  \n",
      "     |  graph_def\n",
      "     |      A serializable version of the underlying TensorFlow graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      "     |        the underlying TensorFlow graph.\n",
      "     |  \n",
      "     |  sess_str\n",
      "     |      The TensorFlow process to which this session will connect.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SessionInterface:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class SessionLog(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      SessionLog\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class SparseConditionalAccumulator(ConditionalAccumulatorBase)\n",
      "     |  SparseConditionalAccumulator(dtype, shape=None, shared_name=None, name='sparse_conditional_accumulator', reduction_type='MEAN')\n",
      "     |  \n",
      "     |  A conditional accumulator for aggregating sparse gradients.\n",
      "     |  \n",
      "     |  Sparse gradients are represented by `IndexedSlices`.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    dtype: Datatype of the accumulated gradients.\n",
      "     |    shape: Shape of the accumulated gradients.\n",
      "     |    shared_name: Optional. If non-empty, this accumulator will be shared under\n",
      "     |      the given name across multiple sessions.\n",
      "     |    name: Optional name for the accumulator.\n",
      "     |    reduction_type: Reduction type to use when taking the gradient.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseConditionalAccumulator\n",
      "     |      ConditionalAccumulatorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape=None, shared_name=None, name='sparse_conditional_accumulator', reduction_type='MEAN')\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        accumulator_ref: A handle to the conditional accumulator, created by sub-\n",
      "     |          classes\n",
      "     |  \n",
      "     |  apply_grad(self, grad_indices, grad_values, grad_shape=None, local_step=0, name=None)\n",
      "     |      Attempts to apply a sparse gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., `local_step`\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      A sparse gradient is represented by its indices, values and possibly empty\n",
      "     |      or None shape. Indices must be a vector representing the locations of\n",
      "     |      non-zero entries in the tensor. Values are the non-zero slices of the\n",
      "     |      gradient, and must have the same first dimension as indices, i.e., the nnz\n",
      "     |      represented by indices and values must be consistent. Shape, if not empty or\n",
      "     |      None, must be consistent with the accumulator's shape (if also provided).\n",
      "     |      \n",
      "     |      Example:\n",
      "     |        A tensor [[0, 0], [0, 1], [2, 3]] can be represented\n",
      "     |          indices: [1,2]\n",
      "     |          values: [[0,1],[2,3]]\n",
      "     |          shape: [3, 2]\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad_indices: Indices of the sparse gradient to be applied.\n",
      "     |        grad_values: Values of the sparse gradient to be applied.\n",
      "     |        grad_shape: Shape of the sparse gradient to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  apply_indexed_slices_grad(self, grad, local_step=0, name=None)\n",
      "     |      Attempts to apply a gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., `local_step`\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad: The gradient `IndexedSlices` to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  take_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of indices, values, and shape representing the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `num_required` < 1\n",
      "     |  \n",
      "     |  take_indexed_slices_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An `IndexedSlices` holding the value of the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `num_required` < 1\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class SparseFeature(SparseFeature)\n",
      "     |  SparseFeature(index_key, value_key, dtype, size, already_sorted=False)\n",
      "     |  \n",
      "     |  Configuration for parsing a sparse input feature from an `Example`.\n",
      "     |  \n",
      "     |  Note, preferably use `VarLenFeature` (possibly in combination with a\n",
      "     |  `SequenceExample`) in order to parse out `SparseTensor`s instead of\n",
      "     |  `SparseFeature` due to its simplicity.\n",
      "     |  \n",
      "     |  Closely mimicking the `SparseTensor` that will be obtained by parsing an\n",
      "     |  `Example` with a `SparseFeature` config, a `SparseFeature` contains a\n",
      "     |  \n",
      "     |  * `value_key`: The name of key for a `Feature` in the `Example` whose parsed\n",
      "     |    `Tensor` will be the resulting `SparseTensor.values`.\n",
      "     |  \n",
      "     |  * `index_key`: A list of names - one for each dimension in the resulting\n",
      "     |    `SparseTensor` whose `indices[i][dim]` indicating the position of\n",
      "     |    the `i`-th value in the `dim` dimension will be equal to the `i`-th value in\n",
      "     |    the Feature with key named `index_key[dim]` in the `Example`.\n",
      "     |  \n",
      "     |  * `size`: A list of ints for the resulting `SparseTensor.dense_shape`.\n",
      "     |  \n",
      "     |  For example, we can represent the following 2D `SparseTensor`\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseTensor(indices=[[3, 1], [20, 0]],\n",
      "     |               values=[0.5, -1.0]\n",
      "     |               dense_shape=[100, 3])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  with an `Example` input proto\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  features {\n",
      "     |    feature { key: \"val\" value { float_list { value: [ 0.5, -1.0 ] } } }\n",
      "     |    feature { key: \"ix0\" value { int64_list { value: [ 3, 20 ] } } }\n",
      "     |    feature { key: \"ix1\" value { int64_list { value: [ 1, 0 ] } } }\n",
      "     |  }\n",
      "     |  ```\n",
      "     |  \n",
      "     |  and `SparseFeature` config with 2 `index_key`s\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseFeature(index_key=[\"ix0\", \"ix1\"],\n",
      "     |                value_key=\"val\",\n",
      "     |                dtype=tf.float32,\n",
      "     |                size=[100, 3])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    index_key: A single string name or a list of string names of index features.\n",
      "     |      For each key the underlying feature's type must be `int64` and its length\n",
      "     |      must always match that of the `value_key` feature.\n",
      "     |      To represent `SparseTensor`s with a `dense_shape` of `rank` higher than 1\n",
      "     |      a list of length `rank` should be used.\n",
      "     |    value_key: Name of value feature.  The underlying feature's type must\n",
      "     |      be `dtype` and its length must always match that of all the `index_key`s'\n",
      "     |      features.\n",
      "     |    dtype: Data type of the `value_key` feature.\n",
      "     |    size: A Python int or list thereof specifying the dense shape. Should be a\n",
      "     |      list if and only if `index_key` is a list. In that case the list must be\n",
      "     |      equal to the length of `index_key`. Each for each entry `i` all values in\n",
      "     |      the `index_key`[i] feature must be in `[0, size[i])`.\n",
      "     |    already_sorted: A Python boolean to specify whether the values in\n",
      "     |      `value_key` are already sorted by their index position. If so skip\n",
      "     |      sorting. False by default (optional).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseFeature\n",
      "     |      SparseFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, index_key, value_key, dtype, size, already_sorted=False)\n",
      "     |      Create new instance of SparseFeature(index_key, value_key, dtype, size, already_sorted)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.SparseFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.SparseFeature', 'SparseFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from SparseFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new SparseFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from SparseFeature:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new SparseFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SparseFeature:\n",
      "     |  \n",
      "     |  index_key\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  value_key\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  size\n",
      "     |      Alias for field number 3\n",
      "     |  \n",
      "     |  already_sorted\n",
      "     |      Alias for field number 4\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from SparseFeature:\n",
      "     |  \n",
      "     |  __match_args__ = ('index_key', 'value_key', 'dtype', 'size', 'already_...\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('index_key', 'value_key', 'dtype', 'size', 'already_sorted'...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    class SparseTensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  SparseTensor(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  Represents a sparse tensor.\n",
      "     |  \n",
      "     |  TensorFlow represents a sparse tensor as three separate dense tensors:\n",
      "     |  `indices`, `values`, and `dense_shape`.  In Python, the three tensors are\n",
      "     |  collected into a `SparseTensor` class for ease of use.  If you have separate\n",
      "     |  `indices`, `values`, and `dense_shape` tensors, wrap them in a `SparseTensor`\n",
      "     |  object before passing to the ops below.\n",
      "     |  \n",
      "     |  Concretely, the sparse tensor `SparseTensor(indices, values, dense_shape)`\n",
      "     |  comprises the following components, where `N` and `ndims` are the number\n",
      "     |  of values and number of dimensions in the `SparseTensor`, respectively:\n",
      "     |  \n",
      "     |  * `indices`: A 2-D int64 tensor of shape `[N, ndims]`, which specifies the\n",
      "     |    indices of the elements in the sparse tensor that contain nonzero values\n",
      "     |    (elements are zero-indexed). For example, `indices=[[1,3], [2,4]]` specifies\n",
      "     |    that the elements with indexes of [1,3] and [2,4] have nonzero values.\n",
      "     |  \n",
      "     |  * `values`: A 1-D tensor of any type and shape `[N]`, which supplies the\n",
      "     |    values for each element in `indices`. For example, given `indices=[[1,3],\n",
      "     |    [2,4]]`, the parameter `values=[18, 3.6]` specifies that element [1,3] of\n",
      "     |    the sparse tensor has a value of 18, and element [2,4] of the tensor has a\n",
      "     |    value of 3.6.\n",
      "     |  \n",
      "     |  * `dense_shape`: A 1-D int64 tensor of shape `[ndims]`, which specifies the\n",
      "     |    dense_shape of the sparse tensor. Takes a list indicating the number of\n",
      "     |    elements in each dimension. For example, `dense_shape=[3,6]` specifies a\n",
      "     |    two-dimensional 3x6 tensor, `dense_shape=[2,3,4]` specifies a\n",
      "     |    three-dimensional 2x3x4 tensor, and `dense_shape=[9]` specifies a\n",
      "     |    one-dimensional tensor with 9 elements.\n",
      "     |  \n",
      "     |  The corresponding dense tensor satisfies:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dense.shape = dense_shape\n",
      "     |  dense[tuple(indices[i])] = values[i]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  By convention, `indices` should be sorted in row-major order (or equivalently\n",
      "     |  lexicographic order on the tuples `indices[i]`). This is not enforced when\n",
      "     |  `SparseTensor` objects are constructed, but most ops assume correct ordering.\n",
      "     |  If the ordering of sparse tensor `st` is wrong, a fixed version can be\n",
      "     |  obtained by calling `tf.sparse.reorder(st)`.\n",
      "     |  \n",
      "     |  Example: The sparse tensor\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  represents the dense tensor\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  [[1, 0, 0, 0]\n",
      "     |   [0, 0, 2, 0]\n",
      "     |   [0, 0, 0, 0]]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Component-wise divides a SparseTensor by a dense Tensor.\n",
      "     |      \n",
      "     |      *Limitation*: this Op only broadcasts the dense side to the sparse side, but not\n",
      "     |      the other direction.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sp_indices: A `Tensor` of type `int64`.\n",
      "     |          2-D.  `N x R` matrix with the indices of non-empty values in a\n",
      "     |          SparseTensor, possibly not in canonical ordering.\n",
      "     |        sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "     |          1-D.  `N` non-empty values corresponding to `sp_indices`.\n",
      "     |        sp_shape: A `Tensor` of type `int64`.\n",
      "     |          1-D.  Shape of the input SparseTensor.\n",
      "     |        dense: A `Tensor`. Must have the same type as `sp_values`.\n",
      "     |          `R`-D.  The dense Tensor operand.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `sp_values`.\n",
      "     |  \n",
      "     |  __init__(self, indices, values, dense_shape)\n",
      "     |      Creates a `SparseTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A 2-D int64 tensor of shape `[N, ndims]`.\n",
      "     |        values: A 1-D tensor of any type and shape `[N]`.\n",
      "     |        dense_shape: A 1-D int64 tensor of shape `[ndims]`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: When building an eager SparseTensor if `dense_shape` is\n",
      "     |          unknown or contains unknown elements (None or -1).\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Component-wise multiplies a SparseTensor by a dense Tensor.\n",
      "     |      \n",
      "     |      The output locations corresponding to the implicitly zero elements in the sparse\n",
      "     |      tensor will be zero (i.e., will not take up storage space), regardless of the\n",
      "     |      contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).\n",
      "     |      \n",
      "     |      *Limitation*: this Op only broadcasts the dense side to the sparse side, but not\n",
      "     |      the other direction.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sp_indices: A `Tensor` of type `int64`.\n",
      "     |          2-D.  `N x R` matrix with the indices of non-empty values in a\n",
      "     |          SparseTensor, possibly not in canonical ordering.\n",
      "     |        sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "     |          1-D.  `N` non-empty values corresponding to `sp_indices`.\n",
      "     |        sp_shape: A `Tensor` of type `int64`.\n",
      "     |          1-D.  Shape of the input SparseTensor.\n",
      "     |        dense: A `Tensor`. Must have the same type as `sp_values`.\n",
      "     |          `R`-D.  The dense Tensor operand.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `sp_values`.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Internal helper function for 'sp_t / dense_t'.\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  eval(self, feed_dict=None, session=None)\n",
      "     |      Evaluates this sparse tensor in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for the operation that produces this\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `SparseTensor.eval()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to evaluate this sparse\n",
      "     |          tensor. If none, the default session will be used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `SparseTensorValue` object.\n",
      "     |  \n",
      "     |  get_shape(self) -> tensorflow.python.framework.tensor_shape.TensorShape\n",
      "     |      Get the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` object.\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Updates the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      With eager execution this operates as a shape assertion.\n",
      "     |      Here the shapes match:\n",
      "     |      \n",
      "     |      >>> st = tf.SparseTensor(\n",
      "     |      ...   indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
      "     |      >>> st.set_shape([3, 4])\n",
      "     |      \n",
      "     |      Passing a `None` in the new shape allows any value for that axis:\n",
      "     |      \n",
      "     |      >>> st.set_shape([3, None])\n",
      "     |      \n",
      "     |      An error is raised if an incompatible shape is passed.\n",
      "     |      \n",
      "     |      >>> st.set_shape([1, 4])\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Tensor's shape (3, 4) is not compatible with supplied\n",
      "     |      shape [1, 4]\n",
      "     |      \n",
      "     |      When executing in a `tf.function`, or building a model using\n",
      "     |      `tf.keras.Input`, `SparseTensor.set_shape` will *merge* the given `shape`\n",
      "     |      with the current shape of this tensor, and set the tensor's shape to the\n",
      "     |      merged value (see `tf.TensorShape.merge_with` for details):\n",
      "     |      \n",
      "     |      >>> st = tf.keras.Input(shape=[None, None, 3], sparse=True)\n",
      "     |      >>> print(st.shape)\n",
      "     |      (None, None, None, 3)\n",
      "     |      \n",
      "     |      Dimensions set to `None` are not updated:\n",
      "     |      \n",
      "     |      >>> st.set_shape([None, 224, 224, None])\n",
      "     |      >>> print(st.shape)\n",
      "     |      (None, 224, 224, 3)\n",
      "     |      \n",
      "     |      The main use case for this is to provide additional shape information\n",
      "     |      that cannot be inferred from the graph alone.\n",
      "     |      \n",
      "     |      Caution: `set_shape` ensures that the applied shape is compatible with\n",
      "     |      the existing shape, but it does not check at runtime. Setting\n",
      "     |      incorrect shapes can result in inconsistencies between the\n",
      "     |      statically-known graph and the runtime value of tensors.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: A `TensorShape` representing the shape of this tensor, a\n",
      "     |          `TensorShapeProto`, a list, a tuple, or None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `shape` is not compatible with the current shape of\n",
      "     |          this tensor.\n",
      "     |  \n",
      "     |  with_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `values` replaced by `new_values`.\n",
      "     |      \n",
      "     |      This method produces a new `SparseTensor` that has the same nonzero\n",
      "     |      `indices` and same `dense_shape`, but updated values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: The values of the new `SparseTensor`. Needs to have the same\n",
      "     |          shape as the current `.values` `Tensor`. May have a different type than\n",
      "     |          the current `values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `SparseTensor` with identical indices and shape but updated values.\n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      >>> st = tf.sparse.from_dense([[1, 0, 2, 0], [3, 0, 0, 4]])\n",
      "     |      >>> tf.sparse.to_dense(st.with_values([10, 20, 30, 40]))  # 4 nonzero values\n",
      "     |      <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "     |      array([[10,  0, 20,  0],\n",
      "     |             [30,  0,  0, 40]], dtype=int32)>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(sparse_tensor_value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      A 1-D Tensor of int64 representing the shape of the dense tensor.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains the index, value, and dense_shape tensors.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      The indices of non-zero values in the represented dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 2-D Tensor of int64 with dense_shape `[N, ndims]`, where `N` is the\n",
      "     |          number of non-zero values in the tensor, and `ndims` is the rank.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces `values` as an output.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Get the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` object.\n",
      "     |  \n",
      "     |  values\n",
      "     |      The non-zero values in the represented dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D Tensor of any data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.NativeObject:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context)\n",
      "    \n",
      "    class SparseTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec)\n",
      "     |  SparseTensorSpec(shape=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Type specification for a `tf.sparse.SparseTensor`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32)\n",
      "     |      Constructs a type specification for a `tf.sparse.SparseTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The dense shape of the `SparseTensor`, or `None` to allow any dense\n",
      "     |          shape.\n",
      "     |        dtype: `tf.DType` of values in the `SparseTensor`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `tf.dtypes.DType` specified by this type for the SparseTensor.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The `tf.TensorShape` specified by this type for the SparseTensor.\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class SparseTensorValue(builtins.tuple)\n",
      "     |  SparseTensorValue(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  SparseTensorValue(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensorValue\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new SparseTensorValue object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new SparseTensorValue object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(_cls, indices, values, dense_shape)\n",
      "     |      Create new instance of SparseTensorValue(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  indices\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  values\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __match_args__ = ('indices', 'values', 'dense_shape')\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('indices', 'values', 'dense_shape')\n",
      "     |  \n",
      "     |  _tf_api_names = ()\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['SparseTensorValue']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    class Summary(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      Summary\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Audio = <class 'tensorflow.core.framework.summary_pb2.Audio'>\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  Image = <class 'tensorflow.core.framework.summary_pb2.Image'>\n",
      "     |  \n",
      "     |  Value = <class 'tensorflow.core.framework.summary_pb2.Value'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class SummaryMetadata(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      SummaryMetadata\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  PluginData = <class 'tensorflow.core.framework.summary_pb2.PluginData'...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class TFRecordReader(ReaderBase)\n",
      "     |  TFRecordReader(name=None, options=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the records from a TFRecords file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TFRecordReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, options=None)\n",
      "     |      Create a TFRecordReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        options: A TFRecordOptions object (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class Tensor(tensorflow.python.types.internal.NativeObject, tensorflow.python.types.core.Symbol)\n",
      "     |  A `tf.Tensor` represents a multidimensional array of elements.\n",
      "     |  \n",
      "     |  All elements are of a single known data type.\n",
      "     |  \n",
      "     |  When writing a TensorFlow program, the main object that is\n",
      "     |  manipulated and passed around is the `tf.Tensor`.\n",
      "     |  \n",
      "     |  A `tf.Tensor` has the following properties:\n",
      "     |  \n",
      "     |  * a single data type (float32, int32, or string, for example)\n",
      "     |  * a shape\n",
      "     |  \n",
      "     |  TensorFlow supports eager execution and graph execution.  In eager\n",
      "     |  execution, operations are evaluated immediately.  In graph\n",
      "     |  execution, a computational graph is constructed for later\n",
      "     |  evaluation.\n",
      "     |  \n",
      "     |  TensorFlow defaults to eager execution.  In the example below, the\n",
      "     |  matrix multiplication results are calculated immediately.\n",
      "     |  \n",
      "     |  >>> # Compute some values using a Tensor\n",
      "     |  >>> c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
      "     |  >>> d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
      "     |  >>> e = tf.matmul(c, d)\n",
      "     |  >>> print(e)\n",
      "     |  tf.Tensor(\n",
      "     |  [[1. 3.]\n",
      "     |   [3. 7.]], shape=(2, 2), dtype=float32)\n",
      "     |  \n",
      "     |  Note that during eager execution, you may discover your `Tensors` are actually\n",
      "     |  of type `EagerTensor`.  This is an internal detail, but it does give you\n",
      "     |  access to a useful function, `numpy`:\n",
      "     |  \n",
      "     |  >>> type(e)\n",
      "     |  <class '...ops.EagerTensor'>\n",
      "     |  >>> print(e.numpy())\n",
      "     |    [[1. 3.]\n",
      "     |     [3. 7.]]\n",
      "     |  \n",
      "     |  In TensorFlow, `tf.function`s are a common way to define graph execution.\n",
      "     |  \n",
      "     |  A Tensor's shape (that is, the rank of the Tensor and the size of\n",
      "     |  each dimension) may not always be fully known.  In `tf.function`\n",
      "     |  definitions, the shape may only be partially known.\n",
      "     |  \n",
      "     |  Most operations produce tensors of fully-known shapes if the shapes of their\n",
      "     |  inputs are also fully known, but in some cases it's only possible to find the\n",
      "     |  shape of a tensor at execution time.\n",
      "     |  \n",
      "     |  A number of specialized tensors are available: see `tf.Variable`,\n",
      "     |  `tf.constant`, `tf.placeholder`, `tf.sparse.SparseTensor`, and\n",
      "     |  `tf.RaggedTensor`.\n",
      "     |  \n",
      "     |  Caution: when constructing a tensor from a numpy array or pandas dataframe\n",
      "     |  the underlying buffer may be re-used:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = np.array([1, 2, 3])\n",
      "     |  b = tf.constant(a)\n",
      "     |  a[0] = 4\n",
      "     |  print(b)  # tf.Tensor([4 2 3], shape=(3,), dtype=int64)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note: this is an implementation detail that is subject to change and users\n",
      "     |  should not rely on this behaviour.\n",
      "     |  \n",
      "     |  For more on Tensors, see the [guide](https://tensorflow.org/guide/tensor).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Tensor\n",
      "     |      tensorflow.python.types.internal.NativeObject\n",
      "     |      tensorflow.python.types.core.Symbol\n",
      "     |      tensorflow.python.types.core.Tensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = _abs_factory(x, name=None)\n",
      "     |  \n",
      "     |  __add__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __and__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Dummy method to prevent a tensor from being used as a Python `bool`.\n",
      "     |      \n",
      "     |      This overload raises a `TypeError` when the user inadvertently\n",
      "     |      treats a `Tensor` as a boolean (most commonly in an `if` or `while`\n",
      "     |      statement), in code that was not converted by AutoGraph. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      if tf.constant(True):  # Will raise.\n",
      "     |        # ...\n",
      "     |      \n",
      "     |      if tf.constant(5) < tf.constant(7):  # Will raise.\n",
      "     |        # ...\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        `TypeError`.\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __eq__ = _tensor_equals_factory(self, other)\n",
      "     |  \n",
      "     |  __floordiv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x: typing.Annotated[_any, ~TV_GreaterEqual_T], y: typing.Annotated[_any, ~TV_GreaterEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      y = tf.constant([5, 2, 5, 10])\n",
      "     |      tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |  \n",
      "     |  __getitem__ = _slice_helper(tensor, slice_spec, var=None)\n",
      "     |      Overload for Tensor.__getitem__.\n",
      "     |      \n",
      "     |      This operation extracts the specified region from the tensor.\n",
      "     |      The notation is similar to NumPy with the restriction that\n",
      "     |      currently only support basic indexing. That means that\n",
      "     |      using a non-scalar tensor as input is not currently allowed.\n",
      "     |      \n",
      "     |      Some useful examples:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # Strip leading and trailing 2 elements\n",
      "     |      foo = tf.constant([1,2,3,4,5,6])\n",
      "     |      print(foo[2:-2])  # => [3,4]\n",
      "     |      \n",
      "     |      # Skip every other row and reverse the order of the columns\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[::2,::-1])  # => [[3,2,1], [9,8,7]]\n",
      "     |      \n",
      "     |      # Use scalar tensors as indices on both dimensions\n",
      "     |      print(foo[tf.constant(0), tf.constant(2)])  # => 3\n",
      "     |      \n",
      "     |      # Insert another dimension\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[tf.newaxis, :, :]) # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[:, tf.newaxis, :]) # => [[[1,2,3]], [[4,5,6]], [[7,8,9]]]\n",
      "     |      print(foo[:, :, tf.newaxis]) # => [[[1],[2],[3]], [[4],[5],[6]],\n",
      "     |      [[7],[8],[9]]]\n",
      "     |      \n",
      "     |      # Ellipses (3 equivalent operations)\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[tf.newaxis, :, :])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[tf.newaxis, ...])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[tf.newaxis])  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      \n",
      "     |      # Masks\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[foo > 2])  # => [3, 4, 5, 6, 7, 8, 9]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |        - `tf.newaxis` is `None` as in NumPy.\n",
      "     |        - An implicit ellipsis is placed at the end of the `slice_spec`\n",
      "     |        - NumPy advanced indexing is currently not supported.\n",
      "     |      \n",
      "     |      Purpose in the API:\n",
      "     |      \n",
      "     |        This method is exposed in TensorFlow's API so that library developers\n",
      "     |        can register dispatching for `Tensor.__getitem__` to allow it to handle\n",
      "     |        custom composite tensors & other custom objects.\n",
      "     |      \n",
      "     |        The API symbol is not intended to be called by users directly and does\n",
      "     |        appear in TensorFlow's generated documentation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: An tensor.Tensor object.\n",
      "     |        slice_spec: The arguments to Tensor.__getitem__.\n",
      "     |        var: In the case of variable slice assignment, the Variable object to slice\n",
      "     |          (i.e. tensor is the read-only view of this variable).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If a slice range is negative size.\n",
      "     |        TypeError: If the slice indices aren't int, slice, ellipsis,\n",
      "     |          tf.newaxis or scalar int32/int64 tensors.\n",
      "     |  \n",
      "     |  __gt__ = greater(x: typing.Annotated[_any, ~TV_Greater_T], y: typing.Annotated[_any, ~TV_Greater_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__ = _invert_factory(x, name=None)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __le__ = less_equal(x: typing.Annotated[_any, ~TV_LessEqual_T], y: typing.Annotated[_any, ~TV_LessEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __lt__ = less(x: typing.Annotated[_any, ~TV_Less_T], y: typing.Annotated[_any, ~TV_Less_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __matmul__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __mod__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __ne__ = _tensor_not_equals_factory(self, other)\n",
      "     |  \n",
      "     |  __neg__ = neg(x: typing.Annotated[_any, ~TV_Neg_T], name=None) -> typing.Annotated[_any, ~TV_Neg_T]\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __nonzero__(self)\n",
      "     |      Dummy method to prevent a tensor from being used as a Python `bool`.\n",
      "     |      \n",
      "     |      This is the Python 2.x counterpart to `__bool__()` above.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        `TypeError`.\n",
      "     |  \n",
      "     |  __or__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __pow__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __radd__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rand__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmod__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmul__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __ror__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __round__ = around(a, decimals=0)\n",
      "     |      TensorFlow variant of NumPy's `around`.\n",
      "     |      \n",
      "     |      Unsupported arguments: `out`.\n",
      "     |      \n",
      "     |      See the NumPy documentation for [`numpy.around`](https://numpy.org/doc/stable/reference/generated/numpy.around.html).\n",
      "     |  \n",
      "     |  __rpow__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rsub__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rxor__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __tf_tensor__(self, dtype: Optional[tensorflow.python.framework.dtypes.DType] = None, name: Optional[str] = None) -> 'Tensor'\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, signature_context)\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __xor__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  eval(self, feed_dict=None, session=None)\n",
      "     |      Evaluates this tensor in a `Session`.\n",
      "     |      \n",
      "     |      Note: If you are not using `compat.v1` libraries, you should not need this,\n",
      "     |      (or `feed_dict` or `Session`).  In eager execution (or within `tf.function`)\n",
      "     |      you do not need to call `eval`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for the operation that produces this\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `Tensor.eval()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to evaluate this tensor. If\n",
      "     |          none, the default session will be used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy array corresponding to the value of this tensor.\n",
      "     |  \n",
      "     |  experimental_ref(self)\n",
      "     |      DEPRECATED FUNCTION\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use ref() instead.\n",
      "     |  \n",
      "     |  get_shape(self) -> tensorflow.python.framework.tensor_shape.TensorShape\n",
      "     |      Returns a `tf.TensorShape` that represents the shape of this tensor.\n",
      "     |      \n",
      "     |      In eager execution the shape is always fully-known.\n",
      "     |      \n",
      "     |      >>> a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
      "     |      >>> print(a.shape)\n",
      "     |      (2, 3)\n",
      "     |      \n",
      "     |      `tf.Tensor.get_shape()` is equivalent to `tf.Tensor.shape`.\n",
      "     |      \n",
      "     |      \n",
      "     |      When executing in a `tf.function` or building a model using\n",
      "     |      `tf.keras.Input`, `Tensor.shape` may return a partial shape (including\n",
      "     |      `None` for unknown dimensions). See `tf.TensorShape` for more details.\n",
      "     |      \n",
      "     |      >>> inputs = tf.keras.Input(shape = [10])\n",
      "     |      >>> # Unknown batch size\n",
      "     |      >>> print(inputs.shape)\n",
      "     |      (None, 10)\n",
      "     |      \n",
      "     |      The shape is computed using shape inference functions that are\n",
      "     |      registered for each `tf.Operation`.\n",
      "     |      \n",
      "     |      The returned `tf.TensorShape` is determined at *build* time, without\n",
      "     |      executing the underlying kernel. It is not a `tf.Tensor`. If you need a\n",
      "     |      shape *tensor*, either convert the `tf.TensorShape` to a `tf.constant`, or\n",
      "     |      use the `tf.shape(tensor)` function, which returns the tensor's shape at\n",
      "     |      *execution* time.\n",
      "     |      \n",
      "     |      This is useful for debugging and providing early errors. For\n",
      "     |      example, when tracing a `tf.function`, no ops are being executed, shapes\n",
      "     |      may be unknown (See the [Concrete Functions\n",
      "     |      Guide](https://www.tensorflow.org/guide/concrete_function) for details).\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_matmul(a, b):\n",
      "     |      ...   result = a@b\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Result shape: \", result.shape)\n",
      "     |      ...   return result\n",
      "     |      \n",
      "     |      The shape inference functions propagate shapes to the extent possible:\n",
      "     |      \n",
      "     |      >>> f = my_matmul.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None,3]),\n",
      "     |      ...   tf.TensorSpec([3,5]))\n",
      "     |      Result shape: (None, 5)\n",
      "     |      \n",
      "     |      Tracing may fail if a shape missmatch can be detected:\n",
      "     |      \n",
      "     |      >>> cf = my_matmul.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None,3]),\n",
      "     |      ...   tf.TensorSpec([4,5]))\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Dimensions must be equal, but are 3 and 4 for 'matmul' (op:\n",
      "     |      'MatMul') with input shapes: [?,3], [4,5].\n",
      "     |      \n",
      "     |      In some cases, the inferred shape may have unknown dimensions. If\n",
      "     |      the caller has additional information about the values of these\n",
      "     |      dimensions, `tf.ensure_shape` or `Tensor.set_shape()` can be used to augment\n",
      "     |      the inferred shape.\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_fun(a):\n",
      "     |      ...   a = tf.ensure_shape(a, [5, 5])\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Result shape: \", a.shape)\n",
      "     |      ...   return a\n",
      "     |      \n",
      "     |      >>> cf = my_fun.get_concrete_function(\n",
      "     |      ...   tf.TensorSpec([None, None]))\n",
      "     |      Result shape: (5, 5)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tf.TensorShape` representing the shape of this tensor.\n",
      "     |  \n",
      "     |  ref(self)\n",
      "     |      Returns a hashable reference object to this Tensor.\n",
      "     |      \n",
      "     |      The primary use case for this API is to put tensors in a set/dictionary.\n",
      "     |      We can't put tensors in a set/dictionary as `tensor.__hash__()` is no longer\n",
      "     |      available starting Tensorflow 2.0.\n",
      "     |      \n",
      "     |      The following will raise an exception starting 2.0\n",
      "     |      \n",
      "     |      >>> x = tf.constant(5)\n",
      "     |      >>> y = tf.constant(10)\n",
      "     |      >>> z = tf.constant(10)\n",
      "     |      >>> tensor_set = {x, y, z}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      >>> tensor_dict = {x: 'five', y: 'ten'}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      \n",
      "     |      Instead, we can use `tensor.ref()`.\n",
      "     |      \n",
      "     |      >>> tensor_set = {x.ref(), y.ref(), z.ref()}\n",
      "     |      >>> x.ref() in tensor_set\n",
      "     |      True\n",
      "     |      >>> tensor_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}\n",
      "     |      >>> tensor_dict[y.ref()]\n",
      "     |      'ten'\n",
      "     |      \n",
      "     |      Also, the reference object provides `.deref()` function that returns the\n",
      "     |      original Tensor.\n",
      "     |      \n",
      "     |      >>> x = tf.constant(5)\n",
      "     |      >>> x.ref().deref()\n",
      "     |      <tf.Tensor: shape=(), dtype=int32, numpy=5>\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Updates the shape of this tensor.\n",
      "     |      \n",
      "     |      Note: It is recommended to use `tf.ensure_shape` instead of\n",
      "     |      `Tensor.set_shape`, because `tf.ensure_shape` provides better checking for\n",
      "     |      programming errors and can create guarantees for compiler\n",
      "     |      optimization.\n",
      "     |      \n",
      "     |      With eager execution this operates as a shape assertion.\n",
      "     |      Here the shapes match:\n",
      "     |      \n",
      "     |      >>> t = tf.constant([[1,2,3]])\n",
      "     |      >>> t.set_shape([1, 3])\n",
      "     |      \n",
      "     |      Passing a `None` in the new shape allows any value for that axis:\n",
      "     |      \n",
      "     |      >>> t.set_shape([1,None])\n",
      "     |      \n",
      "     |      An error is raised if an incompatible shape is passed.\n",
      "     |      \n",
      "     |      >>> t.set_shape([1,5])\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ...\n",
      "     |      ValueError: Tensor's shape (1, 3) is not compatible with supplied\n",
      "     |      shape [1, 5]\n",
      "     |      \n",
      "     |      When executing in a `tf.function`, or building a model using\n",
      "     |      `tf.keras.Input`, `Tensor.set_shape` will *merge* the given `shape` with\n",
      "     |      the current shape of this tensor, and set the tensor's shape to the\n",
      "     |      merged value (see `tf.TensorShape.merge_with` for details):\n",
      "     |      \n",
      "     |      >>> t = tf.keras.Input(shape=[None, None, 3])\n",
      "     |      >>> print(t.shape)\n",
      "     |      (None, None, None, 3)\n",
      "     |      \n",
      "     |      Dimensions set to `None` are not updated:\n",
      "     |      \n",
      "     |      >>> t.set_shape([None, 224, 224, None])\n",
      "     |      >>> print(t.shape)\n",
      "     |      (None, 224, 224, 3)\n",
      "     |      \n",
      "     |      The main use case for this is to provide additional shape information\n",
      "     |      that cannot be inferred from the graph alone.\n",
      "     |      \n",
      "     |      For example if you know all the images in a dataset have shape [28,28,3] you\n",
      "     |      can set it with `tf.set_shape`:\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def load_image(filename):\n",
      "     |      ...   raw = tf.io.read_file(filename)\n",
      "     |      ...   image = tf.image.decode_png(raw, channels=3)\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Initial shape: \", image.shape)\n",
      "     |      ...   image.set_shape([28, 28, 3])\n",
      "     |      ...   print(\"Final shape: \", image.shape)\n",
      "     |      ...   return image\n",
      "     |      \n",
      "     |      Trace the function, see the [Concrete Functions\n",
      "     |      Guide](https://www.tensorflow.org/guide/concrete_function) for details.\n",
      "     |      \n",
      "     |      >>> cf = load_image.get_concrete_function(\n",
      "     |      ...     tf.TensorSpec([], dtype=tf.string))\n",
      "     |      Initial shape:  (None, None, 3)\n",
      "     |      Final shape: (28, 28, 3)\n",
      "     |      \n",
      "     |      Similarly the `tf.io.parse_tensor` function could return a tensor with\n",
      "     |      any shape, even the `tf.rank` is unknown. If you know that all your\n",
      "     |      serialized tensors will be 2d, set it with `set_shape`:\n",
      "     |      \n",
      "     |      >>> @tf.function\n",
      "     |      ... def my_parse(string_tensor):\n",
      "     |      ...   result = tf.io.parse_tensor(string_tensor, out_type=tf.float32)\n",
      "     |      ...   # the `print` executes during tracing.\n",
      "     |      ...   print(\"Initial shape: \", result.shape)\n",
      "     |      ...   result.set_shape([None, None])\n",
      "     |      ...   print(\"Final shape: \", result.shape)\n",
      "     |      ...   return result\n",
      "     |      \n",
      "     |      Trace the function\n",
      "     |      \n",
      "     |      >>> concrete_parse = my_parse.get_concrete_function(\n",
      "     |      ...     tf.TensorSpec([], dtype=tf.string))\n",
      "     |      Initial shape:  <unknown>\n",
      "     |      Final shape:  (None, None)\n",
      "     |      \n",
      "     |      Make sure it works:\n",
      "     |      \n",
      "     |      >>> t = tf.ones([5,3], dtype=tf.float32)\n",
      "     |      >>> serialized = tf.io.serialize_tensor(t)\n",
      "     |      >>> print(serialized.dtype)\n",
      "     |      <dtype: 'string'>\n",
      "     |      >>> print(serialized.shape)\n",
      "     |      ()\n",
      "     |      >>> t2 = concrete_parse(serialized)\n",
      "     |      >>> print(t2.shape)\n",
      "     |      (5, 3)\n",
      "     |      \n",
      "     |      Caution: `set_shape` ensures that the applied shape is compatible with\n",
      "     |      the existing shape, but it does not check at runtime. Setting\n",
      "     |      incorrect shapes can result in inconsistencies between the\n",
      "     |      statically-known graph and the runtime value of tensors. For runtime\n",
      "     |      validation of the shape, use `tf.ensure_shape` instead. It also modifies\n",
      "     |      the `shape` of the tensor.\n",
      "     |      \n",
      "     |      >>> # Serialize a rank-3 tensor\n",
      "     |      >>> t = tf.ones([5,5,5], dtype=tf.float32)\n",
      "     |      >>> serialized = tf.io.serialize_tensor(t)\n",
      "     |      >>> # The function still runs, even though it `set_shape([None,None])`\n",
      "     |      >>> t2 = concrete_parse(serialized)\n",
      "     |      >>> print(t2.shape)\n",
      "     |      (5, 5, 5)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: A `TensorShape` representing the shape of this tensor, a\n",
      "     |          `TensorShapeProto`, a list, a tuple, or None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `shape` is not compatible with the current shape of\n",
      "     |          this tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ndim\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns a `tf.TensorShape` that represents the shape of this tensor.\n",
      "     |      \n",
      "     |      >>> t = tf.constant([1,2,3,4,5])\n",
      "     |      >>> t.shape\n",
      "     |      TensorShape([5])\n",
      "     |      \n",
      "     |      `tf.Tensor.shape` is equivalent to `tf.Tensor.get_shape()`.\n",
      "     |      \n",
      "     |      In a `tf.function` or when building a model using\n",
      "     |      `tf.keras.Input`, they return the build-time shape of the\n",
      "     |      tensor, which may be partially unknown.\n",
      "     |      \n",
      "     |      A `tf.TensorShape` is not a tensor. Use `tf.shape(t)` to get a tensor\n",
      "     |      containing the shape, calculated at runtime.\n",
      "     |      \n",
      "     |      See `tf.Tensor.get_shape()`, and `tf.TensorShape` for details and examples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  OVERLOADABLE_OPERATORS = {'__abs__', '__add__', '__and__', '__div__', ...\n",
      "     |  \n",
      "     |  __array_priority__ = 100\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.NativeObject:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TensorArray(builtins.object)\n",
      "     |  TensorArray(dtype, size=None, dynamic_size=None, clear_after_read=None, tensor_array_name=None, handle=None, flow=None, infer_shape=True, element_shape=None, colocate_with_first_write_call=True, name=None)\n",
      "     |  \n",
      "     |  Class wrapping dynamic-sized, per-time-step, Tensor arrays.\n",
      "     |  \n",
      "     |  This class is meant to be used with dynamic iteration primitives such as\n",
      "     |  `while_loop` and `map_fn`.  It supports gradient back-propagation via special\n",
      "     |  \"flow\" control flow dependencies.\n",
      "     |  \n",
      "     |  Note that although the array can be read multiple times and positions can be\n",
      "     |  overwritten, behavior may be undefined when storing multiple references to\n",
      "     |  the same array and clear_after_read is False. In particular, avoid using\n",
      "     |  methods like concat() to convert an intermediate TensorArray to a Tensor,\n",
      "     |  then further modifying the TensorArray, particularly if you need to backprop\n",
      "     |  through it later.\n",
      "     |  \n",
      "     |  Example 1: Plain reading and writing.\n",
      "     |  \n",
      "     |  >>> ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
      "     |  >>> ta = ta.write(0, 10)\n",
      "     |  >>> ta = ta.write(1, 20)\n",
      "     |  >>> ta = ta.write(2, 30)\n",
      "     |  >>>\n",
      "     |  >>> ta.read(0)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=10.0>\n",
      "     |  >>> ta.read(1)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=20.0>\n",
      "     |  >>> ta.read(2)\n",
      "     |  <tf.Tensor: shape=(), dtype=float32, numpy=30.0>\n",
      "     |  >>> ta.stack()\n",
      "     |  <tf.Tensor: shape=(3,), dtype=float32, numpy=array([10., 20., 30.],\n",
      "     |  dtype=float32)>\n",
      "     |  \n",
      "     |  Example 2: Fibonacci sequence algorithm that writes in a loop then returns.\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def fibonacci(n):\n",
      "     |  ...   ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
      "     |  ...   ta = ta.unstack([0., 1.])\n",
      "     |  ...\n",
      "     |  ...   for i in range(2, n):\n",
      "     |  ...     ta = ta.write(i, ta.read(i - 1) + ta.read(i - 2))\n",
      "     |  ...\n",
      "     |  ...   return ta.stack()\n",
      "     |  >>>\n",
      "     |  >>> fibonacci(7)\n",
      "     |  <tf.Tensor: shape=(7,), dtype=float32,\n",
      "     |  numpy=array([0., 1., 1., 2., 3., 5., 8.], dtype=float32)>\n",
      "     |  \n",
      "     |  Example 3: A simple loop interacting with a `tf.Variable`.\n",
      "     |  \n",
      "     |  >>> v = tf.Variable(1)\n",
      "     |  >>> @tf.function\n",
      "     |  ... def f(x):\n",
      "     |  ...   ta = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
      "     |  ...   for i in tf.range(x):\n",
      "     |  ...     v.assign_add(i)\n",
      "     |  ...     ta = ta.write(i, v)\n",
      "     |  ...   return ta.stack()\n",
      "     |  >>> f(5)\n",
      "     |  <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 1,  2,  4,  7, 11],\n",
      "     |  dtype=int32)>\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, size=None, dynamic_size=None, clear_after_read=None, tensor_array_name=None, handle=None, flow=None, infer_shape=True, element_shape=None, colocate_with_first_write_call=True, name=None)\n",
      "     |      Construct a new TensorArray or wrap an existing TensorArray handle.\n",
      "     |      \n",
      "     |      A note about the parameter `name`:\n",
      "     |      \n",
      "     |      The name of the `TensorArray` (even if passed in) is uniquified: each time\n",
      "     |      a new `TensorArray` is created at runtime it is assigned its own name for\n",
      "     |      the duration of the run.  This avoids name collisions if a `TensorArray`\n",
      "     |      is created within a `while_loop`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: (required) data type of the TensorArray.\n",
      "     |        size: (optional) int32 scalar `Tensor`: the size of the TensorArray.\n",
      "     |          Required if handle is not provided.\n",
      "     |        dynamic_size: (optional) Python bool: If true, writes to the TensorArray\n",
      "     |          can grow the TensorArray past its initial size.  Default: False.\n",
      "     |        clear_after_read: Boolean (optional, default: True).  If True, clear\n",
      "     |          TensorArray values after reading them.  This disables read-many\n",
      "     |          semantics, but allows early release of memory.\n",
      "     |        tensor_array_name: (optional) Python string: the name of the TensorArray.\n",
      "     |          This is used when creating the TensorArray handle.  If this value is\n",
      "     |          set, handle should be None.\n",
      "     |        handle: (optional) A `Tensor` handle to an existing TensorArray.  If this\n",
      "     |          is set, tensor_array_name should be None. Only supported in graph mode.\n",
      "     |        flow: (optional) A float `Tensor` scalar coming from an existing\n",
      "     |          `TensorArray.flow`. Only supported in graph mode.\n",
      "     |        infer_shape: (optional, default: True) If True, shape inference is\n",
      "     |          enabled.  In this case, all elements must have the same shape.\n",
      "     |        element_shape: (optional, default: None) A `TensorShape` object specifying\n",
      "     |          the shape constraints of each of the elements of the TensorArray. Need\n",
      "     |          not be fully defined.\n",
      "     |        colocate_with_first_write_call: If `True`, the TensorArray will be\n",
      "     |          colocated on the same device as the Tensor used on its first write\n",
      "     |          (write operations include `write`, `unstack`, and `split`).  If `False`,\n",
      "     |          the TensorArray will be placed on the device determined by the device\n",
      "     |          context available during its initialization.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if both handle and tensor_array_name are provided.\n",
      "     |        TypeError: if handle is provided but is not a Tensor.\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, _)\n",
      "     |  \n",
      "     |  close(self, name=None)\n",
      "     |      Close the current TensorArray.\n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  concat(self, name=None)\n",
      "     |      Return the values in the TensorArray as a concatenated `Tensor`.\n",
      "     |      \n",
      "     |      All of the values must have been written, their ranks must match, and\n",
      "     |      and their shapes must all match for all dimensions except the first.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        All the tensors in the TensorArray concatenated into one tensor.\n",
      "     |  \n",
      "     |  gather(self, indices, name=None)\n",
      "     |      Return selected values in the TensorArray as a packed `Tensor`.\n",
      "     |      \n",
      "     |      All of selected values must have been written and their shapes\n",
      "     |      must all match.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `1-D` `Tensor` taking values in `[0, max_value)`.  If the\n",
      "     |          `TensorArray` is not dynamic, `max_value=size()`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensors in the `TensorArray` selected by `indices`, packed into one\n",
      "     |        tensor.\n",
      "     |  \n",
      "     |  grad(self, source, flow=None, name=None)\n",
      "     |  \n",
      "     |  identity(self)\n",
      "     |      Returns a TensorArray with the same content and properties.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the control dependencies\n",
      "     |        from the contexts will become control dependencies for writes, reads, etc.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |  \n",
      "     |  read(self, index, name=None)\n",
      "     |      Read the value at location `index` in the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: 0-D.  int32 tensor with the index to read from.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensor at index `index`.\n",
      "     |  \n",
      "     |  scatter(self, indices, value, name=None)\n",
      "     |      Scatter the values of a `Tensor` in specific indices of a `TensorArray`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `1-D` `Tensor` taking values in `[0, max_value)`.  If the\n",
      "     |          `TensorArray` is not dynamic, `max_value=size()`.\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to unpack.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the scatter occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Return the size of the TensorArray.\n",
      "     |  \n",
      "     |  split(self, value, lengths, name=None)\n",
      "     |      Split the values of a `Tensor` into the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to split.\n",
      "     |        lengths: 1-D.  int32 vector with the lengths to use when splitting `value`\n",
      "     |          along its first dimension.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the split occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  stack(self, name=None)\n",
      "     |      Return the values in the TensorArray as a stacked `Tensor`.\n",
      "     |      \n",
      "     |      All of the values must have been written and their shapes must all match.\n",
      "     |      If input shapes have rank-`R`, then output shape will have rank-`(R+1)`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      \n",
      "     |      >>> ta = tf.TensorArray(tf.int32, size=3)\n",
      "     |      >>> ta = ta.write(0, tf.constant([1, 2]))\n",
      "     |      >>> ta = ta.write(1, tf.constant([3, 4]))\n",
      "     |      >>> ta = ta.write(2, tf.constant([5, 6]))\n",
      "     |      >>> ta.stack()\n",
      "     |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "     |      array([[1, 2],\n",
      "     |             [3, 4],\n",
      "     |             [5, 6]], dtype=int32)>\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        All the tensors in the TensorArray stacked into one tensor.\n",
      "     |  \n",
      "     |  unstack(self, value, name=None)\n",
      "     |      Unstack the values of a `Tensor` in the TensorArray.\n",
      "     |      \n",
      "     |      If input value shapes have rank-`R`, then the output TensorArray will\n",
      "     |      contain elements whose shapes are rank-`(R-1)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to unstack.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the unstack occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the shape inference fails.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  write(self, index, value, name=None)\n",
      "     |      Write `value` into index `index` of the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: 0-D.  int32 scalar with the index to write to.\n",
      "     |        value: N-D.  Tensor of type `dtype`.  The Tensor to write to this index.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the write occurs.\n",
      "     |        Use this object for all subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if there are more writers than specified.\n",
      "     |      \n",
      "     |      \n",
      "     |      Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The data type of this TensorArray.\n",
      "     |  \n",
      "     |  dynamic_size\n",
      "     |      Python bool; if `True` the TensorArray can grow dynamically.\n",
      "     |  \n",
      "     |  element_shape\n",
      "     |      The `tf.TensorShape` of elements in this TensorArray.\n",
      "     |  \n",
      "     |  flow\n",
      "     |      The flow `Tensor` forcing ops leading to this TensorArray state.\n",
      "     |  \n",
      "     |  handle\n",
      "     |      The reference to the TensorArray.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TensorArraySpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  TensorArraySpec(element_shape=None, dtype=tf.float32, dynamic_size=False, infer_shape=True)\n",
      "     |  \n",
      "     |  Type specification for a `tf.TensorArray`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorArraySpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, element_shape=None, dtype=tf.float32, dynamic_size=False, infer_shape=True)\n",
      "     |      Constructs a type specification for a `tf.TensorArray`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        element_shape: The shape of each element in the `TensorArray`.\n",
      "     |        dtype: Data type of the `TensorArray`.\n",
      "     |        dynamic_size: Whether the `TensorArray` can grow past its initial size.\n",
      "     |        infer_shape: Whether shape inference is enabled.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other)\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others)\n",
      "     |      Returns the most specific supertype of `self` and `others`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A Sequence of `TypeSpec`.\n",
      "     |      \n",
      "     |      Returns `None` if a supertype does not exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_value(value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TensorInfo(google._upb._message.Message, google.protobuf.message.Message)\n",
      "     |  Method resolution order:\n",
      "     |      TensorInfo\n",
      "     |      google._upb._message.Message\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CompositeTensor = <class 'tensorflow.core.protobuf.meta_graph_pb2.Comp...\n",
      "     |  \n",
      "     |  CooSparse = <class 'tensorflow.core.protobuf.meta_graph_pb2.CooSparse'...\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google._upb._message.Descriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  FromString(...) from google._upb._message.MessageMeta\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google._upb._message.Message:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Outputs a human-readable representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  RegisterExtension(field_descriptor)\n",
      "    \n",
      "    class TensorShape(tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  TensorShape(dims)\n",
      "     |  \n",
      "     |  Represents the shape of a `Tensor`.\n",
      "     |  \n",
      "     |  >>> t = tf.constant([[1,2,3],[4,5,6]])\n",
      "     |  >>> t.shape\n",
      "     |  TensorShape([2, 3])\n",
      "     |  \n",
      "     |  `TensorShape` is the *static* shape representation of a Tensor.\n",
      "     |  During eager execution a Tensor always has a fully specified shape but\n",
      "     |  when tracing a `tf.function` it may be one of the following:\n",
      "     |  \n",
      "     |  * *Fully-known shape:* has a known number of dimensions and a known size\n",
      "     |    for each dimension. e.g. `TensorShape([16, 256])`\n",
      "     |  * *Partially-known shape:* has a known number of dimensions, and an unknown\n",
      "     |    size for one or more dimension. e.g. `TensorShape([None, 256])`\n",
      "     |  * *Unknown shape:* has an unknown number of dimensions, and an unknown\n",
      "     |    size in all dimensions. e.g. `TensorShape(None)`\n",
      "     |  \n",
      "     |  During function tracing `t.shape` will return a `TensorShape` object\n",
      "     |  representing the shape of Tensor as it is known during tracing.\n",
      "     |  This static representation will be partially defined in cases where the\n",
      "     |  exact shape depends on the values within the tensors. To get the\n",
      "     |  *dynamic* representation, please use `tf.shape(t)`\n",
      "     |  which will return Tensor representing the fully defined shape of `t`.\n",
      "     |  This way, you can express logic that manipulates the shapes of tensors by\n",
      "     |  building other tensors that depend on the dynamic shape of `t`.\n",
      "     |  \n",
      "     |  Note: `tf.RaggedTensor.shape` also returns a `tf.TensorShape`,\n",
      "     |  the lengths of any ragged dimensions are unknown (`None`).\n",
      "     |  \n",
      "     |  For example, this function prints the `TensorShape' (`t.shape`), when you\n",
      "     |  trace the function, and returns a tensor `tf.shape(t)` for given input `t`:\n",
      "     |  \n",
      "     |  >>> @tf.function\n",
      "     |  ... def get_dynamic_shape(t):\n",
      "     |  ...   print(\"tracing...\")\n",
      "     |  ...   print(f\"static shape is {t.shape}\")\n",
      "     |  ...   return tf.shape(t)\n",
      "     |  \n",
      "     |  Just calling the function traces it with a fully-specified static shape:\n",
      "     |  \n",
      "     |  >>> result = get_dynamic_shape(tf.constant([[1, 1, 1], [0, 0, 0]]))\n",
      "     |  tracing...\n",
      "     |  static shape is (2, 3)\n",
      "     |  >>> result.numpy()\n",
      "     |  array([2, 3], dtype=int32)\n",
      "     |  \n",
      "     |  But `tf.function` can also trace the function with a partially specified\n",
      "     |  (or even unspecified) shape:\n",
      "     |  \n",
      "     |  >>> cf1 = get_dynamic_shape.get_concrete_function(tf.TensorSpec(\n",
      "     |  ...                                               shape=[None, 2]))\n",
      "     |  tracing...\n",
      "     |  static shape is (None, 2)\n",
      "     |  >>> cf1(tf.constant([[1., 0],[1, 0],[1, 0]])).numpy()\n",
      "     |  array([3, 2], dtype=int32)\n",
      "     |  \n",
      "     |  >>> cf2 = get_dynamic_shape.get_concrete_function(tf.TensorSpec(shape=None))\n",
      "     |  tracing...\n",
      "     |  static shape is <unknown>\n",
      "     |  >>> cf2(tf.constant([[[[[1., 0]]]]])).numpy()\n",
      "     |  array([1, 1, 1, 1, 2], dtype=int32)\n",
      "     |  \n",
      "     |  If a tensor is produced by an operation of type `\"Foo\"`, its shape\n",
      "     |  may be inferred if there is a registered shape function for\n",
      "     |  `\"Foo\"`. See [Shape\n",
      "     |  functions](https://www.tensorflow.org/guide/create_op#shape_functions_in_c)\n",
      "     |  for details of shape functions and how to register them. Alternatively,\n",
      "     |  you may set the shape explicitly using `tf.Tensor.ensure_shape`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorShape\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Returns True if this shape contains non-zero information.\n",
      "     |  \n",
      "     |  __concat__(self, other)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns True if `self` is equivalent to `other`.\n",
      "     |      \n",
      "     |      It first tries to convert `other` to `TensorShape`. `TypeError` is thrown\n",
      "     |      when the conversion fails. Otherwise, it compares each element in the\n",
      "     |      TensorShape dimensions.\n",
      "     |      \n",
      "     |      * Two *Fully known* shapes, return True iff each element is equal.\n",
      "     |      >>> t_a = tf.TensorShape([1,2])\n",
      "     |      >>> a = [1, 2]\n",
      "     |      >>> t_b = tf.TensorShape([1,2])\n",
      "     |      >>> t_c = tf.TensorShape([1,2,3])\n",
      "     |      >>> t_a.__eq__(a)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(t_b)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(t_c)\n",
      "     |      False\n",
      "     |      \n",
      "     |      * Two *Partially-known* shapes, return True iff each element is equal.\n",
      "     |      >>> p_a = tf.TensorShape([1,None])\n",
      "     |      >>> p_b = tf.TensorShape([1,None])\n",
      "     |      >>> p_c = tf.TensorShape([2,None])\n",
      "     |      >>> p_a.__eq__(p_b)\n",
      "     |      True\n",
      "     |      >>> t_a.__eq__(p_a)\n",
      "     |      False\n",
      "     |      >>> p_a.__eq__(p_c)\n",
      "     |      False\n",
      "     |      \n",
      "     |      * Two *Unknown shape*, return True.\n",
      "     |      >>> unk_a = tf.TensorShape(None)\n",
      "     |      >>> unk_b = tf.TensorShape(None)\n",
      "     |      >>> unk_a.__eq__(unk_b)\n",
      "     |      True\n",
      "     |      >>> unk_a.__eq__(t_a)\n",
      "     |      False\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TensorShape` or type that can be converted to `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the dimensions are all equal.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError if `other` can not be converted to `TensorShape`.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Returns the value of a dimension or a shape, depending on the key.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        key: If `key` is an integer, returns the dimension at that index;\n",
      "     |          otherwise if `key` is a slice, returns a TensorShape whose dimensions\n",
      "     |          are those selected by the slice from `self`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An integer if `key` is an integer, or a `TensorShape` if `key` is a\n",
      "     |        slice.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `key` is a slice and `self` is completely unknown and\n",
      "     |          the step is set.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, dims)\n",
      "     |      Creates a new TensorShape with the given dimensions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dims: A list of Dimensions, or None if the shape is unspecified.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If dims cannot be converted to a list of dimensions.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Returns `self.dims` if the rank is known, otherwise raises ValueError.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Returns the rank of this shape, or raises ValueError if unspecified.\n",
      "     |  \n",
      "     |  __nonzero__ = __bool__(self)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  as_list(self)\n",
      "     |      Returns a list of integers or `None` for each dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of integers or `None` for each dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` is an unknown shape with an unknown rank.\n",
      "     |  \n",
      "     |  as_proto(self)\n",
      "     |      Returns this shape as a `TensorShapeProto`.\n",
      "     |  \n",
      "     |  assert_has_rank(self, rank)\n",
      "     |      Raises an exception if `self` is not compatible with the given `rank`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with the given `rank`.\n",
      "     |  \n",
      "     |  assert_is_compatible_with(self, other)\n",
      "     |      Raises exception if `self` and `other` do not represent the same shape.\n",
      "     |      \n",
      "     |      This method can be used to assert that there exists a shape that both\n",
      "     |      `self` and `other` represent.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another TensorShape.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` do not represent the same shape.\n",
      "     |  \n",
      "     |  assert_is_fully_defined(self)\n",
      "     |      Raises an exception if `self` is not fully defined in every dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not have a known value for every dimension.\n",
      "     |  \n",
      "     |  assert_same_rank(self, other)\n",
      "     |      Raises an exception if `self` and `other` do not have compatible ranks.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` do not represent shapes with the\n",
      "     |          same rank.\n",
      "     |  \n",
      "     |  cast(self, value, cast_context)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  concatenate(self, other)\n",
      "     |      Returns the concatenation of the dimension in `self` and `other`.\n",
      "     |      \n",
      "     |      *N.B.* If either `self` or `other` is completely unknown,\n",
      "     |      concatenation will discard information about the other shape. In\n",
      "     |      future, we might support concatenation that preserves this\n",
      "     |      information for use with slicing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` whose dimensions are the concatenation of the\n",
      "     |        dimensions in `self` and `other`.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto\n",
      "     |      Returns a proto representation of the TensorShape instance.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns True iff `self` is compatible with `other`.\n",
      "     |      \n",
      "     |      Two possibly-partially-defined shapes are compatible if there\n",
      "     |      exists a fully-defined shape that both shapes can represent. Thus,\n",
      "     |      compatibility allows the shape inference code to reason about\n",
      "     |      partially-defined shapes. For example:\n",
      "     |      \n",
      "     |      * TensorShape(None) is compatible with all shapes.\n",
      "     |      \n",
      "     |      * TensorShape([None, None]) is compatible with all two-dimensional\n",
      "     |        shapes, such as TensorShape([32, 784]), and also TensorShape(None). It is\n",
      "     |        not compatible with, for example, TensorShape([None]) or\n",
      "     |        TensorShape([None, None, None]).\n",
      "     |      \n",
      "     |      * TensorShape([32, None]) is compatible with all two-dimensional shapes\n",
      "     |        with size 32 in the 0th dimension, and also TensorShape([None, None])\n",
      "     |        and TensorShape(None). It is not compatible with, for example,\n",
      "     |        TensorShape([32]), TensorShape([32, None, 1]) or TensorShape([64, None]).\n",
      "     |      \n",
      "     |      * TensorShape([32, 784]) is compatible with itself, and also\n",
      "     |        TensorShape([32, None]), TensorShape([None, 784]), TensorShape([None,\n",
      "     |        None]) and TensorShape(None). It is not compatible with, for example,\n",
      "     |        TensorShape([32, 1, 784]) or TensorShape([None]).\n",
      "     |      \n",
      "     |      The compatibility relation is reflexive and symmetric, but not\n",
      "     |      transitive. For example, TensorShape([32, 784]) is compatible with\n",
      "     |      TensorShape(None), and TensorShape(None) is compatible with\n",
      "     |      TensorShape([4, 4]), but TensorShape([32, 784]) is not compatible with\n",
      "     |      TensorShape([4, 4]).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another TensorShape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True iff `self` is compatible with `other`.\n",
      "     |  \n",
      "     |  is_fully_defined(self)\n",
      "     |      Returns True iff `self` is fully defined in every dimension.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True iff `self` is subtype of `other`.\n",
      "     |      \n",
      "     |      Shape A is a subtype of shape B if shape B can successfully represent it:\n",
      "     |      \n",
      "     |      * A `TensorShape` of any rank is a subtype of `TensorShape(None)`.\n",
      "     |      \n",
      "     |      *  TensorShapes of equal ranks are covariant, i.e.\n",
      "     |        `TensorShape([A1, A2, ..])` is a subtype of\n",
      "     |        `TensorShape([B1, B2, ..])` iff An is a subtype of Bn.\n",
      "     |      \n",
      "     |        An is subtype of Bn iff An == Bn or Bn is None.\n",
      "     |      \n",
      "     |      * TensorShapes of different defined ranks have no subtyping relation.\n",
      "     |      \n",
      "     |      The subtyping relation is reflexive and transitive, but not symmetric.\n",
      "     |      \n",
      "     |      Some examples:\n",
      "     |      * `TensorShape([32, 784])` is a subtype of `TensorShape(None)`, and\n",
      "     |        `TensorShape([4, 4])` is also a subtype of `TensorShape(None)` but\n",
      "     |        `TensorShape([32, 784])` and `TensorShape([4, 4])` are not subtypes of\n",
      "     |        each other.\n",
      "     |      \n",
      "     |      * All two-dimensional shapes are subtypes of `TensorShape([None, None])`,\n",
      "     |        such as `TensorShape([32, 784])`. There is no subtype relationship with,\n",
      "     |        for example, `TensorShape([None])` or `TensorShape([None, None, None])`.\n",
      "     |      \n",
      "     |      * `TensorShape([32, None])` is also a subtype of `TensorShape([None, None])`\n",
      "     |        and `TensorShape(None)`. It is not a subtype of, for example,\n",
      "     |        `TensorShape([32])`, `TensorShape([32, None, 1])`,\n",
      "     |        `TensorShape([64, None])` or `TensorShape([None, 32])`.\n",
      "     |      \n",
      "     |      * `TensorShape([32, 784])` is a subtype of itself, and also\n",
      "     |        `TensorShape([32, None])`, `TensorShape([None, 784])`,\n",
      "     |        `TensorShape([None, None])` and `TensorShape(None)`.\n",
      "     |        It has no subtype relation with, for example, `TensorShape([32, 1, 784])`\n",
      "     |        or `TensorShape([None])`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True iff `self` is subtype of `other`.\n",
      "     |  \n",
      "     |  merge_with(self, other)\n",
      "     |      Returns a `TensorShape` combining the information in `self` and `other`.\n",
      "     |      \n",
      "     |      The dimensions in `self` and `other` are merged element-wise,\n",
      "     |      according to the rules below:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      Dimension(n).merge_with(Dimension(None)) == Dimension(n)\n",
      "     |      Dimension(None).merge_with(Dimension(n)) == Dimension(n)\n",
      "     |      Dimension(None).merge_with(Dimension(None)) == Dimension(None)\n",
      "     |      # raises ValueError for n != m\n",
      "     |      Dimension(n).merge_with(Dimension(m))\n",
      "     |      ```\n",
      "     |      >> ts = tf.TensorShape([1,2])\n",
      "     |      >> ot1 = tf.TensorShape([1,2])\n",
      "     |      >> ts.merge_with(ot).as_list()\n",
      "     |      [1,2]\n",
      "     |      \n",
      "     |      >> ot2 = tf.TensorShape([1,None])\n",
      "     |      >> ts.merge_with(ot2).as_list()\n",
      "     |      [1,2]\n",
      "     |      \n",
      "     |      >> ot3 = tf.TensorShape([None, None])\n",
      "     |      >> ot3.merge_with(ot2).as_list()\n",
      "     |      [1, None]\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the combined information of `self` and\n",
      "     |        `other`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TensorShape')]\n",
      "     |      Returns the most specific supertype `TensorShape` of self and others.\n",
      "     |      \n",
      "     |      * `TensorShape([None, 1])` is the most specific `TensorShape` supertyping\n",
      "     |        both `TensorShape([2, 1])` and `TensorShape([5, 1])`. Note that\n",
      "     |        `TensorShape(None)` is also a supertype but it is not \"most specific\".\n",
      "     |      \n",
      "     |      * `TensorShape([1, 2, 3])` is the most specific `TensorShape` supertyping\n",
      "     |        both `TensorShape([1, 2, 3])` and `TensorShape([1, 2, 3]`). There are\n",
      "     |        other less specific TensorShapes that supertype above mentioned\n",
      "     |        TensorShapes, e.g. `TensorShape([1, 2, None])`, `TensorShape(None)`.\n",
      "     |      \n",
      "     |       * `TensorShape([None, None])` is the most specific `TensorShape`\n",
      "     |         supertyping both `TensorShape([2, None])` and `TensorShape([None, 3])`.\n",
      "     |         As always, `TensorShape(None)` is also a supertype but not the most\n",
      "     |         specific one.\n",
      "     |      \n",
      "     |       * `TensorShape(None`) is the only `TensorShape` supertyping both\n",
      "     |         `TensorShape([1, 2, 3])` and `TensorShape([1, 2])`. In general, any two\n",
      "     |         shapes that have different ranks will only have `TensorShape(None)`\n",
      "     |         as a common supertype.\n",
      "     |      \n",
      "     |       * `TensorShape(None)` is the only `TensorShape` supertyping both\n",
      "     |         `TensorShape([1, 2, 3])` and `TensorShape(None)`. In general, the common\n",
      "     |         supertype of any shape with `TensorShape(None)` is `TensorShape(None)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: Sequence of `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` which is the most specific supertype shape of `self`\n",
      "     |        and `others`. None if it does not exist.\n",
      "     |  \n",
      "     |  most_specific_compatible_shape(self, other) -> 'TensorShape'\n",
      "     |      Returns the most specific TensorShape compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      * TensorShape([None, 1]) is the most specific TensorShape compatible with\n",
      "     |        both TensorShape([2, 1]) and TensorShape([5, 1]). Note that\n",
      "     |        TensorShape(None) is also compatible with above mentioned TensorShapes.\n",
      "     |      \n",
      "     |      * TensorShape([1, 2, 3]) is the most specific TensorShape compatible with\n",
      "     |        both TensorShape([1, 2, 3]) and TensorShape([1, 2, 3]). There are more\n",
      "     |        less specific TensorShapes compatible with above mentioned TensorShapes,\n",
      "     |        e.g. TensorShape([1, 2, None]), TensorShape(None).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` which is the most specific compatible shape of `self`\n",
      "     |        and `other`.\n",
      "     |  \n",
      "     |  num_elements(self)\n",
      "     |      Returns the total number of elements, or none for incomplete shapes.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See tf.types.experimental.TraceType base class.\n",
      "     |  \n",
      "     |  with_rank(self, rank)\n",
      "     |      Returns a shape based on `self` with the given rank.\n",
      "     |      \n",
      "     |      This method promotes a completely unknown shape to one with a\n",
      "     |      known rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with the given rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with the given `rank`.\n",
      "     |  \n",
      "     |  with_rank_at_least(self, rank)\n",
      "     |      Returns a shape based on `self` with at least the given rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with at least the given\n",
      "     |        rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with at least the given\n",
      "     |          `rank`.\n",
      "     |  \n",
      "     |  with_rank_at_most(self, rank)\n",
      "     |      Returns a shape based on `self` with at most the given rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with at most the given\n",
      "     |        rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with at most the given\n",
      "     |          `rank`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto) -> 'TensorShape' from abc.ABCMeta\n",
      "     |      Returns a TensorShape instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.framework.tensor_shape_pb2.TensorShapeProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TensorShape serialization.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  dims\n",
      "     |      Deprecated.  Returns list of dimensions for this shape.\n",
      "     |      \n",
      "     |      Suggest `TensorShape.as_list` instead.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list containing `tf.compat.v1.Dimension`s, or None if the shape is\n",
      "     |        unspecified.\n",
      "     |  \n",
      "     |  ndims\n",
      "     |      Deprecated accessor for `rank`.\n",
      "     |  \n",
      "     |  rank\n",
      "     |      Returns the rank of this shape, or None if it is unspecified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.trace.TraceType:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TensorSpec(DenseSpec, tensorflow.python.framework.type_spec.BatchableTypeSpec, tensorflow.core.function.trace_type.serialization.Serializable, tensorflow.python.types.internal.TensorSpec)\n",
      "     |  TensorSpec(shape, dtype=tf.float32, name=None)\n",
      "     |  \n",
      "     |  Describes the type of a tf.Tensor.\n",
      "     |  \n",
      "     |  >>> t = tf.constant([[1,2,3],[4,5,6]])\n",
      "     |  >>> tf.TensorSpec.from_tensor(t)\n",
      "     |  TensorSpec(shape=(2, 3), dtype=tf.int32, name=None)\n",
      "     |  \n",
      "     |  Contains metadata for describing the nature of `tf.Tensor` objects\n",
      "     |  accepted or returned by some TensorFlow APIs.\n",
      "     |  \n",
      "     |  For example, it can be used to constrain the type of inputs accepted by\n",
      "     |  a tf.function:\n",
      "     |  \n",
      "     |  >>> @tf.function(input_signature=[tf.TensorSpec([1, None])])\n",
      "     |  ... def constrained_foo(t):\n",
      "     |  ...   print(\"tracing...\")\n",
      "     |  ...   return t\n",
      "     |  \n",
      "     |  Now the `tf.function` is able to assume that `t` is always of the type\n",
      "     |  `tf.TensorSpec([1, None])` which will avoid retracing as well as enforce the\n",
      "     |  type restriction on inputs.\n",
      "     |  \n",
      "     |  As a result, the following call with tensor of type `tf.TensorSpec([1, 2])`\n",
      "     |  triggers a trace and succeeds:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2]])).numpy()\n",
      "     |  tracing...\n",
      "     |  array([[1., 2.]], dtype=float32)\n",
      "     |  \n",
      "     |  The following subsequent call with tensor of type `tf.TensorSpec([1, 4])`\n",
      "     |  does not trigger a trace and succeeds:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2, 3, 4]])).numpy()\n",
      "     |  array([[1., 2., 3., 4.], dtype=float32)\n",
      "     |  \n",
      "     |  But the following call with tensor of type `tf.TensorSpec([2, 2])` fails:\n",
      "     |  >>> constrained_foo(tf.constant([[1., 2], [3, 4]])).numpy()\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: Binding inputs to tf.function `constrained_foo` failed ...\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorSpec\n",
      "     |      DenseSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      tensorflow.python.types.internal.TensorSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      Cast value to a tensor that is a subtype of this TensorSpec.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TensorSpecProto\n",
      "     |      Returns a proto representation of the TensorSpec instance.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_tensor)\n",
      "     |      Returns True if spec_or_tensor is compatible with this TensorSpec.\n",
      "     |      \n",
      "     |      Two tensors are considered compatible if they have the same dtype\n",
      "     |      and their shapes are compatible (see `tf.TensorShape.is_compatible_with`).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_tensor: A tf.TensorSpec or a tf.Tensor\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if spec_or_tensor is compatible with self.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other)\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Generates a graph placholder with the given TensorSpec information.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TensorSpecProto) -> 'TensorSpec' from abc.ABCMeta\n",
      "     |      Returns a TensorSpec instance based on the serialized proto.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TensorSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TensorSpec serialization.\n",
      "     |  \n",
      "     |  from_spec(spec, name=None) from abc.ABCMeta\n",
      "     |      Returns a `TensorSpec` with the same shape and dtype as `spec`.\n",
      "     |      \n",
      "     |      >>> spec = tf.TensorSpec(shape=[8, 3], dtype=tf.int32, name=\"OriginalName\")\n",
      "     |      >>> tf.TensorSpec.from_spec(spec, \"NewName\")\n",
      "     |      TensorSpec(shape=(8, 3), dtype=tf.int32, name='NewName')\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: The `TypeSpec` used to create the new `TensorSpec`.\n",
      "     |        name: The name for the new `TensorSpec`.  Defaults to `spec.name`.\n",
      "     |  \n",
      "     |  from_tensor(tensor, name=None) from abc.ABCMeta\n",
      "     |      Returns a `TensorSpec` that describes `tensor`.\n",
      "     |      \n",
      "     |      >>> tf.TensorSpec.from_tensor(tf.constant([1, 2, 3]))\n",
      "     |      TensorSpec(shape=(3,), dtype=tf.int32, name=None)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: The `tf.Tensor` that should be described.\n",
      "     |        name: A name for the `TensorSpec`.  Defaults to `tensor.op.name`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorSpec` that describes `tensor`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, shape, dtype=tf.float32, name=None)\n",
      "     |      Creates a TensorSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Value convertible to `tf.TensorShape`. The shape of the tensor.\n",
      "     |        dtype: Value convertible to `tf.DType`. The type of the tensor values.\n",
      "     |        name: Optional name for the Tensor.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If shape is not convertible to a `tf.TensorShape`, or dtype is\n",
      "     |          not convertible to a `tf.DType`.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from DenseSpec:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Returns the `dtype` of elements in the tensor.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the (optionally provided) name of the described tensor.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns the `TensorShape` that represents the shape of the tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.framework.type_spec.BatchableTypeSpec:\n",
      "     |  \n",
      "     |  __batch_encoder__ = <tensorflow.python.framework.type_spec.LegacyTypeS...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TextLineReader(ReaderBase)\n",
      "     |  TextLineReader(skip_header_lines=None, name=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the lines of a file delimited by newlines.\n",
      "     |  \n",
      "     |  Newlines are stripped from the output.\n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TextLineReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, skip_header_lines=None, name=None)\n",
      "     |      Create a TextLineReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        skip_header_lines: An optional int. Defaults to 0.  Number of lines\n",
      "     |          to skip from the beginning of every file.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class TypeSpec(tensorflow.python.types.internal.TypeSpec, tensorflow.python.types.trace.TraceType, tensorflow.core.function.trace_type.serialization.Serializable)\n",
      "     |  Specifies a TensorFlow value type.\n",
      "     |  \n",
      "     |  A `tf.TypeSpec` provides metadata describing an object accepted or returned\n",
      "     |  by TensorFlow APIs.  Concrete subclasses, such as `tf.TensorSpec` and\n",
      "     |  `tf.RaggedTensorSpec`, are used to describe different value types.\n",
      "     |  \n",
      "     |  For example, `tf.function`'s `input_signature` argument accepts a list\n",
      "     |  (or nested structure) of `TypeSpec`s.\n",
      "     |  \n",
      "     |  Creating new subclasses of `TypeSpec` (outside of TensorFlow core) is not\n",
      "     |  currently supported.  In particular, we may make breaking changes to the\n",
      "     |  private methods and properties defined by this base class.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  >>> spec = tf.TensorSpec(shape=[None, None], dtype=tf.int32)\n",
      "     |  >>> @tf.function(input_signature=[spec])\n",
      "     |  ... def double(x):\n",
      "     |  ...   return x * 2\n",
      "     |  >>> double(tf.constant([[1, 2], [3, 4]]))\n",
      "     |  <tf.Tensor: shape=(2, 2), dtype=int32,\n",
      "     |      numpy=array([[2, 4], [6, 8]], dtype=int32)>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TypeSpec\n",
      "     |      tensorflow.python.types.internal.TypeSpec\n",
      "     |      tensorflow.python.types.trace.TraceType\n",
      "     |      tensorflow.core.function.trace_type.serialization.Serializable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __tf_tracing_type__(self, context: tensorflow.python.types.trace.TracingContext) -> tensorflow.python.types.trace.TraceType\n",
      "     |      # TODO(b/154541175): Currently this usage is used to represent a Tensor\n",
      "     |      # argument not a TensorSpec argument as it should be.\n",
      "     |  \n",
      "     |  cast(self, value, casting_context)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  experimental_as_proto(self) -> tensorflow.core.protobuf.struct_pb2.TypeSpecProto\n",
      "     |      Returns a proto representation of the TypeSpec instance.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  flatten(self)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  from_tensors(self, tensors)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      Prefer using \"is_subtype_of\" and \"most_specific_common_supertype\" wherever\n",
      "     |      possible.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_value: A TypeSpec or TypeSpec associated value to compare against.\n",
      "     |  \n",
      "     |  is_subtype_of(self, other: tensorflow.python.types.trace.TraceType) -> bool\n",
      "     |      Returns True if `self` is a subtype of `other`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A TraceType object.\n",
      "     |  \n",
      "     |  most_specific_common_supertype(self, others: Sequence[tensorflow.python.types.trace.TraceType]) -> Optional[ForwardRef('TypeSpec')]\n",
      "     |      Returns the most specific supertype TypeSpec  of `self` and `others`.\n",
      "     |      \n",
      "     |      Implements the tf.types.experimental.func.TraceType interface.\n",
      "     |      \n",
      "     |      If not overridden by a subclass, the default behavior is to assume the\n",
      "     |      TypeSpec is covariant upon attributes that implement TraceType and\n",
      "     |      invariant upon rest of the attributes as well as the structure and type\n",
      "     |      of the TypeSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        others: A sequence of TraceTypes.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other: 'TypeSpec') -> 'TypeSpec'\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use most_specific_common_supertype instead.\n",
      "     |      \n",
      "     |      Deprecated. Please use `most_specific_common_supertype` instead.\n",
      "     |      Do not override this function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  placeholder_value(self, placeholder_context)\n",
      "     |      Value used for tracing a function signature with this TraceType.\n",
      "     |      \n",
      "     |      WARNING: Do not override.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        placeholder_context: A class container for context information when\n",
      "     |          creating a placeholder value.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `CompositeTensor` placeholder whose components are recursively composed\n",
      "     |          of placeholders themselves.\n",
      "     |  \n",
      "     |  to_tensors(self, value)\n",
      "     |      See TraceType base class for details. Do not override.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  experimental_from_proto(proto: tensorflow.core.protobuf.struct_pb2.TypeSpecProto) -> 'TypeSpec' from abc.ABCMeta\n",
      "     |      Returns a TypeSpec instance based on the serialized proto.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proto: Proto generated using 'experimental_as_proto'.\n",
      "     |  \n",
      "     |  experimental_type_proto() -> Type[tensorflow.core.protobuf.struct_pb2.TypeSpecProto] from abc.ABCMeta\n",
      "     |      Returns the type of proto associated with TypeSpec serialization.\n",
      "     |      \n",
      "     |      Do NOT override for custom non-TF types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |      \n",
      "     |      In particular, all values that are compatible with this TypeSpec must be an\n",
      "     |      instance of this type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'_component_specs', '_from_components...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.types.internal.TypeSpec:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class UnconnectedGradients(enum.Enum)\n",
      "     |  UnconnectedGradients(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)\n",
      "     |  \n",
      "     |  Controls how gradient computation behaves when y does not depend on x.\n",
      "     |  \n",
      "     |  The gradient of y with respect to x can be zero in two different ways: there\n",
      "     |  could be no differentiable path in the graph connecting x to y (and so we can\n",
      "     |  statically prove that the gradient is zero) or it could be that runtime values\n",
      "     |  of tensors in a particular execution lead to a gradient of zero (say, if a\n",
      "     |  relu unit happens to not be activated). To allow you to distinguish between\n",
      "     |  these two cases you can choose what value gets returned for the gradient when\n",
      "     |  there is no path in the graph from x to y:\n",
      "     |  \n",
      "     |  * `NONE`: Indicates that [None] will be returned if there is no path from x\n",
      "     |    to y\n",
      "     |  * `ZERO`: Indicates that a zero tensor will be returned in the shape of x.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnconnectedGradients\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  NONE = <UnconnectedGradients.NONE: 'none'>\n",
      "     |  \n",
      "     |  ZERO = <UnconnectedGradients.ZERO: 'zero'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __contains__(member) from enum.EnumType\n",
      "     |      Return True if member is a member of this enum\n",
      "     |      raises TypeError if member is not an enum member\n",
      "     |      \n",
      "     |      note: in 3.12 TypeError will no longer be raised, and True will also be\n",
      "     |      returned if member is the value of a member in this enum\n",
      "     |  \n",
      "     |  __getitem__(name) from enum.EnumType\n",
      "     |      Return the member matching `name`.\n",
      "     |  \n",
      "     |  __iter__() from enum.EnumType\n",
      "     |      Return members in definition order.\n",
      "     |  \n",
      "     |  __len__() from enum.EnumType\n",
      "     |      Return the number of members (no aliases)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class VarLenFeature(VarLenFeature)\n",
      "     |  VarLenFeature(dtype)\n",
      "     |  \n",
      "     |  Configuration for parsing a variable-length input feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    dtype: Data type of input.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VarLenFeature\n",
      "     |      VarLenFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.VarLenFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['VarLenFeature', 'io.VarLenFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new VarLenFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new VarLenFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  __new__(_cls, dtype)\n",
      "     |      Create new instance of VarLenFeature(dtype,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  __match_args__ = ('dtype',)\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('dtype',)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "    \n",
      "    Variable = class VariableV1(tensorflow.python.ops.variables.Variable)\n",
      "     |  Variable(*args, **kwargs)\n",
      "     |  \n",
      "     |  See the [Variables Guide](https://tensorflow.org/guide/variables).\n",
      "     |  \n",
      "     |  A variable maintains state in the graph across calls to `run()`. You add a\n",
      "     |  variable to the graph by constructing an instance of the class `Variable`.\n",
      "     |  \n",
      "     |  The `Variable()` constructor requires an initial value for the variable,\n",
      "     |  which can be a `Tensor` of any type and shape. The initial value defines the\n",
      "     |  type and shape of the variable. After construction, the type and shape of\n",
      "     |  the variable are fixed. The value can be changed using one of the assign\n",
      "     |  methods.\n",
      "     |  \n",
      "     |  If you want to change the shape of a variable later you have to use an\n",
      "     |  `assign` Op with `validate_shape=False`.\n",
      "     |  \n",
      "     |  Just like any `Tensor`, variables created with `Variable()` can be used as\n",
      "     |  inputs for other Ops in the graph. Additionally, all the operators\n",
      "     |  overloaded for the `Tensor` class are carried over to variables, so you can\n",
      "     |  also add nodes to the graph by just doing arithmetic on variables.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  import tensorflow as tf\n",
      "     |  \n",
      "     |  # Create a variable.\n",
      "     |  w = tf.Variable(<initial-value>, name=<optional-name>)\n",
      "     |  \n",
      "     |  # Use the variable in the graph like any Tensor.\n",
      "     |  y = tf.matmul(w, ...another variable or tensor...)\n",
      "     |  \n",
      "     |  # The overloaded operators are available too.\n",
      "     |  z = tf.sigmoid(w + y)\n",
      "     |  \n",
      "     |  # Assign a new value to the variable with `assign()` or a related method.\n",
      "     |  w.assign(w + 1.0)\n",
      "     |  w.assign_add(1.0)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  When you launch the graph, variables have to be explicitly initialized before\n",
      "     |  you can run Ops that use their value. You can initialize a variable by\n",
      "     |  running its *initializer op*, restoring the variable from a save file, or\n",
      "     |  simply running an `assign` Op that assigns a value to the variable. In fact,\n",
      "     |  the variable *initializer op* is just an `assign` Op that assigns the\n",
      "     |  variable's initial value to the variable itself.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Launch the graph in a session.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |      # Run the variable initializer.\n",
      "     |      sess.run(w.initializer)\n",
      "     |      # ...you now can run ops that use the value of 'w'...\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The most common initialization pattern is to use the convenience function\n",
      "     |  `global_variables_initializer()` to add an Op to the graph that initializes\n",
      "     |  all the variables. You then run that Op after launching the graph.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Add an Op to initialize global variables.\n",
      "     |  init_op = tf.compat.v1.global_variables_initializer()\n",
      "     |  \n",
      "     |  # Launch the graph in a session.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |      # Run the Op that initializes global variables.\n",
      "     |      sess.run(init_op)\n",
      "     |      # ...you can now run any Op that uses variable values...\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If you need to create a variable with an initial value dependent on another\n",
      "     |  variable, use the other variable's `initialized_value()`. This ensures that\n",
      "     |  variables are initialized in the right order.\n",
      "     |  \n",
      "     |  All variables are automatically collected in the graph where they are\n",
      "     |  created. By default, the constructor adds the new variable to the graph\n",
      "     |  collection `GraphKeys.GLOBAL_VARIABLES`. The convenience function\n",
      "     |  `global_variables()` returns the contents of that collection.\n",
      "     |  \n",
      "     |  When building a machine learning model it is often convenient to distinguish\n",
      "     |  between variables holding the trainable model parameters and other variables\n",
      "     |  such as a `global step` variable used to count training steps. To make this\n",
      "     |  easier, the variable constructor supports a `trainable=<bool>` parameter. If\n",
      "     |  `True`, the new variable is also added to the graph collection\n",
      "     |  `GraphKeys.TRAINABLE_VARIABLES`. The convenience function\n",
      "     |  `trainable_variables()` returns the contents of this collection. The\n",
      "     |  various `Optimizer` classes use this collection as the default list of\n",
      "     |  variables to optimize.\n",
      "     |  \n",
      "     |  WARNING: tf.Variable objects by default have a non-intuitive memory model. A\n",
      "     |  Variable is represented internally as a mutable Tensor which can\n",
      "     |  non-deterministically alias other Tensors in a graph. The set of operations\n",
      "     |  which consume a Variable and can lead to aliasing is undetermined and can\n",
      "     |  change across TensorFlow versions. Avoid writing code which relies on the\n",
      "     |  value of a Variable either changing or not changing as other operations\n",
      "     |  happen. For example, using Variable objects or simple functions thereof as\n",
      "     |  predicates in a `tf.cond` is dangerous and error-prone:\n",
      "     |  \n",
      "     |  ```\n",
      "     |  v = tf.Variable(True)\n",
      "     |  tf.cond(v, lambda: v.assign(False), my_false_fn)  # Note: this is broken.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Here, adding `use_resource=True` when constructing the variable will\n",
      "     |  fix any nondeterminism issues:\n",
      "     |  ```\n",
      "     |  v = tf.Variable(True, use_resource=True)\n",
      "     |  tf.cond(v, lambda: v.assign(False), my_false_fn)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  To use the replacement for variables which does\n",
      "     |  not have these issues:\n",
      "     |  \n",
      "     |  * Add `use_resource=True` when constructing `tf.Variable`;\n",
      "     |  * Call `tf.compat.v1.get_variable_scope().set_use_resource(True)` inside a\n",
      "     |    `tf.compat.v1.variable_scope` before the `tf.compat.v1.get_variable()` call.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableV1\n",
      "     |      tensorflow.python.ops.variables.Variable\n",
      "     |      tensorflow.python.trackable.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, initial_value=None, trainable=None, collections=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, expected_shape=None, import_scope=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, shape=None)\n",
      "     |      Creates a new variable with value `initial_value`.\n",
      "     |      \n",
      "     |      The new variable is added to the graph collections listed in `collections`,\n",
      "     |      which defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "     |      \n",
      "     |      If `trainable` is `True` the variable is also added to the graph collection\n",
      "     |      `GraphKeys.TRAINABLE_VARIABLES`.\n",
      "     |      \n",
      "     |      This constructor creates both a `variable` Op and an `assign` Op to set the\n",
      "     |      variable to its initial value.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
      "     |          which is the initial value for the Variable. The initial value must have\n",
      "     |          a shape specified unless `validate_shape` is set to False. Can also be a\n",
      "     |          callable with no argument that returns the initial value when called. In\n",
      "     |          that case, `dtype` must be specified. (Note that initializer functions\n",
      "     |          from init_ops.py must first be bound to a shape before being used here.)\n",
      "     |        trainable: If `True`, also adds the variable to the graph collection\n",
      "     |          `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as the default\n",
      "     |          list of variables to use by the `Optimizer` classes. Defaults to `True`,\n",
      "     |          unless `synchronization` is set to `ON_READ`, in which case it defaults\n",
      "     |          to `False`.\n",
      "     |        collections: List of graph collections keys. The new variable is added to\n",
      "     |          these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "     |        validate_shape: If `False`, allows the variable to be initialized with a\n",
      "     |          value of unknown shape. If `True`, the default, the shape of\n",
      "     |          `initial_value` must be known.\n",
      "     |        caching_device: Optional device string describing where the Variable\n",
      "     |          should be cached for reading.  Defaults to the Variable's device. If not\n",
      "     |          `None`, caches on another device.  Typical use is to cache on the device\n",
      "     |          where the Ops using the Variable reside, to deduplicate copying through\n",
      "     |          `Switch` and other conditional statements.\n",
      "     |        name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
      "     |          uniquified automatically.\n",
      "     |        variable_def: `VariableDef` protocol buffer. If not `None`, recreates the\n",
      "     |          Variable object with its contents, referencing the variable's nodes in\n",
      "     |          the graph, which must already exist. The graph is not changed.\n",
      "     |          `variable_def` and the other arguments are mutually exclusive.\n",
      "     |        dtype: If set, initial_value will be converted to the given type. If\n",
      "     |          `None`, either the datatype will be kept (if `initial_value` is a\n",
      "     |          Tensor), or `convert_to_tensor` will decide.\n",
      "     |        expected_shape: A TensorShape. If set, initial_value is expected to have\n",
      "     |          this shape.\n",
      "     |        import_scope: Optional `string`. Name scope to add to the `Variable.` Only\n",
      "     |          used when initializing from protocol buffer.\n",
      "     |        constraint: An optional projection function to be applied to the variable\n",
      "     |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |          constraints or value constraints for layer weights). The function must\n",
      "     |          take as input the unprojected Tensor representing the value of the\n",
      "     |          variable and return the Tensor for the projected value (which must have\n",
      "     |          the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |          distributed training.\n",
      "     |        use_resource: whether to use resource variables.\n",
      "     |        synchronization: Indicates when a distributed a variable will be\n",
      "     |          aggregated. Accepted values are constants defined in the class\n",
      "     |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "     |          `AUTO` and the current `DistributionStrategy` chooses when to\n",
      "     |          synchronize.\n",
      "     |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      "     |          Accepted values are constants defined in the class\n",
      "     |          `tf.VariableAggregation`.\n",
      "     |        shape: (optional) The shape of this variable. If None, the shape of\n",
      "     |          `initial_value` will be used. When setting this argument to\n",
      "     |          `tf.TensorShape(None)` (representing an unspecified shape), the variable\n",
      "     |          can be assigned with values of different shapes.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If both `variable_def` and initial_value are specified.\n",
      "     |        ValueError: If the initial value is not specified, or does not have a\n",
      "     |          shape and `validate_shape` is `True`.\n",
      "     |        RuntimeError: If eager execution is enabled.\n",
      "     |  \n",
      "     |  initialized_value(self)\n",
      "     |      Returns the value of the initialized variable. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "     |      \n",
      "     |      You should use this instead of the variable itself to initialize another\n",
      "     |      variable with a value that depends on the value of this variable.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # Initialize 'v' with a random tensor.\n",
      "     |      v = tf.Variable(tf.random.truncated_normal([10, 40]))\n",
      "     |      # Use `initialized_value` to guarantee that `v` has been\n",
      "     |      # initialized before its value is used to initialize `w`.\n",
      "     |      # The random values are picked only once.\n",
      "     |      w = tf.Variable(v.initialized_value() * 2.0)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` holding the value of this variable after its initializer\n",
      "     |        has run.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_proto(variable_def, import_scope=None)\n",
      "     |      Returns a `Variable` object created from `variable_def`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  SaveSliceInfo = <class 'tensorflow.python.ops.variables.Variable.SaveS...\n",
      "     |      Information on how to save this Variable as a slice.\n",
      "     |      \n",
      "     |      Provides internal support for saving variables as slices of a larger\n",
      "     |      variable.  This API is not public and is subject to change.\n",
      "     |      \n",
      "     |      Available properties:\n",
      "     |      \n",
      "     |      * full_name\n",
      "     |      * full_shape\n",
      "     |      * var_offset\n",
      "     |      * var_shape\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.ops.variables.Variable:\n",
      "     |  \n",
      "     |  __abs__ = _abs_factory(x, name=None)\n",
      "     |  \n",
      "     |  __add__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __and__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Compares two variables element-wise for equality.\n",
      "     |  \n",
      "     |  __floordiv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x: typing.Annotated[_any, ~TV_GreaterEqual_T], y: typing.Annotated[_any, ~TV_GreaterEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      y = tf.constant([5, 2, 5, 10])\n",
      "     |      tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6, 7])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getitem__ = _slice_helper_var(var, slice_spec)\n",
      "     |      Creates a slice helper object given a variable.\n",
      "     |      \n",
      "     |      This allows creating a sub-tensor from part of the current contents\n",
      "     |      of a variable. See `tf.Tensor.__getitem__` for detailed examples\n",
      "     |      of slicing.\n",
      "     |      \n",
      "     |      This function in addition also allows assignment to a sliced range.\n",
      "     |      This is similar to `__setitem__` functionality in Python. However,\n",
      "     |      the syntax is different so that the user can capture the assignment\n",
      "     |      operation for grouping or passing to `sess.run()` in TF1.\n",
      "     |      For example,\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      import tensorflow as tf\n",
      "     |      A = tf.Variable([[1,2,3], [4,5,6], [7,8,9]], dtype=tf.float32)\n",
      "     |      print(A[:2, :2])  # => [[1,2], [4,5]]\n",
      "     |      \n",
      "     |      A[:2,:2].assign(22. * tf.ones((2, 2))))\n",
      "     |      print(A) # => [[22, 22, 3], [22, 22, 6], [7,8,9]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Note that assignments currently do not support NumPy broadcasting\n",
      "     |      semantics.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        var: An `ops.Variable` object.\n",
      "     |        slice_spec: The arguments to `Tensor.__getitem__`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
      "     |        As an operator. The operator also has a `assign()` method\n",
      "     |        that can be used to generate an assignment operator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If a slice range is negative size.\n",
      "     |        TypeError: TypeError: If the slice indices aren't int, slice,\n",
      "     |          ellipsis, tf.newaxis or int32/int64 tensors.\n",
      "     |  \n",
      "     |  __gt__ = greater(x: typing.Annotated[_any, ~TV_Greater_T], y: typing.Annotated[_any, ~TV_Greater_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 2, 5])\n",
      "     |      tf.math.greater(x, y) ==> [False, True, True]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.greater(x, y) ==> [False, False, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__ = _invert_factory(x, name=None)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      When executing eagerly, iterates over the value of the variable.\n",
      "     |  \n",
      "     |  __le__ = less_equal(x: typing.Annotated[_any, ~TV_LessEqual_T], y: typing.Annotated[_any, ~TV_LessEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 6])\n",
      "     |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __lt__ = less(x: typing.Annotated[_any, ~TV_Less_T], y: typing.Annotated[_any, ~TV_Less_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5])\n",
      "     |      tf.math.less(x, y) ==> [False, True, False]\n",
      "     |      \n",
      "     |      x = tf.constant([5, 4, 6])\n",
      "     |      y = tf.constant([5, 6, 7])\n",
      "     |      tf.math.less(x, y) ==> [False, True, True]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __matmul__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __mod__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Compares two variables element-wise for equality.\n",
      "     |  \n",
      "     |  __neg__ = neg(x: typing.Annotated[_any, ~TV_Neg_T], name=None) -> typing.Annotated[_any, ~TV_Neg_T]\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __or__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __pow__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __radd__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rand__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmod__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rmul__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __ror__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rpow__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rsub__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rxor__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __sub__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __xor__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  assign(self, value, use_locking=False, name=None, read_value=True)\n",
      "     |      Assigns a new value to the variable.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `assign(self, value)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: A `Tensor`. The new value for this variable.\n",
      "     |        use_locking: If `True`, use locking during the assignment.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  assign_add(self, delta, use_locking=False, name=None, read_value=True)\n",
      "     |      Adds a value to this variable.\n",
      "     |      \n",
      "     |       This is essentially a shortcut for `assign_add(self, delta)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        delta: A `Tensor`. The value to add to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  assign_sub(self, delta, use_locking=False, name=None, read_value=True)\n",
      "     |      Subtracts a value from this variable.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `assign_sub(self, delta)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        delta: A `Tensor`. The value to subtract from this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable. If `read_value` is false, instead returns None in\n",
      "     |        Eager mode and the assign op in graph mode.\n",
      "     |  \n",
      "     |  batch_scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Assigns `tf.IndexedSlices` to this variable batch-wise.\n",
      "     |      \n",
      "     |      Analogous to `batch_gather`. This assumes that this variable and the\n",
      "     |      sparse_delta IndexedSlices have a series of leading dimensions that are the\n",
      "     |      same for all of them, and the updates are performed on the last dimension of\n",
      "     |      indices. In other words, the dimensions should be the following:\n",
      "     |      \n",
      "     |      `num_prefix_dims = sparse_delta.indices.ndims - 1`\n",
      "     |      `batch_dim = num_prefix_dims + 1`\n",
      "     |      `sparse_delta.updates.shape = sparse_delta.indices.shape + var.shape[\n",
      "     |           batch_dim:]`\n",
      "     |      \n",
      "     |      where\n",
      "     |      \n",
      "     |      `sparse_delta.updates.shape[:num_prefix_dims]`\n",
      "     |      `== sparse_delta.indices.shape[:num_prefix_dims]`\n",
      "     |      `== var.shape[:num_prefix_dims]`\n",
      "     |      \n",
      "     |      And the operation performed can be expressed as:\n",
      "     |      \n",
      "     |      `var[i_1, ..., i_n,\n",
      "     |           sparse_delta.indices[i_1, ..., i_n, j]] = sparse_delta.updates[\n",
      "     |              i_1, ..., i_n, j]`\n",
      "     |      \n",
      "     |      When sparse_delta.indices is a 1D tensor, this operation is equivalent to\n",
      "     |      `scatter_update`.\n",
      "     |      \n",
      "     |      To avoid this operation one can looping over the first `ndims` of the\n",
      "     |      variable and using `scatter_update` on the subtensors that result of slicing\n",
      "     |      the first dimension. This is a valid option for `ndims = 1`, but less\n",
      "     |      efficient than this implementation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  count_up_to(self, limit)\n",
      "     |      Increments this variable until it reaches `limit`. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Prefer Dataset.range instead.\n",
      "     |      \n",
      "     |      When that Op is run it tries to increment the variable by `1`. If\n",
      "     |      incrementing the variable would bring it above `limit` then the Op raises\n",
      "     |      the exception `OutOfRangeError`.\n",
      "     |      \n",
      "     |      If no error is raised, the Op outputs the value of the variable before\n",
      "     |      the increment.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `count_up_to(self, limit)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        limit: value at which incrementing the variable raises an error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the variable value before the increment. If no\n",
      "     |        other Op modifies this variable, the values produced will all be\n",
      "     |        distinct.\n",
      "     |  \n",
      "     |  eval(self, session=None)\n",
      "     |      In a session, computes and returns the value of this variable.\n",
      "     |      \n",
      "     |      This is not a graph construction method, it does not add ops to the graph.\n",
      "     |      \n",
      "     |      This convenience method requires a session where the graph\n",
      "     |      containing this variable has been launched. If no session is\n",
      "     |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
      "     |      information on launching a graph and on sessions.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      v = tf.Variable([1, 2])\n",
      "     |      init = tf.compat.v1.global_variables_initializer()\n",
      "     |      \n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |          sess.run(init)\n",
      "     |          # Usage passing the session explicitly.\n",
      "     |          print(v.eval(sess))\n",
      "     |          # Usage with the default session.  The 'with' block\n",
      "     |          # above makes 'sess' the default session.\n",
      "     |          print(v.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        session: The session to use to evaluate this variable. If none, the\n",
      "     |          default session is used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy `ndarray` with a copy of the value of this variable.\n",
      "     |  \n",
      "     |  experimental_ref(self)\n",
      "     |      DEPRECATED FUNCTION\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use ref() instead.\n",
      "     |  \n",
      "     |  gather_nd(self, indices, name=None)\n",
      "     |      Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
      "     |      \n",
      "     |      See tf.gather_nd for details.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "     |          Index tensor.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `params`.\n",
      "     |  \n",
      "     |  get_shape(self) -> tensorflow.python.framework.tensor_shape.TensorShape\n",
      "     |      Alias of `Variable.shape`.\n",
      "     |  \n",
      "     |  load(self, value, session=None)\n",
      "     |      Load new value into this variable. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "     |      \n",
      "     |      Writes new value to variable's memory. Doesn't add ops to the graph.\n",
      "     |      \n",
      "     |      This convenience method requires a session where the graph\n",
      "     |      containing this variable has been launched. If no session is\n",
      "     |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
      "     |      information on launching a graph and on sessions.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      v = tf.Variable([1, 2])\n",
      "     |      init = tf.compat.v1.global_variables_initializer()\n",
      "     |      \n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |          sess.run(init)\n",
      "     |          # Usage passing the session explicitly.\n",
      "     |          v.load([2, 3], sess)\n",
      "     |          print(v.eval(sess)) # prints [2 3]\n",
      "     |          # Usage with the default session.  The 'with' block\n",
      "     |          # above makes 'sess' the default session.\n",
      "     |          v.load([3, 4], sess)\n",
      "     |          print(v.eval()) # prints [3 4]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          value: New variable value\n",
      "     |          session: The session to use to evaluate this variable. If none, the\n",
      "     |            default session is used.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: Session is not passed and no default session\n",
      "     |  \n",
      "     |  read_value(self)\n",
      "     |      Returns the value of this variable, read in the current context.\n",
      "     |      \n",
      "     |      Can be different from value() if it's on another device, with control\n",
      "     |      dependencies, etc.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` containing the value of the variable.\n",
      "     |  \n",
      "     |  ref(self)\n",
      "     |      Returns a hashable reference object to this Variable.\n",
      "     |      \n",
      "     |      The primary use case for this API is to put variables in a set/dictionary.\n",
      "     |      We can't put variables in a set/dictionary as `variable.__hash__()` is no\n",
      "     |      longer available starting Tensorflow 2.0.\n",
      "     |      \n",
      "     |      The following will raise an exception starting 2.0\n",
      "     |      \n",
      "     |      >>> x = tf.Variable(5)\n",
      "     |      >>> y = tf.Variable(10)\n",
      "     |      >>> z = tf.Variable(10)\n",
      "     |      >>> variable_set = {x, y, z}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      >>> variable_dict = {x: 'five', y: 'ten'}\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
      "     |      \n",
      "     |      Instead, we can use `variable.ref()`.\n",
      "     |      \n",
      "     |      >>> variable_set = {x.ref(), y.ref(), z.ref()}\n",
      "     |      >>> x.ref() in variable_set\n",
      "     |      True\n",
      "     |      >>> variable_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}\n",
      "     |      >>> variable_dict[y.ref()]\n",
      "     |      'ten'\n",
      "     |      \n",
      "     |      Also, the reference object provides `.deref()` function that returns the\n",
      "     |      original Variable.\n",
      "     |      \n",
      "     |      >>> x = tf.Variable(5)\n",
      "     |      >>> x.ref().deref()\n",
      "     |      <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>\n",
      "     |  \n",
      "     |  scatter_add(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Adds `tf.IndexedSlices` to this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be added to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_div(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Divide this variable by `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to divide this variable by.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_max(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Updates this variable with the max of `tf.IndexedSlices` and itself.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to use as an argument of max with this\n",
      "     |          variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_min(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Updates this variable with the min of `tf.IndexedSlices` and itself.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to use as an argument of min with this\n",
      "     |          variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_mul(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Multiply this variable by `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to multiply this variable by.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_nd_add(self, indices, updates, name=None)\n",
      "     |      Applies sparse addition to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_add(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, 13, 3, 14, 14, 6, 7, 20]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_nd_sub(self, indices, updates, name=None)\n",
      "     |      Applies sparse subtraction to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      Assuming the variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_sub(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      After the update `v` would look like this:\n",
      "     |      \n",
      "     |          [1, -9, 3, -6, -4, 6, 7, -4]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_nd_update(self, indices, updates, name=None)\n",
      "     |      Applies sparse assignment to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          v.scatter_nd_update(indices, updates)\n",
      "     |          print(v)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, 11, 3, 10, 9, 6, 7, 12]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |  \n",
      "     |  scatter_sub(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Subtracts `tf.IndexedSlices` from this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be subtracted from this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Assigns `tf.IndexedSlices` to this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The updated variable.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Overrides the shape for this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: the `TensorShape` representing the overridden shape.\n",
      "     |  \n",
      "     |  sparse_read(self, indices, name=None)\n",
      "     |      Gather slices from params axis axis according to indices.\n",
      "     |      \n",
      "     |      This function supports a subset of tf.gather, see tf.gather for details on\n",
      "     |      usage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
      "     |          `int64`. Must be in range `[0, params.shape[axis])`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `params`.\n",
      "     |  \n",
      "     |  to_proto(self, export_scope=None)\n",
      "     |      Converts a `Variable` to a `VariableDef` protocol buffer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        export_scope: Optional `string`. Name scope to remove.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `VariableDef` protocol buffer, or `None` if the `Variable` is not\n",
      "     |        in the specified name scope.\n",
      "     |  \n",
      "     |  value(self)\n",
      "     |      Returns the last snapshot of this variable.\n",
      "     |      \n",
      "     |      You usually do not need to call this method as all ops that need the value\n",
      "     |      of the variable call it automatically through a `convert_to_tensor()` call.\n",
      "     |      \n",
      "     |      Returns a `Tensor` which holds the value of the variable.  You can not\n",
      "     |      assign a new value to this tensor as it is not a reference to the variable.\n",
      "     |      \n",
      "     |      To avoid copies, if the consumer of the returned value is on the same device\n",
      "     |      as the variable, this actually returns the live value of the variable, not\n",
      "     |      a copy.  Updates to the variable are seen by the consumer.  If the consumer\n",
      "     |      is on a different device it will get a copy of the variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` containing the value of the variable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from tensorflow.python.ops.variables.Variable:\n",
      "     |  \n",
      "     |  aggregation\n",
      "     |  \n",
      "     |  constraint\n",
      "     |      Returns the constraint function associated with this variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The constraint function that was passed to the variable constructor.\n",
      "     |        Can be `None` if no constraint was passed.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The device of this variable.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of this variable.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` of this variable.\n",
      "     |  \n",
      "     |  initial_value\n",
      "     |      Returns the Tensor used as the initial value for the variable.\n",
      "     |      \n",
      "     |      Note that this is different from `initialized_value()` which runs\n",
      "     |      the op that initializes the variable before returning its value.\n",
      "     |      This method returns the tensor that is used by the op that initializes\n",
      "     |      the variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  initializer\n",
      "     |      The initializer operation for this variable.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of this variable.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` of this variable.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The `TensorShape` of this variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape`.\n",
      "     |  \n",
      "     |  synchronization\n",
      "     |  \n",
      "     |  trainable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from tensorflow.python.ops.variables.Variable:\n",
      "     |  \n",
      "     |  __array_priority__ = 100\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class VariableAggregation(enum.Enum)\n",
      "     |  VariableAggregation(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)\n",
      "     |  \n",
      "     |  Indicates how a distributed variable will be aggregated.\n",
      "     |  \n",
      "     |  `tf.distribute.Strategy` distributes a model by making multiple copies\n",
      "     |  (called \"replicas\") acting on different elements of the input batch in a\n",
      "     |  data parallel model. When performing some variable-update operation,\n",
      "     |  for example `var.assign_add(x)`, in a model, we need to resolve how to combine\n",
      "     |  the different values for `x` computed in the different replicas.\n",
      "     |  \n",
      "     |  * `NONE`: This is the default, giving an error if you use a\n",
      "     |    variable-update operation with multiple replicas.\n",
      "     |  * `SUM`: Add the updates across replicas.\n",
      "     |  * `MEAN`: Take the arithmetic mean (\"average\") of the updates across replicas.\n",
      "     |  * `ONLY_FIRST_REPLICA`: This is for when every replica is performing the same\n",
      "     |    update, but we only want to perform the update once. Used, e.g., for the\n",
      "     |    global step counter.\n",
      "     |  \n",
      "     |  For example:\n",
      "     |  \n",
      "     |  >>> strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\n",
      "     |  >>> with strategy.scope():\n",
      "     |  ...   v = tf.Variable(5.0, aggregation=tf.VariableAggregation.MEAN)\n",
      "     |  >>> @tf.function\n",
      "     |  ... def update_fn():\n",
      "     |  ...   return v.assign_add(1.0)\n",
      "     |  >>> strategy.run(update_fn)\n",
      "     |  PerReplica:{\n",
      "     |    0: <tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
      "     |    1: <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
      "     |  }\n",
      "     |  \n",
      "     |  * `ONLY_FIRST_TOWER`: Deprecated alias for `ONLY_FIRST_REPLICA`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableAggregation\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MEAN = <VariableAggregation.MEAN: 2>\n",
      "     |  \n",
      "     |  NONE = <VariableAggregation.NONE: 0>\n",
      "     |  \n",
      "     |  ONLY_FIRST_REPLICA = <VariableAggregation.ONLY_FIRST_REPLICA: 3>\n",
      "     |  \n",
      "     |  SUM = <VariableAggregation.SUM: 1>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __contains__(member) from enum.EnumType\n",
      "     |      Return True if member is a member of this enum\n",
      "     |      raises TypeError if member is not an enum member\n",
      "     |      \n",
      "     |      note: in 3.12 TypeError will no longer be raised, and True will also be\n",
      "     |      returned if member is the value of a member in this enum\n",
      "     |  \n",
      "     |  __getitem__(name) from enum.EnumType\n",
      "     |      Return the member matching `name`.\n",
      "     |  \n",
      "     |  __iter__() from enum.EnumType\n",
      "     |      Return members in definition order.\n",
      "     |  \n",
      "     |  __len__() from enum.EnumType\n",
      "     |      Return the number of members (no aliases)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class VariableScope(builtins.object)\n",
      "     |  VariableScope(reuse, name='', initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, name_scope='', dtype=tf.float32, use_resource=None, constraint=None)\n",
      "     |  \n",
      "     |  Variable scope object to carry defaults to provide to `get_variable`.\n",
      "     |  \n",
      "     |  Many of the arguments we need for `get_variable` in a variable store are most\n",
      "     |  easily handled with a context. This object is used for the defaults.\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |    name: name of the current scope, used as prefix in get_variable.\n",
      "     |    initializer: default initializer passed to get_variable.\n",
      "     |    regularizer: default regularizer passed to get_variable.\n",
      "     |    reuse: Boolean, None, or tf.compat.v1.AUTO_REUSE, setting the reuse in\n",
      "     |      get_variable. When eager execution is enabled this argument is always\n",
      "     |      forced to be False.\n",
      "     |    caching_device: string, callable, or None: the caching device passed to\n",
      "     |      get_variable.\n",
      "     |    partitioner: callable or `None`: the partitioner passed to `get_variable`.\n",
      "     |    custom_getter: default custom getter passed to get_variable.\n",
      "     |    name_scope: The name passed to `tf.name_scope`.\n",
      "     |    dtype: default type passed to get_variable (defaults to DT_FLOAT).\n",
      "     |    use_resource: if False, create a normal Variable; if True create an\n",
      "     |      experimental ResourceVariable with well-defined semantics. Defaults to\n",
      "     |      False (will later change to True). When eager execution is enabled this\n",
      "     |      argument is always forced to be True.\n",
      "     |    constraint: An optional projection function to be applied to the variable\n",
      "     |      after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |      constraints or value constraints for layer weights). The function must\n",
      "     |      take as input the unprojected Tensor representing the value of the\n",
      "     |      variable and return the Tensor for the projected value (which must have\n",
      "     |      the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |      distributed training.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, reuse, name='', initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, name_scope='', dtype=tf.float32, use_resource=None, constraint=None)\n",
      "     |      Creates a new VariableScope with the given properties.\n",
      "     |  \n",
      "     |  get_collection(self, name)\n",
      "     |      Get this scope's variables.\n",
      "     |  \n",
      "     |  get_variable(self, var_store, name, shape=None, dtype=None, initializer=None, regularizer=None, reuse=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "     |      Gets an existing variable with this name or create a new one.\n",
      "     |  \n",
      "     |  global_variables(self)\n",
      "     |      Get this scope's global variables.\n",
      "     |  \n",
      "     |  local_variables(self)\n",
      "     |      Get this scope's local variables.\n",
      "     |  \n",
      "     |  reuse_variables(self)\n",
      "     |      Reuse variables in this scope.\n",
      "     |  \n",
      "     |  set_caching_device(self, caching_device)\n",
      "     |      Set caching_device for this scope.\n",
      "     |  \n",
      "     |  set_custom_getter(self, custom_getter)\n",
      "     |      Set custom getter for this scope.\n",
      "     |  \n",
      "     |  set_dtype(self, dtype)\n",
      "     |      Set data type for this scope.\n",
      "     |  \n",
      "     |  set_initializer(self, initializer)\n",
      "     |      Set initializer for this scope.\n",
      "     |  \n",
      "     |  set_partitioner(self, partitioner)\n",
      "     |      Set partitioner for this scope.\n",
      "     |  \n",
      "     |  set_regularizer(self, regularizer)\n",
      "     |      Set regularizer for this scope.\n",
      "     |  \n",
      "     |  set_use_resource(self, use_resource)\n",
      "     |      Sets whether to use ResourceVariables for this scope.\n",
      "     |  \n",
      "     |  trainable_variables(self)\n",
      "     |      Get this scope's trainable variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  caching_device\n",
      "     |  \n",
      "     |  constraint\n",
      "     |  \n",
      "     |  custom_getter\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  initializer\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  original_name_scope\n",
      "     |  \n",
      "     |  partitioner\n",
      "     |  \n",
      "     |  regularizer\n",
      "     |  \n",
      "     |  reuse\n",
      "     |  \n",
      "     |  use_resource\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class VariableSynchronization(enum.Enum)\n",
      "     |  VariableSynchronization(value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)\n",
      "     |  \n",
      "     |  Indicates when a distributed variable will be synced.\n",
      "     |  \n",
      "     |  * `AUTO`: Indicates that the synchronization will be determined by the current\n",
      "     |    `DistributionStrategy` (eg. With `MirroredStrategy` this would be\n",
      "     |    `ON_WRITE`).\n",
      "     |  * `NONE`: Indicates that there will only be one copy of the variable, so\n",
      "     |    there is no need to sync.\n",
      "     |  * `ON_WRITE`: Indicates that the variable will be updated across devices\n",
      "     |    every time it is written.\n",
      "     |  * `ON_READ`: Indicates that the variable will be aggregated across devices\n",
      "     |    when it is read (eg. when checkpointing or when evaluating an op that uses\n",
      "     |    the variable).\n",
      "     |  \n",
      "     |    Example:\n",
      "     |  >>> temp_grad=[tf.Variable([0.], trainable=False,\n",
      "     |  ...                      synchronization=tf.VariableSynchronization.ON_READ,\n",
      "     |  ...                      aggregation=tf.VariableAggregation.MEAN\n",
      "     |  ...                      )]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableSynchronization\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AUTO = <VariableSynchronization.AUTO: 0>\n",
      "     |  \n",
      "     |  NONE = <VariableSynchronization.NONE: 1>\n",
      "     |  \n",
      "     |  ON_READ = <VariableSynchronization.ON_READ: 3>\n",
      "     |  \n",
      "     |  ON_WRITE = <VariableSynchronization.ON_WRITE: 2>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __contains__(member) from enum.EnumType\n",
      "     |      Return True if member is a member of this enum\n",
      "     |      raises TypeError if member is not an enum member\n",
      "     |      \n",
      "     |      note: in 3.12 TypeError will no longer be raised, and True will also be\n",
      "     |      returned if member is the value of a member in this enum\n",
      "     |  \n",
      "     |  __getitem__(name) from enum.EnumType\n",
      "     |      Return the member matching `name`.\n",
      "     |  \n",
      "     |  __iter__() from enum.EnumType\n",
      "     |      Return members in definition order.\n",
      "     |  \n",
      "     |  __len__() from enum.EnumType\n",
      "     |      Return the number of members (no aliases)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class WholeFileReader(ReaderBase)\n",
      "     |  WholeFileReader(name=None)\n",
      "     |  \n",
      "     |  A Reader that outputs the entire contents of a file as a value.\n",
      "     |  \n",
      "     |  To use, enqueue filenames in a Queue.  The output of Read will\n",
      "     |  be a filename (key) and the contents of that file (value).\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WholeFileReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Create a WholeFileReader. (deprecated)\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ReaderBase:\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    constant_initializer = class Constant(Initializer)\n",
      "     |  constant_initializer(value=0, dtype=tf.float32, verify_shape=False)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with constant values.\n",
      "     |  \n",
      "     |  The resulting tensor is populated with values of type `dtype`, as\n",
      "     |  specified by arguments `value` following the desired `shape` of the\n",
      "     |  new tensor (see examples below).\n",
      "     |  \n",
      "     |  The argument `value` can be a constant value, or a list of values of type\n",
      "     |  `dtype`. If `value` is a list, then the length of the list must be less\n",
      "     |  than or equal to the number of elements implied by the desired shape of the\n",
      "     |  tensor. In the case where the total number of elements in `value` is less\n",
      "     |  than the number of elements required by the tensor shape, the last element\n",
      "     |  in `value` will be used to fill the remaining entries. If the total number of\n",
      "     |  elements in `value` is greater than the number of elements required by the\n",
      "     |  tensor shape, the initializer will raise a `ValueError`.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    value: A Python scalar, list or tuple of values, or a N-dimensional numpy\n",
      "     |      array. All elements of the initialized variable will be set to the\n",
      "     |      corresponding value in the `value` argument.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer.\n",
      "     |    verify_shape: Boolean that enables verification of the shape of `value`. If\n",
      "     |      `True`, the initializer will throw an error if the shape of `value` is not\n",
      "     |      compatible with the shape of the initialized tensor.\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |    TypeError: If the input `value` is not one of the expected types.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |    The following example can be rewritten using a numpy.ndarray instead\n",
      "     |    of the `value` list, even reshaped, as shown in the two commented lines\n",
      "     |    below the `value` list initialization.\n",
      "     |  \n",
      "     |  >>> value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "     |  >>> init = tf.compat.v1.constant_initializer(value)\n",
      "     |  >>> # fitting shape\n",
      "     |  >>> with tf.compat.v1.Session():\n",
      "     |  ...   x = tf.compat.v1.get_variable('x', shape=[2, 4], initializer=init)\n",
      "     |  ...   x.initializer.run()\n",
      "     |  ...   print(x.eval())\n",
      "     |  [[0. 1. 2. 3.]\n",
      "     |   [4. 5. 6. 7.]]\n",
      "     |  >>> # Larger shape\n",
      "     |  >>> with tf.compat.v1.Session():\n",
      "     |  ...   y = tf.compat.v1.get_variable('y', shape=[3, 4], initializer=init)\n",
      "     |  ...   y.initializer.run()\n",
      "     |  ...   print(y.eval())\n",
      "     |  [[0.  1.  2.  3.]\n",
      "     |   [4.  5.  6.  7.]\n",
      "     |   [7.  7.  7.  7.]]\n",
      "     |  >>> # Smaller shape\n",
      "     |  >>> with tf.compat.v1.Session():\n",
      "     |  ...   z = tf.compat.v1.get_variable('z', shape=[2, 3], initializer=init)\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  ValueError: Too many elements provided. Needed at most 6, but received 8\n",
      "     |  >>> # Shape verification\n",
      "     |  >>> init_verify = tf.compat.v1.constant_initializer(value, verify_shape=True)\n",
      "     |  >>> with tf.compat.v1.Session():\n",
      "     |  ...  u = tf.compat.v1.get_variable('u', shape=[3, 4],\n",
      "     |  ...                                initializer=init_verify)\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: Expected Tensor's shape: (3, 4), got (8,).\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy API endpoint, `tf.compat.v1.constant_initializer`\n",
      "     |  is compatible with eager execution and `tf.function`.\n",
      "     |  \n",
      "     |  To migrate to a non-legacy TF2 API, please use `tf.constant_initializer`\n",
      "     |  instead. The `dtype`\n",
      "     |  argument in `tf.compat.v1.constant_initializer.__init__()` does not exist in\n",
      "     |  `tf.constant_initializer.__init__()`. However, you can specify the `dtype` in\n",
      "     |  `__call__()` in both cases.\n",
      "     |  \n",
      "     |  In the `compat.v1` symbol, if `verify_shape` is set to `True`, an exception\n",
      "     |  is raised when initializing a variable with a different shape from\n",
      "     |  `value`. If set to `False`, `value` is reshaped to initialize the variable\n",
      "     |  if necessary. An exception would only be raised when the number of\n",
      "     |  elements are different.\n",
      "     |  \n",
      "     |  The `verify_shape` argument is not supported in TF2. Using\n",
      "     |  `tf.constant_initializer` is equivalent to setting `verify_shape` to `False`.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "     |  initializer = tf.compat.v1.constant_initializer(\n",
      "     |      value=value,\n",
      "     |      dtype=tf.float32,\n",
      "     |      verify_shape=False)\n",
      "     |  variable = tf.Variable(initializer(shape=[2, 4]))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "     |  initializer = tf.constant_initializer(value=value)\n",
      "     |  tf.Variable(initializer(shape=[2, 4], dtype=tf.float32))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name          | TF2 Arg Name     | Note                        |\n",
      "     |  | :-------------------- | :--------------- | :-------------------------- |\n",
      "     |  | `value`               | `value`          | In constructor              |\n",
      "     |  | `dtype`               | `dtype`          | In `__call__()` method      |\n",
      "     |  | `verify_shape`        | Not Supported    | Equivalent to set to `False`|\n",
      "     |  | `partition_info`      | - |  (`__call__` arg in TF1) Not supported     |\n",
      "     |  \n",
      "     |  \n",
      "     |  #### Before & After Usage Example\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  >>> value = [1., 2., 3., 4.]\n",
      "     |  >>> initializer = tf.compat.v1.constant_initializer(\n",
      "     |  ...     value=value, dtype=tf.float32, verify_shape=True)\n",
      "     |  >>> tf.Variable(initializer(shape=[2, 2])).numpy()\n",
      "     |  Traceback (most recent call last):\n",
      "     |  ...\n",
      "     |  TypeError: Expected Tensor's shape: (2, 2), got (4,).\n",
      "     |  >>> initializer = tf.compat.v1.constant_initializer(\n",
      "     |  ...     value=value, dtype=tf.float32, verify_shape=False)\n",
      "     |  >>> tf.Variable(initializer(shape=[2, 2])).numpy()\n",
      "     |  array([[1., 2.],\n",
      "     |         [3., 4.]], dtype=float32)\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  >>> value = [1., 2., 3., 4.]\n",
      "     |  >>> initializer = tf.constant_initializer(value=value)\n",
      "     |  >>> tf.Variable(initializer(shape=[2, 2], dtype=tf.float32)).numpy()\n",
      "     |  array([[1., 2.],\n",
      "     |         [3., 4.]], dtype=float32)\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Constant\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None, verify_shape=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, value=0, dtype=tf.float32, verify_shape=False)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(verify_shape)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Objects must now be the required shape or no shape can be specified\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    glorot_normal_initializer = class GlorotNormal(VarianceScaling)\n",
      "     |  glorot_normal_initializer(seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  The Glorot normal initializer, also called Xavier normal initializer.\n",
      "     |  \n",
      "     |  It draws samples from a truncated normal distribution centered on 0\n",
      "     |  with standard deviation (after truncation) given by\n",
      "     |  `stddev = sqrt(2 / (fan_in + fan_out))` where `fan_in` is the number\n",
      "     |  of input units in the weight tensor and `fan_out` is the number of\n",
      "     |  output units in the weight tensor.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)\n",
      "     |      ([pdf](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlorotNormal\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarianceScaling:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    glorot_uniform_initializer = class GlorotUniform(VarianceScaling)\n",
      "     |  glorot_uniform_initializer(seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  The Glorot uniform initializer, also called Xavier uniform initializer.\n",
      "     |  \n",
      "     |  It draws samples from a uniform distribution within [-limit, limit]\n",
      "     |  where `limit` is `sqrt(6 / (fan_in + fan_out))`\n",
      "     |  where `fan_in` is the number of input units in the weight tensor\n",
      "     |  and `fan_out` is the number of output units in the weight tensor.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)\n",
      "     |      ([pdf](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlorotUniform\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarianceScaling:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    name_scope = class name_scope_v1(contextlib.AbstractContextManager)\n",
      "     |  name_scope(name, default_name=None, values=None) -> None\n",
      "     |  \n",
      "     |  A context manager for use when defining a Python op.\n",
      "     |  \n",
      "     |  This context manager validates that the given `values` are from the\n",
      "     |  same graph, makes that graph the default graph, and pushes a\n",
      "     |  name scope in that graph (see\n",
      "     |  `tf.Graph.name_scope`\n",
      "     |  for more details on that).\n",
      "     |  \n",
      "     |  For example, to define a new Python op called `my_op`:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  def my_op(a, b, c, name=None):\n",
      "     |    with tf.name_scope(name, \"MyOp\", [a, b, c]) as scope:\n",
      "     |      a = tf.convert_to_tensor(a, name=\"a\")\n",
      "     |      b = tf.convert_to_tensor(b, name=\"b\")\n",
      "     |      c = tf.convert_to_tensor(c, name=\"c\")\n",
      "     |      # Define some computation that uses `a`, `b`, and `c`.\n",
      "     |      return foo_op(..., name=scope)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      name_scope_v1\n",
      "     |      contextlib.AbstractContextManager\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self) -> Optional[str]\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  __exit__(self, *exc_info) -> Optional[bool]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __init__(self, name, default_name=None, values=None) -> None\n",
      "     |      Initialize the context manager.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name argument that is passed to the op function.\n",
      "     |        default_name: The default name to use if the `name` argument is `None`.\n",
      "     |        values: The list of `Tensor` arguments that are passed to the op function.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `default_name` is passed in but not a string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __orig_bases__ = (contextlib.AbstractContextManager[typing.Optional[st...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractContextManager:\n",
      "     |  \n",
      "     |  __class_getitem__ = GenericAlias(...) from abc.ABCMeta\n",
      "     |      Represent a PEP 585 generic type\n",
      "     |      \n",
      "     |      E.g. for t = list[int], t.__origin__ is list and t.__args__ is (int,).\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    ones_initializer = class Ones(Initializer)\n",
      "     |  ones_initializer(dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors initialized to 1.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  This API is compatible with TF2 behavior and `tf.function`, and can be\n",
      "     |  migrated immediately with `tf.keras.initializers.ones`.\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  >>> initializer = tf.compat.v1.keras.initializers.ones()\n",
      "     |  >>> initializer((1, 1))\n",
      "     |  <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.]], dtype=float32)>\n",
      "     |  \n",
      "     |  After:\n",
      "     |  >>> initializer = tf.keras.initializers.ones()\n",
      "     |  >>> initializer((1, 1))\n",
      "     |  <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.]], dtype=float32)>\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Ones\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    orthogonal_initializer = class Orthogonal(Initializer)\n",
      "     |  orthogonal_initializer(gain=1.0, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates an orthogonal matrix.\n",
      "     |  \n",
      "     |  If the shape of the tensor to initialize is two-dimensional, it is initialized\n",
      "     |  with an orthogonal matrix obtained from the QR decomposition of a matrix of\n",
      "     |  random numbers drawn from a normal distribution.\n",
      "     |  If the matrix has fewer rows than columns then the output will have orthogonal\n",
      "     |  rows. Otherwise, the output will have orthogonal columns.\n",
      "     |  \n",
      "     |  If the shape of the tensor to initialize is more than two-dimensional,\n",
      "     |  a matrix of shape `(shape[0] * ... * shape[n - 2], shape[n - 1])`\n",
      "     |  is initialized, where `n` is the length of the shape vector.\n",
      "     |  The matrix is subsequently reshaped to give a tensor of the desired shape.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    gain: multiplicative factor to apply to the orthogonal matrix\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Saxe et al., 2014](https://openreview.net/forum?id=_wzZwKpTDF_9C)\n",
      "     |      ([pdf](https://arxiv.org/pdf/1312.6120.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Orthogonal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, gain=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    random_normal_initializer = class RandomNormal(Initializer)\n",
      "     |  random_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with a normal distribution.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    mean: a python scalar or a scalar tensor. Mean of the random values to\n",
      "     |      generate.\n",
      "     |    stddev: a python scalar or a scalar tensor. Standard deviation of the random\n",
      "     |      values to generate.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy `compat.v1` API, this symbol is compatible with eager\n",
      "     |  execution and `tf.function`.\n",
      "     |  \n",
      "     |  To switch to TF2, switch to using either\n",
      "     |  `tf.initializers.RandomNormal` or `tf.keras.initializers.RandomNormal`\n",
      "     |  (neither from `compat.v1`) and\n",
      "     |  pass the dtype when calling the initializer. Keep in mind that\n",
      "     |  the default stddev and the behavior of fixed seeds have changed.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.random_normal_initializer(\n",
      "     |    mean=mean,\n",
      "     |    stddev=stddev,\n",
      "     |    seed=seed,\n",
      "     |    dtype=dtype)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.initializers.RandomNormal(\n",
      "     |    mean=mean,\n",
      "     |    seed=seed,\n",
      "     |    stddev=stddev)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one, dtype=dtype))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two, dtype=dtype))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name       | TF2 Arg Name    | Note                       |\n",
      "     |  | :----------------- | :-------------- | :------------------------- |\n",
      "     |  | `mean`             | `mean`          | No change to defaults |\n",
      "     |  | `stddev`           | `stddev`        | Default changes from 1.0 to 0.05 |\n",
      "     |  | `seed`             | `seed`          |                                  |\n",
      "     |  | `dtype`            | `dtype`  | The TF2 native api only takes it as a |\n",
      "     |  :                    :          : `__call__` arg, not a constructor arg. :\n",
      "     |  | `partition_info`   | -     |  (`__call__` arg in TF1) Not supported.  |\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomNormal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    random_uniform_initializer = class RandomUniform(Initializer)\n",
      "     |  random_uniform_initializer(minval=0.0, maxval=None, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors with a uniform distribution.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    minval: A python scalar or a scalar tensor. Lower bound of the range of\n",
      "     |      random values to generate.\n",
      "     |    maxval: A python scalar or a scalar tensor. Upper bound of the range of\n",
      "     |      random values to generate.  Defaults to 1 for float types.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy compat.v1 API, this symbol is compatible with eager\n",
      "     |  execution and `tf.function`.\n",
      "     |  \n",
      "     |  To switch to TF2, switch to using either\n",
      "     |  `tf.initializers.RandomUniform` or `tf.keras.initializers.RandomUniform`\n",
      "     |  (neither from `compat.v1`) and\n",
      "     |  pass the dtype when calling the initializer. Keep in mind that\n",
      "     |  the default minval, maxval and the behavior of fixed seeds have changed.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.random_uniform_initializer(\n",
      "     |    minval=minval,\n",
      "     |    maxval=maxval,\n",
      "     |    seed=seed,\n",
      "     |    dtype=dtype)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.initializers.RandomUniform(\n",
      "     |    minval=minval,\n",
      "     |    maxval=maxval,\n",
      "     |    seed=seed)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one, dtype=dtype))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two, dtype=dtype))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "     |  | :-------------------- | :-------------- | :------------------------- |\n",
      "     |  | `minval`               | `minval`    | Default changes from 0 to -0.05 |\n",
      "     |  | `maxval`         | `maxval`        | Default changes from 1.0 to 0.05 |\n",
      "     |  | `seed`             | `seed` |  |\n",
      "     |  | `dtype` | `dtype`   | The TF2 native api only takes it  |\n",
      "     |  :                     :      : as a `__call__` arg, not a constructor arg. :\n",
      "     |  | `partition_info`     | - |  (`__call__` arg in TF1) Not supported       |\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomUniform\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, minval=0.0, maxval=None, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    truncated_normal_initializer = class TruncatedNormal(Initializer)\n",
      "     |  truncated_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates a truncated normal distribution.\n",
      "     |  \n",
      "     |  These values are similar to values from a `random_normal_initializer`\n",
      "     |  except that values more than two standard deviations from the mean\n",
      "     |  are discarded and re-drawn. This is the recommended initializer for\n",
      "     |  neural network weights and filters.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    mean: a python scalar or a scalar tensor. Mean of the random values to\n",
      "     |      generate.\n",
      "     |    stddev: a python scalar or a scalar tensor. Standard deviation of the random\n",
      "     |      values to generate.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy `compat.v1` API, this symbol is compatible with eager\n",
      "     |  execution and `tf.function`.\n",
      "     |  \n",
      "     |  To switch to TF2, switch to using either\n",
      "     |  `tf.initializers.truncated_normal` or `tf.keras.initializers.TruncatedNormal`\n",
      "     |  (neither from `compat.v1`) and\n",
      "     |  pass the dtype when calling the initializer. Keep in mind that\n",
      "     |  the default stddev and the behavior of fixed seeds have changed.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.truncated_normal_initializer(\n",
      "     |    mean=mean,\n",
      "     |    stddev=stddev,\n",
      "     |    seed=seed,\n",
      "     |    dtype=dtype)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.initializers.truncated_normal(\n",
      "     |    mean=mean,\n",
      "     |    seed=seed,\n",
      "     |    stddev=stddev)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one, dtype=dtype))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two, dtype=dtype))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "     |  | :-------------------- | :-------------- | :------------------------- |\n",
      "     |  | `mean`               | `mean`        | No change to defaults |\n",
      "     |  | `stddev`         | `stddev`        | Default changes from 1.0 to 0.05 |\n",
      "     |  | `seed`             | `seed` | |\n",
      "     |  | `dtype` | `dtype`   | The TF2 native api only takes it  |\n",
      "     |  :                     :      : as a `__call__` arg, not a constructor arg. :\n",
      "     |  | `partition_info`     | - |  (`__call__` arg in TF1) Not supported       |\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TruncatedNormal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    uniform_unit_scaling_initializer = class UniformUnitScaling(Initializer)\n",
      "     |  uniform_unit_scaling_initializer(factor=1.0, seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors without scaling variance.\n",
      "     |  \n",
      "     |  When initializing a deep network, it is in principle advantageous to keep\n",
      "     |  the scale of the input variance constant, so it does not explode or diminish\n",
      "     |  by reaching the final layer. If the input is `x` and the operation `x * W`,\n",
      "     |  and we want to initialize `W` uniformly at random, we need to pick `W` from\n",
      "     |  \n",
      "     |      [-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]\n",
      "     |  \n",
      "     |  to keep the scale intact, where `dim = W.shape[0]` (the size of the input).\n",
      "     |  A similar calculation for convolutional networks gives an analogous result\n",
      "     |  with `dim` equal to the product of the first 3 dimensions.  When\n",
      "     |  nonlinearities are present, we need to multiply this by a constant `factor`.\n",
      "     |  See (Sussillo et al., 2014) for deeper motivation, experiments\n",
      "     |  and the calculation of constants. In section 2.3 there, the constants were\n",
      "     |  numerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    factor: Float.  A multiplicative factor by which the values will be scaled.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Sussillo et al., 2014](https://arxiv.org/abs/1412.6558)\n",
      "     |      ([pdf](http://arxiv.org/pdf/1412.6558.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UniformUnitScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, factor=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    class variable_scope(builtins.object)\n",
      "     |  variable_scope(name_or_scope, default_name=None, values=None, initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, reuse=None, dtype=None, use_resource=None, constraint=None, auxiliary_name_scope=True)\n",
      "     |  \n",
      "     |  A context manager for defining ops that creates variables (layers).\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy `compat.v1` api,\n",
      "     |  `tf.compat.v1.variable_scope` is mostly compatible with eager\n",
      "     |  execution and `tf.function` as long as you combine it with the\n",
      "     |  `tf.compat.v1.keras.utils.track_tf1_style_variables` decorator (though\n",
      "     |  it will behave as if reuse is always set to `AUTO_REUSE`.)\n",
      "     |  \n",
      "     |  See the\n",
      "     |  [model migration guide](\n",
      "     |      https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "     |  for more info on\n",
      "     |  migrating code that relies on `variable_scope`-based variable reuse.\n",
      "     |  \n",
      "     |  When you use it with eager execution enabled but without\n",
      "     |  `tf.compat.v1.keras.utils.track_tf1_style_variables`,\n",
      "     |  `tf.compat.v1.variable_scope` will still be able to prefix the names\n",
      "     |  of variables created within the scope but it will not enable variable reuse\n",
      "     |  or error-raising checks around variable reuse (`get_variable` calls within\n",
      "     |  it would always create new variables).\n",
      "     |  \n",
      "     |  Once you have switched away from `get_variable`-based variable reuse\n",
      "     |  mechanisms, to switch to TF2 APIs you can just use\n",
      "     |  `tf.name_scope` to prefix variable names.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  This context manager validates that the (optional) `values` are from the same\n",
      "     |  graph, ensures that graph is the default graph, and pushes a name scope and a\n",
      "     |  variable scope.\n",
      "     |  \n",
      "     |  If `name_or_scope` is not None, it is used as is. If `name_or_scope` is None,\n",
      "     |  then `default_name` is used.  In that case, if the same name has been\n",
      "     |  previously used in the same scope, it will be made unique by appending `_N`\n",
      "     |  to it.\n",
      "     |  \n",
      "     |  Variable scope allows you to create new variables and to share already created\n",
      "     |  ones while providing checks to not create or share by accident. For details,\n",
      "     |  see the [Variable Scope How To](https://tensorflow.org/guide/variables), here\n",
      "     |  we present only a few basic examples.\n",
      "     |  \n",
      "     |  The Variable Scope works as expected when the Eager Execution is Disabled.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  tf.compat.v1.disable_eager_execution()\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Simple example of how to create a new variable:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      with tf.compat.v1.variable_scope(\"bar\"):\n",
      "     |          v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |          assert v.name == \"foo/bar/v:0\"\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Simple example of how to reenter a premade variable scope safely:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\") as vs:\n",
      "     |    pass\n",
      "     |  \n",
      "     |  # Re-enter the variable scope.\n",
      "     |  with tf.compat.v1.variable_scope(vs,\n",
      "     |                         auxiliary_name_scope=False) as vs1:\n",
      "     |    # Restore the original name_scope.\n",
      "     |    with tf.name_scope(vs1.original_name_scope):\n",
      "     |        v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |        assert v.name == \"foo/v:0\"\n",
      "     |        c = tf.constant([1], name=\"c\")\n",
      "     |        assert c.name == \"foo/c:0\"\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Keep in mind that the counters for `default_name` are discarded once the\n",
      "     |  parent scope is exited. Therefore when the code re-enters the scope (for\n",
      "     |  instance by saving it), all nested default_name counters will be restarted.\n",
      "     |  \n",
      "     |  For instance:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\") as vs:\n",
      "     |    with tf.compat.v1.variable_scope(None, default_name=\"bar\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"a\", [1])\n",
      "     |      assert v.name == \"foo/bar/a:0\", v.name\n",
      "     |    with tf.compat.v1.variable_scope(None, default_name=\"bar\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"b\", [1])\n",
      "     |      assert v.name == \"foo/bar_1/b:0\"\n",
      "     |  \n",
      "     |  with tf.compat.v1.variable_scope(vs):\n",
      "     |    with tf.compat.v1.variable_scope(None, default_name=\"bar\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"c\", [1])\n",
      "     |      assert v.name == \"foo/bar/c:0\"   # Uses bar instead of bar_2!\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Basic example of sharing a variable AUTO_REUSE:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  def foo():\n",
      "     |    with tf.compat.v1.variable_scope(\"foo\", reuse=tf.compat.v1.AUTO_REUSE):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |    return v\n",
      "     |  \n",
      "     |  v1 = foo()  # Creates v.\n",
      "     |  v2 = foo()  # Gets the same, existing v.\n",
      "     |  assert v1 == v2\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Basic example of sharing a variable with reuse=True:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\", reuse=True):\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  assert v1 == v\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Sharing a variable by capturing a scope and setting reuse:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\") as scope:\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      scope.reuse_variables()\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  assert v1 == v\n",
      "     |  ```\n",
      "     |  \n",
      "     |  To prevent accidental sharing of variables, we raise an exception when getting\n",
      "     |  an existing variable in a non-reusing scope.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      #  Raises ValueError(\"... v already exists ...\").\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Similarly, we raise an exception when trying to get a variable that does not\n",
      "     |  exist in reuse mode.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\", reuse=True):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      #  Raises ValueError(\"... v does not exists ...\").\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that the `reuse` flag is inherited: if we open a reusing scope, then all\n",
      "     |  its sub-scopes become reusing as well.\n",
      "     |  \n",
      "     |  A note about name scoping: Setting `reuse` does not impact the naming of other\n",
      "     |  ops such as mult. See related discussion on\n",
      "     |  [github#6189](https://github.com/tensorflow/tensorflow/issues/6189)\n",
      "     |  \n",
      "     |  Note that up to and including version 1.0, it was allowed (though explicitly\n",
      "     |  discouraged) to pass False to the reuse argument, yielding undocumented\n",
      "     |  behaviour slightly different from None. Starting at 1.1.0 passing None and\n",
      "     |  False as reuse has exactly the same effect.\n",
      "     |  \n",
      "     |  A note about using variable scopes in multi-threaded environment: Variable\n",
      "     |  scopes are thread local, so one thread will not see another thread's current\n",
      "     |  scope. Also, when using `default_name`, unique scopes names are also generated\n",
      "     |  only on a per thread basis. If the same name was used within a different\n",
      "     |  thread, that doesn't prevent a new thread from creating the same scope.\n",
      "     |  However, the underlying variable store is shared across threads (within the\n",
      "     |  same graph). As such, if another thread tries to create a new variable with\n",
      "     |  the same name as a variable created by a previous thread, it will fail unless\n",
      "     |  reuse is True.\n",
      "     |  \n",
      "     |  Further, each thread starts with an empty variable scope. So if you wish to\n",
      "     |  preserve name prefixes from a scope from the main thread, you should capture\n",
      "     |  the main thread's scope and re-enter it in each thread. For e.g.\n",
      "     |  \n",
      "     |  ```\n",
      "     |  main_thread_scope = variable_scope.get_variable_scope()\n",
      "     |  \n",
      "     |  # Thread's target function:\n",
      "     |  def thread_target_fn(captured_scope):\n",
      "     |    with variable_scope.variable_scope(captured_scope):\n",
      "     |      # .... regular code for this thread\n",
      "     |  \n",
      "     |  \n",
      "     |  thread = threading.Thread(target=thread_target_fn, args=(main_thread_scope,))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, type_arg, value_arg, traceback_arg)\n",
      "     |  \n",
      "     |  __init__(self, name_or_scope, default_name=None, values=None, initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, reuse=None, dtype=None, use_resource=None, constraint=None, auxiliary_name_scope=True)\n",
      "     |      Initialize the context manager.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name_or_scope: `string` or `VariableScope`: the scope to open.\n",
      "     |        default_name: The default name to use if the `name_or_scope` argument is\n",
      "     |          `None`, this name will be uniquified. If name_or_scope is provided it\n",
      "     |          won't be used and therefore it is not required and can be None.\n",
      "     |        values: The list of `Tensor` arguments that are passed to the op function.\n",
      "     |        initializer: default initializer for variables within this scope.\n",
      "     |        regularizer: default regularizer for variables within this scope.\n",
      "     |        caching_device: default caching device for variables within this scope.\n",
      "     |        partitioner: default partitioner for variables within this scope.\n",
      "     |        custom_getter: default custom getter for variables within this scope.\n",
      "     |        reuse: `True`, None, or tf.compat.v1.AUTO_REUSE; if `True`, we go into\n",
      "     |          reuse mode for this scope as well as all sub-scopes; if\n",
      "     |          tf.compat.v1.AUTO_REUSE, we create variables if they do not exist, and\n",
      "     |          return them otherwise; if None, we inherit the parent scope's reuse\n",
      "     |          flag. When eager execution is enabled, new variables are always created\n",
      "     |          unless an EagerVariableStore or template is currently active.\n",
      "     |        dtype: type of variables created in this scope (defaults to the type in\n",
      "     |          the passed scope, or inherited from parent scope).\n",
      "     |        use_resource: If False, all variables will be regular Variables. If True,\n",
      "     |          experimental ResourceVariables with well-defined semantics will be used\n",
      "     |          instead. Defaults to False (will later change to True). When eager\n",
      "     |          execution is enabled this argument is always forced to be True.\n",
      "     |        constraint: An optional projection function to be applied to the variable\n",
      "     |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |          constraints or value constraints for layer weights). The function must\n",
      "     |          take as input the unprojected Tensor representing the value of the\n",
      "     |          variable and return the Tensor for the projected value (which must have\n",
      "     |          the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |          distributed training.\n",
      "     |        auxiliary_name_scope: If `True`, we create an auxiliary name scope with\n",
      "     |          the scope. If `False`, we don't create it. Note that the argument is not\n",
      "     |          inherited, and it only takes effect for once when creating. You should\n",
      "     |          only use it for re-entering a premade variable scope.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scope that can be captured and reused.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: when trying to reuse within a create scope, or create within\n",
      "     |          a reuse scope.\n",
      "     |        TypeError: when the types of some arguments are not appropriate.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    variance_scaling_initializer = class VarianceScaling(Initializer)\n",
      "     |  variance_scaling_initializer(scale=1.0, mode='fan_in', distribution='truncated_normal', seed=None, dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer capable of adapting its scale to the shape of weights tensors.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  Although it is a legacy `compat.v1` API, this symbol is compatible with eager\n",
      "     |  execution and `tf.function`.\n",
      "     |  \n",
      "     |  To switch to TF2 APIs, move to using either\n",
      "     |  `tf.initializers.variance_scaling` or `tf.keras.initializers.VarianceScaling`\n",
      "     |  (neither from `compat.v1`) and\n",
      "     |  pass the dtype when calling the initializer.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.variance_scaling_initializer(\n",
      "     |    scale=scale,\n",
      "     |    mode=mode,\n",
      "     |    distribution=distribution\n",
      "     |    seed=seed,\n",
      "     |    dtype=dtype)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.keras.initializers.VarianceScaling(\n",
      "     |    scale=scale,\n",
      "     |    mode=mode,\n",
      "     |    distribution=distribution\n",
      "     |    seed=seed)\n",
      "     |  \n",
      "     |  weight_one = tf.Variable(initializer(shape_one, dtype=dtype))\n",
      "     |  weight_two = tf.Variable(initializer(shape_two, dtype=dtype))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name       | TF2 Arg Name    | Note                       |\n",
      "     |  | :----------------- | :-------------- | :------------------------- |\n",
      "     |  | `scale`            | `scale`        | No change to defaults       |\n",
      "     |  | `mode`             | `mode`         | No change to defaults       |\n",
      "     |  | `distribution`     | `distribution` | No change to defaults.      |\n",
      "     |  :                    :                : 'normal' maps to 'truncated_normal' :\n",
      "     |  | `seed`             | `seed`         | |\n",
      "     |  | `dtype`        |  `dtype` | The TF2 api only takes it  |\n",
      "     |  :                :          : as a `__call__` arg, not a constructor arg. :\n",
      "     |  | `partition_info`     | - |  (`__call__` arg in TF1) Not supported       |\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  With `distribution=\"truncated_normal\" or \"untruncated_normal\"`,\n",
      "     |  samples are drawn from a truncated/untruncated normal\n",
      "     |  distribution with a mean of zero and a standard deviation (after truncation,\n",
      "     |  if used) `stddev = sqrt(scale / n)`\n",
      "     |  where n is:\n",
      "     |    - number of input units in the weight tensor, if mode = \"fan_in\"\n",
      "     |    - number of output units, if mode = \"fan_out\"\n",
      "     |    - average of the numbers of input and output units, if mode = \"fan_avg\"\n",
      "     |  \n",
      "     |  With `distribution=\"uniform\"`, samples are drawn from a uniform distribution\n",
      "     |  within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    scale: Scaling factor (positive float).\n",
      "     |    mode: One of \"fan_in\", \"fan_out\", \"fan_avg\".\n",
      "     |    distribution: Random distribution to use. One of \"normal\", \"uniform\".\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |    ValueError: In case of an invalid value for the \"scale\", mode\" or\n",
      "     |      \"distribution\" arguments.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, scale=1.0, mode='fan_in', distribution='truncated_normal', seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENT VALUES (deprecated arguments)\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENT VALUES ARE DEPRECATED: `(distribution='normal')`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      `normal` is a deprecated alias for `truncated_normal`\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "    \n",
      "    zeros_initializer = class Zeros(Initializer)\n",
      "     |  zeros_initializer(dtype=tf.float32)\n",
      "     |  \n",
      "     |  Initializer that generates tensors initialized to 0.\n",
      "     |  \n",
      "     |  @compatibility(TF2)\n",
      "     |  `tf.compat.v1.zeros_initializer` is compatible with eager execution\n",
      "     |  and `tf.function`.\n",
      "     |  \n",
      "     |  To migrate to TF2, please use `tf.zeros_initializer` instead. The `dtype`\n",
      "     |  argument in `tf.compat.v1.zeros_initializer.__init__()` does not exist in\n",
      "     |  `tf.zeros_initializer.__init__()`. However, you can specify the `dtype` in\n",
      "     |  `__call__()` in both cases.\n",
      "     |  \n",
      "     |  #### Structural Mapping to TF2\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.compat.v1.zeros_initializer(dtype=tf.float32)\n",
      "     |  variable = tf.Variable(initializer(shape=[3, 3]))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  initializer = tf.zeros_initializer()\n",
      "     |  variable = tf.Variable(initializer(shape=[3, 3], dtype=tf.float32))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  #### How to Map Arguments\n",
      "     |  \n",
      "     |  | TF1 Arg Name         | TF2 Arg Name     | Note                       |\n",
      "     |  | :------------------- | :--------------- | :------------------------- |\n",
      "     |  | `dtype`              | `dtype`          | In `__call__()` method     |\n",
      "     |  | `partition_info`     | - |  (`__call__` arg in TF1) Not supported    |\n",
      "     |  \n",
      "     |  \n",
      "     |  #### Before & After Usage Example\n",
      "     |  \n",
      "     |  Before:\n",
      "     |  \n",
      "     |  >>> initializer = tf.compat.v1.zeros_initializer(dtype=tf.float32)\n",
      "     |  >>> tf.Variable(initializer(shape=[3])).numpy()\n",
      "     |  array([0., 0., 0.], dtype=float32)\n",
      "     |  >>> tf.Variable(initializer(shape=[3, 3])).numpy()\n",
      "     |  array([[0., 0., 0.],\n",
      "     |         [0., 0., 0.],\n",
      "     |         [0., 0., 0.]], dtype=float32)\n",
      "     |  >>> initializer = tf.compat.v1.zeros_initializer()\n",
      "     |  >>> tf.Variable(initializer(shape=[3], dtype=tf.float32)).numpy()\n",
      "     |  array([0., 0., 0.], dtype=float32)\n",
      "     |  >>> tf.Variable(initializer(shape=[3, 3], dtype=tf.float32)).numpy()\n",
      "     |  array([[0., 0., 0.],\n",
      "     |         [0., 0., 0.],\n",
      "     |         [0., 0., 0.]], dtype=float32)\n",
      "     |  \n",
      "     |  After:\n",
      "     |  \n",
      "     |  >>> initializer = tf.zeros_initializer()\n",
      "     |  >>> tf.Variable(initializer(shape=[3], dtype=tf.float32)).numpy()\n",
      "     |  array([0., 0., 0.], dtype=float32)\n",
      "     |  >>> tf.Variable(initializer(shape=[3, 3], dtype=tf.float32)).numpy()\n",
      "     |  array([[0., 0., 0.],\n",
      "     |         [0., 0., 0.],\n",
      "     |         [0., 0., 0.]], dtype=float32)\n",
      "     |  \n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Zeros\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "FUNCTIONS\n",
      "    Assert(condition, data, summarize=None, name=None)\n",
      "        Asserts that the given condition is true.\n",
      "        \n",
      "        If `condition` evaluates to false, print the list of tensors in `data`.\n",
      "        `summarize` determines how many entries of the tensors to print.\n",
      "        \n",
      "        Args:\n",
      "          condition: The condition to evaluate.\n",
      "          data: The tensors to print out when condition is false.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          assert_op: An `Operation` that, when executed, raises a\n",
      "          `tf.errors.InvalidArgumentError` if `condition` is not true.\n",
      "          @compatibility(eager)\n",
      "          returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          @compatibility(TF1)\n",
      "          When in TF V1 mode (that is, outside `tf.function`) Assert needs a control\n",
      "          dependency on the output to ensure the assertion executes:\n",
      "        \n",
      "        ```python\n",
      "        # Ensure maximum element of x is smaller or equal to 1\n",
      "        assert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])\n",
      "        with tf.control_dependencies([assert_op]):\n",
      "          ... code using x ...\n",
      "        ```\n",
      "        \n",
      "          @end_compatibility\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    NoGradient = no_gradient(op_type: str) -> None\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    NotDifferentiable = no_gradient(op_type: str) -> None\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    Print(input_, data, message=None, first_n=None, summarize=None, name=None)\n",
      "        Prints a list of tensors. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2018-08-20.\n",
      "        Instructions for updating:\n",
      "        Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "        \n",
      "        \n",
      "        This is an identity op (behaves like `tf.identity`) with the side effect\n",
      "        of printing `data` when evaluating.\n",
      "        \n",
      "        Note: This op prints to the standard error. It is not currently compatible\n",
      "          with jupyter notebook (printing to the notebook *server's* output, not into\n",
      "          the notebook).\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is deprecated. Use `tf.print` instead. `tf.print` does not need the\n",
      "        `input_` argument.\n",
      "        \n",
      "        `tf.print` works in TF2 when executing eagerly and inside a `tf.function`.\n",
      "        \n",
      "        In TF1-styled sessions, an explicit control dependency declaration is needed\n",
      "        to execute the `tf.print` operation. Refer to the documentation of\n",
      "        `tf.print` for more details.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          input_: A tensor passed through this op.\n",
      "          data: A list of tensors to print out when op is evaluated.\n",
      "          message: A string, prefix of the error message.\n",
      "          first_n: Only log `first_n` number of times. Negative numbers log always;\n",
      "            this is the default.\n",
      "          summarize: Only print this many entries of each tensor. If None, then a\n",
      "            maximum of 3 elements are printed per input tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type and contents as `input_`.\n",
      "        \n",
      "          ```python\n",
      "          sess = tf.compat.v1.Session()\n",
      "          with sess.as_default():\n",
      "              tensor = tf.range(10)\n",
      "              print_op = tf.print(tensor)\n",
      "              with tf.control_dependencies([print_op]):\n",
      "                out = tf.add(tensor, tensor)\n",
      "              sess.run(out)\n",
      "          ```\n",
      "    \n",
      "    abs(x, name=None)\n",
      "        Computes the absolute value of a tensor.\n",
      "        \n",
      "        Given a tensor of integer or floating-point values, this operation returns a\n",
      "        tensor of the same type, where each element contains the absolute value of the\n",
      "        corresponding element in the input.\n",
      "        \n",
      "        Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "        `float32` or `float64` that is the absolute value of each element in `x`. For\n",
      "        a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
      "        \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> # real number\n",
      "        >>> x = tf.constant([-2.25, 3.25])\n",
      "        >>> tf.abs(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32,\n",
      "        numpy=array([2.25, 3.25], dtype=float32)>\n",
      "        \n",
      "        >>> # complex number\n",
      "        >>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "        >>> tf.abs(x)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
      "        array([[5.25594901],\n",
      "               [6.60492241]])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "            `int32`, `int64`, `complex64` or `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` of the same size, type and sparsity as `x`,\n",
      "            with absolute values. Note, for `complex64` or `complex128` input, the\n",
      "            returned `Tensor` will be of type `float32` or `float64`, respectively.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    accumulate_n(inputs, shape=None, tensor_dtype=None, name=None)\n",
      "        Returns the element-wise sum of a list of tensors. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.math.add_n` Instead\n",
      "        \n",
      "        Optionally, pass `shape` and `tensor_dtype` for shape and type checking,\n",
      "        otherwise, these are inferred.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([[1, 2], [3, 4]])\n",
      "        >>> b = tf.constant([[5, 0], [0, 6]])\n",
      "        >>> tf.math.accumulate_n([a, b, a]).numpy()\n",
      "        array([[ 7, 4],\n",
      "               [ 6, 14]], dtype=int32)\n",
      "        \n",
      "        >>> # Explicitly pass shape and type\n",
      "        >>> tf.math.accumulate_n(\n",
      "        ...     [a, b, a], shape=[2, 2], tensor_dtype=tf.int32).numpy()\n",
      "        array([[ 7,  4],\n",
      "               [ 6, 14]], dtype=int32)\n",
      "        \n",
      "        Note: The input must be a list or tuple. This function does not handle\n",
      "        `IndexedSlices`\n",
      "        \n",
      "        See Also:\n",
      "        \n",
      "        * `tf.reduce_sum(inputs, axis=0)` - This performe the same mathematical\n",
      "          operation, but `tf.add_n` may be more efficient because it sums the\n",
      "          tensors directly. `reduce_sum` on the other hand calls\n",
      "          `tf.convert_to_tensor` on the list of tensors, unncessairly stacking them\n",
      "          into a single tensor before summing.\n",
      "        * `tf.add_n` - This is another python wrapper for the same Op. It has\n",
      "          nearly identical functionality.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `Tensor` objects, each with same shape and type.\n",
      "          shape: Expected shape of elements of `inputs` (optional). Also controls the\n",
      "            output shape of this op, which may affect type inference in other ops. A\n",
      "            value of `None` means \"infer the input shape from the shapes in `inputs`\".\n",
      "          tensor_dtype: Expected data type of `inputs` (optional). A value of `None`\n",
      "            means \"infer the input dtype from `inputs[0]`\".\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of same shape and type as the elements of `inputs`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `inputs` don't all have same shape and dtype or the shape\n",
      "          cannot be inferred.\n",
      "    \n",
      "    acos(x, name=None)\n",
      "        Computes acos of x element-wise.\n",
      "        \n",
      "        Provided an input tensor, the `tf.math.acos` operation\n",
      "        returns the inverse cosine of each element of the tensor.\n",
      "        If `y = tf.math.cos(x)` then, `x = tf.math.acos(y)`.\n",
      "        \n",
      "        Input range is `[-1, 1]` and the output has a range of `[0, pi]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.0, -0.5, 3.4, 0.2, 0.0, -2], dtype = tf.float32)\n",
      "        >>> tf.math.acos(x)\n",
      "        <tf.Tensor: shape=(6,), dtype=float32,\n",
      "        numpy= array([0. , 2.0943952, nan, 1.3694383, 1.5707964, nan],\n",
      "        dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as x.\n",
      "    \n",
      "    acosh(x: Annotated[Any, ~TV_Acosh_T], name=None) -> Annotated[Any, ~TV_Acosh_T]\n",
      "        Computes inverse hyperbolic cosine of x element-wise.\n",
      "        \n",
      "        Given an input tensor, the function computes inverse hyperbolic cosine of every element.\n",
      "        Input range is `[1, inf]`. It returns `nan` if the input lies outside the range.\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "        tf.math.acosh(x) ==> [nan nan 0. 0.62236255 5.9914584 9.903487 inf]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    add(x, y, name=None)\n",
      "        Returns x + y element-wise.\n",
      "        \n",
      "        Example usages below.\n",
      "        \n",
      "        Add a scalar and a list:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = 1\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        Note that binary `+` operator can be used instead:\n",
      "        \n",
      "        >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "        >>> y = tf.convert_to_tensor(1)\n",
      "        >>> x + y\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        Add a tensor and a list of same shape:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = tf.constant([1, 2, 3, 4, 5])\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 2,  4,  6,  8, 10], dtype=int32)>\n",
      "        \n",
      "        **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "        non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "        of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "        conversion.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "        >>> y = [2**7 + 1, 2**7 + 2]\n",
      "        >>> tf.add(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=int8, numpy=array([-126, -124], dtype=int8)>\n",
      "        \n",
      "        When adding two input values of different shapes, `Add` follows NumPy\n",
      "        broadcasting rules. The two input array shapes are compared element-wise.\n",
      "        Starting with the trailing dimensions, the two dimensions either have to be\n",
      "        equal or one of them needs to be `1`.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = np.ones(6).reshape(1, 2, 1, 3)\n",
      "        >>> y = np.ones(6).reshape(2, 1, 3, 1)\n",
      "        >>> tf.add(x, y).shape.as_list()\n",
      "        [2, 2, 3, 3]\n",
      "        \n",
      "        Another example with two arrays of different dimension.\n",
      "        \n",
      "        >>> x = np.ones([1, 2, 1, 4])\n",
      "        >>> y = np.ones([3, 4])\n",
      "        >>> tf.add(x, y).shape.as_list()\n",
      "        [1, 2, 3, 4]\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_sum`\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: bfloat16, half,\n",
      "            float16, float32, float64, uint8, uint16, uint32, uint64, int8, int16,\n",
      "            int32, int64, complex64, complex128, string.\n",
      "          y: A `tf.Tensor`. Must have the same type as x.\n",
      "          name: A name for the operation (optional)\n",
      "    \n",
      "    add_check_numerics_ops()\n",
      "        Connect a `tf.debugging.check_numerics` to every floating point tensor.\n",
      "        \n",
      "        `check_numerics` operations themselves are added for each `half`, `float`,\n",
      "        or `double` tensor in the current default graph. For all ops in the graph, the\n",
      "        `check_numerics` op for all of its (`half`, `float`, or `double`) inputs\n",
      "        is guaranteed to run before the `check_numerics` op on any of its outputs.\n",
      "        \n",
      "        Note: This API is not compatible with the use of `tf.cond` or\n",
      "        `tf.while_loop`, and will raise a `ValueError` if you attempt to call it\n",
      "        in such a graph.\n",
      "        \n",
      "        Returns:\n",
      "          A `group` op depending on all `check_numerics` ops added.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the graph contains any numeric operations in a control flow\n",
      "            structure.\n",
      "          RuntimeError: If called with eager execution enabled.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Not compatible with eager execution. To check for `Inf`s and `NaN`s under\n",
      "        eager execution, call `tf.debugging.enable_check_numerics()` once before\n",
      "        executing the checked operations.\n",
      "        @end_compatibility\n",
      "    \n",
      "    add_n(inputs, name=None)\n",
      "        Returns the element-wise sum of a list of tensors.\n",
      "        \n",
      "        All inputs in the list must have the same shape. This op does not\n",
      "        [broadcast](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)\n",
      "        its inputs. If you need broadcasting, use `tf.math.add` (or the `+` operator)\n",
      "        instead.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([[3, 5], [4, 8]])\n",
      "        >>> b = tf.constant([[1, 6], [2, 9]])\n",
      "        >>> tf.math.add_n([a, b, a]).numpy()\n",
      "        array([[ 7, 16],\n",
      "               [10, 25]], dtype=int32)\n",
      "        \n",
      "        See Also:\n",
      "        \n",
      "        * `tf.reduce_sum(inputs, axis=0)` - This performs the same mathematical\n",
      "          operation, but `tf.add_n` may be more efficient because it sums the\n",
      "          tensors directly. `reduce_sum` on the other hand calls\n",
      "          `tf.convert_to_tensor` on the list of tensors, unnecessarily stacking them\n",
      "          into a single tensor before summing.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `tf.Tensor` or `tf.IndexedSlices` objects, each with the\n",
      "            same shape and type. `tf.IndexedSlices` objects will be converted into\n",
      "            dense tensors prior to adding.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of the same shape and type as the elements of `inputs`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `inputs` don't all have same shape and dtype or the shape\n",
      "          cannot be inferred.\n",
      "    \n",
      "    add_to_collection(name, value) -> None\n",
      "        Wrapper for `Graph.add_to_collection()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.add_to_collection`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          name: The key for the collection. For example, the `GraphKeys` class\n",
      "            contains many standard names for collections.\n",
      "          value: The value to add to the collection.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are only supported in eager when variables are created inside\n",
      "        an EagerVariableStore (e.g. as part of a layer or template).\n",
      "        @end_compatibility\n",
      "    \n",
      "    add_to_collections(names, value) -> None\n",
      "        Wrapper for `Graph.add_to_collections()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.add_to_collections`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          names: The key for the collections. The `GraphKeys` class contains many\n",
      "            standard names for collections.\n",
      "          value: The value to add to the collections.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are only supported in eager when variables are created inside\n",
      "        an EagerVariableStore (e.g. as part of a layer or template).\n",
      "        @end_compatibility\n",
      "    \n",
      "    all_variables()\n",
      "        Use `tf.compat.v1.global_variables` instead. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Please use tf.global_variables instead.\n",
      "    \n",
      "    angle(input, name=None)\n",
      "        Returns the element-wise argument of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the argument of each element in `input` considered as a complex number.\n",
      "        \n",
      "        The elements in `input` are considered to be complex numbers of the form\n",
      "        \\\\(a + bj\\\\), where *a* is the real part and *b* is the imaginary part.\n",
      "        If `input` is real then *b* is zero by definition.\n",
      "        \n",
      "        The argument returned by this function is of the form \\\\(atan2(b, a)\\\\).\n",
      "        If `input` is real, a tensor of all zeros is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        input = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j], dtype=tf.complex64)\n",
      "        tf.math.angle(input).numpy()\n",
      "        # ==> array([2.0131705, 1.056345 ], dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float`, `double`,\n",
      "            `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    approx_top_k(input: Annotated[Any, ~TV_ApproxTopK_T], k: int, reduction_dimension: int = -1, recall_target: float = 0.95, is_max_k: bool = True, reduction_input_size_override: int = -1, aggregate_to_topk: bool = True, name=None)\n",
      "        Returns min/max k values and their indices of the input operand in an approximate manner.\n",
      "        \n",
      "        See https://arxiv.org/abs/2206.14286 for the algorithm details.\n",
      "        This op is only optimized on TPU currently.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.\n",
      "            Array to search. Must be at least 1-D of the floating type\n",
      "          k: An `int` that is `>= 0`. Specifies the number of min/max-k.\n",
      "          reduction_dimension: An optional `int`. Defaults to `-1`.\n",
      "            Integer dimension along which to search. Default: -1.\n",
      "          recall_target: An optional `float`. Defaults to `0.95`.\n",
      "            Recall target for the approximation. Range in (0,1]\n",
      "          is_max_k: An optional `bool`. Defaults to `True`.\n",
      "            When true, computes max-k; otherwise computes min-k.\n",
      "          reduction_input_size_override: An optional `int`. Defaults to `-1`.\n",
      "            When set to a positive value, it overrides the size determined by\n",
      "            `input[reduction_dim]` for evaluating the recall. This option is useful when\n",
      "            the given `input` is only a subset of the overall computation in SPMD or\n",
      "            distributed pipelines, where the true input size cannot be deferred by the\n",
      "            `input` shape.\n",
      "          aggregate_to_topk: An optional `bool`. Defaults to `True`.\n",
      "            When true, aggregates approximate results to top-k. When false, returns the\n",
      "            approximate results. The number of the approximate results is implementation\n",
      "            defined and is greater equals to the specified `k`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (values, indices).\n",
      "        \n",
      "          values: A `Tensor`. Has the same type as `input`.\n",
      "          indices: A `Tensor` of type `int32`.\n",
      "    \n",
      "    arg_max(input: typing.Annotated[_any, ~TV_ArgMax_T], dimension: typing.Annotated[_any, ~TV_ArgMax_Tidx], output_type: ~TV_ArgMax_output_type = tf.int64, name=None) -> typing.Annotated[_any, ~TV_ArgMax_output_type]\n",
      "        Returns the index with the largest value across dimensions of a tensor. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.math.argmax` instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmax(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 4\n",
      "          # here a[4] = 166.32 which is the largest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`, `bool`.\n",
      "          dimension: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            int16, int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which dimension of the input Tensor to reduce across. For vectors,\n",
      "            use dimension = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int16, tf.uint16, tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    arg_min(input: typing.Annotated[_any, ~TV_ArgMin_T], dimension: typing.Annotated[_any, ~TV_ArgMin_Tidx], output_type: ~TV_ArgMin_output_type = tf.int64, name=None) -> typing.Annotated[_any, ~TV_ArgMin_output_type]\n",
      "        Returns the index with the smallest value across dimensions of a tensor. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.math.argmin` instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmin(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 0\n",
      "          # here a[0] = 1 which is the smallest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`, `bool`.\n",
      "          dimension: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which dimension of the input Tensor to reduce across. For vectors,\n",
      "            use dimension = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argmax(input, axis=None, name=None, dimension=None, output_type=tf.int64)\n",
      "        Returns the index with the largest value across axes of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dimension)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmax(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 4\n",
      "          # here a[4] = 166.32 which is the largest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`, `bool`.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            int16, int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which axis of the input Tensor to reduce across. For vectors,\n",
      "            use axis = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int16, tf.uint16, tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argmin(input, axis=None, name=None, dimension=None, output_type=tf.int64)\n",
      "        Returns the index with the smallest value across axes of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dimension)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmin(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 0\n",
      "          # here a[0] = 1 which is the smallest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`, `bool`.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which axis of the input Tensor to reduce across. For vectors,\n",
      "            use axis = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argsort(values, axis=-1, direction='ASCENDING', stable=False, name=None)\n",
      "        Returns the indices of a tensor that give its sorted order along an axis.\n",
      "        \n",
      "        >>> values = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        >>> sort_order = tf.argsort(values)\n",
      "        >>> sort_order.numpy()\n",
      "        array([0, 3, 1, 2, 5, 4], dtype=int32)\n",
      "        \n",
      "        For a 1D tensor:\n",
      "        \n",
      "        >>> sorted = tf.gather(values, sort_order)\n",
      "        >>> assert tf.reduce_all(sorted == tf.sort(values))\n",
      "        \n",
      "        For higher dimensions, the output has the same shape as\n",
      "        `values`, but along the given axis, values represent the index of the sorted\n",
      "        element in that slice of the tensor at the given position.\n",
      "        \n",
      "        >>> mat = [[30,20,10],\n",
      "        ...        [20,10,30],\n",
      "        ...        [10,30,20]]\n",
      "        >>> indices = tf.argsort(mat)\n",
      "        >>> indices.numpy()\n",
      "        array([[2, 1, 0],\n",
      "               [1, 0, 2],\n",
      "               [0, 2, 1]], dtype=int32)\n",
      "        \n",
      "        If `axis=-1` these indices can be used to apply a sort using `tf.gather`:\n",
      "        \n",
      "        >>> tf.gather(mat, indices, batch_dims=-1).numpy()\n",
      "        array([[10, 20, 30],\n",
      "               [10, 20, 30],\n",
      "               [10, 20, 30]], dtype=int32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "          * `tf.sort`: Sort along an axis.\n",
      "          * `tf.math.top_k`: A partial sort that returns a fixed number of top values\n",
      "            and corresponding indices.\n",
      "        \n",
      "        Args:\n",
      "          values: 1-D or higher **numeric** `Tensor`.\n",
      "          axis: The axis along which to sort. The default is -1, which sorts the last\n",
      "            axis.\n",
      "          direction: The direction in which to sort the values (`'ASCENDING'` or\n",
      "            `'DESCENDING'`).\n",
      "          stable: If True, equal elements in the original tensor will not be\n",
      "            re-ordered in the returned order. Unstable sort is not yet implemented,\n",
      "            but will eventually be the default for performance reasons. If you require\n",
      "            a stable order, pass `stable=True` for forwards compatibility.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          An int32 `Tensor` with the same shape as `values`. The indices that would\n",
      "              sort each slice of the given `values` along the given `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If axis is not a constant scalar, or the direction is invalid.\n",
      "          tf.errors.InvalidArgumentError: If the `values.dtype` is not a `float` or\n",
      "              `int` type.\n",
      "    \n",
      "    as_dtype(type_value)\n",
      "        Converts the given `type_value` to a `tf.DType`.\n",
      "        \n",
      "        Inputs can be existing `tf.DType` objects, a [`DataType`\n",
      "        enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),\n",
      "        a string type name, or a\n",
      "        [`numpy.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html).\n",
      "        \n",
      "        Examples:\n",
      "        >>> tf.as_dtype(2)  # Enum value for float64.\n",
      "        tf.float64\n",
      "        \n",
      "        >>> tf.as_dtype('float')\n",
      "        tf.float32\n",
      "        \n",
      "        >>> tf.as_dtype(np.int32)\n",
      "        tf.int32\n",
      "        \n",
      "        Note: `DType` values are interned (i.e. a single instance of each dtype is\n",
      "        stored in a map). When passed a new `DType` object, `as_dtype` always returns\n",
      "        the interned value.\n",
      "        \n",
      "        Args:\n",
      "          type_value: A value that can be converted to a `tf.DType` object.\n",
      "        \n",
      "        Returns:\n",
      "          A `DType` corresponding to `type_value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `type_value` cannot be converted to a `DType`.\n",
      "    \n",
      "    as_string(input: Annotated[Any, ~TV_AsString_T], precision: int = -1, scientific: bool = False, shortest: bool = False, width: int = -1, fill: str = '', name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Converts each entry in the given tensor to strings.\n",
      "        \n",
      "        Supports many numeric types and boolean.\n",
      "        \n",
      "        For Unicode, see the\n",
      "        [https://www.tensorflow.org/tutorials/representation/unicode](Working with Unicode text)\n",
      "        tutorial.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.strings.as_string([3, 2])\n",
      "        <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'3', b'2'], dtype=object)>\n",
      "        >>> tf.strings.as_string([3.1415926, 2.71828], precision=2).numpy()\n",
      "        array([b'3.14', b'2.72'], dtype=object)\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `complex64`, `complex128`, `bool`, `variant`, `string`.\n",
      "          precision: An optional `int`. Defaults to `-1`.\n",
      "            The post-decimal precision to use for floating point numbers.\n",
      "            Only used if precision > -1.\n",
      "          scientific: An optional `bool`. Defaults to `False`.\n",
      "            Use scientific notation for floating point numbers.\n",
      "          shortest: An optional `bool`. Defaults to `False`.\n",
      "            Use shortest representation (either scientific or standard) for\n",
      "            floating point numbers.\n",
      "          width: An optional `int`. Defaults to `-1`.\n",
      "            Pad pre-decimal numbers to this width.\n",
      "            Applies to both floating point and integer numbers.\n",
      "            Only used if width > -1.\n",
      "          fill: An optional `string`. Defaults to `\"\"`.\n",
      "            The value to pad if width > -1.  If empty, pads with spaces.\n",
      "            Another typical value is '0'.  String cannot be longer than 1 character.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    asin(x: typing.Annotated[_any, ~TV_Asin_T], name=None) -> typing.Annotated[_any, ~TV_Asin_T]\n",
      "        Computes the trignometric inverse sine of x element-wise.\n",
      "        \n",
      "        The `tf.math.asin` operation returns the inverse of `tf.math.sin`, such that\n",
      "        if `y = tf.math.sin(x)` then, `x = tf.math.asin(y)`.\n",
      "        \n",
      "        **Note**: The output of `tf.math.asin` will lie within the invertible range\n",
      "        of sine, i.e [-pi/2, pi/2].\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]\n",
      "        x = tf.constant([1.047, 0.785])\n",
      "        y = tf.math.sin(x) # [0.8659266, 0.7068252]\n",
      "        \n",
      "        tf.math.asin(y) # [1.047, 0.785] = x\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    asinh(x: typing.Annotated[_any, ~TV_Asinh_T], name=None) -> typing.Annotated[_any, ~TV_Asinh_T]\n",
      "        Computes inverse hyperbolic sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes inverse hyperbolic sine\n",
      "          for every element in the tensor. Both input and output has a range of\n",
      "          `[-inf, inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -2, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.asinh(x) ==> [-inf -1.4436355 -0.4812118 0.8813736 1.0159732 5.991471 9.903487 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    assert_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x == y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] == y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x == y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x == y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_equal` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_equal` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_equal(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_equal(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_equal(a, b,\n",
      "        ...     message='\"a == b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[1, 2]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_equal(a, b, message=\n",
      "        ...   '\"a == b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_greater(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x > y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] > y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_greater(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_greater\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x > y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x > y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_greater` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_greater` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_greater(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_greater(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_greater(a, b,\n",
      "        ...     message='\"a > b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[0, 1]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([0, 1], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_greater(a, b, message=\n",
      "        ...   '\"a > b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_greater_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x >= y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] >= y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_greater_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_greater_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x >= y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x >= y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_greater_equal` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_greater_equal` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_greater_equal(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_greater_equal(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_greater_equal(a, b,\n",
      "        ...     message='\"a >= b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[1, 0]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([1, 0], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_greater_equal(a, b, message=\n",
      "        ...   '\"a >= b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_integer(x, message=None, name=None)\n",
      "        Assert that `x` is of integer dtype.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_integer(x)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` whose basetype is integer and is not quantized.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_integer\".\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  If `x.dtype` is anything other than non-quantized integer.\n",
      "        \n",
      "        Returns:\n",
      "          A `no_op` that does nothing.  Type can be determined statically.\n",
      "    \n",
      "    assert_less(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x < y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] < y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_less(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_less\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x < y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x < y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_less` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_less` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_less(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_less(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_less(a, b,\n",
      "        ...     message='\"a < b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[2, 3]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([2, 3], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_less(a, b, message=\n",
      "        ...   '\"a < b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_less_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x <= y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] <= y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_less_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_less_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x <= y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x <= y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_less_equal` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_less_equal` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_less_equal(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_less_equal(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_less_equal(a, b,\n",
      "        ...     message='\"a <= b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[1, 3]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([1, 3], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_less_equal(a, b, message=\n",
      "        ...   '\"a <= b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_near(x, y, rtol=None, atol=None, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x` and `y` are close element-wise.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_near(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have\n",
      "        \n",
      "        ```tf.abs(x[i] - y[i]) <= atol + rtol * tf.abs(y[i])```.\n",
      "        \n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        The default `atol` and `rtol` is `10 * eps`, where `eps` is the smallest\n",
      "        representable positive number such that `1 + eps != 1`.  This is about\n",
      "        `1.2e-6` in `32bit`, `2.22e-15` in `64bit`, and `0.00977` in `16bit`.\n",
      "        See `numpy.finfo`.\n",
      "        \n",
      "        Args:\n",
      "          x:  Float or complex `Tensor`.\n",
      "          y:  Float or complex `Tensor`, same `dtype` as, and broadcastable to, `x`.\n",
      "          rtol:  `Tensor`.  Same `dtype` as, and broadcastable to, `x`.\n",
      "            The relative tolerance.  Default is `10 * eps`.\n",
      "          atol:  `Tensor`.  Same `dtype` as, and broadcastable to, `x`.\n",
      "            The absolute tolerance.  Default is `10 * eps`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_near\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x` and `y` are not close enough.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Similar to `numpy.testing.assert_allclose`, except tolerance depends on data\n",
      "        type. This is due to the fact that `TensorFlow` is often used with `32bit`,\n",
      "        `64bit`, and even `16bit` data.\n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_negative(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x < 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_negative(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Negative means, for every element `x[i]` of `x`, we have `x[i] < 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_negative\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x < 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x < 0` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_non_negative(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x >= 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_non_negative(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Non-negative means, for every element `x[i]` of `x`, we have `x[i] >= 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_non_negative\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x >= 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x >= 0` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_non_positive(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x <= 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_non_positive(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Non-positive means, for every element `x[i]` of `x`, we have `x[i] <= 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_non_positive\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x <= 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x <= 0` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_none_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x != y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] != y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_none_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_none_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x != y` is False.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x != y` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assert_none_equal` is compatible with eager execution and\n",
      "        `tf.function`.\n",
      "        Please use `tf.debugging.assert_none_equal` instead when migrating to TF2. Apart\n",
      "        from `data`, all arguments are supported with the same argument name.\n",
      "        \n",
      "        If you want to ensure the assert statements run before the\n",
      "        potentially-invalid computation, please use `tf.control_dependencies`,\n",
      "        as tf.function auto-control dependencies are insufficient for assert\n",
      "        statements.\n",
      "        \n",
      "        #### Structural Mapping to Native TF2\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.assert_none_equal(\n",
      "          x=x, y=y, data=data, summarize=summarize,\n",
      "          message=message, name=name)\n",
      "        ```\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        ```python\n",
      "        tf.debugging.assert_none_equal(\n",
      "          x=x, y=y, message=message,\n",
      "          summarize=summarize, name=name)\n",
      "        ```\n",
      "        \n",
      "        #### TF1 & TF2 Usage Example\n",
      "        \n",
      "        TF1:\n",
      "        \n",
      "        >>> g = tf.Graph()\n",
      "        >>> with g.as_default():\n",
      "        ...   a = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   b = tf.compat.v1.placeholder(tf.float32, [2])\n",
      "        ...   result = tf.compat.v1.assert_none_equal(a, b,\n",
      "        ...     message='\"a != b\" does not hold for the given inputs')\n",
      "        ...   with tf.compat.v1.control_dependencies([result]):\n",
      "        ...     sum_node = a + b\n",
      "        >>> sess = tf.compat.v1.Session(graph=g)\n",
      "        >>> val = sess.run(sum_node, feed_dict={a: [1, 2], b:[2, 1]})\n",
      "        \n",
      "        \n",
      "        TF2:\n",
      "        \n",
      "        >>> a = tf.Variable([1, 2], dtype=tf.float32)\n",
      "        >>> b = tf.Variable([2, 1], dtype=tf.float32)\n",
      "        >>> assert_op = tf.debugging.assert_none_equal(a, b, message=\n",
      "        ...   '\"a != b\" does not hold for the given inputs')\n",
      "        >>> # When working with tf.control_dependencies\n",
      "        >>> with tf.control_dependencies([assert_op]):\n",
      "        ...   val = a + b\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_positive(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x > 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_positive(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Positive means, for every element `x[i]` of `x`, we have `x[i] > 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_positive\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x > 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x > 0` is False. The check can be performed immediately during\n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_proper_iterable(values)\n",
      "        Static assert that values is a \"proper\" iterable.\n",
      "        \n",
      "        `Ops` that expect iterables of `Tensor` can call this to validate input.\n",
      "        Useful since `Tensor`, `ndarray`, byte/text type are all iterables themselves.\n",
      "        \n",
      "        Args:\n",
      "          values:  Object to be checked.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  If `values` is not iterable or is one of\n",
      "            `Tensor`, `SparseTensor`, `np.array`, `tf.compat.bytes_or_text_types`.\n",
      "    \n",
      "    assert_rank(x, rank, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank equal to `rank`.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank(x, 2)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          rank:  Scalar integer `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and the shape of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_rank\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless `x` has specified rank.\n",
      "          If static checks determine `x` has correct rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has wrong rank.\n",
      "    \n",
      "    assert_rank_at_least(x, rank, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank equal to `rank` or higher.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank_at_least(x, 2)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          rank:  Scalar `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"assert_rank_at_least\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless `x` has specified rank or higher.\n",
      "          If static checks determine `x` has correct rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has wrong rank.\n",
      "    \n",
      "    assert_rank_in(x, ranks, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank in `ranks`.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank_in(x, (2, 4))]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          ranks:  Iterable of scalar `Tensor` objects.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"assert_rank_in\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless rank of `x` is in `ranks`.\n",
      "          If static checks determine `x` has matching rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has mismatched rank.\n",
      "    \n",
      "    assert_same_float_dtype(tensors=None, dtype=None)\n",
      "        Validate and return float type based on `tensors` and `dtype`.\n",
      "        \n",
      "        For ops such as matrix multiplication, inputs and weights must be of the\n",
      "        same float type. This function validates that all `tensors` are the same type,\n",
      "        validates that type is `dtype` (if supplied), and returns the type. Type must\n",
      "        be a floating point type. If neither `tensors` nor `dtype` is supplied,\n",
      "        the function will return `dtypes.float32`.\n",
      "        \n",
      "        Args:\n",
      "          tensors: Tensors of input values. Can include `None` elements, which will be\n",
      "              ignored.\n",
      "          dtype: Expected type.\n",
      "        \n",
      "        Returns:\n",
      "          Validated type.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if neither `tensors` nor `dtype` is supplied, or result is not\n",
      "              float, or the common type of the inputs is not a floating point type.\n",
      "    \n",
      "    assert_scalar(tensor, name=None, message=None)\n",
      "        Asserts that the given `tensor` is a scalar (i.e. zero-dimensional).\n",
      "        \n",
      "        This function raises `ValueError` unless it can be certain that the given\n",
      "        `tensor` is a scalar. `ValueError` is also raised if the shape of `tensor` is\n",
      "        unknown.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          name:  A name for this operation. Defaults to \"assert_scalar\"\n",
      "          message: A string to prefix to the default message.\n",
      "        \n",
      "        Returns:\n",
      "          The input tensor (potentially converted to a `Tensor`).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the tensor is not scalar (rank 0), or if its shape is\n",
      "            unknown.\n",
      "    \n",
      "    assert_type(tensor, tf_type, message=None, name=None)\n",
      "        Statically asserts that the given `Tensor` is of the specified type.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor` or `SparseTensor`.\n",
      "          tf_type: A tensorflow type (`dtypes.float32`, `tf.int64`, `dtypes.bool`,\n",
      "            etc).\n",
      "          message: A string to prefix to the default message.\n",
      "          name:  A name to give this `Op`.  Defaults to \"assert_type\"\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the tensors data type doesn't match `tf_type`.\n",
      "        \n",
      "        Returns:\n",
      "          A `no_op` that does nothing.  Type can be determined statically.\n",
      "    \n",
      "    assert_variables_initialized(var_list=None)\n",
      "        Returns an Op to check if variables are initialized.\n",
      "        \n",
      "        NOTE: This function is obsolete and will be removed in 6 months.  Please\n",
      "        change your implementation to use `report_uninitialized_variables()`.\n",
      "        \n",
      "        When run, the returned Op will raise the exception `FailedPreconditionError`\n",
      "        if any of the variables has not yet been initialized.\n",
      "        \n",
      "        Note: This function is implemented by trying to fetch the values of the\n",
      "        variables. If one of the variables is not initialized a message may be\n",
      "        logged by the C++ runtime. This is expected.\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to check. Defaults to the value of\n",
      "            `global_variables().`\n",
      "        \n",
      "        Returns:\n",
      "          An Op, or None if there are no variables.\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    assign(ref, value, validate_shape=None, use_locking=None, name=None)\n",
      "        Update `ref` by assigning `value` to it.\n",
      "        \n",
      "        This operation outputs a Tensor that holds the new value of `ref` after\n",
      "        the value has been assigned. This makes it easier to chain operations that\n",
      "        need to use the reset value.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Should be from a `Variable` node. May be\n",
      "            uninitialized.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be assigned to the variable.\n",
      "          validate_shape: An optional `bool`. Defaults to `True`. If true, the\n",
      "            operation will validate that the shape of 'value' matches the shape of the\n",
      "            Tensor being assigned to.  If false, 'ref' will take on the shape of\n",
      "            'value'.\n",
      "          use_locking: An optional `bool`. Defaults to `True`. If True, the assignment\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that will hold the new value of `ref` after\n",
      "            the assignment has completed.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assign` is mostly compatible with eager\n",
      "        execution and `tf.function`. However, argument 'validate_shape' will be\n",
      "        ignored. To avoid shape validation, set 'shape' to tf.TensorShape(None) when\n",
      "        constructing the variable:\n",
      "        \n",
      "        >>> import tensorflow as tf\n",
      "        >>> a = tf.Variable([1], shape=tf.TensorShape(None))\n",
      "        >>> tf.compat.v1.assign(a, [2,3])\n",
      "        \n",
      "        To switch to the native TF2 style, one could use method 'assign' of\n",
      "        `tf.Variable`:\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "        | :-------------------- | :-------------- | :------------------------- |\n",
      "        | `ref`                 | `self`          | In `assign()` method       |\n",
      "        | `value`               | `value`         | In `assign()` method       |\n",
      "        | `validate_shape`      | Not supported   | Specify `shape` in the     |\n",
      "        :                       :                 : constructor to replicate   :\n",
      "        :                       :                 : behavior                   :\n",
      "        | `use_locking`         | `use_locking`   | In `assign()` method       |\n",
      "        | `name`                | `name`          | In `assign()` method       |\n",
      "        | -                     | `read_value`    | Set to True to replicate   |\n",
      "        :                       :                 : behavior (True is default) :\n",
      "        @end_compatibility\n",
      "        \n",
      "        \n",
      "        #### Before & After Usage Example\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> with tf.Graph().as_default():\n",
      "        ...   with tf.compat.v1.Session() as sess:\n",
      "        ...     a = tf.compat.v1.Variable(0, dtype=tf.int64)\n",
      "        ...     sess.run(a.initializer)\n",
      "        ...     update_op = tf.compat.v1.assign(a, 2)\n",
      "        ...     res_a = sess.run(update_op)\n",
      "        ...     res_a\n",
      "        2\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> b = tf.Variable(0, dtype=tf.int64)\n",
      "        >>> res_b = b.assign(2)\n",
      "        >>> res_b.numpy()\n",
      "        2\n",
      "    \n",
      "    assign_add(ref, value, use_locking=None, name=None)\n",
      "        Update `ref` by adding `value` to it.\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        Unlike `tf.math.add`, this op does not broadcast. `ref` and `value` must have\n",
      "        the same shape.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`,\n",
      "            `complex64`, `complex128`, `qint8`, `quint8`, `qint32`, `half`. Should be\n",
      "            from a `Variable` node.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be added to the variable.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the addition\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the new value after the variable has been updated.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assign_add` is mostly compatible with eager\n",
      "        execution and `tf.function`.\n",
      "        \n",
      "        To switch to the native TF2 style, one could use method 'assign_add' of\n",
      "        `tf.Variable`:\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "        | :-------------------- | :-------------- | :------------------------- |\n",
      "        | `ref`                 | `self`          | In `assign_add()` method   |\n",
      "        | `value`               | `value`         | In `assign_add()` method   |\n",
      "        | `use_locking`         | `use_locking`   | In `assign_add()` method   |\n",
      "        | `name`                | `name`          | In `assign_add()` method   |\n",
      "        | -                     | `read_value`    | Set to True to replicate   |\n",
      "        :                       :                 : behavior (True is default) :\n",
      "        \n",
      "        \n",
      "        #### Before & After Usage Example\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> with tf.Graph().as_default():\n",
      "        ...   with tf.compat.v1.Session() as sess:\n",
      "        ...     a = tf.compat.v1.Variable(0, dtype=tf.int64)\n",
      "        ...     sess.run(a.initializer)\n",
      "        ...     update_op = tf.compat.v1.assign_add(a, 1)\n",
      "        ...     res_a = sess.run(update_op)\n",
      "        ...     res_a\n",
      "        1\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> b = tf.Variable(0, dtype=tf.int64)\n",
      "        >>> res_b = b.assign_add(1)\n",
      "        >>> res_b.numpy()\n",
      "        1\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    assign_sub(ref, value, use_locking=None, name=None)\n",
      "        Update `ref` by subtracting `value` from it.\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        Unlike `tf.math.subtract`, this op does not broadcast. `ref` and `value`\n",
      "        must have the same shape.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`,\n",
      "            `complex64`, `complex128`, `qint8`, `quint8`, `qint32`, `half`. Should be\n",
      "            from a `Variable` node.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be subtracted to the variable.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the\n",
      "            subtraction will be protected by a lock; otherwise the behavior is\n",
      "            undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the new value after the variable has been updated.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.assign_sub` is mostly compatible with eager\n",
      "        execution and `tf.function`.\n",
      "        \n",
      "        To switch to the native TF2 style, one could use method 'assign_sub' of\n",
      "        `tf.Variable`:\n",
      "        \n",
      "        #### How to Map Arguments\n",
      "        \n",
      "        | TF1 Arg Name          | TF2 Arg Name    | Note                       |\n",
      "        | :-------------------- | :-------------- | :------------------------- |\n",
      "        | `ref`                 | `self`          | In `assign_sub()` method   |\n",
      "        | `value`               | `value`         | In `assign_sub()` method   |\n",
      "        | `use_locking`         | `use_locking`   | In `assign_sub()` method   |\n",
      "        | `name`                | `name`          | In `assign_sub()` method   |\n",
      "        | -                     | `read_value`    | Set to True to replicate   |\n",
      "        :                       :                 : behavior (True is default) :\n",
      "        \n",
      "        \n",
      "        #### Before & After Usage Example\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> with tf.Graph().as_default():\n",
      "        ...   with tf.compat.v1.Session() as sess:\n",
      "        ...     a = tf.compat.v1.Variable(1, dtype=tf.int64)\n",
      "        ...     sess.run(a.initializer)\n",
      "        ...     update_op = tf.compat.v1.assign_sub(a, 1)\n",
      "        ...     res_a = sess.run(update_op)\n",
      "        ...     res_a\n",
      "        0\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> b = tf.Variable(1, dtype=tf.int64)\n",
      "        >>> res_b = b.assign_sub(1)\n",
      "        >>> res_b.numpy()\n",
      "        0\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    atan(x: typing.Annotated[_any, ~TV_Atan_T], name=None) -> typing.Annotated[_any, ~TV_Atan_T]\n",
      "        Computes the trignometric inverse tangent of x element-wise.\n",
      "        \n",
      "        The `tf.math.atan` operation returns the inverse of `tf.math.tan`, such that\n",
      "        if `y = tf.math.tan(x)` then, `x = tf.math.atan(y)`.\n",
      "        \n",
      "        **Note**: The output of `tf.math.atan` will lie within the invertible range\n",
      "        of tan, i.e (-pi/2, pi/2).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]\n",
      "        x = tf.constant([1.047, 0.785])\n",
      "        y = tf.math.tan(x) # [1.731261, 0.99920404]\n",
      "        \n",
      "        tf.math.atan(y) # [1.047, 0.785] = x\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    atan2(y: typing.Annotated[_any, ~TV_Atan2_T], x: typing.Annotated[_any, ~TV_Atan2_T], name=None) -> typing.Annotated[_any, ~TV_Atan2_T]\n",
      "        Computes arctangent of `y/x` element-wise, respecting signs of the arguments.\n",
      "        \n",
      "        This is the angle \\\\( \\theta \\in [-\\pi, \\pi] \\\\) such that\n",
      "        \\\\[ x = r \\cos(\\theta) \\\\]\n",
      "        and\n",
      "        \\\\[ y = r \\sin(\\theta) \\\\]\n",
      "        where \\\\(r = \\sqrt{x^2 + y^2} \\\\).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = [1., 1.]\n",
      "        >>> y = [1., -1.]\n",
      "        >>> print((tf.math.atan2(y,x) * (180 / np.pi)).numpy())\n",
      "        [ 45. -45.]\n",
      "        \n",
      "        Args:\n",
      "          y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `y`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `y`.\n",
      "    \n",
      "    atanh(x: typing.Annotated[_any, ~TV_Atanh_T], name=None) -> typing.Annotated[_any, ~TV_Atanh_T]\n",
      "        Computes inverse hyperbolic tangent of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes inverse hyperbolic tangent\n",
      "          for every element in the tensor. Input range is `[-1,1]` and output range is\n",
      "          `[-inf, inf]`. If input is `-1`, output will be `-inf` and if the\n",
      "          input is `1`, output will be `inf`. Values outside the range will have\n",
      "          `nan` as output.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -1, -0.5, 1, 0, 0.5, 10, float(\"inf\")])\n",
      "          tf.math.atanh(x) ==> [nan -inf -0.54930615 inf  0. 0.54930615 nan nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    batch_gather(params, indices, name=None)\n",
      "        Gather slices from params according to indices with leading batch dims. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-10-25.\n",
      "        Instructions for updating:\n",
      "        `tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=tf.rank(indices) - 1` instead.\n",
      "    \n",
      "    batch_scatter_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Generalization of `tf.compat.v1.scatter_update` to axis different than 0. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2018-11-29.\n",
      "        Instructions for updating:\n",
      "        Use the batch_scatter_update method of Variable instead.\n",
      "        \n",
      "        Analogous to `batch_gather`. This assumes that `ref`, `indices` and `updates`\n",
      "        have a series of leading dimensions that are the same for all of them, and the\n",
      "        updates are performed on the last dimension of indices. In other words, the\n",
      "        dimensions should be the following:\n",
      "        \n",
      "        `num_prefix_dims = indices.ndims - 1`\n",
      "        `batch_dim = num_prefix_dims + 1`\n",
      "        `updates.shape = indices.shape + var.shape[batch_dim:]`\n",
      "        \n",
      "        where\n",
      "        \n",
      "        `updates.shape[:num_prefix_dims]`\n",
      "        `== indices.shape[:num_prefix_dims]`\n",
      "        `== var.shape[:num_prefix_dims]`\n",
      "        \n",
      "        And the operation performed can be expressed as:\n",
      "        \n",
      "        `var[i_1, ..., i_n, indices[i_1, ..., i_n, j]] = updates[i_1, ..., i_n, j]`\n",
      "        \n",
      "        When indices is a 1D tensor, this operation is equivalent to\n",
      "        `tf.compat.v1.scatter_update`.\n",
      "        \n",
      "        To avoid this operation there would be 2 alternatives:\n",
      "        1) Reshaping the variable by merging the first `ndims` dimensions. However,\n",
      "           this is not possible because `tf.reshape` returns a Tensor, which we\n",
      "           cannot use `tf.compat.v1.scatter_update` on.\n",
      "        2) Looping over the first `ndims` of the variable and using\n",
      "           `tf.compat.v1.scatter_update` on the subtensors that result of slicing the\n",
      "           first\n",
      "           dimension. This is a valid option for `ndims = 1`, but less efficient than\n",
      "           this implementation.\n",
      "        \n",
      "        See also `tf.compat.v1.scatter_update` and `tf.compat.v1.scatter_nd_update`.\n",
      "        \n",
      "        Args:\n",
      "          ref: `Variable` to scatter onto.\n",
      "          indices: Tensor containing indices as described above.\n",
      "          updates: Tensor of updates to apply to `ref`.\n",
      "          use_locking: Boolean indicating whether to lock the writing operation.\n",
      "          name: Optional scope name string.\n",
      "        \n",
      "        Returns:\n",
      "          Ref to `variable` after it has been modified.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the initial `ndims` of `ref`, `indices`, and `updates` are\n",
      "              not the same.\n",
      "    \n",
      "    batch_to_space(input, crops, block_size, name=None, block_shape=None)\n",
      "        BatchToSpace for 4-D tensors of type T.\n",
      "        \n",
      "        This is a legacy version of the more general BatchToSpaceND.\n",
      "        \n",
      "        Rearranges (permutes) data from batch into blocks of spatial data, followed by\n",
      "        cropping. This is the reverse transformation of SpaceToBatch. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `batch`\n",
      "        dimension are moved in spatial blocks to the `height` and `width` dimensions,\n",
      "        followed by cropping along the `height` and `width` dimensions.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. 4-D tensor with shape\n",
      "            `[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,\n",
      "              depth]`. Note that the batch size of the input tensor must be divisible by\n",
      "            `block_size * block_size`.\n",
      "          crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D tensor of non-negative integers with shape `[2, 2]`. It specifies\n",
      "            how many elements to crop from the intermediate result across the spatial\n",
      "            dimensions as follows:\n",
      "        \n",
      "                crops = [[crop_top, crop_bottom], [crop_left, crop_right]]\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    batch_to_space_nd(input: Annotated[Any, ~TV_BatchToSpaceND_T], block_shape: Annotated[Any, ~TV_BatchToSpaceND_Tblock_shape], crops: Annotated[Any, ~TV_BatchToSpaceND_Tcrops], name=None) -> Annotated[Any, ~TV_BatchToSpaceND_T]\n",
      "        BatchToSpace for N-D tensors of type T.\n",
      "        \n",
      "        This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of shape\n",
      "        `block_shape + [batch]`, interleaves these blocks back into the grid defined by\n",
      "        the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as\n",
      "        the input.  The spatial dimensions of this intermediate result are then\n",
      "        optionally cropped according to `crops` to produce the output.  This is the\n",
      "        reverse of SpaceToBatch.  See below for a precise description.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "            N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,\n",
      "            where spatial_shape has M dimensions.\n",
      "          block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with shape `[M]`, all values must be >= 1.\n",
      "          crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D with shape `[M, 2]`, all values must be >= 0.\n",
      "              `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input\n",
      "              dimension `i + 1`, which corresponds to spatial dimension `i`.  It is\n",
      "              required that\n",
      "              `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.\n",
      "        \n",
      "            This operation is equivalent to the following steps:\n",
      "        \n",
      "            1. Reshape `input` to `reshaped` of shape:\n",
      "                 [block_shape[0], ..., block_shape[M-1],\n",
      "                  batch / prod(block_shape),\n",
      "                  input_shape[1], ..., input_shape[N-1]]\n",
      "        \n",
      "            2. Permute dimensions of `reshaped` to produce `permuted` of shape\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1], block_shape[0],\n",
      "                  ...,\n",
      "                  input_shape[M], block_shape[M-1],\n",
      "        \n",
      "                  input_shape[M+1], ..., input_shape[N-1]]\n",
      "        \n",
      "            3. Reshape `permuted` to produce `reshaped_permuted` of shape\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1] * block_shape[0],\n",
      "                  ...,\n",
      "                  input_shape[M] * block_shape[M-1],\n",
      "        \n",
      "                  input_shape[M+1],\n",
      "                  ...,\n",
      "                  input_shape[N-1]]\n",
      "        \n",
      "            4. Crop the start and end of dimensions `[1, ..., M]` of\n",
      "               `reshaped_permuted` according to `crops` to produce the output of shape:\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],\n",
      "                  ...,\n",
      "                  input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],\n",
      "        \n",
      "                  input_shape[M+1], ..., input_shape[N-1]]\n",
      "        \n",
      "            Some examples:\n",
      "        \n",
      "            (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 2, 2, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [2]], [[3], [4]]]]\n",
      "            ```\n",
      "        \n",
      "            (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 2, 2, 3]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "                  [[7, 8, 9], [10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [3]], [[9], [11]]],\n",
      "                 [[[2], [4]], [[10], [12]]],\n",
      "                 [[[5], [7]], [[13], [15]]],\n",
      "                 [[[6], [8]], [[14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 4, 4, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                 [[5],   [6],  [7],  [8]],\n",
      "                 [[9],  [10], [11],  [12]],\n",
      "                 [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "        \n",
      "            (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [2, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[0], [1], [3]]], [[[0], [9], [11]]],\n",
      "                 [[[0], [2], [4]]], [[[0], [10], [12]]],\n",
      "                 [[[0], [5], [7]]], [[[0], [13], [15]]],\n",
      "                 [[[0], [6], [8]]], [[[0], [14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[2, 2, 4, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                  [[5],   [6],  [7],  [8]]],\n",
      "                 [[[9],  [10], [11],  [12]],\n",
      "                  [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    betainc(a: typing.Annotated[_any, ~TV_Betainc_T], b: typing.Annotated[_any, ~TV_Betainc_T], x: typing.Annotated[_any, ~TV_Betainc_T], name=None) -> typing.Annotated[_any, ~TV_Betainc_T]\n",
      "        Compute the regularized incomplete beta integral \\\\(I_x(a, b)\\\\).\n",
      "        \n",
      "        The regularized incomplete beta integral is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(I_x(a, b) = \\frac{B(x; a, b)}{B(a, b)}\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \n",
      "        \\\\(B(x; a, b) = \\int_0^x t^{a-1} (1 - t)^{b-1} dt\\\\)\n",
      "        \n",
      "        \n",
      "        is the incomplete beta function and \\\\(B(a, b)\\\\) is the *complete*\n",
      "        beta function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          b: A `Tensor`. Must have the same type as `a`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    bincount = bincount_v1(arr, weights=None, minlength=None, maxlength=None, dtype=tf.int32)\n",
      "        Counts the number of occurrences of each value in an integer array.\n",
      "        \n",
      "        If `minlength` and `maxlength` are not given, returns a vector with length\n",
      "        `tf.reduce_max(arr) + 1` if `arr` is non-empty, and length 0 otherwise.\n",
      "        If `weights` are non-None, then index `i` of the output stores the sum of the\n",
      "        value in `weights` at each index where the corresponding value in `arr` is\n",
      "        `i`.\n",
      "        \n",
      "        Args:\n",
      "          arr: An int32 tensor of non-negative values.\n",
      "          weights: If non-None, must be the same shape as arr. For each value in\n",
      "            `arr`, the bin will be incremented by the corresponding weight instead of\n",
      "            1.\n",
      "          minlength: If given, ensures the output has length at least `minlength`,\n",
      "            padding with zeros at the end if necessary.\n",
      "          maxlength: If given, skips values in `arr` that are equal or greater than\n",
      "            `maxlength`, ensuring that the output has length at most `maxlength`.\n",
      "          dtype: If `weights` is None, determines the type of the output bins.\n",
      "        \n",
      "        Returns:\n",
      "          A vector with the same dtype as `weights` or the given `dtype`. The bin\n",
      "          values.\n",
      "    \n",
      "    bitcast(input: Annotated[Any, ~TV_Bitcast_T], type: ~TV_Bitcast_type, name=None) -> Annotated[Any, ~TV_Bitcast_type]\n",
      "        Bitcasts a tensor from one type to another without copying data.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor that has the same buffer\n",
      "        data as `input` with datatype `type`.\n",
      "        \n",
      "        If the input datatype `T` is larger than the output datatype `type` then the\n",
      "        shape changes from [...] to [..., sizeof(`T`)/sizeof(`type`)].\n",
      "        \n",
      "        If `T` is smaller than `type`, the operator requires that the rightmost\n",
      "        dimension be equal to sizeof(`type`)/sizeof(`T`). The shape then goes from\n",
      "        [..., sizeof(`type`)/sizeof(`T`)] to [...].\n",
      "        \n",
      "        tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype\n",
      "        (e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast()\n",
      "        gives module error.\n",
      "        For example,\n",
      "        \n",
      "        Example 1:\n",
      "        \n",
      "        >>> a = [1., 2., 3.]\n",
      "        >>> equality_bitcast = tf.bitcast(a, tf.complex128)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError: Cannot bitcast from 1 to 18 [Op:Bitcast]\n",
      "        >>> equality_cast = tf.cast(a, tf.complex128)\n",
      "        >>> print(equality_cast)\n",
      "        tf.Tensor([1.+0.j 2.+0.j 3.+0.j], shape=(3,), dtype=complex128)\n",
      "        \n",
      "        Example 2:\n",
      "        \n",
      "        >>> tf.bitcast(tf.constant(0xffffffff, dtype=tf.uint32), tf.uint8)\n",
      "        <tf.Tensor: shape=(4,), dtype=uint8, numpy=array([255, 255, 255, 255], dtype=uint8)>\n",
      "        \n",
      "        Example 3:\n",
      "        \n",
      "        >>> x = [1., 2., 3.]\n",
      "        >>> y = [0., 2., 3.]\n",
      "        >>> equality= tf.equal(x,y)\n",
      "        >>> equality_cast = tf.cast(equality,tf.float32)\n",
      "        >>> equality_bitcast = tf.bitcast(equality_cast,tf.uint8)\n",
      "        >>> print(equality)\n",
      "        tf.Tensor([False True True], shape=(3,), dtype=bool)\n",
      "        >>> print(equality_cast)\n",
      "        tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)\n",
      "        >>> print(equality_bitcast)\n",
      "        tf.Tensor(\n",
      "            [[  0   0   0   0]\n",
      "             [  0   0 128  63]\n",
      "             [  0   0 128  63]], shape=(3, 4), dtype=uint8)\n",
      "        \n",
      "        *NOTE*: Bitcast is implemented as a low-level cast, so machines with different\n",
      "        endian orderings will give different results. A copy from input buffer to output\n",
      "        buffer is made on BE machines when types are of different sizes in order to get\n",
      "        the same casting results as on LE machines.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `complex64`, `complex128`, `qint8`, `quint8`, `qint16`, `quint16`, `qint32`.\n",
      "          type: A `tf.DType` from: `tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `type`.\n",
      "    \n",
      "    boolean_mask(tensor, mask, name='boolean_mask', axis=None)\n",
      "        Apply boolean mask to tensor.\n",
      "        \n",
      "        Numpy equivalent is `tensor[mask]`.\n",
      "        \n",
      "        In general, `0 < dim(mask) = K <= dim(tensor)`, and `mask`'s shape must match\n",
      "        the first K dimensions of `tensor`'s shape.  We then have:\n",
      "          `boolean_mask(tensor, mask)[i, j1,...,jd] = tensor[i1,...,iK,j1,...,jd]`\n",
      "        where `(i1,...,iK)` is the ith `True` entry of `mask` (row-major order).\n",
      "        The `axis` could be used with `mask` to indicate the axis to mask from.\n",
      "        In that case, `axis + dim(mask) <= dim(tensor)` and `mask`'s shape must match\n",
      "        the first `axis + dim(mask)` dimensions of `tensor`'s shape.\n",
      "        \n",
      "        See also: `tf.ragged.boolean_mask`, which can be applied to both dense and\n",
      "        ragged tensors, and can be used if you need to preserve the masked dimensions\n",
      "        of `tensor` (rather than flattening them, as `tf.boolean_mask` does).\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        # 1-D example\n",
      "        tensor = [0, 1, 2, 3]\n",
      "        mask = np.array([True, False, True, False])\n",
      "        tf.boolean_mask(tensor, mask)  # [0, 2]\n",
      "        \n",
      "        # 2-D example\n",
      "        tensor = [[1, 2], [3, 4], [5, 6]]\n",
      "        mask = np.array([True, False, True])\n",
      "        tf.boolean_mask(tensor, mask)  # [[1, 2], [5, 6]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor:  N-D Tensor.\n",
      "          mask:  K-D boolean Tensor, K <= N and K must be known statically.\n",
      "          name:  A name for this operation (optional).\n",
      "          axis:  A 0-D int Tensor representing the axis in `tensor` to mask from. By\n",
      "            default, axis is 0 which will mask from the first dimension. Otherwise K +\n",
      "            axis <= N.\n",
      "        \n",
      "        Returns:\n",
      "          (N-K+1)-dimensional tensor populated by entries in `tensor` corresponding\n",
      "          to `True` values in `mask`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If shapes do not conform.\n",
      "    \n",
      "    broadcast_dynamic_shape(shape_x, shape_y)\n",
      "        Computes the shape of a broadcast given symbolic shapes.\n",
      "        \n",
      "        When `shape_x` and `shape_y` are Tensors representing shapes (i.e. the result\n",
      "        of calling tf.shape on another Tensor) this computes a Tensor which is the\n",
      "        shape of the result of a broadcasting op applied in tensors of shapes\n",
      "        `shape_x` and `shape_y`.\n",
      "        \n",
      "        This is useful when validating the result of a broadcasting operation when the\n",
      "        tensors do not have statically known shapes.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> shape_x = (1, 2, 3)\n",
      "        >>> shape_y = (5, 1, 3)\n",
      "        >>> tf.broadcast_dynamic_shape(shape_x, shape_y)\n",
      "        <tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 2, 3], ...>\n",
      "        \n",
      "        Args:\n",
      "          shape_x: A rank 1 integer `Tensor`, representing the shape of x.\n",
      "          shape_y: A rank 1 integer `Tensor`, representing the shape of y.\n",
      "        \n",
      "        Returns:\n",
      "          A rank 1 integer `Tensor` representing the broadcasted shape.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: If the two shapes are incompatible for\n",
      "          broadcasting.\n",
      "    \n",
      "    broadcast_static_shape(shape_x, shape_y)\n",
      "        Computes the shape of a broadcast given known shapes.\n",
      "        \n",
      "        When `shape_x` and `shape_y` are fully known `TensorShape`s this computes a\n",
      "        `TensorShape` which is the shape of the result of a broadcasting op applied in\n",
      "        tensors of shapes `shape_x` and `shape_y`.\n",
      "        \n",
      "        For example, if shape_x is `TensorShape([1, 2, 3])` and shape_y is\n",
      "        `TensorShape([5, 1, 3])`, the result is a TensorShape whose value is\n",
      "        `TensorShape([5, 2, 3])`.\n",
      "        \n",
      "        This is useful when validating the result of a broadcasting operation when the\n",
      "        tensors have statically known shapes.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> shape_x = tf.TensorShape([1, 2, 3])\n",
      "        >>> shape_y = tf.TensorShape([5, 1 ,3])\n",
      "        >>> tf.broadcast_static_shape(shape_x, shape_y)\n",
      "        TensorShape([5, 2, 3])\n",
      "        \n",
      "        Args:\n",
      "          shape_x: A `TensorShape`\n",
      "          shape_y: A `TensorShape`\n",
      "        \n",
      "        Returns:\n",
      "          A `TensorShape` representing the broadcasted shape.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the two shapes can not be broadcasted.\n",
      "    \n",
      "    broadcast_to(input: Annotated[Any, ~TV_BroadcastTo_T], shape: Annotated[Any, ~TV_BroadcastTo_Tidx], name=None) -> Annotated[Any, ~TV_BroadcastTo_T]\n",
      "        Broadcast an array for a compatible shape.\n",
      "        \n",
      "        Broadcasting is the process of making arrays to have compatible shapes\n",
      "        for arithmetic operations. Two shapes are compatible if for each\n",
      "        dimension pair they are either equal or one of them is one.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([[1, 2, 3]])   # Shape (1, 3,)\n",
      "        >>> y = tf.broadcast_to(x, [2, 3])\n",
      "        >>> print(y)\n",
      "        tf.Tensor(\n",
      "            [[1 2 3]\n",
      "             [1 2 3]], shape=(2, 3), dtype=int32)\n",
      "        \n",
      "        In the above example, the input Tensor with the shape of `[1, 3]`\n",
      "        is broadcasted to output Tensor with shape of `[2, 3]`.\n",
      "        \n",
      "        When broadcasting, if a tensor has fewer axes than necessary its shape is\n",
      "        padded on the left with ones. So this gives the same result as the previous\n",
      "        example:\n",
      "        \n",
      "        >>> x = tf.constant([1, 2, 3])   # Shape (3,)\n",
      "        >>> y = tf.broadcast_to(x, [2, 3])\n",
      "        \n",
      "        \n",
      "        When doing broadcasted operations such as multiplying a tensor\n",
      "        by a scalar, broadcasting (usually) confers some time or space\n",
      "        benefit, as the broadcasted tensor is never materialized.\n",
      "        \n",
      "        However, `broadcast_to` does not carry with it any such benefits.\n",
      "        The newly-created tensor takes the full memory of the broadcasted\n",
      "        shape. (In a graph context, `broadcast_to` might be fused to\n",
      "        subsequent operation and then be optimized away, however.)\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. A Tensor to broadcast.\n",
      "          shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            An 1-D `int` Tensor. The shape of the desired output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    case(pred_fn_pairs, default=None, exclusive=False, strict=False, name='case')\n",
      "        Create a case operation.\n",
      "        \n",
      "        See also `tf.switch_case`.\n",
      "        \n",
      "        The `pred_fn_pairs` parameter is a dict or list of pairs of size N.\n",
      "        Each pair contains a boolean scalar tensor and a python callable that\n",
      "        creates the tensors to be returned if the boolean evaluates to True.\n",
      "        `default` is a callable generating a list of tensors. All the callables\n",
      "        in `pred_fn_pairs` as well as `default` (if provided) should return the same\n",
      "        number and types of tensors.\n",
      "        \n",
      "        If `exclusive==True`, all predicates are evaluated, and an exception is\n",
      "        thrown if more than one of the predicates evaluates to `True`.\n",
      "        If `exclusive==False`, execution stops at the first predicate which\n",
      "        evaluates to True, and the tensors generated by the corresponding function\n",
      "        are returned immediately. If none of the predicates evaluate to True, this\n",
      "        operation returns the tensors generated by `default`.\n",
      "        \n",
      "        `tf.case` supports nested structures as implemented in\n",
      "        `tf.nest`. All of the callables must return the same (possibly nested) value\n",
      "        structure of lists, tuples, and/or named tuples. Singleton lists and tuples\n",
      "        form the only exceptions to this: when returned by a callable, they are\n",
      "        implicitly unpacked to single values. This behavior is disabled by passing\n",
      "        `strict=True`.\n",
      "        \n",
      "        If an unordered dictionary is used for `pred_fn_pairs`, the order of the\n",
      "        conditional tests is not guaranteed. However, the order is guaranteed to be\n",
      "        deterministic, so that variables created in conditional branches are created\n",
      "        in fixed order across runs.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Unordered dictionaries are not supported in eager mode when `exclusive=False`.\n",
      "        Use a list of tuples instead.\n",
      "        @end_compatibility\n",
      "        \n",
      "        \n",
      "        **Example 1:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```\n",
      "        if (x < y) return 17;\n",
      "        else return 23;\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        f1 = lambda: tf.constant(17)\n",
      "        f2 = lambda: tf.constant(23)\n",
      "        r = tf.case([(tf.less(x, y), f1)], default=f2)\n",
      "        ```\n",
      "        \n",
      "        **Example 2:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```\n",
      "        if (x < y && x > z) raise OpError(\"Only one predicate may evaluate to True\");\n",
      "        if (x < y) return 17;\n",
      "        else if (x > z) return 23;\n",
      "        else return -1;\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        def f1(): return tf.constant(17)\n",
      "        def f2(): return tf.constant(23)\n",
      "        def f3(): return tf.constant(-1)\n",
      "        r = tf.case({tf.less(x, y): f1, tf.greater(x, z): f2},\n",
      "                 default=f3, exclusive=True)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          pred_fn_pairs: Dict or list of pairs of a boolean scalar tensor and a\n",
      "            callable which returns a list of tensors.\n",
      "          default: Optional callable that returns a list of tensors.\n",
      "          exclusive: True iff at most one predicate is allowed to evaluate to `True`.\n",
      "          strict: A boolean that enables/disables 'strict' mode; see above.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The tensors returned by the first pair whose predicate evaluated to True, or\n",
      "          those returned by `default` if none does.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `pred_fn_pairs` is not a list/dictionary.\n",
      "          TypeError: If `pred_fn_pairs` is a list but does not contain 2-tuples.\n",
      "          TypeError: If `fns[i]` is not callable for any i, or `default` is not\n",
      "                     callable.\n",
      "    \n",
      "    cast(x, dtype, name=None)\n",
      "        Casts a tensor to a new type.\n",
      "        \n",
      "        The operation casts `x` (in case of `Tensor`) or `x.values`\n",
      "        (in case of `SparseTensor` or `IndexedSlices`) to `dtype`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
      "        >>> tf.cast(x, tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
      "        \n",
      "        Notice `tf.cast` has an alias `tf.dtypes.cast`:\n",
      "        \n",
      "        >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
      "        >>> tf.dtypes.cast(x, tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
      "        \n",
      "        The operation supports data types (for `x` and `dtype`) of\n",
      "        `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`, `int64`,\n",
      "        `float16`, `float32`, `float64`, `complex64`, `complex128`, `bfloat16`.\n",
      "        In case of casting from complex types (`complex64`, `complex128`) to real\n",
      "        types, only the real part of `x` is returned. In case of casting from real\n",
      "        types to complex types (`complex64`, `complex128`), the imaginary part of the\n",
      "        returned value is set to `0`. The handling of complex types here matches the\n",
      "        behavior of numpy.\n",
      "        \n",
      "        Note casting nan and inf values to integral types has undefined behavior.\n",
      "        \n",
      "        Note this operation can lead to a loss of precision when converting native\n",
      "        Python `float` and `complex` variables to `tf.float64` or `tf.complex128`\n",
      "        tensors, since the input is first converted to the `float32` data type and\n",
      "        then widened. It is recommended to use `tf.convert_to_tensor` instead of\n",
      "        `tf.cast` for any non-tensor inputs.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could\n",
      "            be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,\n",
      "            `int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,\n",
      "            `bfloat16`.\n",
      "          dtype: The destination type. The list of supported dtypes is the same as\n",
      "            `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` and\n",
      "            same type as `dtype`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `dtype`.\n",
      "    \n",
      "    ceil(x, name=None)\n",
      "        Return the ceiling of the input, element-wise.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.math.ceil([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])\n",
      "        <tf.Tensor: shape=(7,), dtype=float32,\n",
      "        numpy=array([-1., -1., -0.,  1.,  2.,  2.,  2.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`. `int32`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor`. Has the same type as `x`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.ceil\n",
      "        @end_compatibility\n",
      "    \n",
      "    check_numerics(tensor: Annotated[Any, ~TV_CheckNumerics_T], message: str, name=None) -> Annotated[Any, ~TV_CheckNumerics_T]\n",
      "        Checks a tensor for NaN and Inf values.\n",
      "        \n",
      "        When run, reports an `InvalidArgument` error if `tensor` has any values\n",
      "        that are not a number (NaN) or infinity (Inf). Otherwise, returns the input\n",
      "        tensor.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        ``` python\n",
      "        a = tf.Variable(1.0)\n",
      "        tf.debugging.check_numerics(a, message='')\n",
      "        \n",
      "        b = tf.Variable(np.nan)\n",
      "        try:\n",
      "          tf.debugging.check_numerics(b, message='Checking b')\n",
      "        except Exception as e:\n",
      "          assert \"Checking b : Tensor had NaN values\" in e.message\n",
      "        \n",
      "        c = tf.Variable(np.inf)\n",
      "        try:\n",
      "          tf.debugging.check_numerics(c, message='Checking c')\n",
      "        except Exception as e:\n",
      "          assert \"Checking c : Tensor had Inf values\" in e.message\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          message: A `string`. Prefix of the error message.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    cholesky(input: Annotated[Any, ~TV_Cholesky_T], name=None) -> Annotated[Any, ~TV_Cholesky_T]\n",
      "        Computes the Cholesky decomposition of one or more square matrices.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices.\n",
      "        \n",
      "        The input has to be symmetric and positive definite. Only the lower-triangular\n",
      "        part of the input will be used for this operation. The upper-triangular part\n",
      "        will not be read.\n",
      "        \n",
      "        The output is a tensor of the same shape as the input\n",
      "        containing the Cholesky decompositions for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        **Note**: The gradient computation on GPU is faster for large matrices but\n",
      "        not for large batch dimensions when the submatrices are small. In this\n",
      "        case it might be faster to use the CPU.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    cholesky_solve(chol, rhs, name=None)\n",
      "        Solves systems of linear eqns `A X = RHS`, given Cholesky factorizations.\n",
      "        \n",
      "        Specifically, returns `X` from `A X = RHS`, where `A = L L^T`, `L` is the\n",
      "        `chol` arg and `RHS` is the `rhs` arg.\n",
      "        \n",
      "        ```python\n",
      "        # Solve 10 separate 2x2 linear systems:\n",
      "        A = ... # shape 10 x 2 x 2\n",
      "        RHS = ... # shape 10 x 2 x 1\n",
      "        chol = tf.linalg.cholesky(A)  # shape 10 x 2 x 2\n",
      "        X = tf.linalg.cholesky_solve(chol, RHS)  # shape 10 x 2 x 1\n",
      "        # tf.matmul(A, X) ~ RHS\n",
      "        X[3, :, 0]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 0]\n",
      "        \n",
      "        # Solve five linear systems (K = 5) for every member of the length 10 batch.\n",
      "        A = ... # shape 10 x 2 x 2\n",
      "        RHS = ... # shape 10 x 2 x 5\n",
      "        ...\n",
      "        X[3, :, 2]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 2]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          chol:  A `Tensor`.  Must be `float32` or `float64`, shape is `[..., M, M]`.\n",
      "            Cholesky factorization of `A`, e.g. `chol = tf.linalg.cholesky(A)`.\n",
      "            For that reason, only the lower triangular parts (including the diagonal)\n",
      "            of the last two dimensions of `chol` are used.  The strictly upper part is\n",
      "            assumed to be zero and not accessed.\n",
      "          rhs:  A `Tensor`, same type as `chol`, shape is `[..., M, K]`.\n",
      "          name:  A name to give this `Op`.  Defaults to `cholesky_solve`.\n",
      "        \n",
      "        Returns:\n",
      "          Solution to `A x = rhs`, shape `[..., M, K]`.\n",
      "    \n",
      "    clip_by_average_norm(t, clip_norm, name=None)\n",
      "        Clips tensor values to a maximum average L2-norm. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        clip_by_average_norm is deprecated in TensorFlow 2.0. Please use clip_by_norm(t, clip_norm * tf.cast(tf.size(t), tf.float32), name) instead.\n",
      "        \n",
      "        Given a tensor `t`, and a maximum clip value `clip_norm`, this operation\n",
      "        normalizes `t` so that its average L2-norm is less than or equal to\n",
      "        `clip_norm`. Specifically, if the average L2-norm is already less than or\n",
      "        equal to `clip_norm`, then `t` is not modified. If the average L2-norm is\n",
      "        greater than `clip_norm`, then this operation returns a tensor of the same\n",
      "        type and shape as `t` with its values set to:\n",
      "        \n",
      "        `t * clip_norm / l2norm_avg(t)`\n",
      "        \n",
      "        In this case, the average L2-norm of the output tensor is `clip_norm`.\n",
      "        \n",
      "        This operation is typically used to clip gradients before applying them with\n",
      "        an optimizer.\n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor`.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor`.\n",
      "    \n",
      "    clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None)\n",
      "        Clips values of multiple tensors by the ratio of the sum of their norms.\n",
      "        \n",
      "        Given a tuple or list of tensors `t_list`, and a clipping ratio `clip_norm`,\n",
      "        this operation returns a list of clipped tensors `list_clipped`\n",
      "        and the global norm (`global_norm`) of all tensors in `t_list`. Optionally,\n",
      "        if you've already computed the global norm for `t_list`, you can specify\n",
      "        the global norm with `use_norm`.\n",
      "        \n",
      "        To perform the clipping, the values `t_list[i]` are set to:\n",
      "        \n",
      "            t_list[i] * clip_norm / max(global_norm, clip_norm)\n",
      "        \n",
      "        where:\n",
      "        \n",
      "            global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))\n",
      "        \n",
      "        If `clip_norm > global_norm` then the entries in `t_list` remain as they are,\n",
      "        otherwise they're all shrunk by the global ratio.\n",
      "        \n",
      "        If `global_norm == infinity` then the entries in `t_list` are all set to `NaN`\n",
      "        to signal that an error occurred.\n",
      "        \n",
      "        Any of the entries of `t_list` that are of type `None` are ignored.\n",
      "        \n",
      "        This is the correct way to perform gradient clipping (Pascanu et al., 2012).\n",
      "        \n",
      "        However, it is slower than `clip_by_norm()` because all the parameters must be\n",
      "        ready before the clipping operation can be performed.\n",
      "        \n",
      "        Args:\n",
      "          t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. The clipping ratio.\n",
      "          use_norm: A 0-D (scalar) `Tensor` of type `float` (optional). The global\n",
      "            norm to use. If not provided, `global_norm()` is used to compute the norm.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          list_clipped: A list of `Tensors` of the same type as `list_t`.\n",
      "          global_norm: A 0-D (scalar) `Tensor` representing the global norm.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `t_list` is not a sequence.\n",
      "        \n",
      "        References:\n",
      "          On the difficulty of training Recurrent Neural Networks:\n",
      "            [Pascanu et al., 2012](http://proceedings.mlr.press/v28/pascanu13.html)\n",
      "            ([pdf](http://proceedings.mlr.press/v28/pascanu13.pdf))\n",
      "    \n",
      "    clip_by_norm(t, clip_norm, axes=None, name=None)\n",
      "        Clips tensor values to a maximum L2-norm.\n",
      "        \n",
      "        Given a tensor `t`, and a maximum clip value `clip_norm`, this operation\n",
      "        normalizes `t` so that its L2-norm is less than or equal to `clip_norm`,\n",
      "        along the dimensions given in `axes`. Specifically, in the default case\n",
      "        where all dimensions are used for calculation, if the L2-norm of `t` is\n",
      "        already less than or equal to `clip_norm`, then `t` is not modified. If\n",
      "        the L2-norm is greater than `clip_norm`, then this operation returns a\n",
      "        tensor of the same type and shape as `t` with its values set to:\n",
      "        \n",
      "        `t * clip_norm / l2norm(t)`\n",
      "        \n",
      "        In this case, the L2-norm of the output tensor is `clip_norm`.\n",
      "        \n",
      "        As another example, if `t` is a matrix and `axes == [1]`, then each row\n",
      "        of the output will have L2-norm less than or equal to `clip_norm`. If\n",
      "        `axes == [0]` instead, each column of the output will be clipped.\n",
      "        \n",
      "        Code example:\n",
      "        \n",
      "        >>> some_nums = tf.constant([[1, 2, 3, 4, 5]], dtype=tf.float32)\n",
      "        >>> tf.clip_by_norm(some_nums, 2.0).numpy()\n",
      "        array([[0.26967996, 0.5393599 , 0.80903983, 1.0787199 , 1.3483998 ]],\n",
      "              dtype=float32)\n",
      "        \n",
      "        This operation is typically used to clip gradients before applying them with\n",
      "        an optimizer.  Most gradient data is a collection of different shaped tensors\n",
      "        for different parts of the model.  Thus, this is a common usage:\n",
      "        \n",
      "        ```\n",
      "        # Get your gradients after training\n",
      "        loss_value, grads = grad(model, features, labels)\n",
      "        \n",
      "        # Apply some clipping\n",
      "        grads = [tf.clip_by_norm(g, norm)\n",
      "                     for g in grads]\n",
      "        \n",
      "        # Continue on with training\n",
      "        optimizer.apply_gradients(grads)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor` or `IndexedSlices`.  This must be a floating point type.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value, also\n",
      "            floating point.\n",
      "            Note: If a negative clip_norm is provided, it will be treated as zero.\n",
      "          axes: A 1-D (vector) `Tensor` of type int32 containing the dimensions to use\n",
      "            for computing the L2-norm. If `None` (the default), uses all dimensions.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor` or `IndexedSlices`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the clip_norm tensor is not a 0-D scalar tensor.\n",
      "          TypeError: If dtype of the input is not a floating point or\n",
      "            complex type.\n",
      "    \n",
      "    clip_by_value(t, clip_value_min, clip_value_max, name=None)\n",
      "        Clips tensor values to a specified min and max.\n",
      "        \n",
      "        Given a tensor `t`, this operation returns a tensor of the same type and\n",
      "        shape as `t` with its values clipped to `clip_value_min` and `clip_value_max`.\n",
      "        Any values less than `clip_value_min` are set to `clip_value_min`. Any values\n",
      "        greater than `clip_value_max` are set to `clip_value_max`.\n",
      "        \n",
      "        Note: `clip_value_min` needs to be smaller or equal to `clip_value_max` for\n",
      "        correct results.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        Basic usage passes a scalar as the min and max value.\n",
      "        \n",
      "        >>> t = tf.constant([[-10., -1., 0.], [0., 2., 10.]])\n",
      "        >>> t2 = tf.clip_by_value(t, clip_value_min=-1, clip_value_max=1)\n",
      "        >>> t2.numpy()\n",
      "        array([[-1., -1.,  0.],\n",
      "               [ 0.,  1.,  1.]], dtype=float32)\n",
      "        \n",
      "        The min and max can be the same size as `t`, or broadcastable to that size.\n",
      "        \n",
      "        >>> t = tf.constant([[-1, 0., 10.], [-1, 0, 10]])\n",
      "        >>> clip_min = [[2],[1]]\n",
      "        >>> t3 = tf.clip_by_value(t, clip_value_min=clip_min, clip_value_max=100)\n",
      "        >>> t3.numpy()\n",
      "        array([[ 2.,  2., 10.],\n",
      "               [ 1.,  1., 10.]], dtype=float32)\n",
      "        \n",
      "        Broadcasting fails, intentionally, if you would expand the dimensions of `t`\n",
      "        \n",
      "        >>> t = tf.constant([[-1, 0., 10.], [-1, 0, 10]])\n",
      "        >>> clip_min = [[[2, 1]]] # Has a third axis\n",
      "        >>> t4 = tf.clip_by_value(t, clip_value_min=clip_min, clip_value_max=100)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError: Incompatible shapes: [2,3] vs. [1,1,2]\n",
      "        \n",
      "        It throws a `TypeError` if you try to clip an `int` to a `float` value\n",
      "        (`tf.cast` the input to `float` first).\n",
      "        \n",
      "        >>> t = tf.constant([[1, 2], [3, 4]], dtype=tf.int32)\n",
      "        >>> t5 = tf.clip_by_value(t, clip_value_min=-3.1, clip_value_max=3.1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        TypeError: Cannot convert ...\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor` or `IndexedSlices`.\n",
      "          clip_value_min: The minimum value to clip to. A scalar `Tensor` or one that\n",
      "            is broadcastable to the shape of `t`.\n",
      "          clip_value_max: The maximum value to clip to. A scalar `Tensor` or one that\n",
      "            is broadcastable to the shape of `t`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor` or `IndexedSlices`.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If the clip tensors would trigger array\n",
      "            broadcasting that would make the returned tensor larger than the input.\n",
      "          TypeError: If dtype of the input is `int32` and dtype of\n",
      "            the `clip_value_min` or `clip_value_max` is `float32`\n",
      "    \n",
      "    colocate_with = _colocate_with(op, ignore_existing=False) -> ContextManager[NoneType]\n",
      "        DEPRECATED FUNCTION\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Colocations handled automatically by placer.\n",
      "    \n",
      "    complex(real, imag, name=None)\n",
      "        Converts two real numbers to a complex number.\n",
      "        \n",
      "        Given a tensor `real` representing the real part of a complex number, and a\n",
      "        tensor `imag` representing the imaginary part of a complex number, this\n",
      "        operation returns complex numbers elementwise of the form \\\\(a + bj\\\\), where\n",
      "        *a* represents the `real` part and *b* represents the `imag` part.\n",
      "        \n",
      "        The input tensors `real` and `imag` must have the same shape.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        real = tf.constant([2.25, 3.25])\n",
      "        imag = tf.constant([4.75, 5.75])\n",
      "        tf.complex(real, imag)  # [[2.25 + 4.75j], [3.25 + 5.75j]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          real: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          imag: A `Tensor`. Must have the same type as `real`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `complex64` or `complex128`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: Real and imag must be correct types\n",
      "    \n",
      "    concat(values, axis, name='concat')\n",
      "        Concatenates tensors along one dimension.\n",
      "        \n",
      "        See also `tf.tile`, `tf.stack`, `tf.repeat`.\n",
      "        \n",
      "        Concatenates the list of tensors `values` along dimension `axis`.  If\n",
      "        `values[i].shape = [D0, D1, ... Daxis(i), ...Dn]`, the concatenated\n",
      "        result has shape\n",
      "        \n",
      "            [D0, D1, ... Raxis, ...Dn]\n",
      "        \n",
      "        where\n",
      "        \n",
      "            Raxis = sum(Daxis(i))\n",
      "        \n",
      "        That is, the data from the input tensors is joined along the `axis`\n",
      "        dimension.\n",
      "        \n",
      "        The number of dimensions of the input tensors must match, and all dimensions\n",
      "        except `axis` must be equal.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> t1 = [[1, 2, 3], [4, 5, 6]]\n",
      "        >>> t2 = [[7, 8, 9], [10, 11, 12]]\n",
      "        >>> tf.concat([t1, t2], 0)\n",
      "        <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
      "        array([[ 1,  2,  3],\n",
      "               [ 4,  5,  6],\n",
      "               [ 7,  8,  9],\n",
      "               [10, 11, 12]], dtype=int32)>\n",
      "        \n",
      "        >>> tf.concat([t1, t2], 1)\n",
      "        <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
      "        array([[ 1,  2,  3,  7,  8,  9],\n",
      "               [ 4,  5,  6, 10, 11, 12]], dtype=int32)>\n",
      "        \n",
      "        As in Python, the `axis` could also be negative numbers. Negative `axis`\n",
      "        are interpreted as counting from the end of the rank, i.e.,\n",
      "         `axis + rank(values)`-th dimension.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> t1 = [[[1, 2], [2, 3]], [[4, 4], [5, 3]]]\n",
      "        >>> t2 = [[[7, 4], [8, 4]], [[2, 10], [15, 11]]]\n",
      "        >>> tf.concat([t1, t2], -1)\n",
      "        <tf.Tensor: shape=(2, 2, 4), dtype=int32, numpy=\n",
      "          array([[[ 1,  2,  7,  4],\n",
      "                  [ 2,  3,  8,  4]],\n",
      "                 [[ 4,  4,  2, 10],\n",
      "                  [ 5,  3, 15, 11]]], dtype=int32)>\n",
      "        \n",
      "        Note: If you are concatenating along a new axis consider using stack.\n",
      "        E.g.\n",
      "        \n",
      "        ```python\n",
      "        tf.concat([tf.expand_dims(t, axis) for t in tensors], axis)\n",
      "        ```\n",
      "        \n",
      "        can be rewritten as\n",
      "        \n",
      "        ```python\n",
      "        tf.stack(tensors, axis=axis)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects or a single `Tensor`.\n",
      "          axis: 0-D `int32` `Tensor`.  Dimension along which to concatenate. Must be\n",
      "            in the range `[-rank(values), rank(values))`. As in Python, indexing for\n",
      "            axis is 0-based. Positive axis in the rage of `[0, rank(values))` refers\n",
      "            to `axis`-th dimension. And negative axis refers to `axis +\n",
      "            rank(values)`-th dimension.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` resulting from concatenation of the input tensors.\n",
      "    \n",
      "    cond(pred, true_fn=None, false_fn=None, strict=False, name=None, fn1=None, fn2=None)\n",
      "        Return `true_fn()` if the predicate `pred` is true else `false_fn()`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(fn1, fn2)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "        \n",
      "        `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and\n",
      "        `false_fn` must have the same non-zero number and type of outputs.\n",
      "        \n",
      "        **WARNING**: Any Tensors or Operations created outside of `true_fn` and\n",
      "        `false_fn` will be executed regardless of which branch is selected at runtime.\n",
      "        \n",
      "        Although this behavior is consistent with the dataflow model of TensorFlow,\n",
      "        it has frequently surprised users who expected a lazier semantics.\n",
      "        Consider the following simple program:\n",
      "        \n",
      "        ```python\n",
      "        z = tf.multiply(a, b)\n",
      "        result = tf.cond(x < y, lambda: tf.add(x, z), lambda: tf.square(y))\n",
      "        ```\n",
      "        \n",
      "        If `x < y`, the `tf.add` operation will be executed and `tf.square`\n",
      "        operation will not be executed. Since `z` is needed for at least one\n",
      "        branch of the `cond`, the `tf.multiply` operation is always executed,\n",
      "        unconditionally.\n",
      "        \n",
      "        Note that `cond` calls `true_fn` and `false_fn` *exactly once* (inside the\n",
      "        call to `cond`, and not at all during `Session.run()`). `cond`\n",
      "        stitches together the graph fragments created during the `true_fn` and\n",
      "        `false_fn` calls with some additional graph nodes to ensure that the right\n",
      "        branch gets executed depending on the value of `pred`.\n",
      "        \n",
      "        `tf.cond` supports nested structures as implemented in\n",
      "        `tensorflow.python.util.nest`. Both `true_fn` and `false_fn` must return the\n",
      "        same (possibly nested) value structure of lists, tuples, and/or named tuples.\n",
      "        Singleton lists and tuples form the only exceptions to this: when returned by\n",
      "        `true_fn` and/or `false_fn`, they are implicitly unpacked to single values.\n",
      "        This behavior is disabled by passing `strict=True`.\n",
      "        \n",
      "        Args:\n",
      "          pred: A scalar determining whether to return the result of `true_fn` or\n",
      "            `false_fn`.\n",
      "          true_fn: The callable to be performed if pred is true.\n",
      "          false_fn: The callable to be performed if pred is false.\n",
      "          strict: A boolean that enables/disables 'strict' mode; see above.\n",
      "          name: Optional name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          Tensors returned by the call to either `true_fn` or `false_fn`. If the\n",
      "          callables return a singleton list, the element is extracted from the list.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `true_fn` or `false_fn` is not callable.\n",
      "          ValueError: if `true_fn` and `false_fn` do not return the same number of\n",
      "            tensors, or return tensors of different types.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant(2)\n",
      "        y = tf.constant(5)\n",
      "        def f1(): return tf.multiply(x, 17)\n",
      "        def f2(): return tf.add(y, 23)\n",
      "        r = tf.cond(tf.less(x, y), f1, f2)\n",
      "        # r is set to f1().\n",
      "        # Operations in f2 (e.g., tf.add) are not executed.\n",
      "        ```\n",
      "    \n",
      "    confusion_matrix = confusion_matrix_v1(labels, predictions, num_classes=None, dtype=tf.int32, name=None, weights=None)\n",
      "        Computes the confusion matrix from predictions and labels.\n",
      "        \n",
      "        The matrix columns represent the prediction labels and the rows represent the\n",
      "        real labels. The confusion matrix is always a 2-D array of shape `[n, n]`,\n",
      "        where `n` is the number of valid labels for a given classification task. Both\n",
      "        prediction and labels must be 1-D arrays of the same shape in order for this\n",
      "        function to work.\n",
      "        \n",
      "        If `num_classes` is `None`, then `num_classes` will be set to one plus the\n",
      "        maximum value in either predictions or labels. Class labels are expected to\n",
      "        start at 0. For example, if `num_classes` is 3, then the possible labels\n",
      "        would be `[0, 1, 2]`.\n",
      "        \n",
      "        If `weights` is not `None`, then each prediction contributes its\n",
      "        corresponding weight to the total value of the confusion matrix cell.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "          tf.math.confusion_matrix([1, 2, 4], [2, 2, 4]) ==>\n",
      "              [[0 0 0 0 0]\n",
      "               [0 0 1 0 0]\n",
      "               [0 0 1 0 0]\n",
      "               [0 0 0 0 0]\n",
      "               [0 0 0 0 1]]\n",
      "        ```\n",
      "        \n",
      "        Note that the possible labels are assumed to be `[0, 1, 2, 3, 4]`,\n",
      "        resulting in a 5x5 confusion matrix.\n",
      "        \n",
      "        Args:\n",
      "          labels: 1-D `Tensor` of real labels for the classification task.\n",
      "          predictions: 1-D `Tensor` of predictions for a given classification.\n",
      "          num_classes: The possible number of labels the classification task can have.\n",
      "            If this value is not provided, it will be calculated using both\n",
      "            predictions and labels array.\n",
      "          dtype: Data type of the confusion matrix.\n",
      "          name: Scope name.\n",
      "          weights: An optional `Tensor` whose shape matches `predictions`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `dtype` with shape `[n, n]` representing the confusion\n",
      "          matrix, where `n` is the number of possible labels in the classification\n",
      "          task.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If both predictions and labels are not 1-D vectors and have\n",
      "            mismatched shapes, or if `weights` is not `None` and its shape doesn't\n",
      "            match `predictions`.\n",
      "    \n",
      "    conj(x, name=None)\n",
      "        Returns the complex conjugate of a complex number.\n",
      "        \n",
      "        Given a tensor `x` of complex numbers, this operation returns a tensor of\n",
      "        complex numbers that are the complex conjugate of each element in `x`. The\n",
      "        complex numbers in `x` must be of the form \\\\(a + bj\\\\), where `a` is the\n",
      "        real part and `b` is the imaginary part.\n",
      "        \n",
      "        The complex conjugate returned by this operation is of the form \\\\(a - bj\\\\).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n",
      "        >>> tf.math.conj(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=complex128,\n",
      "        numpy=array([-2.25-4.75j,  3.25-5.75j])>\n",
      "        \n",
      "        If `x` is real, it is returned unchanged.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([-2.25, 3.25])\n",
      "        >>> tf.math.conj(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32,\n",
      "        numpy=array([-2.25,  3.25], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` to conjugate.  Must have numeric or variant type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that is the conjugate of `x` (with the same type).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` is not a numeric tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to numpy.conj.\n",
      "        @end_compatibility\n",
      "    \n",
      "    constant = constant_v1(value, dtype=None, shape=None, name='Const', verify_shape=False) -> Union[tensorflow.python.framework.ops.Operation, tensorflow.python.framework.ops._EagerTensorBase]\n",
      "        Creates a constant tensor.\n",
      "        \n",
      "        The resulting tensor is populated with values of type `dtype`, as\n",
      "        specified by arguments `value` and (optionally) `shape` (see examples\n",
      "        below).\n",
      "        \n",
      "        The argument `value` can be a constant value, or a list of values of type\n",
      "        `dtype`. If `value` is a list, then the length of the list must be less\n",
      "        than or equal to the number of elements implied by the `shape` argument (if\n",
      "        specified). In the case where the list length is less than the number of\n",
      "        elements specified by `shape`, the last element in the list will be used\n",
      "        to fill the remaining entries.\n",
      "        \n",
      "        The argument `shape` is optional. If present, it specifies the dimensions of\n",
      "        the resulting tensor. If not present, the shape of `value` is used.\n",
      "        \n",
      "        If the argument `dtype` is not specified, then the type is inferred from\n",
      "        the type of `value`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Constant 1-D Tensor populated with value list.\n",
      "        tensor = tf.constant([1, 2, 3, 4, 5, 6, 7]) => [1 2 3 4 5 6 7]\n",
      "        \n",
      "        # Constant 2-D tensor populated with scalar value -1.\n",
      "        tensor = tf.constant(-1.0, shape=[2, 3]) => [[-1. -1. -1.]\n",
      "                                                     [-1. -1. -1.]]\n",
      "        ```\n",
      "        \n",
      "        `tf.constant` differs from `tf.fill` in a few ways:\n",
      "        \n",
      "        *   `tf.constant` supports arbitrary constants, not just uniform scalar\n",
      "            Tensors like `tf.fill`.\n",
      "        *   `tf.constant` creates a `Const` node in the computation graph with the\n",
      "            exact value at graph construction time. On the other hand, `tf.fill`\n",
      "            creates an Op in the graph that is expanded at runtime.\n",
      "        *   Because `tf.constant` only embeds constant values in the graph, it does\n",
      "            not support dynamic shapes based on other runtime Tensors, whereas\n",
      "            `tf.fill` does.\n",
      "        \n",
      "        Args:\n",
      "          value:          A constant value (or list) of output type `dtype`.\n",
      "        \n",
      "          dtype:          The type of the elements of the resulting tensor.\n",
      "        \n",
      "          shape:          Optional dimensions of resulting tensor.\n",
      "        \n",
      "          name:           Optional name for the tensor.\n",
      "        \n",
      "          verify_shape:   Boolean that enables verification of a shape of values.\n",
      "        \n",
      "        Returns:\n",
      "          A Constant Tensor.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if shape is incorrectly specified or unsupported.\n",
      "    \n",
      "    container(container_name) -> ContextManager[str]\n",
      "        Wrapper for `Graph.container()` using the default graph.\n",
      "        \n",
      "        Args:\n",
      "          container_name: The container string to use in the context.\n",
      "        \n",
      "        Returns:\n",
      "          A context manager that specifies the default container to use for newly\n",
      "          created stateful ops.\n",
      "    \n",
      "    control_dependencies(control_inputs) -> tensorflow.python.framework.ops.Graph._ControlDependenciesController\n",
      "        Wrapper for `Graph.control_dependencies()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.control_dependencies` for more details.\n",
      "        \n",
      "        In TensorFlow 2 with eager and/or Autograph, you should not need this method\n",
      "        most of the times, as ops execute in the expected order thanks to automatic\n",
      "        control dependencies. Only use it to manually control ordering, for example as\n",
      "        a workaround to known issues such as `tf.function` with `tf.debugging.assert*`\n",
      "        and `tf.py_function`.\n",
      "        For example:\n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...   input_signature=[tf.TensorSpec([None, None], tf.float32),\n",
      "        ...                    tf.TensorSpec([None, None], tf.float32)])\n",
      "        ... def my_assert_func_1(x, bias):\n",
      "        ...   # `tf.function` attempts to execute `tf.math.add` in parallel to\n",
      "        ...   # `assert_equal`. As a result an error can get raised from `tf.math.add`\n",
      "        ...   # without triggering the assertion error.\n",
      "        ...   tf.assert_equal(tf.shape(x)[1],\n",
      "        ...                   tf.shape(bias)[1],\n",
      "        ...                   message='bad shape')\n",
      "        ...   return x + bias\n",
      "        \n",
      "        >>> # Error raised in either `add` or `assert`\n",
      "        >>> my_assert_func_1(tf.ones((2, 5)), tf.ones((2, 7)))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...   input_signature=[tf.TensorSpec([None, None], tf.float32),\n",
      "        ...                    tf.TensorSpec([None, None], tf.float32)])\n",
      "        ... def my_assert_func_2(x, bias):\n",
      "        ...   with tf.control_dependencies(\n",
      "        ...       [tf.assert_equal(tf.shape(x)[1],\n",
      "        ...                       tf.shape(bias)[1],\n",
      "        ...                       message='bad shape')]):\n",
      "        ...     return x + bias\n",
      "        \n",
      "        >>> # Error raised in `assert`\n",
      "        >>> my_assert_func_2(tf.ones((2, 5)), tf.ones((2, 7)))\n",
      "        Traceback (most recent call last):\n",
      "           ...\n",
      "        InvalidArgumentError: ...\n",
      "        \n",
      "        When eager execution is enabled, any callable object in the `control_inputs`\n",
      "        list will be called.\n",
      "        \n",
      "        Args:\n",
      "          control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      "            executed or computed before running the operations defined in the context.\n",
      "            Can also be `None` to clear the control dependencies. If eager execution\n",
      "            is enabled, any callable object in the `control_inputs` list will be\n",
      "            called.\n",
      "        \n",
      "        Returns:\n",
      "         A context manager that specifies control dependencies for all\n",
      "         operations constructed within the context.\n",
      "    \n",
      "    control_flow_v2_enabled()\n",
      "        Returns `True` if v2 control flow is enabled.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function.\n",
      "    \n",
      "    conv(input: Annotated[Any, ~TV_Conv_T], filter: Annotated[Any, ~TV_Conv_T], strides, padding: str, explicit_paddings=[], data_format: str = 'CHANNELS_LAST', dilations=[], batch_dims: int = 1, groups: int = 1, name=None) -> Annotated[Any, ~TV_Conv_T]\n",
      "        Computes a N-D convolution given (N+1+batch_dims)-D `input` and (N+2)-D `filter` tensors.\n",
      "        \n",
      "        General function for computing a N-D convolution. It is required that\n",
      "        `1 <= N <= 3`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`.\n",
      "            Tensor of type T and shape `batch_shape + spatial_shape + [in_channels]` in the\n",
      "            case that `channels_last_format = true` or shape\n",
      "            `batch_shape + [in_channels] + spatial_shape` if `channels_last_format = false`.\n",
      "            spatial_shape is N-dimensional with `N=2` or `N=3`.\n",
      "            Also note that `batch_shape` is dictated by the parameter `batch_dims`\n",
      "            and defaults to 1.\n",
      "          filter: A `Tensor`. Must have the same type as `input`.\n",
      "            An `(N+2)-D` Tensor with the same type as `input` and shape\n",
      "            `spatial_filter_shape + [in_channels, out_channels]`, where spatial_filter_shape\n",
      "            is N-dimensional with `N=2` or `N=3`.\n",
      "          strides: A list of `ints`.\n",
      "            1-D tensor of length `N+2`. The stride of the sliding window for each\n",
      "            dimension of `input`. Must have `strides[0] = strides[N+1] = 1`.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\", \"EXPLICIT\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          explicit_paddings: An optional list of `ints`. Defaults to `[]`.\n",
      "            If `padding` is `\"EXPLICIT\"`, the list of explicit padding amounts. For the ith\n",
      "            dimension, the amount of padding inserted before and after the dimension is\n",
      "            `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If\n",
      "            `padding` is not `\"EXPLICIT\"`, `explicit_paddings` must be empty.\n",
      "          data_format: An optional `string` from: `\"CHANNELS_FIRST\", \"CHANNELS_LAST\"`. Defaults to `\"CHANNELS_LAST\"`.\n",
      "            Used to set the data format. By default `CHANNELS_FIRST`, uses \n",
      "            `NHWC (2D) / NDHWC (3D)` or if `CHANNELS_LAST`, uses `NCHW (2D) / NCDHW (3D)`.\n",
      "          dilations: An optional list of `ints`. Defaults to `[]`.\n",
      "            1-D tensor of length `N+2`. The dilation factor for each dimension of\n",
      "            `input`. If set to `k > 1`, there will be `k-1` skipped cells between each\n",
      "            filter element on that dimension. The dimension order is determined by the\n",
      "            value of `channels_last_format`, see above for details. Dilations in the batch\n",
      "            and depth dimensions must be 1.\n",
      "          batch_dims: An optional `int`. Defaults to `1`.\n",
      "            A positive integer specifying the number of batch dimensions for the input\n",
      "            tensor. Should be less than the rank of the input tensor.\n",
      "          groups: An optional `int`. Defaults to `1`.\n",
      "            A positive integer specifying the number of groups in which the input is split\n",
      "            along the channel axis. Each group is convolved separately with\n",
      "            `filters / groups` filters. The output is the concatenation of all the groups\n",
      "            results along the channel axis. Input channels and filters must both be\n",
      "            divisible by groups.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    conv2d_backprop_filter_v2(input: Annotated[Any, ~TV_Conv2DBackpropFilterV2_T], filter: Annotated[Any, ~TV_Conv2DBackpropFilterV2_T], out_backprop: Annotated[Any, ~TV_Conv2DBackpropFilterV2_T], strides, padding: str, use_cudnn_on_gpu: bool = True, explicit_paddings=[], data_format: str = 'NHWC', dilations=[1, 1, 1, 1], name=None) -> Annotated[Any, ~TV_Conv2DBackpropFilterV2_T]\n",
      "        Computes the gradients of convolution with respect to the filter.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.\n",
      "            4-D with shape `[batch, in_height, in_width, in_channels]`.\n",
      "          filter: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[filter_height, filter_width, in_channels, out_channels]`.\n",
      "            Only shape of tensor is used.\n",
      "          out_backprop: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[batch, out_height, out_width, out_channels]`.\n",
      "            Gradients w.r.t. the output of the convolution.\n",
      "          strides: A list of `ints`.\n",
      "            The stride of the sliding window for each dimension of the input\n",
      "            of the convolution. Must be in the same order as the dimension specified with\n",
      "            format.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\", \"EXPLICIT\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "          explicit_paddings: An optional list of `ints`. Defaults to `[]`.\n",
      "            If `padding` is `\"EXPLICIT\"`, the list of explicit padding amounts. For the ith\n",
      "            dimension, the amount of padding inserted before and after the dimension is\n",
      "            `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If\n",
      "            `padding` is not `\"EXPLICIT\"`, `explicit_paddings` must be empty.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`. Defaults to `\"NHWC\"`.\n",
      "            Specify the data format of the input and output data. With the\n",
      "            default format \"NHWC\", the data is stored in the order of:\n",
      "                [batch, in_height, in_width, in_channels].\n",
      "            Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "                [batch, in_channels, in_height, in_width].\n",
      "          dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.\n",
      "            1-D tensor of length 4.  The dilation factor for each dimension of\n",
      "            `input`. If set to k > 1, there will be k-1 skipped cells between each filter\n",
      "            element on that dimension. The dimension order is determined by the value of\n",
      "            `data_format`, see above for details. Dilations in the batch and depth\n",
      "            dimensions must be 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    conv2d_backprop_input_v2(input: Annotated[Any, ~TV_Conv2DBackpropInputV2_T], filter: Annotated[Any, ~TV_Conv2DBackpropInputV2_T], out_backprop: Annotated[Any, ~TV_Conv2DBackpropInputV2_T], strides, padding: str, use_cudnn_on_gpu: bool = True, explicit_paddings=[], data_format: str = 'NHWC', dilations=[1, 1, 1, 1], name=None) -> Annotated[Any, ~TV_Conv2DBackpropInputV2_T]\n",
      "        Computes the gradients of convolution with respect to the input.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`.\n",
      "            4-D with shape `[batch, in_height, in_width, in_channels]`.\n",
      "            Only shape of tensor is used.\n",
      "          filter: A `Tensor`. Must have the same type as `input`. 4-D with shape\n",
      "            `[filter_height, filter_width, in_channels, out_channels]`.\n",
      "          out_backprop: A `Tensor`. Must have the same type as `input`.\n",
      "            4-D with shape `[batch, out_height, out_width, out_channels]`.\n",
      "            Gradients w.r.t. the output of the convolution.\n",
      "          strides: A list of `ints`.\n",
      "            The stride of the sliding window for each dimension of the input\n",
      "            of the convolution. Must be in the same order as the dimension specified with\n",
      "            format.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\", \"EXPLICIT\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "          explicit_paddings: An optional list of `ints`. Defaults to `[]`.\n",
      "            If `padding` is `\"EXPLICIT\"`, the list of explicit padding amounts. For the ith\n",
      "            dimension, the amount of padding inserted before and after the dimension is\n",
      "            `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If\n",
      "            `padding` is not `\"EXPLICIT\"`, `explicit_paddings` must be empty.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`. Defaults to `\"NHWC\"`.\n",
      "            Specify the data format of the input and output data. With the\n",
      "            default format \"NHWC\", the data is stored in the order of:\n",
      "                [batch, in_height, in_width, in_channels].\n",
      "            Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "                [batch, in_channels, in_height, in_width].\n",
      "          dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.\n",
      "            1-D tensor of length 4.  The dilation factor for each dimension of\n",
      "            `input`. If set to k > 1, there will be k-1 skipped cells between each filter\n",
      "            element on that dimension. The dimension order is determined by the value of\n",
      "            `data_format`, see above for details. Dilations in the batch and depth\n",
      "            dimensions must be 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    convert_to_tensor = convert_to_tensor_v1_with_dispatch(value, dtype=None, name=None, preferred_dtype=None, dtype_hint=None) -> tensorflow.python.framework.tensor.Tensor\n",
      "        Converts the given `value` to a `Tensor`.\n",
      "        \n",
      "        This function converts Python objects of various types to `Tensor`\n",
      "        objects. It accepts `Tensor` objects, numpy arrays, Python lists,\n",
      "        and Python scalars. For example:\n",
      "        \n",
      "        ```python\n",
      "        import numpy as np\n",
      "        \n",
      "        def my_func(arg):\n",
      "          arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
      "          return tf.matmul(arg, arg) + arg\n",
      "        \n",
      "        # The following calls are equivalent.\n",
      "        value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\n",
      "        value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\n",
      "        value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n",
      "        ```\n",
      "        \n",
      "        This function can be useful when composing a new operation in Python\n",
      "        (such as `my_func` in the example above). All standard Python op\n",
      "        constructors apply this function to each of their Tensor-valued\n",
      "        inputs, which allows those ops to accept numpy arrays, Python lists,\n",
      "        and scalars in addition to `Tensor` objects.\n",
      "        \n",
      "        Note: This function diverges from default Numpy behavior for `float` and\n",
      "          `string` types when `None` is present in a Python list or scalar. Rather\n",
      "          than silently converting `None` values, an error will be thrown.\n",
      "        \n",
      "        Args:\n",
      "          value: An object whose type has a registered `Tensor` conversion function.\n",
      "          dtype: Optional element type for the returned tensor. If missing, the type\n",
      "            is inferred from the type of `value`.\n",
      "          name: Optional name to use if a new `Tensor` is created.\n",
      "          preferred_dtype: Optional element type for the returned tensor, used when\n",
      "            dtype is None. In some cases, a caller may not have a dtype in mind when\n",
      "            converting to a tensor, so preferred_dtype can be used as a soft\n",
      "            preference.  If the conversion to `preferred_dtype` is not possible, this\n",
      "            argument has no effect.\n",
      "          dtype_hint: same meaning as preferred_dtype, and overrides it.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If no conversion function is registered for `value` to `dtype`.\n",
      "          RuntimeError: If a registered conversion function returns an invalid value.\n",
      "          ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\n",
      "    \n",
      "    convert_to_tensor_or_indexed_slices(value, dtype=None, name=None)\n",
      "        Converts the given object to a `Tensor` or an `IndexedSlices`.\n",
      "        \n",
      "        If `value` is an `IndexedSlices` or `SparseTensor` it is returned\n",
      "        unmodified. Otherwise, it is converted to a `Tensor` using\n",
      "        `convert_to_tensor()`.\n",
      "        \n",
      "        Args:\n",
      "          value: An `IndexedSlices`, `SparseTensor`, or an object that can be consumed\n",
      "            by `convert_to_tensor()`.\n",
      "          dtype: (Optional.) The required `DType` of the returned `Tensor` or\n",
      "            `IndexedSlices`.\n",
      "          name: (Optional.) A name to use if a new `Tensor` is created.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`, `IndexedSlices`, or `SparseTensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `dtype` does not match the element type of `value`.\n",
      "    \n",
      "    convert_to_tensor_or_sparse_tensor(value, dtype=None, name=None)\n",
      "        Converts value to a `SparseTensor` or `Tensor`.\n",
      "        \n",
      "        Args:\n",
      "          value: A `SparseTensor`, `SparseTensorValue`, or an object whose type has a\n",
      "            registered `Tensor` conversion function.\n",
      "          dtype: Optional element type for the returned tensor. If missing, the type\n",
      "            is inferred from the type of `value`.\n",
      "          name: Optional name to use if a new `Tensor` is created.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or `Tensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If result type is incompatible with `dtype`.\n",
      "    \n",
      "    cos(x: typing.Annotated[_any, ~TV_Cos_T], name=None) -> typing.Annotated[_any, ~TV_Cos_T]\n",
      "        Computes cos of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes cosine of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `[-1,1]`. If input lies outside the boundary, `nan`\n",
      "          is returned.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.cos(x) ==> [nan -0.91113025 0.87758255 0.5403023 0.36235774 0.48718765 -0.95215535 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    cosh(x: typing.Annotated[_any, ~TV_Cosh_T], name=None) -> typing.Annotated[_any, ~TV_Cosh_T]\n",
      "        Computes hyperbolic cosine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic cosine of every\n",
      "          element in the tensor. Input range is `[-inf, inf]` and output range\n",
      "          is `[1, inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 2, 10, float(\"inf\")])\n",
      "          tf.math.cosh(x) ==> [inf 4.0515420e+03 1.1276259e+00 1.5430807e+00 1.8106556e+00 3.7621956e+00 1.1013233e+04 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    count_nonzero(input_tensor=None, axis=None, keepdims=None, dtype=tf.int64, name=None, reduction_indices=None, keep_dims=None, input=None)\n",
      "        Computes number of nonzero elements across dimensions of a tensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(reduction_indices)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_indices is deprecated, use axis instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` has no entries, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        **NOTE** Floating point comparison to zero is done by exact floating point\n",
      "        equality check.  Small values are **not** rounded to zero for purposes of\n",
      "        the nonzero check.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[0, 1, 0], [1, 1, 0]])\n",
      "        tf.math.count_nonzero(x)  # 3\n",
      "        tf.math.count_nonzero(x, 0)  # [1, 2, 0]\n",
      "        tf.math.count_nonzero(x, 1)  # [1, 2]\n",
      "        tf.math.count_nonzero(x, 1, keepdims=True)  # [[1], [2]]\n",
      "        tf.math.count_nonzero(x, [0, 1])  # 3\n",
      "        ```\n",
      "        \n",
      "        **NOTE** Strings are compared against zero-length empty string `\"\"`. Any\n",
      "        string with a size greater than zero is already considered as nonzero.\n",
      "        \n",
      "        For example:\n",
      "        ```python\n",
      "        x = tf.constant([\"\", \"a\", \"  \", \"b\", \"\"])\n",
      "        tf.math.count_nonzero(x) # 3, with \"a\", \"  \", and \"b\" as nonzero strings.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should be of numeric type, `bool`, or\n",
      "            `string`.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          dtype: The output dtype; defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "          input: Overrides input_tensor. For compatibility.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor (number of nonzero values).\n",
      "    \n",
      "    count_up_to(ref, limit, name=None)\n",
      "        Increments 'ref' until it reaches 'limit'. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Prefer Dataset.range instead.\n",
      "        \n",
      "        Args:\n",
      "          ref: A Variable. Must be one of the following types: `int32`, `int64`.\n",
      "            Should be from a scalar `Variable` node.\n",
      "          limit: An `int`.\n",
      "            If incrementing ref would bring it above limit, instead generates an\n",
      "            'OutOfRange' error.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `ref`.\n",
      "          A copy of the input before increment. If nothing else modifies the\n",
      "          input, the values produced will all be distinct.\n",
      "    \n",
      "    create_partitioned_variables(shape, slicing, initializer, dtype=tf.float32, trainable=True, collections=None, name=None, reuse=None)\n",
      "        Create a list of partitioned variables according to the given `slicing`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.get_variable` with a partitioner set.\n",
      "        \n",
      "        Currently only one dimension of the full variable can be sliced, and the\n",
      "        full variable can be reconstructed by the concatenation of the returned\n",
      "        list along that dimension.\n",
      "        \n",
      "        Args:\n",
      "          shape: List of integers.  The shape of the full variable.\n",
      "          slicing: List of integers.  How to partition the variable.\n",
      "            Must be of the same length as `shape`.  Each value\n",
      "            indicate how many slices to create in the corresponding\n",
      "            dimension.  Presently only one of the values can be more than 1;\n",
      "            that is, the variable can only be sliced along one dimension.\n",
      "        \n",
      "            For convenience, The requested number of partitions does not have to\n",
      "            divide the corresponding dimension evenly.  If it does not, the\n",
      "            shapes of the partitions are incremented by 1 starting from partition\n",
      "            0 until all slack is absorbed.  The adjustment rules may change in the\n",
      "            future, but as you can save/restore these variables with different\n",
      "            slicing specifications this should not be a problem.\n",
      "          initializer: A `Tensor` of shape `shape` or a variable initializer\n",
      "            function.  If a function, it will be called once for each slice,\n",
      "            passing the shape and data type of the slice as parameters.  The\n",
      "            function must return a tensor with the same shape as the slice.\n",
      "          dtype: Type of the variables. Ignored if `initializer` is a `Tensor`.\n",
      "          trainable: If True also add all the variables to the graph collection\n",
      "            `GraphKeys.TRAINABLE_VARIABLES`.\n",
      "          collections: List of graph collections keys to add the variables to.\n",
      "            Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "          name: Optional name for the full variable.  Defaults to\n",
      "            `\"PartitionedVariable\"` and gets uniquified automatically.\n",
      "          reuse: Boolean or `None`; if `True` and name is set, it would reuse\n",
      "            previously created variables. if `False` it will create new variables.\n",
      "            if `None`, it would inherit the parent scope reuse.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variables corresponding to the slicing.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the arguments is malformed.\n",
      "    \n",
      "    cross(a: typing.Annotated[_any, ~TV_Cross_T], b: typing.Annotated[_any, ~TV_Cross_T], name=None) -> typing.Annotated[_any, ~TV_Cross_T]\n",
      "        Compute the pairwise cross product.\n",
      "        \n",
      "        `a` and `b` must be the same shape; they can either be simple 3-element vectors,\n",
      "        or any shape where the innermost dimension is 3. In the latter case, each pair\n",
      "        of corresponding 3-element vectors is cross-multiplied independently.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "            A tensor containing 3-element vectors.\n",
      "          b: A `Tensor`. Must have the same type as `a`.\n",
      "            Another tensor, of same type and shape as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    cumprod(x, axis=0, exclusive=False, reverse=False, name=None)\n",
      "        Compute the cumulative product of the tensor `x` along `axis`.\n",
      "        \n",
      "        By default, this op performs an inclusive cumprod, which means that the\n",
      "        first element of the input is identical to the first element of the output:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c])  # [a, a * b, a * b * c]\n",
      "        ```\n",
      "        \n",
      "        By setting the `exclusive` kwarg to `True`, an exclusive cumprod is\n",
      "        performed\n",
      "        instead:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], exclusive=True)  # [1, a, a * b]\n",
      "        ```\n",
      "        \n",
      "        By setting the `reverse` kwarg to `True`, the cumprod is performed in the\n",
      "        opposite direction:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], reverse=True)  # [a * b * c, b * c, c]\n",
      "        ```\n",
      "        \n",
      "        This is more efficient than using separate `tf.reverse` ops.\n",
      "        The `reverse` and `exclusive` kwargs can also be combined:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], exclusive=True, reverse=True)  # [b * c, c, 1]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`,\n",
      "            `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,\n",
      "            `complex128`, `qint8`, `quint8`, `qint32`, `half`.\n",
      "          axis: A `Tensor` of type `int32` (default: 0). Must be in the range\n",
      "            `[-rank(x), rank(x))`.\n",
      "          exclusive: If `True`, perform exclusive cumprod.\n",
      "          reverse: A `bool` (default: False).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    cumsum(x, axis=0, exclusive=False, reverse=False, name=None)\n",
      "        Compute the cumulative sum of the tensor `x` along `axis`.\n",
      "        \n",
      "        By default, this op performs an inclusive cumsum, which means that the first\n",
      "        element of the input is identical to the first element of the output:\n",
      "        For example:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c])   # [a, a + b, a + b + c]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([ 2,  6, 12, 20], dtype=int32)>\n",
      "        \n",
      "        >>> # using varying `axis` values\n",
      "        >>> y = tf.constant([[2, 4, 6, 8], [1,3,5,7]])\n",
      "        >>> tf.cumsum(y, axis=0)\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "        array([[ 2,  4,  6,  8],\n",
      "               [ 3,  7, 11, 15]], dtype=int32)>\n",
      "        >>> tf.cumsum(y, axis=1)\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "        array([[ 2,  6, 12, 20],\n",
      "               [ 1,  4,  9, 16]], dtype=int32)>\n",
      "        \n",
      "        By setting the `exclusive` kwarg to `True`, an exclusive cumsum is performed\n",
      "        instead:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], exclusive=True)  => [0, a, a + b]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, exclusive=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([ 0,  2,  6, 12], dtype=int32)>\n",
      "        \n",
      "        By setting the `reverse` kwarg to `True`, the cumsum is performed in the\n",
      "        opposite direction:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], reverse=True)  # [a + b + c, b + c, c]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, reverse=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([20, 18, 14,  8], dtype=int32)>\n",
      "        \n",
      "        This is more efficient than using separate `tf.reverse` ops.\n",
      "        The `reverse` and `exclusive` kwargs can also be combined:\n",
      "        \n",
      "        >>> # tf.cumsum([a, b, c], exclusive=True, reverse=True)  # [b + c, c, 0]\n",
      "        >>> x = tf.constant([2, 4, 6, 8])\n",
      "        >>> tf.cumsum(x, exclusive=True, reverse=True)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32,\n",
      "        numpy=array([18, 14,  8,  0], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`,\n",
      "            `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,\n",
      "            `complex128`, `qint8`, `quint8`, `qint32`, `half`.\n",
      "          axis: A `Tensor` of type `int32` (default: 0). Must be in the range\n",
      "            `[-rank(x), rank(x))`.\n",
      "          exclusive: If `True`, perform exclusive cumsum.\n",
      "          reverse: A `bool` (default: False).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    custom_gradient(f=None)\n",
      "        Decorator to define a function with a custom gradient.\n",
      "        \n",
      "        This decorator allows fine grained control over the gradients of a sequence\n",
      "        for operations.  This may be useful for multiple reasons, including providing\n",
      "        a more efficient or numerically stable gradient for a sequence of operations.\n",
      "        \n",
      "        For example, consider the following function that commonly occurs in the\n",
      "        computation of cross entropy and log likelihoods:\n",
      "        \n",
      "        ```python\n",
      "        def log1pexp(x):\n",
      "          return tf.math.log(1 + tf.exp(x))\n",
      "        ```\n",
      "        \n",
      "        Due to numerical instability, the gradient of this function evaluated at x=100\n",
      "        is NaN.  For example:\n",
      "        \n",
      "        ```python\n",
      "        with tf.GradientTape() as tape:\n",
      "          tape.watch(x)\n",
      "          y=log1pexp(x)\n",
      "        dy_dx = tape.gradient(y, x) # Will be NaN when evaluated.\n",
      "        ```\n",
      "        \n",
      "        The gradient expression can be analytically simplified to provide numerical\n",
      "        stability:\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def log1pexp(x):\n",
      "          e = tf.exp(x)\n",
      "          def grad(upstream):\n",
      "            return upstream * (1 - 1 / (1 + e))\n",
      "          return tf.math.log(1 + e), grad\n",
      "        ```\n",
      "        \n",
      "        With this definition, the gradient `dy_dx` at `x = 100` will be correctly\n",
      "        evaluated as 1.0.\n",
      "        \n",
      "        The variable `upstream` is defined as the upstream gradient. i.e. the gradient\n",
      "        from all the layers or functions originating from this layer. The above\n",
      "        example has no upstream functions, therefore `upstream = dy/dy = 1.0`.\n",
      "        \n",
      "        Assume that `x_i` is `log1pexp` in the forward pass `x_1 = x_1(x_0)`,\n",
      "        `x_2 = x_2(x_1)`, ..., `x_i = x_i(x_i-1)`, ..., `x_n = x_n(x_n-1)`. By\n",
      "        chain rule we know that `dx_n/dx_0 = dx_n/dx_n-1 * dx_n-1/dx_n-2 * ... *\n",
      "        dx_i/dx_i-1 * ... * dx_1/dx_0`.\n",
      "        \n",
      "        In this case the gradient of our current function defined as\n",
      "        `dx_i/dx_i-1 = (exp(x_i) / (1 + exp(x_i))) = (1 - 1 / (1 + exp(x_i)))`. The\n",
      "        upstream gradient `upstream` would be `dx_n/dx_n-1 * dx_n-1/dx_n-2 * ... *\n",
      "        dx_i+1/dx_i`. The upstream gradient multiplied by the current gradient is\n",
      "        then passed downstream.\n",
      "        \n",
      "        In case the function takes multiple variables as input, the `grad`\n",
      "        function must also return  the same number of variables.\n",
      "        We take the function `z = x * y` as an example.\n",
      "        \n",
      "        >>> @tf.custom_gradient\n",
      "        ... def bar(x, y):\n",
      "        ...   def grad(upstream):\n",
      "        ...     dz_dx = y\n",
      "        ...     dz_dy = x\n",
      "        ...     return upstream * dz_dx, upstream * dz_dy\n",
      "        ...   z = x * y\n",
      "        ...   return z, grad\n",
      "        >>> x = tf.constant(2.0, dtype=tf.float32)\n",
      "        >>> y = tf.constant(3.0, dtype=tf.float32)\n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   tape.watch(y)\n",
      "        ...   z = bar(x, y)\n",
      "        >>> z\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
      "        >>> tape.gradient(z, x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=3.0>\n",
      "        >>> tape.gradient(z, y)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=2.0>\n",
      "        \n",
      "        Nesting custom gradients can lead to unintuitive results. The default\n",
      "        behavior does not correspond to n-th order derivatives. For example\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def op(x):\n",
      "          y = op1(x)\n",
      "          @tf.custom_gradient\n",
      "          def grad_fn(dy):\n",
      "            gdy = op2(x, y, dy)\n",
      "            def grad_grad_fn(ddy):  # Not the 2nd order gradient of op w.r.t. x.\n",
      "              return op3(x, y, dy, ddy)\n",
      "            return gdy, grad_grad_fn\n",
      "          return y, grad_fn\n",
      "        ```\n",
      "        \n",
      "        The function `grad_grad_fn` will be calculating the first order gradient\n",
      "        of `grad_fn` with respect to `dy`, which is used to generate forward-mode\n",
      "        gradient graphs from backward-mode gradient graphs, but is not the same as\n",
      "        the second order gradient of `op` with respect to `x`.\n",
      "        \n",
      "        Instead, wrap nested `@tf.custom_gradients` in another function:\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def op_with_fused_backprop(x):\n",
      "          y, x_grad = fused_op(x)\n",
      "          def first_order_gradient(dy):\n",
      "            @tf.custom_gradient\n",
      "            def first_order_custom(unused_x):\n",
      "              def second_order_and_transpose(ddy):\n",
      "                return second_order_for_x(...), gradient_wrt_dy(...)\n",
      "              return x_grad, second_order_and_transpose\n",
      "            return dy * first_order_custom(x)\n",
      "          return y, first_order_gradient\n",
      "        ```\n",
      "        \n",
      "        Additional arguments to the inner `@tf.custom_gradient`-decorated function\n",
      "        control the expected return values of the innermost function.\n",
      "        \n",
      "        The examples above illustrate how to specify custom gradients for functions\n",
      "        which do not read from variables. The following example uses variables, which\n",
      "        require special handling because they are effectively inputs of the forward\n",
      "        function.\n",
      "        \n",
      "        >>> weights = tf.Variable(tf.ones([2]))  # Trainable variable weights\n",
      "        >>> @tf.custom_gradient\n",
      "        ... def linear_poly(x):\n",
      "        ...   # Creating polynomial\n",
      "        ...   poly = weights[1] * x + weights[0]\n",
      "        ...\n",
      "        ...   def grad_fn(dpoly, variables):\n",
      "        ...     # dy/dx = weights[1] and we need to left multiply dpoly\n",
      "        ...     grad_xs = dpoly * weights[1]  # Scalar gradient\n",
      "        ...\n",
      "        ...     grad_vars = []  # To store gradients of passed variables\n",
      "        ...     assert variables is not None\n",
      "        ...     assert len(variables) == 1\n",
      "        ...     assert variables[0] is weights\n",
      "        ...     # Manually computing dy/dweights\n",
      "        ...     dy_dw = dpoly * tf.stack([x ** 1, x ** 0])\n",
      "        ...     grad_vars.append(\n",
      "        ...         tf.reduce_sum(tf.reshape(dy_dw, [2, -1]), axis=1)\n",
      "        ...     )\n",
      "        ...     return grad_xs, grad_vars\n",
      "        ...   return poly, grad_fn\n",
      "        >>> x = tf.constant([1., 2., 3.])\n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   poly = linear_poly(x)\n",
      "        >>> poly # poly = x + 1\n",
      "        <tf.Tensor: shape=(3,),\n",
      "          dtype=float32,\n",
      "          numpy=array([2., 3., 4.], dtype=float32)>\n",
      "        >>> tape.gradient(poly, x)  # conventional scalar gradient dy/dx\n",
      "        <tf.Tensor: shape=(3,),\n",
      "          dtype=float32,\n",
      "          numpy=array([1., 1., 1.], dtype=float32)>\n",
      "        >>> tape.gradient(poly, weights)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([6., 3.], dtype=float32)>\n",
      "        \n",
      "        Above example illustrates usage of trainable variable `weights`.\n",
      "        In the example, the inner `grad_fn` accepts an extra `variables` input\n",
      "        parameter and also returns an extra `grad_vars` output. That extra argument\n",
      "        is passed if the forward function reads any variables. You need to\n",
      "        compute the gradient w.r.t. each of those `variables` and output it as a list\n",
      "        of `grad_vars`. Note here that default value of `variables` is set to `None`\n",
      "        when no variables are used in the forward function.\n",
      "        \n",
      "        It should be noted `tf.GradientTape` is still watching the forward pass of a\n",
      "        `tf.custom_gradient`, and will use the ops it watches. As a consequence,\n",
      "        calling `tf.function` while the tape is still watching leads\n",
      "        to a gradient graph being built. If an op is used in `tf.function` without\n",
      "        registered gradient, a `LookupError` will be raised.\n",
      "        \n",
      "        Users can insert `tf.stop_gradient` to customize this behavior. This\n",
      "        is demonstrated in the example below. `tf.random.shuffle` does not have a\n",
      "        registered gradient. As a result `tf.stop_gradient` is used to avoid the\n",
      "        `LookupError`.\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0.3, 0.5], dtype=tf.float32)\n",
      "        \n",
      "        @tf.custom_gradient\n",
      "        def test_func_with_stop_grad(x):\n",
      "          @tf.function\n",
      "          def _inner_func():\n",
      "            # Avoid exception during the forward pass\n",
      "            return tf.stop_gradient(tf.random.shuffle(x))\n",
      "            # return tf.random.shuffle(x)  # This will raise\n",
      "        \n",
      "          res = _inner_func()\n",
      "          def grad(upstream):\n",
      "            return upstream  # Arbitrarily defined custom gradient\n",
      "          return res, grad\n",
      "        \n",
      "        with tf.GradientTape() as g:\n",
      "          g.watch(x)\n",
      "          res = test_func_with_stop_grad(x)\n",
      "        \n",
      "        g.gradient(res, x)\n",
      "        ```\n",
      "        \n",
      "        See also `tf.RegisterGradient` which registers a gradient function for a\n",
      "        primitive TensorFlow operation. `tf.custom_gradient` on the other hand allows\n",
      "        for fine grained control over the gradient computation of a sequence of\n",
      "        operations.\n",
      "        \n",
      "        Note that if the decorated function uses `Variable`s, the enclosing variable\n",
      "        scope must be using\n",
      "        [ResourceVariables](https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables).\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a tuple `(y, grad_fn)` where: - `x` is a\n",
      "            sequence of (nested structures of) `Tensor` inputs to the function. - `y`\n",
      "            is a (nested structure of) `Tensor` outputs of applying TensorFlow\n",
      "            operations in `f` to `x`. - `grad_fn` is a function with the signature\n",
      "            `g(*grad_ys)` which returns a list of `Tensor`s the same size as\n",
      "            (flattened) `x` - the derivatives of `Tensor`s in `y` with respect to the\n",
      "            `Tensor`s in `x`.  `grad_ys` is a sequence of `Tensor`s the same size as\n",
      "            (flattened) `y` holding the initial value gradients for each `Tensor` in\n",
      "            `y`.  In a pure mathematical sense, a vector-argument vector-valued\n",
      "            function `f`'s derivatives should be its Jacobian matrix `J`. Here we are\n",
      "            expressing the Jacobian `J` as a function `grad_fn` which defines how `J`\n",
      "            will transform a vector `grad_ys` when left-multiplied with it (`grad_ys *\n",
      "            J`, the vector-Jacobian product, or VJP). This functional representation\n",
      "            of a matrix is convenient to use for chain-rule calculation (in e.g. the\n",
      "            back-propagation algorithm).  If `f` uses `Variable`s (that are not part\n",
      "            of the inputs), i.e. through `get_variable`, then `grad_fn` should have\n",
      "            signature `g(*grad_ys, variables=None)`, where `variables` is a list of\n",
      "            the `Variable`s, and return a 2-tuple `(grad_xs, grad_vars)`, where\n",
      "            `grad_xs` is the same as above, and `grad_vars` is a `list<Tensor>` with\n",
      "            the derivatives of `Tensor`s in `y` with respect to the variables (that\n",
      "            is, grad_vars has one Tensor per variable in variables).\n",
      "        \n",
      "        Returns:\n",
      "          A function `h(x)` which returns the same value as `f(x)[0]` and whose\n",
      "          gradient (as calculated by `tf.gradients`) is determined by `f(x)[1]`.\n",
      "    \n",
      "    decode_base64(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Decode web-safe base64-encoded strings.\n",
      "        \n",
      "        Input may or may not have padding at the end. See\n",
      "        [EncodeBase64](https://www.tensorflow.org/api_docs/python/tf/io/encode_base64)\n",
      "        for padding. Web-safe means that input must use - and _ instead of + and /.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Base64 strings to decode.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    decode_compressed(bytes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], compression_type: str = '', name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Decompress strings.\n",
      "        \n",
      "        This op decompresses each element of the `bytes` input `Tensor`, which\n",
      "        is assumed to be compressed using the given `compression_type`.\n",
      "        \n",
      "        The `output` is a string `Tensor` of the same shape as `bytes`,\n",
      "        each element containing the decompressed data from the corresponding\n",
      "        element in `bytes`.\n",
      "        \n",
      "        Args:\n",
      "          bytes: A `Tensor` of type `string`.\n",
      "            A Tensor of string which is compressed.\n",
      "          compression_type: An optional `string`. Defaults to `\"\"`.\n",
      "            A scalar containing either (i) the empty string (no\n",
      "            compression), (ii) \"ZLIB\", or (iii) \"GZIP\".\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    decode_csv(records, record_defaults, field_delim=',', use_quote_delim=True, name=None, na_value='', select_cols=None)\n",
      "        Convert CSV records to tensors. Each column maps to one tensor.\n",
      "        \n",
      "        RFC 4180 format is expected for the CSV records.\n",
      "        (https://tools.ietf.org/html/rfc4180)\n",
      "        Note that we allow leading and trailing spaces with int or float field.\n",
      "        \n",
      "        Args:\n",
      "          records: A `Tensor` of type `string`.\n",
      "            Each string is a record/row in the csv and all records should have\n",
      "            the same format.\n",
      "          record_defaults: A list of `Tensor` objects with specific types.\n",
      "            Acceptable types are `float32`, `float64`, `int32`, `int64`, `string`.\n",
      "            One tensor per column of the input record, with either a\n",
      "            scalar default value for that column or an empty vector if the column is\n",
      "            required.\n",
      "          field_delim: An optional `string`. Defaults to `\",\"`.\n",
      "            char delimiter to separate fields in a record.\n",
      "          use_quote_delim: An optional `bool`. Defaults to `True`.\n",
      "            If false, treats double quotation marks as regular\n",
      "            characters inside of the string fields (ignoring RFC 4180, Section 2,\n",
      "            Bullet 5).\n",
      "          name: A name for the operation (optional).\n",
      "          na_value: Additional string to recognize as NA/NaN.\n",
      "          select_cols: Optional sorted list of column indices to select. If specified,\n",
      "            only this subset of columns will be parsed and returned.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` objects. Has the same type as `record_defaults`.\n",
      "          Each tensor will have the same shape as records.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the arguments is malformed.\n",
      "    \n",
      "    decode_json_example(json_examples, name=None)\n",
      "        Convert JSON-encoded Example records to binary protocol buffer strings.\n",
      "        \n",
      "        Note: This is **not** a general purpose JSON parsing op.\n",
      "        \n",
      "        This op converts JSON-serialized `tf.train.Example` (maybe created with\n",
      "        `json_format.MessageToJson`, following the\n",
      "        [standard JSON mapping](\n",
      "        https://developers.google.com/protocol-buffers/docs/proto3#json))\n",
      "        to a binary-serialized `tf.train.Example` (equivalent to\n",
      "        `Example.SerializeToString()`) suitable for conversion to tensors with\n",
      "        `tf.io.parse_example`.\n",
      "        \n",
      "        Here is a `tf.train.Example` proto:\n",
      "        \n",
      "        >>> example = tf.train.Example(\n",
      "        ...   features=tf.train.Features(\n",
      "        ...       feature={\n",
      "        ...           \"a\": tf.train.Feature(\n",
      "        ...               int64_list=tf.train.Int64List(\n",
      "        ...                   value=[1, 1, 3]))}))\n",
      "        \n",
      "        Here it is converted to JSON:\n",
      "        \n",
      "        >>> from google.protobuf import json_format\n",
      "        >>> example_json = json_format.MessageToJson(example)\n",
      "        >>> print(example_json)\n",
      "        {\n",
      "          \"features\": {\n",
      "            \"feature\": {\n",
      "              \"a\": {\n",
      "                \"int64List\": {\n",
      "                  \"value\": [\n",
      "                    \"1\",\n",
      "                    \"1\",\n",
      "                    \"3\"\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        \n",
      "        This op converts the above json string to a binary proto:\n",
      "        \n",
      "        >>> example_binary = tf.io.decode_json_example(example_json)\n",
      "        >>> example_binary.numpy()\n",
      "        b'\\n\\x0f\\n\\r\\n\\x01a\\x12\\x08\\x1a\\x06\\x08\\x01\\x08\\x01\\x08\\x03'\n",
      "        \n",
      "        The OP works on string tensors of andy shape:\n",
      "        \n",
      "        >>> tf.io.decode_json_example([\n",
      "        ...     [example_json, example_json],\n",
      "        ...     [example_json, example_json]]).shape.as_list()\n",
      "        [2, 2]\n",
      "        \n",
      "        This resulting binary-string is equivalent to `Example.SerializeToString()`,\n",
      "        and can be converted to Tensors using `tf.io.parse_example` and related\n",
      "        functions:\n",
      "        \n",
      "        >>> tf.io.parse_example(\n",
      "        ...   serialized=[example_binary.numpy(),\n",
      "        ...              example.SerializeToString()],\n",
      "        ...   features = {'a': tf.io.FixedLenFeature(shape=[3], dtype=tf.int64)})\n",
      "        {'a': <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
      "         array([[1, 1, 3],\n",
      "                [1, 1, 3]])>}\n",
      "        \n",
      "        Args:\n",
      "          json_examples: A string tensor containing json-serialized `tf.Example`\n",
      "            protos.\n",
      "          name: A name for the op.\n",
      "        \n",
      "        Returns:\n",
      "          A string Tensor containing the binary-serialized `tf.Example` protos.\n",
      "        \n",
      "        Raises:\n",
      "           `tf.errors.InvalidArgumentError`: If the JSON could not be converted to a\n",
      "           `tf.Example`\n",
      "    \n",
      "    decode_raw = decode_raw_v1(input_bytes=None, out_type=None, little_endian=True, name=None, bytes=None)\n",
      "        Convert raw byte strings into tensors. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(bytes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        bytes is deprecated, use input_bytes instead\n",
      "        \n",
      "        Args:\n",
      "          input_bytes:\n",
      "            Each element of the input Tensor is converted to an array of bytes.\n",
      "          out_type:\n",
      "            `DType` of the output. Acceptable types are `half`, `float`, `double`,\n",
      "            `int32`, `uint16`, `uint8`, `int16`, `int8`, `int64`.\n",
      "          little_endian:\n",
      "            Whether the `input_bytes` data is in little-endian format. Data will be\n",
      "            converted into host byte order if necessary.\n",
      "          name: A name for the operation (optional).\n",
      "          bytes: Deprecated parameter. Use `input_bytes` instead.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` object storing the decoded bytes.\n",
      "    \n",
      "    delete_session_tensor(handle, name=None)\n",
      "        Delete the tensor for the given tensor handle.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Delete the tensor of a given tensor handle. The tensor is produced\n",
      "        in a previous run() and stored in the state of the session.\n",
      "        \n",
      "        Args:\n",
      "          handle: The string representation of a persistent tensor handle.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A pair of graph elements. The first is a placeholder for feeding a\n",
      "          tensor handle and the second is a deletion operation.\n",
      "    \n",
      "    depth_to_space(input, block_size, name=None, data_format='NHWC')\n",
      "        DepthToSpace for tensors of type T.\n",
      "        \n",
      "        Rearranges data from depth into blocks of spatial data.\n",
      "        This is the reverse transformation of SpaceToDepth. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `depth`\n",
      "        dimension are moved in spatial blocks to the `height` and `width` dimensions.\n",
      "        The attr `block_size` indicates the input block size and how the data is moved.\n",
      "        \n",
      "          * Chunks of data of size `block_size * block_size` from depth are rearranged\n",
      "            into non-overlapping blocks of size `block_size x block_size`\n",
      "          * The width of the output tensor is `input_depth * block_size`, whereas the\n",
      "            height is `input_height * block_size`.\n",
      "          * The Y, X coordinates within each block of the output image are determined\n",
      "            by the high order component of the input channel index.\n",
      "          * The depth of the input tensor must be divisible by\n",
      "            `block_size * block_size`.\n",
      "        \n",
      "        The `data_format` attr specifies the layout of the input and output tensors\n",
      "        with the following options:\n",
      "          \"NHWC\": `[ batch, height, width, channels ]`\n",
      "          \"NCHW\": `[ batch, channels, height, width ]`\n",
      "          \"NCHW_VECT_C\":\n",
      "              `qint8 [ batch, channels / 4, height, width, 4 ]`\n",
      "        \n",
      "        It is useful to consider the operation as transforming a 6-D Tensor.\n",
      "        e.g. for data_format = NHWC,\n",
      "             Each element in the input tensor can be specified via 6 coordinates,\n",
      "             ordered by decreasing memory layout significance as:\n",
      "             n,iY,iX,bY,bX,oC  (where n=batch index, iX, iY means X or Y coordinates\n",
      "                                within the input image, bX, bY means coordinates\n",
      "                                within the output block, oC means output channels).\n",
      "             The output would be the input transposed to the following layout:\n",
      "             n,iY,bY,iX,bX,oC\n",
      "        \n",
      "        This operation is useful for resizing the activations between convolutions\n",
      "        (but keeping all data), e.g. instead of pooling. It is also useful for training\n",
      "        purely convolutional models.\n",
      "        \n",
      "        For example, given an input of shape `[1, 1, 1, 4]`, data_format = \"NHWC\" and\n",
      "        block_size = 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        This operation will output a tensor of shape `[1, 2, 2, 1]`:\n",
      "        \n",
      "        ```\n",
      "           [[[[1], [2]],\n",
      "             [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,\n",
      "        the corresponding output will have 2x2 elements and will have a depth of\n",
      "        1 channel (1 = `4 / (block_size * block_size)`).\n",
      "        The output element shape is `[2, 2, 1]`.\n",
      "        \n",
      "        For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation, for block size of 2, will return the following tensor of shape\n",
      "        `[1, 2, 2, 3]`\n",
      "        \n",
      "        ```\n",
      "           [[[[1, 2, 3], [4, 5, 6]],\n",
      "             [[7, 8, 9], [10, 11, 12]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:\n",
      "        \n",
      "        ```\n",
      "        x =  [[[[1, 2, 3, 4],\n",
      "               [5, 6, 7, 8]],\n",
      "              [[9, 10, 11, 12],\n",
      "               [13, 14, 15, 16]]]]\n",
      "        ```\n",
      "        \n",
      "        the operator will return the following tensor of shape `[1 4 4 1]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[ [1],   [2],  [5],  [6]],\n",
      "              [ [3],   [4],  [7],  [8]],\n",
      "              [ [9],  [10], [13],  [14]],\n",
      "              [ [11], [12], [15],  [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "            The size of the spatial block, same as in Space2Depth.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\", \"NCHW_VECT_C\"`. Defaults to `\"NHWC\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    dequantize(input, min_range, max_range, mode='MIN_COMBINED', name=None, axis=None, narrow_range=False, dtype=tf.float32)\n",
      "        Dequantize the 'input' tensor into a float or bfloat16 Tensor.\n",
      "        \n",
      "        [min_range, max_range] are scalar floats that specify the range for\n",
      "        the output. The 'mode' attribute controls exactly which calculations are\n",
      "        used to convert the float values to their quantized equivalents.\n",
      "        \n",
      "        In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:\n",
      "        \n",
      "        ```\n",
      "        if T == qint8: in[i] += (range(T) + 1)/ 2.0\n",
      "        out[i] = min_range + (in[i]* (max_range - min_range) / range(T))\n",
      "        ```\n",
      "        here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`\n",
      "        \n",
      "        *MIN_COMBINED Mode Example*\n",
      "        \n",
      "        If the input comes from a QuantizedRelu6, the output type is\n",
      "        quint8 (range of 0-255) but the possible range of QuantizedRelu6 is\n",
      "        0-6.  The min_range and max_range values are therefore 0.0 and 6.0.\n",
      "        Dequantize on quint8 will take each value, cast to float, and multiply\n",
      "        by 6 / 255.\n",
      "        Note that if quantizedtype is qint8, the operation will additionally add\n",
      "        each value by 128 prior to casting.\n",
      "        \n",
      "        If the mode is 'MIN_FIRST', then this approach is used:\n",
      "        \n",
      "        ```c++\n",
      "        num_discrete_values = 1 << (# of bits in T)\n",
      "        range_adjust = num_discrete_values / (num_discrete_values - 1)\n",
      "        range = (range_max - range_min) * range_adjust\n",
      "        range_scale = range / num_discrete_values\n",
      "        const double offset_input = static_cast<double>(input) - lowest_quantized;\n",
      "        result = range_min + ((input - numeric_limits<T>::min()) * range_scale)\n",
      "        ```\n",
      "        \n",
      "        If the mode is `SCALED`, dequantization is performed by multiplying each\n",
      "        input value by a scaling_factor. (Thus an input of 0 always maps to 0.0).\n",
      "        \n",
      "        The scaling_factor is determined from `min_range`, `max_range`, and\n",
      "        `narrow_range` in a way that is compatible with `QuantizeAndDequantize{V2|V3}`\n",
      "        and `QuantizeV2`, using the following algorithm:\n",
      "        \n",
      "        ```c++\n",
      "        \n",
      "          const int min_expected_T = std::numeric_limits<T>::min() +\n",
      "            (narrow_range ? 1 : 0);\n",
      "          const int max_expected_T = std::numeric_limits<T>::max();\n",
      "          const float max_expected_T = std::numeric_limits<float>::max();\n",
      "        \n",
      "          const float scale_factor =\n",
      "            (std::numeric_limits<T>::min() == 0) ? (max_range / max_expected_T)\n",
      "                                                 : std::max(min_range / min_expected_T,\n",
      "                                                            max_range / max_expected_T);\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.\n",
      "          min_range: A `Tensor` of type `float32`.\n",
      "            The minimum scalar value possibly produced for the input.\n",
      "          max_range: A `Tensor` of type `float32`.\n",
      "            The maximum scalar value possibly produced for the input.\n",
      "          mode: An optional `string` from: `\"MIN_COMBINED\", \"MIN_FIRST\", \"SCALED\"`. Defaults to `\"MIN_COMBINED\"`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          axis: An optional `int`. Defaults to `-1`.\n",
      "          dtype: An optional `tf.DType` from: `tf.bfloat16, tf.float32`. Defaults to `tf.float32`.\n",
      "            Type of the output tensor. Currently Dequantize supports float and bfloat16.\n",
      "            If 'dtype' is 'bfloat16', it only supports 'MIN_COMBINED' mode.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `dtype`.\n",
      "    \n",
      "    deserialize_many_sparse(serialized_sparse, dtype, rank=None, name=None)\n",
      "        Deserialize and concatenate `SparseTensors` from a serialized minibatch.\n",
      "        \n",
      "        The input `serialized_sparse` must be a string matrix of shape `[N x 3]` where\n",
      "        `N` is the minibatch size and the rows correspond to packed outputs of\n",
      "        `serialize_sparse`.  The ranks of the original `SparseTensor` objects\n",
      "        must all match.  When the final `SparseTensor` is created, it has rank one\n",
      "        higher than the ranks of the incoming `SparseTensor` objects (they have been\n",
      "        concatenated along a new row dimension).\n",
      "        \n",
      "        The output `SparseTensor` object's shape values for all dimensions but the\n",
      "        first are the max across the input `SparseTensor` objects' shape values\n",
      "        for the corresponding dimensions.  Its first shape value is `N`, the minibatch\n",
      "        size.\n",
      "        \n",
      "        The input `SparseTensor` objects' indices are assumed ordered in\n",
      "        standard lexicographic order.  If this is not the case, after this\n",
      "        step run `sparse.reorder` to restore index ordering.\n",
      "        \n",
      "        For example, if the serialized input is a `[2, 3]` matrix representing two\n",
      "        original `SparseTensor` objects:\n",
      "        \n",
      "            index = [ 0]\n",
      "                    [10]\n",
      "                    [20]\n",
      "            values = [1, 2, 3]\n",
      "            shape = [50]\n",
      "        \n",
      "        and\n",
      "        \n",
      "            index = [ 2]\n",
      "                    [10]\n",
      "            values = [4, 5]\n",
      "            shape = [30]\n",
      "        \n",
      "        then the final deserialized `SparseTensor` will be:\n",
      "        \n",
      "            index = [0  0]\n",
      "                    [0 10]\n",
      "                    [0 20]\n",
      "                    [1  2]\n",
      "                    [1 10]\n",
      "            values = [1, 2, 3, 4, 5]\n",
      "            shape = [2 50]\n",
      "        \n",
      "        Args:\n",
      "          serialized_sparse: 2-D `Tensor` of type `string` of shape `[N, 3]`.\n",
      "            The serialized and packed `SparseTensor` objects.\n",
      "          dtype: The `dtype` of the serialized `SparseTensor` objects.\n",
      "          rank: (optional) Python int, the rank of the `SparseTensor` objects.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` representing the deserialized `SparseTensor`s,\n",
      "          concatenated along the `SparseTensor`s' first dimension.\n",
      "        \n",
      "          All of the serialized `SparseTensor`s must have had the same rank and type.\n",
      "    \n",
      "    device(device_name_or_function) -> ContextManager[NoneType]\n",
      "        Wrapper for `Graph.device()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.device` for more details.\n",
      "        \n",
      "        Args:\n",
      "          device_name_or_function: The device name or function to use in the context.\n",
      "        \n",
      "        Returns:\n",
      "          A context manager that specifies the default device to use for newly\n",
      "          created ops.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If eager execution is enabled and a function is passed in.\n",
      "    \n",
      "    diag(diagonal: Annotated[Any, ~TV_Diag_T], name=None) -> Annotated[Any, ~TV_Diag_T]\n",
      "        Returns a diagonal tensor with a given diagonal values.\n",
      "        \n",
      "        Given a `diagonal`, this operation returns a tensor with the `diagonal` and\n",
      "        everything else padded with zeros. The diagonal is computed as follows:\n",
      "        \n",
      "        Assume `diagonal` has dimensions [D1,..., Dk], then the output is a tensor of\n",
      "        rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:\n",
      "        \n",
      "        `output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]` and 0 everywhere else.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # 'diagonal' is [1, 2, 3, 4]\n",
      "        tf.diag(diagonal) ==> [[1, 0, 0, 0]\n",
      "                               [0, 2, 0, 0]\n",
      "                               [0, 0, 3, 0]\n",
      "                               [0, 0, 0, 4]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          diagonal: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "            Rank k tensor where k is at most 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `diagonal`.\n",
      "    \n",
      "    diag_part = tensor_diag_part(input, name=None)\n",
      "        Returns the diagonal part of the tensor.\n",
      "        \n",
      "        This operation returns a tensor with the `diagonal` part\n",
      "        of the `input`. The `diagonal` part is computed as follows:\n",
      "        \n",
      "        Assume `input` has dimensions `[D1,..., Dk, D1,..., Dk]`, then the output is a\n",
      "        tensor of rank `k` with dimensions `[D1,..., Dk]` where:\n",
      "        \n",
      "        `diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]`.\n",
      "        \n",
      "        For a rank 2 tensor, `linalg.diag_part` and `linalg.tensor_diag_part`\n",
      "        produce the same result. For rank 3 and higher, linalg.diag_part extracts\n",
      "        the diagonal of each inner-most matrix in the tensor. An example where\n",
      "        they differ is given below.\n",
      "        \n",
      "        >>> x = [[[[1111,1112],[1121,1122]],\n",
      "        ...       [[1211,1212],[1221,1222]]],\n",
      "        ...      [[[2111, 2112], [2121, 2122]],\n",
      "        ...       [[2211, 2212], [2221, 2222]]]\n",
      "        ...      ]\n",
      "        >>> tf.linalg.tensor_diag_part(x)\n",
      "        <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "        array([[1111, 1212],\n",
      "               [2121, 2222]], dtype=int32)>\n",
      "        >>> tf.linalg.diag_part(x).shape\n",
      "        TensorShape([2, 2, 2])\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` with rank `2k`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor containing diagonals of `input`. Has the same type as `input`, and\n",
      "          rank `k`.\n",
      "    \n",
      "    digamma(x: typing.Annotated[_any, ~TV_Digamma_T], name=None) -> typing.Annotated[_any, ~TV_Digamma_T]\n",
      "        Computes Psi, the derivative of Lgamma (the log of the absolute value of\n",
      "        \n",
      "        `Gamma(x)`), element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    dimension_at_index(shape, index) -> 'Dimension'\n",
      "        Compatibility utility required to allow for both V1 and V2 behavior in TF.\n",
      "        \n",
      "        Until the release of TF 2.0, we need the legacy behavior of `TensorShape` to\n",
      "        coexist with the new behavior. This utility is a bridge between the two.\n",
      "        \n",
      "        If you want to retrieve the Dimension instance corresponding to a certain\n",
      "        index in a TensorShape instance, use this utility, like this:\n",
      "        \n",
      "        ```\n",
      "        # If you had this in your V1 code:\n",
      "        dim = tensor_shape[i]\n",
      "        \n",
      "        # Use `dimension_at_index` as direct replacement compatible with both V1 & V2:\n",
      "        dim = dimension_at_index(tensor_shape, i)\n",
      "        \n",
      "        # Another possibility would be this, but WARNING: it only works if the\n",
      "        # tensor_shape instance has a defined rank.\n",
      "        dim = tensor_shape.dims[i]  # `dims` may be None if the rank is undefined!\n",
      "        \n",
      "        # In native V2 code, we recommend instead being more explicit:\n",
      "        if tensor_shape.rank is None:\n",
      "          dim = Dimension(None)\n",
      "        else:\n",
      "          dim = tensor_shape.dims[i]\n",
      "        \n",
      "        # Being more explicit will save you from the following trap (present in V1):\n",
      "        # you might do in-place modifications to `dim` and expect them to be reflected\n",
      "        # in `tensor_shape[i]`, but they would not be (as the Dimension object was\n",
      "        # instantiated on the fly.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          shape: A TensorShape instance.\n",
      "          index: An integer index.\n",
      "        \n",
      "        Returns:\n",
      "          A dimension object.\n",
      "    \n",
      "    dimension_value(dimension: Union[ForwardRef('Dimension'), int, NoneType]) -> Optional[int]\n",
      "        Compatibility utility required to allow for both V1 and V2 behavior in TF.\n",
      "        \n",
      "        Until the release of TF 2.0, we need the legacy behavior of `TensorShape` to\n",
      "        coexist with the new behavior. This utility is a bridge between the two.\n",
      "        \n",
      "        When accessing the value of a TensorShape dimension,\n",
      "        use this utility, like this:\n",
      "        \n",
      "        ```\n",
      "        # If you had this in your V1 code:\n",
      "        value = tensor_shape[i].value\n",
      "        \n",
      "        # Use `dimension_value` as direct replacement compatible with both V1 & V2:\n",
      "        value = dimension_value(tensor_shape[i])\n",
      "        \n",
      "        # This would be the V2 equivalent:\n",
      "        value = tensor_shape[i]  # Warning: this will return the dim value in V2!\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          dimension: Either a `Dimension` instance, an integer, or None.\n",
      "        \n",
      "        Returns:\n",
      "          A plain value, i.e. an integer or None.\n",
      "    \n",
      "    disable_control_flow_v2()\n",
      "        Opts out of control flow v2.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function. Calling this\n",
      "        function has no effect in that case.\n",
      "        \n",
      "        If your code needs tf.disable_control_flow_v2() to be called to work\n",
      "        properly please file a bug.\n",
      "    \n",
      "    disable_eager_execution() -> None\n",
      "        Disables eager execution.\n",
      "        \n",
      "        This function can only be called before any Graphs, Ops, or Tensors have been\n",
      "        created.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This function is not necessary if you are using TF2. Eager execution is\n",
      "        enabled by default. If you want to use Graph mode please consider\n",
      "        [tf.function](https://www.tensorflow.org/api_docs/python/tf/function).\n",
      "        @end_compatibility\n",
      "    \n",
      "    disable_resource_variables() -> None\n",
      "        Opts out of resource variables. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        non-resource variables are not supported in the long term\n",
      "        \n",
      "        If your code needs tf.disable_resource_variables() to be called to work\n",
      "        properly please file a bug.\n",
      "    \n",
      "    disable_tensor_equality()\n",
      "        Compare Tensors by their id and be hashable.\n",
      "        \n",
      "        This is a legacy behaviour of TensorFlow and is highly discouraged.\n",
      "    \n",
      "    disable_v2_behavior()\n",
      "        Disables TensorFlow 2.x behaviors.\n",
      "        \n",
      "        This function can be called at the beginning of the program (before `Tensors`,\n",
      "        `Graphs` or other structures have been created, and before devices have been\n",
      "        initialized. It switches all global behaviors that are different between\n",
      "        TensorFlow 1.x and 2.x to behave as intended for 1.x.\n",
      "        \n",
      "        User can call this function to disable 2.x behavior during complex migrations.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Using this function indicates that your software is not compatible\n",
      "        with eager execution and `tf.function` in TF2.\n",
      "        \n",
      "        To migrate to TF2, rewrite your code to be compatible with eager execution.\n",
      "        Please refer to the [migration guide]\n",
      "        (https://www.tensorflow.org/guide/migrate) for additional resource on the\n",
      "        topic.\n",
      "        @end_compatibility\n",
      "    \n",
      "    disable_v2_tensorshape()\n",
      "        Disables the V2 TensorShape behavior and reverts to V1 behavior.\n",
      "        \n",
      "        See docstring for `enable_v2_tensorshape` for details about the new behavior.\n",
      "    \n",
      "    div(x, y, name=None)\n",
      "        Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Deprecated in favor of operator or tf.math.divide.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
      "        `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
      "        semantics.\n",
      "        @end_compatibility\n",
      "        \n",
      "        \n",
      "        This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "        and `y` are both integers then the result will be an integer. This is in\n",
      "        contrast to Python 3, where division with `/` is always a float while division\n",
      "        with `//` is always an integer.\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of real numeric type.\n",
      "          y: `Tensor` denominator of real numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` returns the quotient of x and y.\n",
      "    \n",
      "    div_no_nan(x, y, name=None)\n",
      "        Computes a safe divide which returns 0 if `y` (denominator) is zero.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.constant(3.0) / 0.0\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=inf>\n",
      "        >>> tf.math.divide_no_nan(3.0, 0.0)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=0.0>\n",
      "        \n",
      "        Note that 0 is returned if `y` is 0 even if `x` is nonfinite:\n",
      "        \n",
      "        >>> tf.math.divide_no_nan(np.nan, 0.0)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=0.0>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of a floating or integer dtype.\n",
      "          y: A `Tensor` with the same dtype as `x` and a compatible shape.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The element-wise quotient as in `tf.math.divide(x, y)`,\n",
      "          except that division by zero produces `0.0`, not `nan`.\n",
      "    \n",
      "    divide(x, y, name=None)\n",
      "        Computes Python style division of `x` by `y`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([16, 12, 11])\n",
      "        >>> y = tf.constant([4, 6, 2])\n",
      "        >>> tf.divide(x,y)\n",
      "        <tf.Tensor: shape=(3,), dtype=float64,\n",
      "        numpy=array([4. , 2. , 5.5])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`\n",
      "          y: A `Tensor`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with same shape as input\n",
      "    \n",
      "    dynamic_partition(data: Annotated[Any, ~TV_DynamicPartition_T], partitions: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], num_partitions: int, name=None)\n",
      "        Partitions `data` into `num_partitions` tensors using indices from `partitions`.\n",
      "        \n",
      "        For each index tuple `js` of size `partitions.ndim`, the slice `data[js, ...]`\n",
      "        becomes part of `outputs[partitions[js]]`.  The slices with `partitions[js] = i`\n",
      "        are placed in `outputs[i]` in lexicographic order of `js`, and the first\n",
      "        dimension of `outputs[i]` is the number of entries in `partitions` equal to `i`.\n",
      "        In detail,\n",
      "        \n",
      "        ```python\n",
      "            outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]\n",
      "        \n",
      "            outputs[i] = pack([data[js, ...] for js if partitions[js] == i])\n",
      "        ```\n",
      "        \n",
      "        `data.shape` must start with `partitions.shape`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "            # Scalar partitions.\n",
      "            partitions = 1\n",
      "            num_partitions = 2\n",
      "            data = [10, 20]\n",
      "            outputs[0] = []  # Empty with shape [0, 2]\n",
      "            outputs[1] = [[10, 20]]\n",
      "        \n",
      "            # Vector partitions.\n",
      "            partitions = [0, 0, 1, 1, 0]\n",
      "            num_partitions = 2\n",
      "            data = [10, 20, 30, 40, 50]\n",
      "            outputs[0] = [10, 20, 50]\n",
      "            outputs[1] = [30, 40]\n",
      "        ```\n",
      "        \n",
      "        See `dynamic_stitch` for an example on how to merge partitions back.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/DynamicPartition.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        \n",
      "        Raises:\n",
      "          * `InvalidArgumentError` in following cases:\n",
      "            - If partitions is not in range `[0, num_partiions)`\n",
      "            - If `partitions.shape` does not match prefix of `data.shape` argument.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`.\n",
      "          partitions: A `Tensor` of type `int32`.\n",
      "            Any shape.  Indices in the range `[0, num_partitions)`.\n",
      "          num_partitions: An `int` that is `>= 1`.\n",
      "            The number of partitions to output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `num_partitions` `Tensor` objects with the same type as `data`.\n",
      "    \n",
      "    dynamic_stitch(indices: Annotated[List[Any], <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], data: Annotated[List[Any], ~TV_DynamicStitch_T], name=None) -> Annotated[Any, ~TV_DynamicStitch_T]\n",
      "        Interleave the values from the `data` tensors into a single tensor.\n",
      "        \n",
      "        Builds a merged tensor such that\n",
      "        \n",
      "        ```python\n",
      "            merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        For example, if each `indices[m]` is scalar or vector, we have\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices:\n",
      "            merged[indices[m], ...] = data[m][...]\n",
      "        \n",
      "            # Vector indices:\n",
      "            merged[indices[m][i], ...] = data[m][i, ...]\n",
      "        ```\n",
      "        \n",
      "        Each `data[i].shape` must start with the corresponding `indices[i].shape`,\n",
      "        and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we\n",
      "        must have `data[i].shape = indices[i].shape + constant`.  In terms of this\n",
      "        `constant`, the output shape is\n",
      "        \n",
      "            merged.shape = [max(indices) + 1] + constant\n",
      "        \n",
      "        Values are merged in order, so if an index appears in both `indices[m][i]` and\n",
      "        `indices[n][j]` for `(m,i) < (n,j)` the slice `data[n][j]` will appear in the\n",
      "        merged result. If you do not need this guarantee, ParallelDynamicStitch might\n",
      "        perform better on some devices.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "            indices[0] = 6\n",
      "            indices[1] = [4, 1]\n",
      "            indices[2] = [[5, 2], [0, 3]]\n",
      "            data[0] = [61, 62]\n",
      "            data[1] = [[41, 42], [11, 12]]\n",
      "            data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]\n",
      "            merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],\n",
      "                      [51, 52], [61, 62]]\n",
      "        ```\n",
      "        \n",
      "        This method can be used to merge partitions created by `dynamic_partition`\n",
      "        as illustrated on the following example:\n",
      "        \n",
      "        ```python\n",
      "            # Apply function (increments x_i) on elements for which a certain condition\n",
      "            # apply (x_i != -1 in this example).\n",
      "            x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])\n",
      "            condition_mask=tf.not_equal(x,tf.constant(-1.))\n",
      "            partitioned_data = tf.dynamic_partition(\n",
      "                x, tf.cast(condition_mask, tf.int32) , 2)\n",
      "            partitioned_data[1] = partitioned_data[1] + 1.0\n",
      "            condition_indices = tf.dynamic_partition(\n",
      "                tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)\n",
      "            x = tf.dynamic_stitch(condition_indices, partitioned_data)\n",
      "            # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain\n",
      "            # unchanged.\n",
      "        ```\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/DynamicStitch.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          indices: A list of at least 1 `Tensor` objects with type `int32`.\n",
      "          data: A list with the same length as `indices` of `Tensor` objects with the same type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    edit_distance(hypothesis, truth, normalize=True, name='edit_distance')\n",
      "        Computes the Levenshtein distance between sequences.\n",
      "        \n",
      "        This operation takes variable-length sequences (`hypothesis` and `truth`),\n",
      "        each provided as a `SparseTensor`, and computes the Levenshtein distance.\n",
      "        You can normalize the edit distance by length of `truth` by setting\n",
      "        `normalize` to true.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        Given the following input,\n",
      "        * `hypothesis` is a `tf.SparseTensor` of shape `[2, 1, 1]`\n",
      "        * `truth` is a `tf.SparseTensor` of shape `[2, 2, 2]`\n",
      "        \n",
      "        >>> hypothesis = tf.SparseTensor(\n",
      "        ...   [[0, 0, 0],\n",
      "        ...    [1, 0, 0]],\n",
      "        ...   [\"a\", \"b\"],\n",
      "        ...   (2, 1, 1))\n",
      "        >>> truth = tf.SparseTensor(\n",
      "        ...   [[0, 1, 0],\n",
      "        ...    [1, 0, 0],\n",
      "        ...    [1, 0, 1],\n",
      "        ...    [1, 1, 0]],\n",
      "        ...    [\"a\", \"b\", \"c\", \"a\"],\n",
      "        ...    (2, 2, 2))\n",
      "        >>> tf.edit_distance(hypothesis, truth, normalize=True)\n",
      "        <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "        array([[inf, 1. ],\n",
      "               [0.5, 1. ]], dtype=float32)>\n",
      "        \n",
      "        The operation returns a dense Tensor of shape `[2, 2]` with\n",
      "        edit distances normalized by `truth` lengths.\n",
      "        \n",
      "        **Note**: It is possible to calculate edit distance between two\n",
      "        sparse tensors with variable-length values. However, attempting to create\n",
      "        them while eager execution is enabled will result in a `ValueError`.\n",
      "        \n",
      "        For the following  inputs,\n",
      "        \n",
      "        ```python\n",
      "        # 'hypothesis' is a tensor of shape `[2, 1]` with variable-length values:\n",
      "        #   (0,0) = [\"a\"]\n",
      "        #   (1,0) = [\"b\"]\n",
      "        hypothesis = tf.sparse.SparseTensor(\n",
      "            [[0, 0, 0],\n",
      "             [1, 0, 0]],\n",
      "            [\"a\", \"b\"],\n",
      "            (2, 1, 1))\n",
      "        \n",
      "        # 'truth' is a tensor of shape `[2, 2]` with variable-length values:\n",
      "        #   (0,0) = []\n",
      "        #   (0,1) = [\"a\"]\n",
      "        #   (1,0) = [\"b\", \"c\"]\n",
      "        #   (1,1) = [\"a\"]\n",
      "        truth = tf.sparse.SparseTensor(\n",
      "            [[0, 1, 0],\n",
      "             [1, 0, 0],\n",
      "             [1, 0, 1],\n",
      "             [1, 1, 0]],\n",
      "            [\"a\", \"b\", \"c\", \"a\"],\n",
      "            (2, 2, 2))\n",
      "        \n",
      "        normalize = True\n",
      "        \n",
      "        # The output would be a dense Tensor of shape `(2,)`, with edit distances\n",
      "        normalized by 'truth' lengths.\n",
      "        # output => array([0., 0.5], dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          hypothesis: A `SparseTensor` containing hypothesis sequences.\n",
      "          truth: A `SparseTensor` containing truth sequences.\n",
      "          normalize: A `bool`. If `True`, normalizes the Levenshtein distance by\n",
      "            length of `truth.`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A dense `Tensor` with rank `R - 1`, where R is the rank of the\n",
      "          `SparseTensor` inputs `hypothesis` and `truth`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If either `hypothesis` or `truth` are not a `SparseTensor`.\n",
      "    \n",
      "    einsum(equation, *inputs, **kwargs)\n",
      "        Tensor contraction over specified indices and outer product.\n",
      "        \n",
      "        Einsum allows defining Tensors by defining their element-wise computation.\n",
      "        This computation is defined by `equation`, a shorthand form based on Einstein\n",
      "        summation. As an example, consider multiplying two matrices A and B to form a\n",
      "        matrix C.  The elements of C are given by:\n",
      "        \n",
      "        $$ C_{i,k} = \\sum_j A_{i,j} B_{j,k} $$\n",
      "        \n",
      "        or\n",
      "        \n",
      "        ```\n",
      "        C[i,k] = sum_j A[i,j] * B[j,k]\n",
      "        ```\n",
      "        \n",
      "        The corresponding einsum `equation` is:\n",
      "        \n",
      "        ```\n",
      "        ij,jk->ik\n",
      "        ```\n",
      "        \n",
      "        In general, to convert the element-wise equation into the `equation` string,\n",
      "        use the following procedure (intermediate strings for matrix multiplication\n",
      "        example provided in parentheses):\n",
      "        \n",
      "        1. remove variable names, brackets, and commas, (`ik = sum_j ij * jk`)\n",
      "        2. replace \"*\" with \",\", (`ik = sum_j ij , jk`)\n",
      "        3. drop summation signs, and (`ik = ij, jk`)\n",
      "        4. move the output to the right, while replacing \"=\" with \"->\". (`ij,jk->ik`)\n",
      "        \n",
      "        Note: If the output indices are not specified repeated indices are summed.\n",
      "        So `ij,jk->ik` can be simplified to `ij,jk`.\n",
      "        \n",
      "        Many common operations can be expressed in this way.  For example:\n",
      "        \n",
      "        **Matrix multiplication**\n",
      "        \n",
      "        >>> m0 = tf.random.normal(shape=[2, 3])\n",
      "        >>> m1 = tf.random.normal(shape=[3, 5])\n",
      "        >>> e = tf.einsum('ij,jk->ik', m0, m1)\n",
      "        >>> # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
      "        >>> print(e.shape)\n",
      "        (2, 5)\n",
      "        \n",
      "        Repeated indices are summed if the output indices are not specified.\n",
      "        \n",
      "        >>> e = tf.einsum('ij,jk', m0, m1)  # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
      "        >>> print(e.shape)\n",
      "        (2, 5)\n",
      "        \n",
      "        \n",
      "        **Dot product**\n",
      "        \n",
      "        >>> u = tf.random.normal(shape=[5])\n",
      "        >>> v = tf.random.normal(shape=[5])\n",
      "        >>> e = tf.einsum('i,i->', u, v)  # output = sum_i u[i]*v[i]\n",
      "        >>> print(e.shape)\n",
      "        ()\n",
      "        \n",
      "        **Outer product**\n",
      "        \n",
      "        >>> u = tf.random.normal(shape=[3])\n",
      "        >>> v = tf.random.normal(shape=[5])\n",
      "        >>> e = tf.einsum('i,j->ij', u, v)  # output[i,j] = u[i]*v[j]\n",
      "        >>> print(e.shape)\n",
      "        (3, 5)\n",
      "        \n",
      "        **Transpose**\n",
      "        \n",
      "        >>> m = tf.ones(2,3)\n",
      "        >>> e = tf.einsum('ij->ji', m0)  # output[j,i] = m0[i,j]\n",
      "        >>> print(e.shape)\n",
      "        (3, 2)\n",
      "        \n",
      "        **Diag**\n",
      "        \n",
      "        >>> m = tf.reshape(tf.range(9), [3,3])\n",
      "        >>> diag = tf.einsum('ii->i', m)\n",
      "        >>> print(diag.shape)\n",
      "        (3,)\n",
      "        \n",
      "        **Trace**\n",
      "        \n",
      "        >>> # Repeated indices are summed.\n",
      "        >>> trace = tf.einsum('ii', m)  # output[j,i] = trace(m) = sum_i m[i, i]\n",
      "        >>> assert trace == sum(diag)\n",
      "        >>> print(trace.shape)\n",
      "        ()\n",
      "        \n",
      "        **Batch matrix multiplication**\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[7,5,3])\n",
      "        >>> t = tf.random.normal(shape=[7,3,2])\n",
      "        >>> e = tf.einsum('bij,bjk->bik', s, t)\n",
      "        >>> # output[a,i,k] = sum_j s[a,i,j] * t[a, j, k]\n",
      "        >>> print(e.shape)\n",
      "        (7, 5, 2)\n",
      "        \n",
      "        This method does not support broadcasting on named-axes. All axes with\n",
      "        matching labels should have the same length. If you have length-1 axes,\n",
      "        use `tf.squeeze` or `tf.reshape` to eliminate them.\n",
      "        \n",
      "        To write code that is agnostic to the number of indices in the input\n",
      "        use an ellipsis. The ellipsis is a placeholder for \"whatever other indices\n",
      "        fit here\".\n",
      "        \n",
      "        For example, to perform a NumPy-style broadcasting-batch-matrix multiplication\n",
      "        where the matrix multiply acts on the last two axes of the input, use:\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[11, 7, 5, 3])\n",
      "        >>> t = tf.random.normal(shape=[11, 7, 3, 2])\n",
      "        >>> e =  tf.einsum('...ij,...jk->...ik', s, t)\n",
      "        >>> print(e.shape)\n",
      "        (11, 7, 5, 2)\n",
      "        \n",
      "        Einsum **will** broadcast over axes covered by the ellipsis.\n",
      "        \n",
      "        >>> s = tf.random.normal(shape=[11, 1, 5, 3])\n",
      "        >>> t = tf.random.normal(shape=[1, 7, 3, 2])\n",
      "        >>> e =  tf.einsum('...ij,...jk->...ik', s, t)\n",
      "        >>> print(e.shape)\n",
      "        (11, 7, 5, 2)\n",
      "        \n",
      "        Args:\n",
      "          equation: a `str` describing the contraction, in the same format as\n",
      "            `numpy.einsum`.\n",
      "          *inputs: the inputs to contract (each one a `Tensor`), whose shapes should\n",
      "            be consistent with `equation`.\n",
      "          **kwargs:\n",
      "            - optimize: Optimization strategy to use to find contraction path using\n",
      "              opt_einsum. Must be 'greedy', 'optimal', 'branch-2', 'branch-all' or\n",
      "                'auto'. (optional, default: 'greedy').\n",
      "            - name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The contracted `Tensor`, with shape determined by `equation`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If\n",
      "            - the format of `equation` is incorrect,\n",
      "            - number of inputs or their shapes are inconsistent with `equation`.\n",
      "    \n",
      "    enable_control_flow_v2()\n",
      "        Use control flow v2.\n",
      "        \n",
      "        control flow v2 (cfv2) is an improved version of control flow in TensorFlow\n",
      "        with support for higher order derivatives. Enabling cfv2 will change the\n",
      "        graph/function representation of control flow, e.g., `tf.while_loop` and\n",
      "        `tf.cond` will generate functional `While` and `If` ops instead of low-level\n",
      "        `Switch`, `Merge` etc. ops. Note: Importing and running graphs exported\n",
      "        with old control flow will still be supported.\n",
      "        \n",
      "        Calling tf.enable_control_flow_v2() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function. Calling this\n",
      "        function is not required.\n",
      "    \n",
      "    enable_eager_execution(config=None, device_policy=None, execution_mode=None) -> None\n",
      "        Enables eager execution for the lifetime of this program.\n",
      "        \n",
      "        Eager execution provides an imperative interface to TensorFlow. With eager\n",
      "        execution enabled, TensorFlow functions execute operations immediately (as\n",
      "        opposed to adding to a graph to be executed later in a `tf.compat.v1.Session`)\n",
      "        and\n",
      "        return concrete values (as opposed to symbolic references to a node in a\n",
      "        computational graph).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        # After eager execution is enabled, operations are executed as they are\n",
      "        # defined and Tensor objects hold concrete values, which can be accessed as\n",
      "        # numpy.ndarray`s through the numpy() method.\n",
      "        assert tf.multiply(6, 7).numpy() == 42\n",
      "        ```\n",
      "        \n",
      "        Eager execution cannot be enabled after TensorFlow APIs have been used to\n",
      "        create or execute graphs. It is typically recommended to invoke this function\n",
      "        at program startup and not in a library (as most libraries should be usable\n",
      "        both with and without eager execution).\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This function is not necessary if you are using TF2. Eager execution is\n",
      "        enabled by default.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          config: (Optional.) A `tf.compat.v1.ConfigProto` to use to configure the\n",
      "            environment in which operations are executed. Note that\n",
      "            `tf.compat.v1.ConfigProto` is also used to configure graph execution (via\n",
      "            `tf.compat.v1.Session`) and many options within `tf.compat.v1.ConfigProto`\n",
      "            are not implemented (or are irrelevant) when eager execution is enabled.\n",
      "          device_policy: (Optional.) Policy controlling how operations requiring\n",
      "            inputs on a specific device (e.g., a GPU 0) handle inputs on a different\n",
      "            device  (e.g. GPU 1 or CPU). When set to None, an appropriate value will\n",
      "            be picked automatically. The value picked may change between TensorFlow\n",
      "            releases.\n",
      "            Valid values:\n",
      "            - DEVICE_PLACEMENT_EXPLICIT: raises an error if the\n",
      "              placement is not correct.\n",
      "            - DEVICE_PLACEMENT_WARN: copies the tensors which are not\n",
      "              on the right device but logs a warning.\n",
      "            - DEVICE_PLACEMENT_SILENT: silently copies the tensors.\n",
      "              Note that this may hide performance problems as there is no notification\n",
      "              provided when operations are blocked on the tensor being copied between\n",
      "              devices.\n",
      "            - DEVICE_PLACEMENT_SILENT_FOR_INT32: silently copies\n",
      "              int32 tensors, raising errors on the other ones.\n",
      "          execution_mode: (Optional.) Policy controlling how operations dispatched are\n",
      "            actually executed. When set to None, an appropriate value will be picked\n",
      "            automatically. The value picked may change between TensorFlow releases.\n",
      "            Valid values:\n",
      "            - SYNC: executes each operation synchronously.\n",
      "            - ASYNC: executes each operation asynchronously. These\n",
      "              operations may return \"non-ready\" handles.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If eager execution is enabled after creating/executing a\n",
      "           TensorFlow graph, or if options provided conflict with a previous call\n",
      "           to this function.\n",
      "    \n",
      "    enable_resource_variables() -> None\n",
      "        Creates resource variables by default.\n",
      "        \n",
      "        Resource variables are improved versions of TensorFlow variables with a\n",
      "        well-defined memory model. Accessing a resource variable reads its value, and\n",
      "        all ops which access a specific read value of the variable are guaranteed to\n",
      "        see the same value for that tensor. Writes which happen after a read (by\n",
      "        having a control or data dependency on the read) are guaranteed not to affect\n",
      "        the value of the read tensor, and similarly writes which happen before a read\n",
      "        are guaranteed to affect the value. No guarantees are made about unordered\n",
      "        read/write pairs.\n",
      "        \n",
      "        Calling tf.enable_resource_variables() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "    \n",
      "    enable_tensor_equality()\n",
      "        Compare Tensors with element-wise comparison and thus be unhashable.\n",
      "        \n",
      "        Comparing tensors with element-wise allows comparisons such as\n",
      "        tf.Variable(1.0) == 1.0. Element-wise equality implies that tensors are\n",
      "        unhashable. Thus tensors can no longer be directly used in sets or as a key in\n",
      "        a dictionary.\n",
      "    \n",
      "    enable_v2_behavior()\n",
      "        Enables TensorFlow 2.x behaviors.\n",
      "        \n",
      "        This function can be called at the beginning of the program (before `Tensors`,\n",
      "        `Graphs` or other structures have been created, and before devices have been\n",
      "        initialized. It switches all global behaviors that are different between\n",
      "        TensorFlow 1.x and 2.x to behave as intended for 2.x.\n",
      "        \n",
      "        This function is called in the main TensorFlow `__init__.py` file, user should\n",
      "        not need to call it, except during complex migrations.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This function is not necessary if you are using TF2. V2 behavior is enabled by\n",
      "        default.\n",
      "        @end_compatibility\n",
      "    \n",
      "    enable_v2_tensorshape()\n",
      "        In TensorFlow 2.0, iterating over a TensorShape instance returns values.\n",
      "        \n",
      "        This enables the new behavior.\n",
      "        \n",
      "        Concretely, `tensor_shape[i]` returned a Dimension instance in V1, but\n",
      "        it V2 it returns either an integer, or None.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```\n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        value = tensor_shape[i].value\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        value = tensor_shape[i]\n",
      "        \n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        for dim in tensor_shape:\n",
      "          value = dim.value\n",
      "          print(value)\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        for value in tensor_shape:\n",
      "          print(value)\n",
      "        \n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        dim = tensor_shape[i]\n",
      "        dim.assert_is_compatible_with(other_shape)  # or using any other shape method\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        if tensor_shape.rank is None:\n",
      "          dim = Dimension(None)\n",
      "        else:\n",
      "          dim = tensor_shape.dims[i]\n",
      "        dim.assert_is_compatible_with(other_shape)  # or using any other shape method\n",
      "        \n",
      "        # The V2 suggestion above is more explicit, which will save you from\n",
      "        # the following trap (present in V1):\n",
      "        # you might do in-place modifications to `dim` and expect them to be reflected\n",
      "        # in `tensor_shape[i]`, but they would not be.\n",
      "        ```\n",
      "    \n",
      "    encode_base64(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], pad: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Encode strings into web-safe base64 format.\n",
      "        \n",
      "        Refer to [this article](https://en.wikipedia.org/wiki/Base64) for more information on\n",
      "        base64 format. Base64 strings may have padding with '=' at the\n",
      "        end so that the encoded has length multiple of 4. See Padding section of the\n",
      "        link above.\n",
      "        \n",
      "        Web-safe means that the encoder uses - and _ instead of + and /.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Strings to be encoded.\n",
      "          pad: An optional `bool`. Defaults to `False`.\n",
      "            Bool whether padding is applied at the ends.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    ensure_shape(x, shape, name=None)\n",
      "        Updates the shape of a tensor and checks at runtime that the shape holds.\n",
      "        \n",
      "        When executed, this operation asserts that the input tensor `x`'s shape\n",
      "        is compatible with the `shape` argument.\n",
      "        See `tf.TensorShape.is_compatible_with` for details.\n",
      "        \n",
      "        >>> x = tf.constant([[1, 2, 3],\n",
      "        ...                  [4, 5, 6]])\n",
      "        >>> x = tf.ensure_shape(x, [2, 3])\n",
      "        \n",
      "        Use `None` for unknown dimensions:\n",
      "        \n",
      "        >>> x = tf.ensure_shape(x, [None, 3])\n",
      "        >>> x = tf.ensure_shape(x, [2, None])\n",
      "        \n",
      "        If the tensor's shape is not compatible with the `shape` argument, an error\n",
      "        is raised:\n",
      "        \n",
      "        >>> x = tf.ensure_shape(x, [5])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        tf.errors.InvalidArgumentError: Shape of tensor dummy_input [3] is not\n",
      "          compatible with expected shape [5]. [Op:EnsureShape]\n",
      "        \n",
      "        During graph construction (typically tracing a `tf.function`),\n",
      "        `tf.ensure_shape` updates the static-shape of the **result** tensor by\n",
      "        merging the two shapes. See `tf.TensorShape.merge_with` for details.\n",
      "        \n",
      "        This is most useful when **you** know a shape that can't be determined\n",
      "        statically by TensorFlow.\n",
      "        \n",
      "        The following trivial `tf.function` prints the input tensor's\n",
      "        static-shape before and after `ensure_shape` is applied.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(tensor):\n",
      "        ...   print(\"Static-shape before:\", tensor.shape)\n",
      "        ...   tensor = tf.ensure_shape(tensor, [None, 3])\n",
      "        ...   print(\"Static-shape after:\", tensor.shape)\n",
      "        ...   return tensor\n",
      "        \n",
      "        This lets you see the effect of `tf.ensure_shape` when the function is traced:\n",
      "        >>> cf = f.get_concrete_function(tf.TensorSpec([None, None]))\n",
      "        Static-shape before: (None, None)\n",
      "        Static-shape after: (None, 3)\n",
      "        \n",
      "        >>> cf(tf.zeros([3, 3])) # Passes\n",
      "        >>> cf(tf.constant([1, 2, 3])) # fails\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError:  Shape of tensor x [3] is not compatible with expected shape [3,3].\n",
      "        \n",
      "        The above example raises `tf.errors.InvalidArgumentError`, because `x`'s\n",
      "        shape, `(3,)`, is not compatible with the `shape` argument, `(None, 3)`\n",
      "        \n",
      "        Inside a `tf.function` or `v1.Graph` context it checks both the buildtime and\n",
      "        runtime shapes. This is stricter than `tf.Tensor.set_shape` which only\n",
      "        checks the buildtime shape.\n",
      "        \n",
      "        Note: This differs from `tf.Tensor.set_shape` in that it sets the static shape\n",
      "        of the resulting tensor and enforces it at runtime, raising an error if the\n",
      "        tensor's runtime shape is incompatible with the specified shape.\n",
      "        `tf.Tensor.set_shape` sets the static shape of the tensor without enforcing it\n",
      "        at runtime, which may result in inconsistencies between the statically-known\n",
      "        shape of tensors and the runtime value of tensors.\n",
      "        \n",
      "        For example, of loading images of a known size:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def decode_image(png):\n",
      "        ...   image = tf.image.decode_png(png, channels=3)\n",
      "        ...   # the `print` executes during tracing.\n",
      "        ...   print(\"Initial shape: \", image.shape)\n",
      "        ...   image = tf.ensure_shape(image,[28, 28, 3])\n",
      "        ...   print(\"Final shape: \", image.shape)\n",
      "        ...   return image\n",
      "        \n",
      "        When tracing a function, no ops are being executed, shapes may be unknown.\n",
      "        See the [Concrete Functions Guide](https://www.tensorflow.org/guide/concrete_function)\n",
      "        for details.\n",
      "        \n",
      "        >>> concrete_decode = decode_image.get_concrete_function(\n",
      "        ...     tf.TensorSpec([], dtype=tf.string))\n",
      "        Initial shape:  (None, None, 3)\n",
      "        Final shape:  (28, 28, 3)\n",
      "        \n",
      "        >>> image = tf.random.uniform(maxval=255, shape=[28, 28, 3], dtype=tf.int32)\n",
      "        >>> image = tf.cast(image,tf.uint8)\n",
      "        >>> png = tf.image.encode_png(image)\n",
      "        >>> image2 = concrete_decode(png)\n",
      "        >>> print(image2.shape)\n",
      "        (28, 28, 3)\n",
      "        \n",
      "        >>> image = tf.concat([image,image], axis=0)\n",
      "        >>> print(image.shape)\n",
      "        (56, 28, 3)\n",
      "        >>> png = tf.image.encode_png(image)\n",
      "        >>> image2 = concrete_decode(png)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        tf.errors.InvalidArgumentError:  Shape of tensor DecodePng [56,28,3] is not\n",
      "          compatible with expected shape [28,28,3].\n",
      "        \n",
      "        Caution: if you don't use the result of `tf.ensure_shape` the check may not\n",
      "        run.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def bad_decode_image(png):\n",
      "        ...   image = tf.image.decode_png(png, channels=3)\n",
      "        ...   # the `print` executes during tracing.\n",
      "        ...   print(\"Initial shape: \", image.shape)\n",
      "        ...   # BAD: forgot to use the returned tensor.\n",
      "        ...   tf.ensure_shape(image,[28, 28, 3])\n",
      "        ...   print(\"Final shape: \", image.shape)\n",
      "        ...   return image\n",
      "        \n",
      "        >>> image = bad_decode_image(png)\n",
      "        Initial shape:  (None, None, 3)\n",
      "        Final shape:  (None, None, 3)\n",
      "        >>> print(image.shape)\n",
      "        (56, 28, 3)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`.\n",
      "          shape: A `TensorShape` representing the shape of this tensor, a\n",
      "            `TensorShapeProto`, a list, a tuple, or None.\n",
      "          name: A name for this operation (optional). Defaults to \"EnsureShape\".\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type and contents as `x`.\n",
      "        \n",
      "        Raises:\n",
      "          tf.errors.InvalidArgumentError: If `shape` is incompatible with the shape\n",
      "          of `x`.\n",
      "    \n",
      "    equal(x, y, name=None)\n",
      "        Returns the truth value of (x == y) element-wise.\n",
      "        \n",
      "        Performs a [broadcast](\n",
      "        https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) with the\n",
      "        arguments and then an element-wise equality comparison, returning a Tensor of\n",
      "        boolean values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant(2)\n",
      "        >>> tf.math.equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  False])>\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant([2, 4])\n",
      "        >>> tf.math.equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`.\n",
      "          y: A `tf.Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If shapes of arguments are incompatible\n",
      "    \n",
      "    erf(x: typing.Annotated[_any, ~TV_Erf_T], name=None) -> typing.Annotated[_any, ~TV_Erf_T]\n",
      "        Computes the [Gauss error function](https://en.wikipedia.org/wiki/Error_function) of `x` element-wise. In statistics, for non-negative values of $x$, the error function has the following interpretation: for a random variable $Y$ that is normally distributed with mean 0 and variance $1/\\sqrt{2}$, $erf(x)$ is the probability that $Y$ falls in the range $[x, x]$.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.math.erf([[1.0, 2.0, 3.0], [0.0, -1.0, -2.0]])\n",
      "        <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
      "        array([[ 0.8427007,  0.9953223,  0.999978 ],\n",
      "               [ 0.       , -0.8427007, -0.9953223]], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.erf(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    erfc(x: typing.Annotated[_any, ~TV_Erfc_T], name=None) -> typing.Annotated[_any, ~TV_Erfc_T]\n",
      "        Computes the complementary error function of `x` element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    executing_eagerly = executing_eagerly_v1()\n",
      "        Checks whether the current thread has eager execution enabled.\n",
      "        \n",
      "        Eager execution is typically enabled via\n",
      "        `tf.compat.v1.enable_eager_execution`, but may also be enabled within the\n",
      "        context of a Python function via tf.contrib.eager.py_func.\n",
      "        \n",
      "        When eager execution is enabled, returns `True` in most cases. However,\n",
      "        this API might return `False` in the following use cases.\n",
      "        \n",
      "        *  Executing inside `tf.function`, unless under `tf.init_scope` or\n",
      "           `tf.config.run_functions_eagerly(True)` is previously called.\n",
      "        *  Executing inside a transformation function for `tf.dataset`.\n",
      "        *  `tf.compat.v1.disable_eager_execution()` is called.\n",
      "        \n",
      "        >>> tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        General case:\n",
      "        \n",
      "        >>> print(tf.executing_eagerly())\n",
      "        True\n",
      "        \n",
      "        Inside `tf.function`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def fn():\n",
      "        ...   with tf.init_scope():\n",
      "        ...     print(tf.executing_eagerly())\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        >>> fn()\n",
      "        True\n",
      "        False\n",
      "        \n",
      "        Inside `tf.function`\n",
      "        after  `tf.config.run_functions_eagerly(True)` is called:\n",
      "        \n",
      "        >>> tf.config.run_functions_eagerly(True)\n",
      "        >>> @tf.function\n",
      "        ... def fn():\n",
      "        ...   with tf.init_scope():\n",
      "        ...     print(tf.executing_eagerly())\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        >>> fn()\n",
      "        True\n",
      "        True\n",
      "        >>> tf.config.run_functions_eagerly(False)\n",
      "        \n",
      "        Inside a transformation function for `tf.dataset`:\n",
      "        \n",
      "        >>> def data_fn(x):\n",
      "        ...   print(tf.executing_eagerly())\n",
      "        ...   return x\n",
      "        >>> dataset = tf.data.Dataset.range(100)\n",
      "        >>> dataset = dataset.map(data_fn)\n",
      "        False\n",
      "        \n",
      "        Returns:\n",
      "          `True` if the current thread has eager execution enabled.\n",
      "    \n",
      "    executing_eagerly_outside_functions() -> bool\n",
      "        Returns True if executing eagerly, even if inside a graph function.\n",
      "        \n",
      "        This function will check the outermost context for the program and see if\n",
      "        it is in eager mode. It is useful comparing to `tf.executing_eagerly()`,\n",
      "        which checks the current context and will return `False` within a\n",
      "        `tf.function` body. It can be used to build library that behave differently\n",
      "        in eager runtime and v1 session runtime (deprecated).\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> tf.compat.v1.enable_eager_execution()\n",
      "        >>> @tf.function\n",
      "        ... def func():\n",
      "        ...   # A function constructs TensorFlow graphs, it does not execute eagerly,\n",
      "        ...   # but the outer most context is still eager.\n",
      "        ...   assert not tf.executing_eagerly()\n",
      "        ...   return tf.compat.v1.executing_eagerly_outside_functions()\n",
      "        >>> func()\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "        \n",
      "        Returns:\n",
      "          boolean, whether the outermost context is in eager mode.\n",
      "    \n",
      "    exp(x, name=None)\n",
      "        Computes exponential of x element-wise.  \\\\(y = e^x\\\\).\n",
      "        \n",
      "        This function computes the exponential of the input tensor element-wise.\n",
      "        i.e. `math.exp(x)` or \\\\(e^x\\\\), where `x` is the input tensor.\n",
      "        \\\\(e\\\\) denotes Euler's number and is approximately equal to 2.718281.\n",
      "        Output is positive for any real input.\n",
      "        \n",
      "        >>> x = tf.constant(2.0)\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=7.389056>\n",
      "        \n",
      "        >>> x = tf.constant([2.0, 8.0])\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32,\n",
      "        numpy=array([   7.389056, 2980.958   ], dtype=float32)>\n",
      "        \n",
      "        For complex numbers, the exponential value is calculated as\n",
      "        $$\n",
      "        e^{x+iy} = {e^x} {e^{iy}} = {e^x} ({\\cos (y) + i \\sin (y)})\n",
      "        $$\n",
      "        \n",
      "        For `1+1j` the value would be computed as:\n",
      "        $$\n",
      "        e^1 (\\cos (1) + i \\sin (1)) = 2.7182817 \\times (0.5403023+0.84147096j)\n",
      "        $$\n",
      "        \n",
      "        >>> x = tf.constant(1 + 1j)\n",
      "        >>> tf.math.exp(x)\n",
      "        <tf.Tensor: shape=(), dtype=complex128,\n",
      "        numpy=(1.4686939399158851+2.2873552871788423j)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor`. Has the same type as `x`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.exp\n",
      "        @end_compatibility\n",
      "    \n",
      "    expand_dims(input, axis=None, name=None, dim=None)\n",
      "        Returns a tensor with a length 1 axis inserted at index `axis`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Given a tensor `input`, this operation inserts a dimension of length 1 at the\n",
      "        dimension index `axis` of `input`'s shape. The dimension index follows Python\n",
      "        indexing rules: It's zero-based, a negative index it is counted backward\n",
      "        from the end.\n",
      "        \n",
      "        This operation is useful to:\n",
      "        \n",
      "        * Add an outer \"batch\" dimension to a single element.\n",
      "        * Align axes for broadcasting.\n",
      "        * To add an inner vector length axis to a tensor of scalars.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        If you have a single image of shape `[height, width, channels]`:\n",
      "        \n",
      "        >>> image = tf.zeros([10,10,3])\n",
      "        \n",
      "        You can add an outer `batch` axis by passing `axis=0`:\n",
      "        \n",
      "        >>> tf.expand_dims(image, axis=0).shape.as_list()\n",
      "        [1, 10, 10, 3]\n",
      "        \n",
      "        The new axis location matches Python `list.insert(axis, 1)`:\n",
      "        \n",
      "        >>> tf.expand_dims(image, axis=1).shape.as_list()\n",
      "        [10, 1, 10, 3]\n",
      "        \n",
      "        Following standard Python indexing rules, a negative `axis` counts from the\n",
      "        end so `axis=-1` adds an inner most dimension:\n",
      "        \n",
      "        >>> tf.expand_dims(image, -1).shape.as_list()\n",
      "        [10, 10, 3, 1]\n",
      "        \n",
      "        This operation requires that `axis` is a valid index for `input.shape`,\n",
      "        following Python indexing rules:\n",
      "        \n",
      "        ```\n",
      "        -1-tf.rank(input) <= axis <= tf.rank(input)\n",
      "        ```\n",
      "        \n",
      "        This operation is related to:\n",
      "        \n",
      "        * `tf.squeeze`, which removes dimensions of size 1.\n",
      "        * `tf.reshape`, which provides more flexible reshaping capability.\n",
      "        * `tf.sparse.expand_dims`, which provides this functionality for\n",
      "          `tf.SparseTensor`\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          axis: 0-D (scalar). Specifies the dimension index at which to expand the\n",
      "            shape of `input`. Must be in the range `[-rank(input) - 1, rank(input)]`.\n",
      "          name: The name of the output `Tensor` (optional).\n",
      "          dim: 0-D (scalar). Equivalent to `axis`, to be deprecated.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same data as `input`, but its shape has an additional\n",
      "          dimension of size 1 added.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if either both or neither of `dim` and `axis` are specified.\n",
      "    \n",
      "    expm1(x: typing.Annotated[_any, ~TV_Expm1_T], name=None) -> typing.Annotated[_any, ~TV_Expm1_T]\n",
      "        Computes `exp(x) - 1` element-wise.\n",
      "        \n",
      "          i.e. `exp(x) - 1` or `e^(x) - 1`, where `x` is the input tensor.\n",
      "          `e` denotes Euler's number and is approximately equal to 2.718281.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant(2.0)\n",
      "          tf.math.expm1(x) ==> 6.389056\n",
      "        \n",
      "          x = tf.constant([2.0, 8.0])\n",
      "          tf.math.expm1(x) ==> array([6.389056, 2979.958], dtype=float32)\n",
      "        \n",
      "          x = tf.constant(1 + 1j)\n",
      "          tf.math.expm1(x) ==> (0.46869393991588515+2.2873552871788423j)\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    extract_image_patches(images, ksizes=None, strides=None, rates=None, padding=None, name=None, sizes=None)\n",
      "        Extract `patches` from `images` and put them in the \"depth\" output dimension.\n",
      "        \n",
      "        Args:\n",
      "          images: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `complex64`, `complex128`, `bool`.\n",
      "            4-D Tensor with shape `[batch, in_rows, in_cols, depth]`.\n",
      "          ksizes: A list of `ints` that has length `>= 4`.\n",
      "            The size of the sliding window for each dimension of `images`.\n",
      "          strides: A list of `ints` that has length `>= 4`.\n",
      "            How far the centers of two consecutive patches are in\n",
      "            the images. Must be: `[1, stride_rows, stride_cols, 1]`.\n",
      "          rates: A list of `ints` that has length `>= 4`.\n",
      "            Must be: `[1, rate_rows, rate_cols, 1]`. This is the\n",
      "            input stride, specifying how far two consecutive patch samples are in the\n",
      "            input. Equivalent to extracting patches with\n",
      "            `patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by\n",
      "            subsampling them spatially by a factor of `rates`. This is equivalent to\n",
      "            `rate` in dilated (a.k.a. Atrous) convolutions.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `images`.\n",
      "    \n",
      "    extract_volume_patches(input: Annotated[Any, ~TV_ExtractVolumePatches_T], ksizes, strides, padding: str, name=None) -> Annotated[Any, ~TV_ExtractVolumePatches_T]\n",
      "        Extract `patches` from `input` and put them in the `\"depth\"` output dimension. 3D extension of `extract_image_patches`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "            5-D Tensor with shape `[batch, in_planes, in_rows, in_cols, depth]`.\n",
      "          ksizes: A list of `ints` that has length `>= 5`.\n",
      "            The size of the sliding window for each dimension of `input`.\n",
      "          strides: A list of `ints` that has length `>= 5`.\n",
      "            1-D of length 5. How far the centers of two consecutive patches are in\n",
      "            `input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "            The type of padding algorithm to use.\n",
      "        \n",
      "            The size-related attributes are specified as follows:\n",
      "        \n",
      "            ```python\n",
      "            ksizes = [1, ksize_planes, ksize_rows, ksize_cols, 1]\n",
      "            strides = [1, stride_planes, strides_rows, strides_cols, 1]\n",
      "            ```\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    eye(num_rows, num_columns=None, batch_shape=None, dtype=tf.float32, name=None)\n",
      "        Construct an identity matrix, or a batch of matrices.\n",
      "        \n",
      "        See also `tf.ones`, `tf.zeros`, `tf.fill`, `tf.one_hot`.\n",
      "        \n",
      "        ```python\n",
      "        # Construct one identity matrix.\n",
      "        tf.eye(2)\n",
      "        ==> [[1., 0.],\n",
      "             [0., 1.]]\n",
      "        \n",
      "        # Construct a batch of 3 identity matrices, each 2 x 2.\n",
      "        # batch_identity[i, :, :] is a 2 x 2 identity matrix, i = 0, 1, 2.\n",
      "        batch_identity = tf.eye(2, batch_shape=[3])\n",
      "        \n",
      "        # Construct one 2 x 3 \"identity\" matrix\n",
      "        tf.eye(2, num_columns=3)\n",
      "        ==> [[ 1.,  0.,  0.],\n",
      "             [ 0.,  1.,  0.]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          num_rows: Non-negative `int32` scalar `Tensor` giving the number of rows\n",
      "            in each batch matrix.\n",
      "          num_columns: Optional non-negative `int32` scalar `Tensor` giving the number\n",
      "            of columns in each batch matrix.  Defaults to `num_rows`.\n",
      "          batch_shape:  A list or tuple of Python integers or a 1-D `int32` `Tensor`.\n",
      "            If provided, the returned `Tensor` will have leading batch dimensions of\n",
      "            this shape.\n",
      "          dtype:  The type of an element in the resulting `Tensor`\n",
      "          name:  A name for this `Op`.  Defaults to \"eye\".\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of shape `batch_shape + [num_rows, num_columns]`\n",
      "    \n",
      "    fake_quant_with_min_max_args(inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: float = -6, max: float = 6, num_bits: int = 8, narrow_range: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same shape and type.\n",
      "        \n",
      "        \n",
      "          Quantization is called fake since the output is still in floating point.\n",
      "          The API converts inputs into values within the range [min and max] and returns\n",
      "          as output.\n",
      "        \n",
      "        Attributes\n",
      "        \n",
      "        *   `[min; max]` define the clamping range for the `inputs` data.\n",
      "        *   `inputs` values are quantized into the quantization range (\n",
      "        `[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`\n",
      "        when it is true) and then de-quantized and output as floats in `[min; max]`\n",
      "        interval.\n",
      "        *   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        \n",
      "        *   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        *   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        *   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        \n",
      "        Examples\n",
      "        \n",
      "        ```python\n",
      "        \n",
      "        inp = tf.constant ([10.03, -10.23, 3])\n",
      "        out = tf.quantization.fake_quant_with_min_max_args(inp, min=-5, max=5,\n",
      "                                                           num_bits=16)\n",
      "        print(out)\n",
      "        \n",
      "        #  Output:\n",
      "        #  tf.Tensor([ 4.9999237 -5.0000763  3.0000763], shape=(3,), dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "          * InvalidArgumentError:\n",
      "            - If num_bits are outside of range [2, 16].\n",
      "            - If min >= max.\n",
      "          * ValueError: If `inputs` are of any other type than float32.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: An optional `float`. Defaults to `-6`.\n",
      "          max: An optional `float`. Defaults to `6`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_args_gradient(gradients: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: float = -6, max: float = 6, num_bits: int = 8, narrow_range: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Compute gradients for a FakeQuantWithMinMaxArgs operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxArgs operation.\n",
      "          min: An optional `float`. Defaults to `-6`.\n",
      "          max: An optional `float`. Defaults to `6`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars(inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], max: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], num_bits: int = 8, narrow_range: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Fake-quantize the 'inputs' tensor of type float via global float scalars\n",
      "        \n",
      "        Fake-quantize the `inputs` tensor of type float via global float scalars\n",
      "        `min` and `max` to `outputs` tensor of same shape as `inputs`.\n",
      "        \n",
      "        Attributes\n",
      "        \n",
      "        *   `[min; max]` define the clamping range for the `inputs` data.\n",
      "        *   `inputs` values are quantized into the quantization range (\n",
      "        `[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`\n",
      "        when it is true) and then de-quantized and output as floats in `[min; max]`\n",
      "        interval.\n",
      "        *   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        \n",
      "        *   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        *   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        *   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        This operation has a gradient and thus allows for training `min` and `max`\n",
      "        values.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_gradient(gradients: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], max: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], num_bits: int = 8, narrow_range: bool = False, name=None)\n",
      "        Compute gradients for a FakeQuantWithMinMaxVars operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxVars operation.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxVars operation.\n",
      "            min, max: Quantization interval, scalar floats.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "            The bitwidth of the quantization; between 2 and 8, inclusive.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "            Whether to quantize into 2^num_bits - 1 distinct values.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).\n",
      "        \n",
      "          backprops_wrt_input: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_min: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_per_channel(inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], max: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], num_bits: int = 8, narrow_range: bool = False, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Fake-quantize the 'inputs' tensor of type float via per-channel floats\n",
      "        \n",
      "        Fake-quantize the `inputs` tensor of type float per-channel and one of the\n",
      "        shapes: `[d]`, `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max`\n",
      "        of shape `[d]` to `outputs` tensor of same shape as `inputs`.\n",
      "        \n",
      "        Attributes\n",
      "        \n",
      "        *   `[min; max]` define the clamping range for the `inputs` data.\n",
      "        *   `inputs` values are quantized into the quantization range (\n",
      "        `[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`\n",
      "        when it is true) and then de-quantized and output as floats in `[min; max]`\n",
      "        interval.\n",
      "        *   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        \n",
      "        *   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        *   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        *   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        This operation has a gradient and thus allows for training `min` and `max`\n",
      "        values.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_per_channel_gradient(gradients: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], inputs: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], min: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], max: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], num_bits: int = 8, narrow_range: bool = False, name=None)\n",
      "        Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxVars operation,\n",
      "            shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape\n",
      "              same as `gradients`.\n",
      "            min, max: Quantization interval, floats of shape `[d]`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "            The bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "            Whether to quantize into 2^num_bits - 1 distinct values.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).\n",
      "        \n",
      "          backprops_wrt_input: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_min: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    fft(input: Annotated[Any, ~TV_FFT_Tcomplex], name=None) -> Annotated[Any, ~TV_FFT_Tcomplex]\n",
      "        Fast Fourier transform.\n",
      "        \n",
      "        Computes the 1-dimensional discrete Fourier transform over the inner-most\n",
      "        dimension of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fft2d(input: Annotated[Any, ~TV_FFT2D_Tcomplex], name=None) -> Annotated[Any, ~TV_FFT2D_Tcomplex]\n",
      "        2D fast Fourier transform.\n",
      "        \n",
      "        Computes the 2-dimensional discrete Fourier transform over the inner-most\n",
      "        2 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fft3d(input: Annotated[Any, ~TV_FFT3D_Tcomplex], name=None) -> Annotated[Any, ~TV_FFT3D_Tcomplex]\n",
      "        3D fast Fourier transform.\n",
      "        \n",
      "        Computes the 3-dimensional discrete Fourier transform over the inner-most 3\n",
      "        dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fftnd(input: Annotated[Any, ~TV_FFTND_Tcomplex], fft_length: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], axes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], name=None) -> Annotated[Any, ~TV_FFTND_Tcomplex]\n",
      "        ND fast Fourier transform.\n",
      "        \n",
      "        Computes the n-dimensional discrete Fourier transform over\n",
      "        designated dimensions of `input`. The designated dimensions of\n",
      "        `input` are assumed to be the result of `FFTND`.\n",
      "        \n",
      "        If fft_length[i]<shape(input)[i], the input is cropped. If\n",
      "        fft_length[i]>shape(input)[i], the input is padded with zeros. If fft_length\n",
      "        is not given, the default shape(input) is used.\n",
      "        \n",
      "        Axes mean the dimensions to perform the transform on. Default is to perform on\n",
      "        all axes.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          fft_length: A `Tensor` of type `int32`.\n",
      "            An int32 tensor. The FFT length for each dimension.\n",
      "          axes: A `Tensor` of type `int32`.\n",
      "            An int32 tensor with a same shape as fft_length. Axes to perform the transform.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fill(dims, value, name=None, layout=None)\n",
      "        Creates a tensor filled with a scalar value.\n",
      "        \n",
      "        See also `tf.ones`, `tf.zeros`, `tf.one_hot`, `tf.eye`.\n",
      "        \n",
      "        This operation creates a tensor of shape `dims` and fills it with `value`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> tf.fill([2, 3], 9)\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[9, 9, 9],\n",
      "               [9, 9, 9]], dtype=int32)>\n",
      "        \n",
      "        `tf.fill` evaluates at graph runtime and supports dynamic shapes based on\n",
      "        other runtime `tf.Tensors`, unlike `tf.constant(value, shape=dims)`, which\n",
      "        embeds the value as a `Const` node.\n",
      "        \n",
      "        Args:\n",
      "          dims: A 1-D sequence of non-negative numbers. Represents the shape of the\n",
      "            output `tf.Tensor`. Entries should be of type: `int32`, `int64`.\n",
      "          value: A value to fill the returned `tf.Tensor`.\n",
      "          name: Optional string. The name of the output `tf.Tensor`.\n",
      "          layout: Optional, `tf.experimental.dtensor.Layout`. If provided, the result\n",
      "            is a [DTensor](https://www.tensorflow.org/guide/dtensor_overview) with the\n",
      "            provided layout.\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` with shape `dims` and the same dtype as `value`.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: `dims` contains negative entries.\n",
      "          NotFoundError: `dims` contains non-integer entries.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Similar to `np.full`. In `numpy`, more parameters are supported. Passing a\n",
      "        number argument as the shape (`np.full(5, value)`) is valid in `numpy` for\n",
      "        specifying a 1-D shaped result, while TensorFlow does not support this syntax.\n",
      "        @end_compatibility\n",
      "    \n",
      "    fingerprint(data, method='farmhash64', name=None)\n",
      "        Generates fingerprint values.\n",
      "        \n",
      "        Generates fingerprint values of `data`.\n",
      "        \n",
      "        Fingerprint op considers the first dimension of `data` as the batch dimension,\n",
      "        and `output[i]` contains the fingerprint value generated from contents in\n",
      "        `data[i, ...]` for all `i`.\n",
      "        \n",
      "        Fingerprint op writes fingerprint values as byte arrays. For example, the\n",
      "        default method `farmhash64` generates a 64-bit fingerprint value at a time.\n",
      "        This 8-byte value is written out as an `tf.uint8` array of size 8, in\n",
      "        little-endian order.\n",
      "        \n",
      "        For example, suppose that `data` has data type `tf.int32` and shape (2, 3, 4),\n",
      "        and that the fingerprint method is `farmhash64`. In this case, the output\n",
      "        shape is (2, 8), where 2 is the batch dimension size of `data`, and 8 is the\n",
      "        size of each fingerprint value in bytes. `output[0, :]` is generated from\n",
      "        12 integers in `data[0, :, :]` and similarly `output[1, :]` is generated from\n",
      "        other 12 integers in `data[1, :, :]`.\n",
      "        \n",
      "        Note that this op fingerprints the raw underlying buffer, and it does not\n",
      "        fingerprint Tensor's metadata such as data type and/or shape. For example, the\n",
      "        fingerprint values are invariant under reshapes and bitcasts as long as the\n",
      "        batch dimension remain the same:\n",
      "        \n",
      "        ```python\n",
      "        tf.fingerprint(data) == tf.fingerprint(tf.reshape(data, ...))\n",
      "        tf.fingerprint(data) == tf.fingerprint(tf.bitcast(data, ...))\n",
      "        ```\n",
      "        \n",
      "        For string data, one should expect `tf.fingerprint(data) !=\n",
      "        tf.fingerprint(tf.string.reduce_join(data))` in general.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must have rank 1 or higher.\n",
      "          method: A `Tensor` of type `tf.string`. Fingerprint method used by this op.\n",
      "            Currently, available method is `farmhash64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A two-dimensional `Tensor` of type `tf.uint8`. The first dimension equals to\n",
      "          `data`'s first dimension, and the second dimension size depends on the\n",
      "          fingerprint algorithm.\n",
      "    \n",
      "    fixed_size_partitioner(num_shards, axis=0)\n",
      "        Partitioner to specify a fixed number of shards along given axis.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is deprecated in TF2. In TF2, partitioner is no longer part of\n",
      "        the variable declaration via `tf.Variable`.\n",
      "        [ParameterServer Training]\n",
      "        (https://www.tensorflow.org/tutorials/distribute/parameter_server_training)\n",
      "        handles partitioning of variables. The corresponding TF2 partitioner class of\n",
      "        `fixed_size_partitioner` is\n",
      "        `tf.distribute.experimental.partitioners.FixedShardsPartitioner`.\n",
      "        \n",
      "        Check the [migration guide]\n",
      "        (https://www.tensorflow.org/guide/migrate#2_use_python_objects_to_track_variables_and_losses)\n",
      "        on the differences in treatment of variables and losses between TF1 and TF2.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "          ```\n",
      "          x = tf.compat.v1.get_variable(\n",
      "            \"x\", shape=(2,), partitioner=tf.compat.v1.fixed_size_partitioner(2)\n",
      "          )\n",
      "          ```\n",
      "        After:\n",
      "        \n",
      "          ```\n",
      "          partitioner = (\n",
      "              tf.distribute.experimental.partitioners.FixedShardsPartitioner(\n",
      "                  num_shards=2)\n",
      "          )\n",
      "          strategy = tf.distribute.experimental.ParameterServerStrategy(\n",
      "                         cluster_resolver=cluster_resolver,\n",
      "                         variable_partitioner=partitioner)\n",
      "        \n",
      "          with strategy.scope():\n",
      "            x = tf.Variable([1.0, 2.0])\n",
      "          ```\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          num_shards: `int`, number of shards to partition variable.\n",
      "          axis: `int`, axis to partition on.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "    \n",
      "    floor(x, name=None)\n",
      "        Returns element-wise largest integer not greater than x.\n",
      "        \n",
      "        Both input range is `(-inf, inf)` and the\n",
      "        output range consists of all integer values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1.3324, -1.5, 5.555, -2.532, 0.99, float(\"inf\")])\n",
      "        >>> tf.floor(x).numpy()\n",
      "        array([ 1., -2.,  5., -3.,  0., inf], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          x:  A `Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as x.\n",
      "    \n",
      "    floor_div(x: typing.Annotated[_any, ~TV_FloorDiv_T], y: typing.Annotated[_any, ~TV_FloorDiv_T], name=None) -> typing.Annotated[_any, ~TV_FloorDiv_T]\n",
      "        Returns x // y element-wise.\n",
      "        \n",
      "        *NOTE*: `floor_div` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    floordiv(x, y, name=None)\n",
      "        Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "        \n",
      "        Mathematically, this is equivalent to floor(x / y). For example:\n",
      "          floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
      "          floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
      "        This is equivalent to the '//' operator in Python 3.0 and above.\n",
      "        \n",
      "        Note: `x` and `y` must have the same type, and the result will have the same\n",
      "        type as well.\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of real numeric type.\n",
      "          y: `Tensor` denominator of real numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` rounded toward -infinity.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the inputs are complex.\n",
      "    \n",
      "    floormod = floor_mod(x: typing.Annotated[_any, ~TV_FloorMod_T], y: typing.Annotated[_any, ~TV_FloorMod_T], name=None) -> typing.Annotated[_any, ~TV_FloorMod_T]\n",
      "        Returns element-wise remainder of division.\n",
      "        \n",
      "        This follows Python semantics in that the\n",
      "        result here is consistent with a flooring divide. E.g.\n",
      "        `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "        \n",
      "        *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    foldl(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)\n",
      "        foldl on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This foldl operator repeatedly applies the callable `fn` to a sequence\n",
      "        of elements from first to last. The elements are made of the tensors\n",
      "        unpacked from `elems` on dimension 0. The callable fn takes two tensors as\n",
      "        arguments. The first argument is the accumulated value computed from the\n",
      "        preceding invocation of fn, and the second is the value at the current\n",
      "        position of `elems`. If `initializer` is None, `elems` must contain at least\n",
      "        one element, and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is fn(initializer, values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            as the initial value for the accumulator.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors, resulting from applying\n",
      "          `fn` consecutively to the list of tensors unpacked from `elems`, from first\n",
      "          to last.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable.\n",
      "        \n",
      "        Example:\n",
      "          ```python\n",
      "          elems = tf.constant([1, 2, 3, 4, 5, 6])\n",
      "          sum = foldl(lambda a, x: a + x, elems)\n",
      "          # sum == 21\n",
      "          ```\n",
      "    \n",
      "    foldr(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)\n",
      "        foldr on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This foldr operator repeatedly applies the callable `fn` to a sequence\n",
      "        of elements from last to first. The elements are made of the tensors\n",
      "        unpacked from `elems`. The callable fn takes two tensors as arguments.\n",
      "        The first argument is the accumulated value computed from the preceding\n",
      "        invocation of fn, and the second is the value at the current position of\n",
      "        `elems`. If `initializer` is None, `elems` must contain at least one element,\n",
      "        and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `fn(initializer, values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            as the initial value for the accumulator.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors, resulting from applying\n",
      "          `fn` consecutively to the list of tensors unpacked from `elems`, from last\n",
      "          to first.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable.\n",
      "        \n",
      "        Example:\n",
      "          ```python\n",
      "          elems = [1, 2, 3, 4, 5, 6]\n",
      "          sum = foldr(lambda a, x: a + x, elems)\n",
      "          # sum == 21\n",
      "          ```\n",
      "    \n",
      "    function(func=None, input_signature=None, autograph=True, jit_compile=None, reduce_retracing=False, experimental_implements=None, experimental_autograph_options=None, experimental_attributes=None, experimental_relax_shapes=None, experimental_compile=None, experimental_follow_type_hints=None) -> tensorflow.python.types.core.PolymorphicFunction\n",
      "        Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_compile)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_compile is deprecated, use jit_compile instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_relax_shapes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_follow_type_hints)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        experimental_follow_type_hints is deprecated\n",
      "        \n",
      "        `tf.function` constructs a `tf.types.experimental.PolymorphicFunction` that\n",
      "        executes a TensorFlow graph (`tf.Graph`) created by trace-compiling the\n",
      "        TensorFlow operations in `func`. More information on the topic can be found\n",
      "        in [Introduction to Graphs and tf.function]\n",
      "        (https://www.tensorflow.org/guide/intro_to_graphs).\n",
      "        \n",
      "        See [Better Performance with tf.function]\n",
      "        (https://www.tensorflow.org/guide/function) for tips on performance and\n",
      "        known limitations.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x, y):\n",
      "        ...   return x ** 2 + y\n",
      "        >>> x = tf.constant([2, 3])\n",
      "        >>> y = tf.constant([3, -2])\n",
      "        >>> f(x, y)\n",
      "        <tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "        \n",
      "        The trace-compilation allows non-TensorFlow operations to execute, but under\n",
      "        special conditions. In general, only TensorFlow operations are guaranteed to\n",
      "        run and create fresh results whenever the `PolymorphicFunction` is called.\n",
      "        \n",
      "        ## Features\n",
      "        \n",
      "        `func` may use data-dependent Python control flow statements, including `if`,\n",
      "        `for`, `while` `break`, `continue` and `return`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   if tf.reduce_sum(x) > 0:\n",
      "        ...     return x * x\n",
      "        ...   else:\n",
      "        ...     return -x // 2\n",
      "        >>> f(tf.constant(-2))\n",
      "        <tf.Tensor: ... numpy=1>\n",
      "        \n",
      "        `func`'s closure may include `tf.Tensor` and `tf.Variable` objects:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f():\n",
      "        ...   return x ** 2 + y\n",
      "        >>> x = tf.constant([-2, -3])\n",
      "        >>> y = tf.Variable([3, -2])\n",
      "        >>> f()\n",
      "        <tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "        \n",
      "        `func` may also use ops with side effects, such as `tf.print`, `tf.Variable`\n",
      "        and others:\n",
      "        \n",
      "        >>> v = tf.Variable(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   for i in tf.range(x):\n",
      "        ...     v.assign_add(i)\n",
      "        >>> f(3)\n",
      "        >>> v\n",
      "        <tf.Variable ... numpy=4>\n",
      "        \n",
      "        Important: Any Python side-effects (appending to a list, printing with\n",
      "        `print`, etc) will only happen once, when `func` is traced. To have\n",
      "        side-effects executed into your `tf.function` they need to be written\n",
      "        as TF ops:\n",
      "        \n",
      "        >>> l = []\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   for i in x:\n",
      "        ...     l.append(i + 1)    # Caution! Will only happen once when tracing\n",
      "        >>> f(tf.constant([1, 2, 3]))\n",
      "        >>> l\n",
      "        [<tf.Tensor ...>]\n",
      "        \n",
      "        Instead, use TensorFlow collections like `tf.TensorArray`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
      "        ...   for i in range(len(x)):\n",
      "        ...     ta = ta.write(i, x[i] + 1)\n",
      "        ...   return ta.stack()\n",
      "        >>> f(tf.constant([1, 2, 3]))\n",
      "        <tf.Tensor: ..., numpy=array([2, 3, 4], ...)>\n",
      "        \n",
      "        ## `tf.function` creates polymorphic callables\n",
      "        \n",
      "        Internally, `tf.types.experimental.PolymorphicFunction` may contain multiple\n",
      "        `tf.types.experimental.ConcreteFunction`s, each specialized to arguments with\n",
      "        different data types or shapes, since TensorFlow can perform more\n",
      "        optimizations on graphs of specific shapes, dtypes and values of constant\n",
      "        arguments. `tf.function` treats any pure Python values as opaque objects (best\n",
      "        thought of as compile-time constants), and builds a separate `tf.Graph` for\n",
      "        each set of Python arguments that it encounters.\n",
      "        For more information, see the\n",
      "        [tf.function guide](https://www.tensorflow.org/guide/function#rules_of_tracing)\n",
      "        \n",
      "        Executing a `PolymorphicFunction` will select and execute the appropriate\n",
      "        `ConcreteFunction` based on the argument types and values.\n",
      "        \n",
      "        To obtain an individual `ConcreteFunction`, use the\n",
      "        `PolymorphicFunction.get_concrete_function` method. It can be called with the\n",
      "        same arguments as `func` and returns a\n",
      "        `tf.types.experimental.ConcreteFunction`. `ConcreteFunction`s are backed by a\n",
      "        single `tf.Graph`:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> isinstance(f.get_concrete_function(1).graph, tf.Graph)\n",
      "        True\n",
      "        \n",
      "        `ConcreteFunction`s can be executed just like `PolymorphicFunction`s, but their\n",
      "        input is resticted to the types to which they're specialized.\n",
      "        \n",
      "        ## Retracing\n",
      "        \n",
      "        `ConcreteFunctions` are built (traced) on the fly, as the `PolymorphicFunction` is\n",
      "        called with new TensorFlow types or shapes, or with new Python values as\n",
      "        arguments. When `PolymorphicFunction` builds a new trace, it is said that `func`\n",
      "        is retraced. Retracing is a frequent performance concern for `tf.function` as\n",
      "        it can be considerably slower than executing a graph that's already been\n",
      "        traced. It is ideal to minimize the amount of retracing in your code.\n",
      "        \n",
      "        Caution: Passing python scalars or lists as arguments to `tf.function` will\n",
      "        usually retrace. To avoid this, pass numeric arguments as Tensors whenever\n",
      "        possible:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return tf.abs(x)\n",
      "        >>> f1 = f.get_concrete_function(1)\n",
      "        >>> f2 = f.get_concrete_function(2)  # Slow - compiles new graph\n",
      "        >>> f1 is f2\n",
      "        False\n",
      "        >>> f1 = f.get_concrete_function(tf.constant(1))\n",
      "        >>> f2 = f.get_concrete_function(tf.constant(2))  # Fast - reuses f1\n",
      "        >>> f1 is f2\n",
      "        True\n",
      "        \n",
      "        Python numerical arguments should only be used when they take few distinct\n",
      "        values, such as hyperparameters like the number of layers in a neural network.\n",
      "        \n",
      "        ## Input signatures\n",
      "        \n",
      "        For Tensor arguments, `PolymorphicFunction`creates a new `ConcreteFunction` for\n",
      "        every unique set of input shapes and datatypes. The example below creates two\n",
      "        separate `ConcreteFunction`s, each specialized to a different shape:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> vector = tf.constant([1.0, 1.0])\n",
      "        >>> matrix = tf.constant([[3.0]])\n",
      "        >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "        False\n",
      "        \n",
      "        An \"input signature\" can be optionally provided to `tf.function` to control\n",
      "        this process. The input signature specifies the shape and type of each\n",
      "        Tensor argument to the function using a `tf.TensorSpec` object. More general\n",
      "        shapes can be used. This ensures only one `ConcreteFunction` is created, and\n",
      "        restricts the `PolymorphicFunction` to the specified shapes and types. It is\n",
      "        an effective way to limit retracing when Tensors have dynamic shapes.\n",
      "        \n",
      "        >>> @tf.function(\n",
      "        ...     input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
      "        ... def f(x):\n",
      "        ...   return x + 1\n",
      "        >>> vector = tf.constant([1.0, 1.0])\n",
      "        >>> matrix = tf.constant([[3.0]])\n",
      "        >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "        True\n",
      "        \n",
      "        ## Variables may only be created once\n",
      "        \n",
      "        `tf.function` only allows creating new `tf.Variable` objects when it is called\n",
      "        for the first time:\n",
      "        \n",
      "        >>> class MyModule(tf.Module):\n",
      "        ...   def __init__(self):\n",
      "        ...     self.v = None\n",
      "        ...\n",
      "        ...   @tf.function\n",
      "        ...   def __call__(self, x):\n",
      "        ...     if self.v is None:\n",
      "        ...       self.v = tf.Variable(tf.ones_like(x))\n",
      "        ...     return self.v * x\n",
      "        \n",
      "        In general, it is recommended to create `tf.Variable`s outside of\n",
      "        `tf.function`.\n",
      "        In simple cases, persisting state across `tf.function` boundaries may be\n",
      "        implemented using a pure functional style in which state is represented by\n",
      "        `tf.Tensor`s passed as arguments and returned as return values.\n",
      "        \n",
      "        Contrast the two styles below:\n",
      "        \n",
      "        >>> state = tf.Variable(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   state.assign_add(x)\n",
      "        >>> f(tf.constant(2))  # Non-pure functional style\n",
      "        >>> state\n",
      "        <tf.Variable ... numpy=3>\n",
      "        \n",
      "        >>> state = tf.constant(1)\n",
      "        >>> @tf.function\n",
      "        ... def f(state, x):\n",
      "        ...   state += x\n",
      "        ...   return state\n",
      "        >>> state = f(state, tf.constant(2))  # Pure functional style\n",
      "        >>> state\n",
      "        <tf.Tensor: ... numpy=3>\n",
      "        \n",
      "        ## Python operations execute only once per trace\n",
      "        \n",
      "        `func` may contain TensorFlow operations mixed with pure Python operations.\n",
      "        However, when the function is executed, only the TensorFlow operations will\n",
      "        run. The Python operations run only once, at trace time. If TensorFlow\n",
      "        operations depend on results from Python operations, those results will be\n",
      "        frozen into the graph.\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(a, b):\n",
      "        ...   print('this runs at trace time; a is', a, 'and b is', b)\n",
      "        ...   return b\n",
      "        >>> f(1, tf.constant(1))\n",
      "        this runs at trace time; a is 1 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        >>> f(1, tf.constant(2))\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        \n",
      "        >>> f(2, tf.constant(1))\n",
      "        this runs at trace time; a is 2 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        >>> f(2, tf.constant(2))\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        \n",
      "        Args:\n",
      "          func: The function to be compiled. If `func` is None, `tf.function` returns\n",
      "            a decorator that can be invoked with a single argument - `func`. In other\n",
      "            words, `tf.function(input_signature=...)(func)` is equivalent to\n",
      "            `tf.function(func, input_signature=...)`. The former can be used as\n",
      "            decorator.\n",
      "          input_signature: A possibly nested sequence of `tf.TensorSpec` objects\n",
      "            specifying the shapes and dtypes of the Tensors that will be supplied to\n",
      "            this function. If `None`, a separate function is instantiated for each\n",
      "            inferred input signature.  If input_signature is specified, every input to\n",
      "            `func` must be a `Tensor`, and `func` cannot accept `**kwargs`.\n",
      "          autograph: Whether autograph should be applied on `func` before tracing a\n",
      "            graph. Data-dependent Python control flow statements require\n",
      "            `autograph=True`. For more information, see the\n",
      "            [tf.function and AutoGraph guide](\n",
      "            https://www.tensorflow.org/guide/function#autograph_transformations).\n",
      "          jit_compile: If `True`, compiles the function using\n",
      "            [XLA](https://tensorflow.org/xla). XLA performs compiler optimizations,\n",
      "            such as fusion, and attempts to emit more efficient code. This may\n",
      "            drastically improve the performance. If set to `True`,\n",
      "            the whole function needs to be compilable by XLA, or an\n",
      "            `errors.InvalidArgumentError` is thrown.\n",
      "            If `None` (default), compiles the function with XLA when running on TPU\n",
      "            and goes through the regular function execution path when running on\n",
      "            other devices.\n",
      "            If `False`, executes the function without XLA compilation.  Set this value\n",
      "            to `False` when directly running a multi-device function on TPUs (e.g. two\n",
      "            TPU cores, one TPU core and its host CPU).\n",
      "            Not all functions are compilable, see a list of\n",
      "            [sharp corners](https://tensorflow.org/xla/known_issues).\n",
      "          reduce_retracing: When True, `tf.function` attempts to reduce the\n",
      "            amount of retracing, for example by using more generic shapes. This\n",
      "            can be controlled for user objects by customizing their associated\n",
      "            `tf.types.experimental.TraceType`.\n",
      "          experimental_implements: If provided, contains a name of a \"known\" function\n",
      "            this implements. For example \"mycompany.my_recurrent_cell\".\n",
      "            This is stored as an attribute in inference function,\n",
      "            which can then be detected when processing serialized function.\n",
      "            See [standardizing composite ops](https://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.md)  # pylint: disable=line-too-long\n",
      "            for details.  For an example of utilizing this attribute see this\n",
      "            [example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.cc)\n",
      "            The code above automatically detects and substitutes function that\n",
      "            implements \"embedded_matmul\" and allows TFLite to substitute its own\n",
      "            implementations. For instance, a tensorflow user can use this\n",
      "             attribute to mark that their function also implements\n",
      "            `embedded_matmul` (perhaps more efficiently!)\n",
      "            by specifying it using this parameter:\n",
      "            `@tf.function(experimental_implements=\"embedded_matmul\")`\n",
      "            This can either be specified as just the string name of the function or\n",
      "            a NameAttrList corresponding to a list of key-value attributes associated\n",
      "            with the function name. The name of the function will be in the 'name'\n",
      "            field of the NameAttrList. To define a formal TF op for this function\n",
      "            implements, try the experimental [composite TF](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tfr)\n",
      "            project.\n",
      "          experimental_autograph_options: Optional tuple of\n",
      "            `tf.autograph.experimental.Feature` values.\n",
      "          experimental_attributes: Optional dictionary of attributes to include in the\n",
      "            generated FunctionDefs.\n",
      "          experimental_relax_shapes: Deprecated. Use `reduce_retracing`\n",
      "            instead.\n",
      "          experimental_compile: Deprecated alias to 'jit_compile'.\n",
      "          experimental_follow_type_hints: Deprecated. Please use input_signature or\n",
      "            reduce_retracing instead.\n",
      "        \n",
      "        Returns:\n",
      "           If `func` is not None, returns a `tf.types.experimental.PolymorphicFunction`.\n",
      "           If `func` is None, returns a decorator that, when invoked with a single\n",
      "           `func` argument, returns a `tf.types.experimental.PolymorphicFunction`.\n",
      "        \n",
      "        Raises:\n",
      "           `ValueError` when attempting to use `jit_compile=True`, but XLA support is\n",
      "           not available.\n",
      "    \n",
      "    gather(params, indices, validate_indices=None, name=None, axis=None, batch_dims=0)\n",
      "        Gather slices from params axis `axis` according to indices. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(validate_indices)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "        \n",
      "        Gather slices from `params` axis `axis` according to `indices`.  `indices`\n",
      "        must be an integer tensor of any dimension (often 1-D).\n",
      "        \n",
      "        `Tensor.__getitem__` works for scalars, `tf.newaxis`, and\n",
      "        [python slices](https://numpy.org/doc/stable/reference/arrays.indexing.html#basic-slicing-and-indexing)\n",
      "        \n",
      "        `tf.gather` extends indexing to handle tensors of indices.\n",
      "        \n",
      "        In the simplest case it's identical to scalar indexing:\n",
      "        \n",
      "        >>> params = tf.constant(['p0', 'p1', 'p2', 'p3', 'p4', 'p5'])\n",
      "        >>> params[3].numpy()\n",
      "        b'p3'\n",
      "        >>> tf.gather(params, 3).numpy()\n",
      "        b'p3'\n",
      "        \n",
      "        The most common case is to pass a single axis tensor of indices (this\n",
      "        can't be expressed as a python slice because the indices are not sequential):\n",
      "        \n",
      "        >>> indices = [2, 0, 2, 5]\n",
      "        >>> tf.gather(params, indices).numpy()\n",
      "        array([b'p2', b'p0', b'p2', b'p5'], dtype=object)\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/Gather.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        The indices can have any shape. When the `params` has 1 axis, the\n",
      "        output shape is equal to the input shape:\n",
      "        \n",
      "        >>> tf.gather(params, [[2, 0], [2, 5]]).numpy()\n",
      "        array([[b'p2', b'p0'],\n",
      "               [b'p2', b'p5']], dtype=object)\n",
      "        \n",
      "        The `params` may also have any shape. `gather` can select slices\n",
      "        across any axis depending on the `axis` argument (which defaults to 0).\n",
      "        Below it is used to gather first rows, then columns from a matrix:\n",
      "        \n",
      "        >>> params = tf.constant([[0, 1.0, 2.0],\n",
      "        ...                       [10.0, 11.0, 12.0],\n",
      "        ...                       [20.0, 21.0, 22.0],\n",
      "        ...                       [30.0, 31.0, 32.0]])\n",
      "        >>> tf.gather(params, indices=[3,1]).numpy()\n",
      "        array([[30., 31., 32.],\n",
      "               [10., 11., 12.]], dtype=float32)\n",
      "        >>> tf.gather(params, indices=[2,1], axis=1).numpy()\n",
      "        array([[ 2.,  1.],\n",
      "               [12., 11.],\n",
      "               [22., 21.],\n",
      "               [32., 31.]], dtype=float32)\n",
      "        \n",
      "        More generally: The output shape has the same shape as the input, with the\n",
      "        indexed-axis replaced by the shape of the indices.\n",
      "        \n",
      "        >>> def result_shape(p_shape, i_shape, axis=0):\n",
      "        ...   return p_shape[:axis] + i_shape + p_shape[axis+1:]\n",
      "        >>>\n",
      "        >>> result_shape([1, 2, 3], [], axis=1)\n",
      "        [1, 3]\n",
      "        >>> result_shape([1, 2, 3], [7], axis=1)\n",
      "        [1, 7, 3]\n",
      "        >>> result_shape([1, 2, 3], [7, 5], axis=1)\n",
      "        [1, 7, 5, 3]\n",
      "        \n",
      "        Here are some examples:\n",
      "        \n",
      "        >>> params.shape.as_list()\n",
      "        [4, 3]\n",
      "        >>> indices = tf.constant([[0, 2]])\n",
      "        >>> tf.gather(params, indices=indices, axis=0).shape.as_list()\n",
      "        [1, 2, 3]\n",
      "        >>> tf.gather(params, indices=indices, axis=1).shape.as_list()\n",
      "        [4, 1, 2]\n",
      "        \n",
      "        >>> params = tf.random.normal(shape=(5, 6, 7, 8))\n",
      "        >>> indices = tf.random.uniform(shape=(10, 11), maxval=7, dtype=tf.int32)\n",
      "        >>> result = tf.gather(params, indices, axis=2)\n",
      "        >>> result.shape.as_list()\n",
      "        [5, 6, 10, 11, 8]\n",
      "        \n",
      "        This is because each index takes a slice from `params`, and\n",
      "        places it at the corresponding location in the output. For the above example\n",
      "        \n",
      "        >>> # For any location in indices\n",
      "        >>> a, b = 0, 1\n",
      "        >>> tf.reduce_all(\n",
      "        ...     # the corresponding slice of the result\n",
      "        ...     result[:, :, a, b, :] ==\n",
      "        ...     # is equal to the slice of `params` along `axis` at the index.\n",
      "        ...     params[:, :, indices[a, b], :]\n",
      "        ... ).numpy()\n",
      "        True\n",
      "        \n",
      "        ### Batching:\n",
      "        \n",
      "        The `batch_dims` argument lets you gather different items from each element\n",
      "        of a batch.\n",
      "        \n",
      "        Using `batch_dims=1` is equivalent to having an outer loop over the first\n",
      "        axis of `params` and `indices`:\n",
      "        \n",
      "        >>> params = tf.constant([\n",
      "        ...     [0, 0, 1, 0, 2],\n",
      "        ...     [3, 0, 0, 0, 4],\n",
      "        ...     [0, 5, 0, 6, 0]])\n",
      "        >>> indices = tf.constant([\n",
      "        ...     [2, 4],\n",
      "        ...     [0, 4],\n",
      "        ...     [1, 3]])\n",
      "        \n",
      "        >>> tf.gather(params, indices, axis=1, batch_dims=1).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        \n",
      "        This is equivalent to:\n",
      "        \n",
      "        >>> def manually_batched_gather(params, indices, axis):\n",
      "        ...   batch_dims=1\n",
      "        ...   result = []\n",
      "        ...   for p,i in zip(params, indices):\n",
      "        ...     r = tf.gather(p, i, axis=axis-batch_dims)\n",
      "        ...     result.append(r)\n",
      "        ...   return tf.stack(result)\n",
      "        >>> manually_batched_gather(params, indices, axis=1).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        \n",
      "        Higher values of `batch_dims` are equivalent to multiple nested loops over\n",
      "        the outer axes of `params` and `indices`. So the overall shape function is\n",
      "        \n",
      "        >>> def batched_result_shape(p_shape, i_shape, axis=0, batch_dims=0):\n",
      "        ...   return p_shape[:axis] + i_shape[batch_dims:] + p_shape[axis+1:]\n",
      "        >>>\n",
      "        >>> batched_result_shape(\n",
      "        ...     p_shape=params.shape.as_list(),\n",
      "        ...     i_shape=indices.shape.as_list(),\n",
      "        ...     axis=1,\n",
      "        ...     batch_dims=1)\n",
      "        [3, 2]\n",
      "        \n",
      "        >>> tf.gather(params, indices, axis=1, batch_dims=1).shape.as_list()\n",
      "        [3, 2]\n",
      "        \n",
      "        This comes up naturally if you need to use the indices of an operation like\n",
      "        `tf.argsort`, or `tf.math.top_k` where the last dimension of the indices\n",
      "        indexes into the last dimension of input, at the corresponding location.\n",
      "        In this case you can use `tf.gather(values, indices, batch_dims=-1)`.\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "        * `tf.Tensor.__getitem__`: The direct tensor index operation (`t[]`), handles\n",
      "          scalars and python-slices `tensor[..., 7, 1:-1]`\n",
      "        * `tf.scatter`: A collection of operations similar to `__setitem__`\n",
      "          (`t[i] = x`)\n",
      "        * `tf.gather_nd`: An operation similar to `tf.gather` but gathers across\n",
      "          multiple axis at once (it can gather elements of a matrix instead of rows\n",
      "          or columns)\n",
      "        * `tf.boolean_mask`, `tf.where`: Binary indexing.\n",
      "        * `tf.slice` and `tf.strided_slice`: For lower level access to the\n",
      "          implementation of `__getitem__`'s python-slice handling (`t[1:-1:2]`)\n",
      "        \n",
      "        Args:\n",
      "          params: The `Tensor` from which to gather values. Must be at least rank\n",
      "            `axis + 1`.\n",
      "          indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
      "            `int64`. The values must be in range `[0, params.shape[axis])`.\n",
      "          validate_indices: Deprecated, does nothing. Indices are always validated on\n",
      "            CPU, never validated on GPU.\n",
      "        \n",
      "            Caution: On CPU, if an out of bound index is found, an error is raised.\n",
      "            On GPU, if an out of bound index is found, a 0 is stored in the\n",
      "            corresponding output value.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`. The\n",
      "            `axis` in `params` to gather `indices` from. Must be greater than or equal\n",
      "            to `batch_dims`.  Defaults to the first non-batch dimension. Supports\n",
      "            negative indexes.\n",
      "          batch_dims: An `integer`.  The number of batch dimensions.  Must be less\n",
      "            than or equal to `rank(indices)`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `params`.\n",
      "    \n",
      "    gather_nd(params, indices, name=None, batch_dims=0)\n",
      "        Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
      "        \n",
      "        `indices` is a `Tensor` of indices into `params`. The index vectors are\n",
      "        arranged along the last axis of `indices`.\n",
      "        \n",
      "        This is similar to `tf.gather`, in which `indices` defines slices into the\n",
      "        first dimension of `params`. In `tf.gather_nd`, `indices` defines slices into\n",
      "        the first `N` dimensions of `params`, where `N = indices.shape[-1]`.\n",
      "        \n",
      "        Caution: On CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, a 0 is stored in the\n",
      "        corresponding output value.\n",
      "        \n",
      "        ## Gathering scalars\n",
      "        \n",
      "        In the simplest case the vectors in `indices` index the full rank of `params`:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices=[[0, 0],\n",
      "        ...              [1, 1]],\n",
      "        ...     params = [['a', 'b'],\n",
      "        ...               ['c', 'd']]).numpy()\n",
      "        array([b'a', b'd'], dtype=object)\n",
      "        \n",
      "        In this case the result has 1-axis fewer than `indices`, and each index vector\n",
      "        is replaced by the scalar indexed from `params`.\n",
      "        \n",
      "        In this case the shape relationship is:\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        assert index_depth == params.shape.rank\n",
      "        result_shape = indices.shape[:-1]\n",
      "        ```\n",
      "        \n",
      "        If `indices` has a rank of `K`, it is helpful to think `indices` as a\n",
      "        (K-1)-dimensional tensor of indices into `params`.\n",
      "        \n",
      "        ## Gathering slices\n",
      "        \n",
      "        If the index vectors do not index the full rank of `params` then each location\n",
      "        in the result contains a slice of params. This example collects rows from a\n",
      "        matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[1],\n",
      "        ...                [0]],\n",
      "        ...     params = [['a', 'b', 'c'],\n",
      "        ...               ['d', 'e', 'f']]).numpy()\n",
      "        array([[b'd', b'e', b'f'],\n",
      "               [b'a', b'b', b'c']], dtype=object)\n",
      "        \n",
      "        Here `indices` contains `[2]` index vectors, each with a length of `1`.\n",
      "        The index vectors each refer to rows of the `params` matrix. Each\n",
      "        row has a shape of `[3]` so the output shape is `[2, 3]`.\n",
      "        \n",
      "        In this case, the relationship between the shapes is:\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        outer_shape = indices.shape[:-1]\n",
      "        assert index_depth <= params.shape.rank\n",
      "        inner_shape = params.shape[index_depth:]\n",
      "        output_shape = outer_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        It is helpful to think of the results in this case as tensors-of-tensors.\n",
      "        The shape of the outer tensor is set by the leading dimensions of `indices`.\n",
      "        While the shape of the inner tensors is the shape of a single slice.\n",
      "        \n",
      "        ## Batches\n",
      "        \n",
      "        Additionally, both `params` and `indices` can have `M` leading batch\n",
      "        dimensions that exactly match. In this case `batch_dims` must be set to `M`.\n",
      "        \n",
      "        For example, to collect one row from each of a batch of matrices you could\n",
      "        set the leading elements of the index vectors to be their location in the\n",
      "        batch:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 1],\n",
      "        ...                [1, 0],\n",
      "        ...                [2, 4],\n",
      "        ...                [3, 2],\n",
      "        ...                [4, 1]],\n",
      "        ...     params=tf.zeros([5, 7, 3])).shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        The `batch_dims` argument lets you omit those leading location dimensions\n",
      "        from the index:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims=1,\n",
      "        ...     indices = [[1],\n",
      "        ...                [0],\n",
      "        ...                [4],\n",
      "        ...                [2],\n",
      "        ...                [1]],\n",
      "        ...     params=tf.zeros([5, 7, 3])).shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        This is equivalent to caling a separate `gather_nd` for each location in the\n",
      "        batch dimensions.\n",
      "        \n",
      "        \n",
      "        >>> params=tf.zeros([5, 7, 3])\n",
      "        >>> indices=tf.zeros([5, 1])\n",
      "        >>> batch_dims = 1\n",
      "        >>>\n",
      "        >>> index_depth = indices.shape[-1]\n",
      "        >>> batch_shape = indices.shape[:batch_dims]\n",
      "        >>> assert params.shape[:batch_dims] == batch_shape\n",
      "        >>> outer_shape = indices.shape[batch_dims:-1]\n",
      "        >>> assert index_depth <= params.shape.rank\n",
      "        >>> inner_shape = params.shape[batch_dims + index_depth:]\n",
      "        >>> output_shape = batch_shape + outer_shape + inner_shape\n",
      "        >>> output_shape.as_list()\n",
      "        [5, 3]\n",
      "        \n",
      "        ### More examples\n",
      "        \n",
      "        Indexing into a 3-tensor:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[1]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'a1', b'b1'],\n",
      "                [b'c1', b'd1']]], dtype=object)\n",
      "        \n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 1], [1, 0]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0', b'd0'],\n",
      "               [b'a1', b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[0, 0, 1], [1, 0, 1]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([b'b0', b'b1'], dtype=object)\n",
      "        \n",
      "        The examples below are for the case when only indices have leading extra\n",
      "        dimensions. If both 'params' and 'indices' have leading batch dimensions, use\n",
      "        the 'batch_dims' parameter to run gather_nd in batch mode.\n",
      "        \n",
      "        Batched indexing into a matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 0]], [[0, 1]]],\n",
      "        ...     params = [['a', 'b'], ['c', 'd']]).numpy()\n",
      "        array([[b'a'],\n",
      "               [b'b']], dtype=object)\n",
      "        \n",
      "        \n",
      "        \n",
      "        Batched slice indexing into a matrix:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [['a', 'b'], ['c', 'd']]).numpy()\n",
      "        array([[[b'c', b'd']],\n",
      "               [[b'a', b'b']]], dtype=object)\n",
      "        \n",
      "        \n",
      "        Batched indexing into a 3-tensor:\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[[b'a1', b'b1'],\n",
      "                 [b'c1', b'd1']]],\n",
      "               [[[b'a0', b'b0'],\n",
      "                 [b'c0', b'd0']]]], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'c0', b'd0'],\n",
      "                [b'a1', b'b1']],\n",
      "               [[b'a0', b'b0'],\n",
      "                [b'c1', b'd1']]], dtype=object)\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'b0', b'b1'],\n",
      "               [b'd0', b'c1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        Examples with batched 'params' and 'indices':\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[1],\n",
      "        ...                [0]],\n",
      "        ...     params = [[['a0', 'b0'],\n",
      "        ...                ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'],\n",
      "        ...                ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0', b'd0'],\n",
      "               [b'a1', b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[[1]], [[0]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[[b'c0', b'd0']],\n",
      "               [[b'a1', b'b1']]], dtype=object)\n",
      "        \n",
      "        >>> tf.gather_nd(\n",
      "        ...     batch_dims = 1,\n",
      "        ...     indices = [[[1, 0]], [[0, 1]]],\n",
      "        ...     params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "        ...               [['a1', 'b1'], ['c1', 'd1']]]).numpy()\n",
      "        array([[b'c0'],\n",
      "               [b'b1']], dtype=object)\n",
      "        \n",
      "        \n",
      "        See also `tf.gather`.\n",
      "        \n",
      "        Args:\n",
      "          params: A `Tensor`. The tensor from which to gather values.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          name: A name for the operation (optional).\n",
      "          batch_dims: An integer or a scalar 'Tensor'. The number of batch dimensions.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `params`.\n",
      "    \n",
      "    get_collection(key, scope=None) -> list[typing.Any]\n",
      "        Wrapper for `Graph.get_collection()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.get_collection`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          key: The key for the collection. For example, the `GraphKeys` class contains\n",
      "            many standard names for collections.\n",
      "          scope: (Optional.) If supplied, the resulting list is filtered to include\n",
      "            only items whose `name` attribute matches using `re.match`. Items without\n",
      "            a `name` attribute are never returned if a scope is supplied and the\n",
      "            choice or `re.match` means that a `scope` without special tokens filters\n",
      "            by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          The list of values in the collection with the given `name`, or\n",
      "          an empty list if no value has been added to that collection. The\n",
      "          list contains the values in the order under which they were\n",
      "          collected.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are not supported when eager execution is enabled.\n",
      "        @end_compatibility\n",
      "    \n",
      "    get_collection_ref(key) -> list[typing.Any]\n",
      "        Wrapper for `Graph.get_collection_ref()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.get_collection_ref`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          key: The key for the collection. For example, the `GraphKeys` class contains\n",
      "            many standard names for collections.\n",
      "        \n",
      "        Returns:\n",
      "          The list of values in the collection with the given `name`, or an empty\n",
      "          list if no value has been added to that collection.  Note that this returns\n",
      "          the collection list itself, which can be modified in place to change the\n",
      "          collection.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are not supported when eager execution is enabled.\n",
      "        @end_compatibility\n",
      "    \n",
      "    get_default_graph() -> tensorflow.python.framework.ops.Graph\n",
      "        Returns the default graph for the current thread.\n",
      "        \n",
      "        The returned graph will be the innermost graph on which a\n",
      "        `Graph.as_default()` context has been entered, or a global default\n",
      "        graph if none has been explicitly created.\n",
      "        \n",
      "        NOTE: The default graph is a property of the current thread. If you\n",
      "        create a new thread, and wish to use the default graph in that\n",
      "        thread, you must explicitly add a `with g.as_default():` in that\n",
      "        thread's function.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `get_default_graph` does not work with either eager execution or\n",
      "        `tf.function`, and you should not invoke it directly. To migrate code that\n",
      "        uses Graph-related functions to TF2, rewrite the code without them. See the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate) for more\n",
      "        description about the behavior and semantic changes between Tensorflow 1 and\n",
      "        Tensorflow 2.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Returns:\n",
      "          The default `Graph` being used in the current thread.\n",
      "    \n",
      "    get_default_session()\n",
      "        Returns the default session for the current thread.\n",
      "        \n",
      "        The returned `Session` will be the innermost session on which a\n",
      "        `Session` or `Session.as_default()` context has been entered.\n",
      "        \n",
      "        NOTE: The default session is a property of the current thread. If you\n",
      "        create a new thread, and wish to use the default session in that\n",
      "        thread, you must explicitly add a `with sess.as_default():` in that\n",
      "        thread's function.\n",
      "        \n",
      "        Returns:\n",
      "          The default `Session` being used in the current thread.\n",
      "    \n",
      "    get_local_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=False, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "        Gets an existing *local* variable or creates a new one.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Although it is a legacy `compat.v1` api,\n",
      "        `tf.compat.v1.get_variable` is mostly compatible with eager\n",
      "        execution and `tf.function` but only if you combine it with the\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables` decorator. (Though\n",
      "        it will behave as if reuse is always set to `AUTO_REUSE`.)\n",
      "        \n",
      "        See the\n",
      "        [model migration guide](https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "        for more info.\n",
      "        \n",
      "        If you do not combine it with\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables`, `get_variable` will create\n",
      "        a brand new variable every single time it is called and will never reuse\n",
      "        variables, regardless of variable names or `reuse` arguments.\n",
      "        \n",
      "        The TF2 equivalent of this symbol would be `tf.Variable`, but note\n",
      "        that when using `tf.Variable` you must make sure you track your variables\n",
      "        (and regularizer arguments) either manually or via `tf.Module` or\n",
      "        `tf.keras.layers.Layer` mechanisms.\n",
      "        \n",
      "        A section of the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate/model_mapping#incremental_migration_to_native_tf2)\n",
      "        provides more details on incrementally migrating these usages to `tf.Variable`\n",
      "        as well.\n",
      "        \n",
      "        Note: The `partitioner` arg is not compatible with TF2 behaviors even when\n",
      "        using `tf.compat.v1.keras.utils.track_tf1_style_variables`. It can be replaced\n",
      "        by using `ParameterServerStrategy` and its partitioners. See the\n",
      "        [multi-gpu migration guide](https://www.tensorflow.org/guide/migrate/multi_worker_cpu_gpu_training)\n",
      "        and the ParameterServerStrategy guides it references for more info.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Behavior is the same as in `get_variable`, except that variables are\n",
      "        added to the `LOCAL_VARIABLES` collection and `trainable` is set to\n",
      "        `False`.\n",
      "        This function prefixes the name with the current variable scope\n",
      "        and performs reuse checks. See the\n",
      "        [Variable Scope How To](https://tensorflow.org/guide/variables)\n",
      "        for an extensive description of how reusing works. Here is a basic example:\n",
      "        \n",
      "        ```python\n",
      "        def foo():\n",
      "          with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
      "            v = tf.get_variable(\"v\", [1])\n",
      "          return v\n",
      "        \n",
      "        v1 = foo()  # Creates v.\n",
      "        v2 = foo()  # Gets the same, existing v.\n",
      "        assert v1 == v2\n",
      "        ```\n",
      "        \n",
      "        If initializer is `None` (the default), the default initializer passed in\n",
      "        the variable scope will be used. If that one is `None` too, a\n",
      "        `glorot_uniform_initializer` will be used. The initializer can also be\n",
      "        a Tensor, in which case the variable is initialized to this value and shape.\n",
      "        \n",
      "        Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "        passed in the variable scope will be used (if that is `None` too,\n",
      "        then by default no regularization is performed).\n",
      "        \n",
      "        If a partitioner is provided, a `PartitionedVariable` is returned.\n",
      "        Accessing this object as a `Tensor` returns the shards concatenated along\n",
      "        the partition axis.\n",
      "        \n",
      "        Some useful partitioners are available.  See, e.g.,\n",
      "        `variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "        \n",
      "        Args:\n",
      "          name: The name of the new or existing variable.\n",
      "          shape: Shape of the new or existing variable.\n",
      "          dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "          initializer: Initializer for the variable if one is created. Can either be\n",
      "            an initializer object or a Tensor. If it's a Tensor, its shape must be known\n",
      "            unless validate_shape is False.\n",
      "          regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "            applying it on a newly created variable will be added to the collection\n",
      "            `tf.GraphKeys.REGULARIZATION_LOSSES` and can be used for regularization.\n",
      "          collections: List of graph collections keys to add the Variable to.\n",
      "            Defaults to `[GraphKeys.LOCAL_VARIABLES]` (see `tf.Variable`).\n",
      "          caching_device: Optional device string or function describing where the\n",
      "            Variable should be cached for reading.  Defaults to the Variable's\n",
      "            device.  If not `None`, caches on another device.  Typical use is to\n",
      "            cache on the device where the Ops using the Variable reside, to\n",
      "            deduplicate copying through `Switch` and other conditional statements.\n",
      "          partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "            and `dtype` of the Variable to be created, and returns a list of\n",
      "            partitions for each axis (currently only one axis can be partitioned).\n",
      "          validate_shape: If False, allows the variable to be initialized with a\n",
      "              value of unknown shape. If True, the default, the shape of initial_value\n",
      "              must be known. For this to be used the initializer must be a Tensor and\n",
      "              not an initializer object.\n",
      "          use_resource: If False, creates a regular Variable. If true, creates an\n",
      "            experimental ResourceVariable instead with well-defined semantics.\n",
      "            Defaults to False (will later change to True). When eager execution is\n",
      "            enabled this argument is always forced to be True.\n",
      "          custom_getter: Callable that takes as a first argument the true getter, and\n",
      "            allows overwriting the internal get_variable method.\n",
      "            The signature of `custom_getter` should match that of this method,\n",
      "            but the most future-proof version will allow for changes:\n",
      "            `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "            all `get_variable` parameters is also allowed:\n",
      "            `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "            custom getter that simply creates variables with modified names is:\n",
      "            ```python\n",
      "            def custom_getter(getter, name, *args, **kwargs):\n",
      "              return getter(name + '_suffix', *args, **kwargs)\n",
      "            ```\n",
      "          constraint: An optional projection function to be applied to the variable\n",
      "            after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "            constraints or value constraints for layer weights). The function must\n",
      "            take as input the unprojected Tensor representing the value of the\n",
      "            variable and return the Tensor for the projected value\n",
      "            (which must have the same shape). Constraints are not safe to\n",
      "            use when doing asynchronous distributed training.\n",
      "          synchronization: Indicates when a distributed a variable will be\n",
      "            aggregated. Accepted values are constants defined in the class\n",
      "            `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "            `AUTO` and the current `DistributionStrategy` chooses\n",
      "            when to synchronize.\n",
      "          aggregation: Indicates how a distributed variable will be aggregated.\n",
      "            Accepted values are constants defined in the class\n",
      "            `tf.VariableAggregation`.\n",
      "        \n",
      "        Returns:\n",
      "          The created or existing `Variable` (or `PartitionedVariable`, if a\n",
      "          partitioner was used).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: when creating a new variable and shape is not declared,\n",
      "            when violating reuse during variable creation, or when `initializer` dtype\n",
      "            and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "    \n",
      "    get_logger()\n",
      "        Return TF logger instance.\n",
      "        \n",
      "        Returns:\n",
      "          An instance of the Python logging library Logger.\n",
      "        \n",
      "        See Python documentation (https://docs.python.org/3/library/logging.html)\n",
      "        for detailed API. Below is only a summary.\n",
      "        \n",
      "        The logger has 5 levels of logging from the most serious to the least:\n",
      "        \n",
      "        1. FATAL\n",
      "        2. ERROR\n",
      "        3. WARN\n",
      "        4. INFO\n",
      "        5. DEBUG\n",
      "        \n",
      "        The logger has the following methods, based on these logging levels:\n",
      "        \n",
      "        1. fatal(msg, *args, **kwargs)\n",
      "        2. error(msg, *args, **kwargs)\n",
      "        3. warn(msg, *args, **kwargs)\n",
      "        4. info(msg, *args, **kwargs)\n",
      "        5. debug(msg, *args, **kwargs)\n",
      "        \n",
      "        The `msg` can contain string formatting.  An example of logging at the `ERROR`\n",
      "        level\n",
      "        using string formating is:\n",
      "        \n",
      "        >>> tf.get_logger().error(\"The value %d is invalid.\", 3)\n",
      "        \n",
      "        You can also specify the logging verbosity.  In this case, the\n",
      "        WARN level log will not be emitted:\n",
      "        \n",
      "        >>> tf.get_logger().setLevel(ERROR)\n",
      "        >>> tf.get_logger().warn(\"This is a warning.\")\n",
      "    \n",
      "    get_seed(op_seed)\n",
      "        Returns the local seeds an operation should use given an op-specific seed.\n",
      "        \n",
      "        Given operation-specific seed, `op_seed`, this helper function returns two\n",
      "        seeds derived from graph-level and op-level seeds. Many random operations\n",
      "        internally use the two seeds to allow user to change the seed globally for a\n",
      "        graph, or for only specific operations.\n",
      "        \n",
      "        For details on how the graph-level seed interacts with op seeds, see\n",
      "        `tf.compat.v1.random.set_random_seed`.\n",
      "        \n",
      "        Args:\n",
      "          op_seed: integer.\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of two integers that should be used for the local seed of this\n",
      "          operation.\n",
      "    \n",
      "    get_session_handle(data, name=None)\n",
      "        Return the handle of `data`.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Keep `data` \"in-place\" in the runtime and create a handle that can be\n",
      "        used to retrieve `data` in a subsequent run().\n",
      "        \n",
      "        Combined with `get_session_tensor`, we can keep a tensor produced in\n",
      "        one run call in place, and use it as the input in a future run call.\n",
      "        \n",
      "        Args:\n",
      "          data: A tensor to be stored in the session.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A scalar string tensor representing a unique handle for `data`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `data` is not a Tensor.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.multiply(a, b)\n",
      "        h = tf.compat.v1.get_session_handle(c)\n",
      "        h = sess.run(h)\n",
      "        \n",
      "        p, a = tf.compat.v1.get_session_tensor(h.handle, tf.float32)\n",
      "        b = tf.multiply(a, 10)\n",
      "        c = sess.run(b, feed_dict={p: h.handle})\n",
      "        ```\n",
      "    \n",
      "    get_session_tensor(handle, dtype, name=None)\n",
      "        Get the tensor of type `dtype` by feeding a tensor handle.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Get the value of the tensor from a tensor handle. The tensor\n",
      "        is produced in a previous run() and stored in the state of the\n",
      "        session.\n",
      "        \n",
      "        Args:\n",
      "          handle: The string representation of a persistent tensor handle.\n",
      "          dtype: The type of the output tensor.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A pair of tensors. The first is a placeholder for feeding a\n",
      "          tensor handle and the second is the tensor in the session state\n",
      "          keyed by the tensor handle.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.multiply(a, b)\n",
      "        h = tf.compat.v1.get_session_handle(c)\n",
      "        h = sess.run(h)\n",
      "        \n",
      "        p, a = tf.compat.v1.get_session_tensor(h.handle, tf.float32)\n",
      "        b = tf.multiply(a, 10)\n",
      "        c = sess.run(b, feed_dict={p: h.handle})\n",
      "        ```\n",
      "    \n",
      "    get_static_value = constant_value(tensor, partial=False)\n",
      "        Returns the constant value of the given tensor, if efficiently calculable.\n",
      "        \n",
      "        This function attempts to partially evaluate the given tensor, and\n",
      "        returns its value as a numpy ndarray if this succeeds.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> a = tf.constant(10)\n",
      "        >>> tf.get_static_value(a)\n",
      "        10\n",
      "        >>> b = tf.constant(20)\n",
      "        >>> tf.get_static_value(tf.add(a, b))\n",
      "        30\n",
      "        \n",
      "        >>> # `tf.Variable` is not supported.\n",
      "        >>> c = tf.Variable(30)\n",
      "        >>> print(tf.get_static_value(c))\n",
      "        None\n",
      "        \n",
      "        Using `partial` option is most relevant when calling `get_static_value` inside\n",
      "        a `tf.function`. Setting it to `True` will return the results but for the\n",
      "        values that cannot be evaluated will be `None`. For example:\n",
      "        \n",
      "        ```python\n",
      "        class Foo:\n",
      "          def __init__(self):\n",
      "            self.a = tf.Variable(1)\n",
      "            self.b = tf.constant(2)\n",
      "        \n",
      "          @tf.function\n",
      "          def bar(self, partial):\n",
      "            packed = tf.raw_ops.Pack(values=[self.a, self.b])\n",
      "            static_val = tf.get_static_value(packed, partial=partial)\n",
      "            tf.print(static_val)\n",
      "        \n",
      "        f = Foo()\n",
      "        f.bar(partial=True)  # `array([None, array(2, dtype=int32)], dtype=object)`\n",
      "        f.bar(partial=False)  # `None`\n",
      "        ```\n",
      "        \n",
      "        Compatibility(V1): If `constant_value(tensor)` returns a non-`None` result, it\n",
      "        will no longer be possible to feed a different value for `tensor`. This allows\n",
      "        the result of this function to influence the graph that is constructed, and\n",
      "        permits static shape optimizations.\n",
      "        \n",
      "        Args:\n",
      "          tensor: The Tensor to be evaluated.\n",
      "          partial: If True, the returned numpy array is allowed to have partially\n",
      "            evaluated values. Values that can't be evaluated will be None.\n",
      "        \n",
      "        Returns:\n",
      "          A numpy ndarray containing the constant value of the given `tensor`,\n",
      "          or None if it cannot be calculated.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if tensor is not an tensor.Tensor.\n",
      "    \n",
      "    get_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "        Gets an existing variable with these parameters or create a new one.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Although it is a legacy `compat.v1` api,\n",
      "        `tf.compat.v1.get_variable` is mostly compatible with eager\n",
      "        execution and `tf.function` but only if you combine it with the\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables` decorator. (Though\n",
      "        it will behave as if reuse is always set to `AUTO_REUSE`.)\n",
      "        \n",
      "        See the\n",
      "        [model migration guide](https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "        for more info.\n",
      "        \n",
      "        If you do not combine it with\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables`, `get_variable` will create\n",
      "        a brand new variable every single time it is called and will never reuse\n",
      "        variables, regardless of variable names or `reuse` arguments.\n",
      "        \n",
      "        The TF2 equivalent of this symbol would be `tf.Variable`, but note\n",
      "        that when using `tf.Variable` you must make sure you track your variables\n",
      "        (and regularizer arguments) either manually or via `tf.Module` or\n",
      "        `tf.keras.layers.Layer` mechanisms.\n",
      "        \n",
      "        A section of the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate/model_mapping#incremental_migration_to_native_tf2)\n",
      "        provides more details on incrementally migrating these usages to `tf.Variable`\n",
      "        as well.\n",
      "        \n",
      "        Note: The `partitioner` arg is not compatible with TF2 behaviors even when\n",
      "        using `tf.compat.v1.keras.utils.track_tf1_style_variables`. It can be replaced\n",
      "        by using `ParameterServerStrategy` and its partitioners. See the\n",
      "        [multi-gpu migration guide](https://www.tensorflow.org/guide/migrate/multi_worker_cpu_gpu_training)\n",
      "        and the ParameterServerStrategy guides it references for more info.\n",
      "        @end_compatibility\n",
      "        \n",
      "        This function prefixes the name with the current variable scope\n",
      "        and performs reuse checks. See the\n",
      "        [Variable Scope How To](https://tensorflow.org/guide/variables)\n",
      "        for an extensive description of how reusing works. Here is a basic example:\n",
      "        \n",
      "        ```python\n",
      "        def foo():\n",
      "          with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
      "            v = tf.get_variable(\"v\", [1])\n",
      "          return v\n",
      "        \n",
      "        v1 = foo()  # Creates v.\n",
      "        v2 = foo()  # Gets the same, existing v.\n",
      "        assert v1 == v2\n",
      "        ```\n",
      "        \n",
      "        If initializer is `None` (the default), the default initializer passed in\n",
      "        the variable scope will be used. If that one is `None` too, a\n",
      "        `glorot_uniform_initializer` will be used. The initializer can also be\n",
      "        a Tensor, in which case the variable is initialized to this value and shape.\n",
      "        \n",
      "        Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "        passed in the variable scope will be used (if that is `None` too,\n",
      "        then by default no regularization is performed).\n",
      "        \n",
      "        If a partitioner is provided, a `PartitionedVariable` is returned.\n",
      "        Accessing this object as a `Tensor` returns the shards concatenated along\n",
      "        the partition axis.\n",
      "        \n",
      "        Some useful partitioners are available.  See, e.g.,\n",
      "        `variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "        \n",
      "        Args:\n",
      "          name: The name of the new or existing variable.\n",
      "          shape: Shape of the new or existing variable.\n",
      "          dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "          initializer: Initializer for the variable if one is created. Can either be\n",
      "            an initializer object or a Tensor. If it's a Tensor, its shape must be known\n",
      "            unless validate_shape is False.\n",
      "          regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "            applying it on a newly created variable will be added to the collection\n",
      "            `tf.GraphKeys.REGULARIZATION_LOSSES` and can be used for regularization.\n",
      "          trainable: If `True` also add the variable to the graph collection\n",
      "            `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).\n",
      "          collections: List of graph collections keys to add the Variable to.\n",
      "            Defaults to `[GraphKeys.GLOBAL_VARIABLES]` (see `tf.Variable`).\n",
      "          caching_device: Optional device string or function describing where the\n",
      "            Variable should be cached for reading.  Defaults to the Variable's\n",
      "            device.  If not `None`, caches on another device.  Typical use is to\n",
      "            cache on the device where the Ops using the Variable reside, to\n",
      "            deduplicate copying through `Switch` and other conditional statements.\n",
      "          partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "            and `dtype` of the Variable to be created, and returns a list of\n",
      "            partitions for each axis (currently only one axis can be partitioned).\n",
      "          validate_shape: If False, allows the variable to be initialized with a\n",
      "              value of unknown shape. If True, the default, the shape of initial_value\n",
      "              must be known. For this to be used the initializer must be a Tensor and\n",
      "              not an initializer object.\n",
      "          use_resource: If False, creates a regular Variable. If true, creates an\n",
      "            experimental ResourceVariable instead with well-defined semantics.\n",
      "            Defaults to False (will later change to True). When eager execution is\n",
      "            enabled this argument is always forced to be True.\n",
      "          custom_getter: Callable that takes as a first argument the true getter, and\n",
      "            allows overwriting the internal get_variable method.\n",
      "            The signature of `custom_getter` should match that of this method,\n",
      "            but the most future-proof version will allow for changes:\n",
      "            `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "            all `get_variable` parameters is also allowed:\n",
      "            `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "            custom getter that simply creates variables with modified names is:\n",
      "            ```python\n",
      "            def custom_getter(getter, name, *args, **kwargs):\n",
      "              return getter(name + '_suffix', *args, **kwargs)\n",
      "            ```\n",
      "          constraint: An optional projection function to be applied to the variable\n",
      "            after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "            constraints or value constraints for layer weights). The function must\n",
      "            take as input the unprojected Tensor representing the value of the\n",
      "            variable and return the Tensor for the projected value\n",
      "            (which must have the same shape). Constraints are not safe to\n",
      "            use when doing asynchronous distributed training.\n",
      "          synchronization: Indicates when a distributed a variable will be\n",
      "            aggregated. Accepted values are constants defined in the class\n",
      "            `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "            `AUTO` and the current `DistributionStrategy` chooses\n",
      "            when to synchronize.\n",
      "          aggregation: Indicates how a distributed variable will be aggregated.\n",
      "            Accepted values are constants defined in the class\n",
      "            `tf.VariableAggregation`.\n",
      "        \n",
      "        Returns:\n",
      "          The created or existing `Variable` (or `PartitionedVariable`, if a\n",
      "          partitioner was used).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: when creating a new variable and shape is not declared,\n",
      "            when violating reuse during variable creation, or when `initializer` dtype\n",
      "            and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "    \n",
      "    get_variable_scope()\n",
      "        Returns the current variable scope.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Although it is a legacy `compat.v1` api,\n",
      "        `tf.compat.v1.get_variable` is compatible with eager\n",
      "        execution and `tf.function`\n",
      "        \n",
      "        However, to maintain variable-scope based variable reuse\n",
      "        you will need to combine it with\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables`. (Though\n",
      "        it will behave as if reuse is always set to `tf.compat.v1.AUTO_REUSE`.)\n",
      "        \n",
      "        See the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "        for more info.\n",
      "        \n",
      "        The TF2 equivalent, if you are just trying to track\n",
      "        variable name prefixes and not control `get_variable`-based variable reuse,\n",
      "        would be to use `tf.name_scope` and capture the output of opening the\n",
      "        scope (which represents the current name prefix).\n",
      "        \n",
      "        For example:\n",
      "        ```python\n",
      "        x = tf.name_scope('foo') as current_scope:\n",
      "          ...\n",
      "        ```\n",
      "        @end_compatibility\n",
      "    \n",
      "    global_norm(t_list, name=None)\n",
      "        Computes the global norm of multiple tensors.\n",
      "        \n",
      "        Given a tuple or list of tensors `t_list`, this operation returns the\n",
      "        global norm of the elements in all tensors in `t_list`. The global norm is\n",
      "        computed as:\n",
      "        \n",
      "        `global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))`\n",
      "        \n",
      "        Any entries in `t_list` that are of type None are ignored.\n",
      "        \n",
      "        Args:\n",
      "          t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A 0-D (scalar) `Tensor` of type `float`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `t_list` is not a sequence.\n",
      "    \n",
      "    global_variables(scope=None)\n",
      "        Returns global variables.\n",
      "        \n",
      "        Global variables are variables that are shared across machines in a\n",
      "        distributed environment. The `Variable()` constructor or `get_variable()`\n",
      "        automatically adds new variables to the graph collection\n",
      "        `GraphKeys.GLOBAL_VARIABLES`.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        An alternative to global variables are local variables. See\n",
      "        `tf.compat.v1.local_variables`\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Not compatible with eager execution and `tf.function`. In particular, Graph\n",
      "        collections are deprecated in TF2. Instead please create a\n",
      "        [tf.Module](https://www.tensorflow.org/guide/intro_to_modules)\n",
      "        container for all your model state, including variables.\n",
      "        You can then list all the variables in your `tf.Module` through the\n",
      "        `variables` attribute.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Variable` objects.\n",
      "    \n",
      "    global_variables_initializer()\n",
      "        Returns an Op that initializes global variables.\n",
      "        \n",
      "        This is just a shortcut for `variables_initializer(global_variables())`\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        In TF2, variables are initialized immediately when they are created. There is\n",
      "        no longer a need to run variable initializers before using them.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes global variables in the graph.\n",
      "    \n",
      "    grad_pass_through(f)\n",
      "        Creates a grad-pass-through op with the forward behavior provided in f.\n",
      "        \n",
      "        Use this function to wrap any op, maintaining its behavior in the forward\n",
      "        pass, but replacing the original op in the backward graph with an identity.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.Variable(1.0, name=\"x\")\n",
      "        z = tf.Variable(3.0, name=\"z\")\n",
      "        \n",
      "        with tf.GradientTape() as tape:\n",
      "          # y will evaluate to 9.0\n",
      "          y = tf.grad_pass_through(x.assign)(z**2)\n",
      "        # grads will evaluate to 6.0\n",
      "        grads = tape.gradient(y, z)\n",
      "        ```\n",
      "        \n",
      "        Another example is a 'differentiable' moving average approximation, where\n",
      "        gradients are allowed to flow into the last value fed to the moving average,\n",
      "        but the moving average is still used for the forward pass:\n",
      "        \n",
      "        ```python\n",
      "        x = ... # Some scalar value\n",
      "        # A moving average object, we don't need to know how this is implemented\n",
      "        moving_average = MovingAverage()\n",
      "        with backprop.GradientTape() as tape:\n",
      "          # mavg_x will evaluate to the current running average value\n",
      "          mavg_x = tf.grad_pass_through(moving_average)(x)\n",
      "        grads = tape.gradient(mavg_x, x) # grads will evaluate to 1.0\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a `Tensor` or nested structure of `Tensor`\n",
      "            outputs.\n",
      "        \n",
      "        Returns:\n",
      "          A function `h(x)` which returns the same values as `f(x)` and whose\n",
      "          gradients are the same as those of an identity function.\n",
      "    \n",
      "    gradients(ys, xs, grad_ys=None, name='gradients', colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None, stop_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      "        Constructs symbolic derivatives of sum of `ys` w.r.t. x in `xs`.\n",
      "        \n",
      "        `ys` and `xs` are each a `Tensor` or a list of tensors.  `grad_ys`\n",
      "        is a list of `Tensor`, holding the gradients received by the\n",
      "        `ys`. The list must be the same length as `ys`.\n",
      "        \n",
      "        `gradients()` adds ops to the graph to output the derivatives of `ys` with\n",
      "        respect to `xs`.  It returns a list of `Tensor` of length `len(xs)` where\n",
      "        each tensor is the `sum(dy/dx)` for y in `ys` and for x in `xs`.\n",
      "        \n",
      "        `grad_ys` is a list of tensors of the same length as `ys` that holds\n",
      "        the initial gradients for each y in `ys`.  When `grad_ys` is None,\n",
      "        we fill in a tensor of '1's of the shape of y for each y in `ys`.  A\n",
      "        user can provide their own initial `grad_ys` to compute the\n",
      "        derivatives using a different initial gradient for each y (e.g., if\n",
      "        one wanted to weight the gradient differently for each value in\n",
      "        each y).\n",
      "        \n",
      "        `stop_gradients` is a `Tensor` or a list of tensors to be considered constant\n",
      "        with respect to all `xs`. These tensors will not be backpropagated through,\n",
      "        as though they had been explicitly disconnected using `stop_gradient`.  Among\n",
      "        other things, this allows computation of partial derivatives as opposed to\n",
      "        total derivatives. For example:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.constant(0.)\n",
      "        b = 2 * a\n",
      "        g = tf.gradients(a + b, [a, b], stop_gradients=[a, b])\n",
      "        ```\n",
      "        \n",
      "        Here the partial derivatives `g` evaluate to `[1.0, 1.0]`, compared to the\n",
      "        total derivatives `tf.gradients(a + b, [a, b])`, which take into account the\n",
      "        influence of `a` on `b` and evaluate to `[3.0, 1.0]`.  Note that the above is\n",
      "        equivalent to:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.stop_gradient(tf.constant(0.))\n",
      "        b = tf.stop_gradient(2 * a)\n",
      "        g = tf.gradients(a + b, [a, b])\n",
      "        ```\n",
      "        \n",
      "        `stop_gradients` provides a way of stopping gradient after the graph has\n",
      "        already been constructed, as compared to `tf.stop_gradient` which is used\n",
      "        during graph construction.  When the two approaches are combined,\n",
      "        backpropagation stops at both `tf.stop_gradient` nodes and nodes in\n",
      "        `stop_gradients`, whichever is encountered first.\n",
      "        \n",
      "        All integer tensors are considered constant with respect to all `xs`, as if\n",
      "        they were included in `stop_gradients`.\n",
      "        \n",
      "        `unconnected_gradients` determines the value returned for each x in xs if it\n",
      "        is unconnected in the graph to ys. By default this is None to safeguard\n",
      "        against errors. Mathematically these gradients are zero which can be requested\n",
      "        using the `'zero'` option. `tf.UnconnectedGradients` provides the\n",
      "        following options and behaviors:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.ones([1, 2])\n",
      "        b = tf.ones([3, 1])\n",
      "        g1 = tf.gradients([b], [a], unconnected_gradients='none')\n",
      "        sess.run(g1)  # [None]\n",
      "        \n",
      "        g2 = tf.gradients([b], [a], unconnected_gradients='zero')\n",
      "        sess.run(g2)  # [array([[0., 0.]], dtype=float32)]\n",
      "        ```\n",
      "        \n",
      "        Let us take one practical example which comes during the back propogation\n",
      "        phase. This function is used to evaluate the derivatives of the cost function\n",
      "        with respect to Weights `Ws` and Biases `bs`. Below sample implementation\n",
      "        provides the exaplantion of what it is actually used for :\n",
      "        \n",
      "        ```python\n",
      "        Ws = tf.constant(0.)\n",
      "        bs = 2 * Ws\n",
      "        cost = Ws + bs  # This is just an example. So, please ignore the formulas.\n",
      "        g = tf.gradients(cost, [Ws, bs])\n",
      "        dCost_dW, dCost_db = g\n",
      "        ```\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          ys: A `Tensor` or list of tensors to be differentiated.\n",
      "          xs: A `Tensor` or list of tensors to be used for differentiation.\n",
      "          grad_ys: Optional. A `Tensor` or list of tensors the same size as\n",
      "            `ys` and holding the gradients computed for each y in `ys`.\n",
      "          name: Optional name to use for grouping all the gradient ops together.\n",
      "            defaults to 'gradients'.\n",
      "          colocate_gradients_with_ops: If True, try colocating gradients with\n",
      "            the corresponding op.\n",
      "          gate_gradients: If True, add a tuple around the gradients returned\n",
      "            for an operations.  This avoids some race conditions.\n",
      "          aggregation_method: Specifies the method used to combine gradient terms.\n",
      "            Accepted values are constants defined in the class `AggregationMethod`.\n",
      "          stop_gradients: Optional. A `Tensor` or list of tensors not to differentiate\n",
      "            through.\n",
      "          unconnected_gradients: Optional. Specifies the gradient value returned when\n",
      "            the given input tensors are unconnected. Accepted values are constants\n",
      "            defined in the class `tf.UnconnectedGradients` and the default value is\n",
      "            `none`.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` of length `len(xs)` where each tensor is the `sum(dy/dx)`\n",
      "          for y in `ys` and for x in `xs`.\n",
      "        \n",
      "        Raises:\n",
      "          LookupError: if one of the operations between `x` and `y` does not\n",
      "            have a registered gradient function.\n",
      "          ValueError: if the arguments are invalid.\n",
      "          RuntimeError: if called in Eager mode.\n",
      "    \n",
      "    greater(x: typing.Annotated[_any, ~TV_Greater_T], y: typing.Annotated[_any, ~TV_Greater_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of (x > y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5, 2, 5])\n",
      "        tf.math.greater(x, y) ==> [False, True, True]\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5])\n",
      "        tf.math.greater(x, y) ==> [False, False, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    greater_equal(x: typing.Annotated[_any, ~TV_GreaterEqual_T], y: typing.Annotated[_any, ~TV_GreaterEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of (x >= y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5, 4, 6, 7])\n",
      "        y = tf.constant([5, 2, 5, 10])\n",
      "        tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
      "        \n",
      "        x = tf.constant([5, 4, 6, 7])\n",
      "        y = tf.constant([5])\n",
      "        tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    group(*inputs, **kwargs)\n",
      "        Create an op that groups multiple operations.\n",
      "        \n",
      "        When this op finishes, all ops in `inputs` have finished. This op has no\n",
      "        output.\n",
      "        \n",
      "        Note: *In TensorFlow 2 with eager and/or Autograph, you should not require\n",
      "        this method, as ops execute in the expected order thanks to automatic control\n",
      "        dependencies.* Only use `tf.group` when working with v1\n",
      "        `tf.Graph` code.\n",
      "        \n",
      "        When operating in a v1-style graph context, ops are not executed in the same\n",
      "        order as specified in the code; TensorFlow will attempt to execute ops in\n",
      "        parallel or in an order convenient to the result it is computing.  `tf.group`\n",
      "        allows you to request that one or more results finish before execution\n",
      "        continues.\n",
      "        \n",
      "        `tf.group` creates a single op (of type `NoOp`), and then adds appropriate\n",
      "        control dependencies.  Thus, `c = tf.group(a, b)` will compute the same graph\n",
      "        as this:\n",
      "        \n",
      "            with tf.control_dependencies([a, b]):\n",
      "                c = tf.no_op()\n",
      "        \n",
      "        See also `tf.tuple` and\n",
      "        `tf.control_dependencies`.\n",
      "        \n",
      "        Args:\n",
      "          *inputs: Zero or more tensors to group.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          An Operation that executes all its inputs.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If an unknown keyword argument is provided.\n",
      "    \n",
      "    guarantee_const(input, name=None)\n",
      "        Promise to the TF runtime that the input tensor is a constant. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Not for public use.\n",
      "        \n",
      "        The runtime is then free to make optimizations based on this.\n",
      "        \n",
      "        Returns the input tensor without modification.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for this operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same dtype as `input`.\n",
      "    \n",
      "    hessians(ys, xs, name='hessians', colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None)\n",
      "        Constructs the Hessian of sum of `ys` with respect to `x` in `xs`.\n",
      "        \n",
      "        `hessians()` adds ops to the graph to output the Hessian matrix of `ys`\n",
      "        with respect to `xs`.  It returns a list of `Tensor` of length `len(xs)`\n",
      "        where each tensor is the Hessian of `sum(ys)`.\n",
      "        \n",
      "        The Hessian is a matrix of second-order partial derivatives of a scalar\n",
      "        tensor (see https://en.wikipedia.org/wiki/Hessian_matrix for more details).\n",
      "        \n",
      "        Args:\n",
      "          ys: A `Tensor` or list of tensors to be differentiated.\n",
      "          xs: A `Tensor` or list of tensors to be used for differentiation.\n",
      "          name: Optional name to use for grouping all the gradient ops together.\n",
      "            defaults to 'hessians'.\n",
      "          colocate_gradients_with_ops: See `gradients()` documentation for details.\n",
      "          gate_gradients: See `gradients()` documentation for details.\n",
      "          aggregation_method: See `gradients()` documentation for details.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Hessian matrices of `sum(ys)` for each `x` in `xs`.\n",
      "        \n",
      "        Raises:\n",
      "          LookupError: if one of the operations between `xs` and `ys` does not\n",
      "            have a registered gradient function.\n",
      "    \n",
      "    histogram_fixed_width(values, value_range, nbins=100, dtype=tf.int32, name=None)\n",
      "        Return histogram of values.\n",
      "        \n",
      "        Given the tensor `values`, this operation returns a rank 1 histogram counting\n",
      "        the number of entries in `values` that fell into every bin.  The bins are\n",
      "        equal width and determined by the arguments `value_range` and `nbins`.\n",
      "        \n",
      "        Args:\n",
      "          values:  Numeric `Tensor`.\n",
      "          value_range:  Shape [2] `Tensor` of same `dtype` as `values`.\n",
      "            values <= value_range[0] will be mapped to hist[0],\n",
      "            values >= value_range[1] will be mapped to hist[-1].\n",
      "          nbins:  Scalar `int32 Tensor`.  Number of histogram bins.\n",
      "          dtype:  dtype for returned histogram.\n",
      "          name:  A name for this operation (defaults to 'histogram_fixed_width').\n",
      "        \n",
      "        Returns:\n",
      "          A 1-D `Tensor` holding histogram of values.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If any unsupported dtype is provided.\n",
      "          tf.errors.InvalidArgumentError: If value_range does not\n",
      "              satisfy value_range[0] < value_range[1].\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)\n",
      "        ...\n",
      "        >>> nbins = 5\n",
      "        >>> value_range = [0.0, 5.0]\n",
      "        >>> new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\n",
      "        >>> hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)\n",
      "        >>> hist.numpy()\n",
      "        array([2, 1, 1, 0, 2], dtype=int32)\n",
      "    \n",
      "    histogram_fixed_width_bins(values, value_range, nbins=100, dtype=tf.int32, name=None)\n",
      "        Bins the given values for use in a histogram.\n",
      "        \n",
      "        Given the tensor `values`, this operation returns a rank 1 `Tensor`\n",
      "        representing the indices of a histogram into which each element\n",
      "        of `values` would be binned. The bins are equal width and\n",
      "        determined by the arguments `value_range` and `nbins`.\n",
      "        \n",
      "        Args:\n",
      "          values:  Numeric `Tensor`.\n",
      "          value_range:  Shape [2] `Tensor` of same `dtype` as `values`.\n",
      "            values <= value_range[0] will be mapped to hist[0],\n",
      "            values >= value_range[1] will be mapped to hist[-1].\n",
      "          nbins:  Scalar `int32 Tensor`.  Number of histogram bins.\n",
      "          dtype:  dtype for returned histogram.\n",
      "          name:  A name for this operation (defaults to 'histogram_fixed_width').\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` holding the indices of the binned values whose shape matches\n",
      "          `values`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If any unsupported dtype is provided.\n",
      "          tf.errors.InvalidArgumentError: If value_range does not\n",
      "              satisfy value_range[0] < value_range[1].\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)\n",
      "        ...\n",
      "        >>> nbins = 5\n",
      "        >>> value_range = [0.0, 5.0]\n",
      "        >>> new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\n",
      "        >>> indices = tf.histogram_fixed_width_bins(new_values, value_range, nbins=5)\n",
      "        >>> indices.numpy()\n",
      "        array([0, 0, 1, 2, 4, 4], dtype=int32)\n",
      "    \n",
      "    identity(input, name=None)\n",
      "        Return a Tensor with the same shape and contents as input.\n",
      "        \n",
      "        The return value is not the same Tensor as the original, but contains the same\n",
      "        values.  This operation is fast when used on the same device.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> a = tf.constant([0.78])\n",
      "        >>> a_identity = tf.identity(a)\n",
      "        >>> a.numpy()\n",
      "        array([0.78], dtype=float32)\n",
      "        >>> a_identity.numpy()\n",
      "        array([0.78], dtype=float32)\n",
      "        \n",
      "        Calling `tf.identity` on a variable will make a Tensor that represents the\n",
      "        value of that variable at the time it is called. This is equivalent to calling\n",
      "        `<variable>.read_value()`.\n",
      "        \n",
      "        >>> a = tf.Variable(5)\n",
      "        >>> a_identity = tf.identity(a)\n",
      "        >>> a.assign_add(1)\n",
      "        <tf.Variable ... shape=() dtype=int32, numpy=6>\n",
      "        >>> a.numpy()\n",
      "        6\n",
      "        >>> a_identity.numpy()\n",
      "        5\n",
      "        \n",
      "        This function can also be used to explicitly transfer tensors between devices.\n",
      "        For example, to transfer a tensor in GPU memory back to host memory, one can\n",
      "        use:\n",
      "        \n",
      "        >>> with tf.device(\"/gpu:0\"):\n",
      "        ...   x_on_gpu = tf.constant(1)\n",
      "        >>> with tf.device(\"/cpu:0\"):\n",
      "        ...   x_on_cpu = tf.identity(x_on_gpu)\n",
      "        >>> x_on_cpu.device\n",
      "        '/job:localhost/replica:0/task:0/device:CPU:0'\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`, a `Variable`, a `CompositeTensor` or anything that can be\n",
      "          converted to a tensor using `tf.convert_to_tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or CompositeTensor. Has the same type and contents as `input`.\n",
      "    \n",
      "    identity_n(input, name=None)\n",
      "        Returns a list of tensors with the same shapes and contents as the input\n",
      "        \n",
      "        tensors.\n",
      "        \n",
      "        This op can be used to override the gradient for complicated functions. For\n",
      "        example, suppose y = f(x) and we wish to apply a custom function g for backprop\n",
      "        such that dx = g(dy). In Python,\n",
      "        \n",
      "        ```python\n",
      "        with tf.get_default_graph().gradient_override_map(\n",
      "            {'IdentityN': 'OverrideGradientWithG'}):\n",
      "          y, _ = identity_n([f(x), x])\n",
      "        \n",
      "        @tf.RegisterGradient('OverrideGradientWithG')\n",
      "        def ApplyG(op, dy, _):\n",
      "          return [None, g(dy)]  # Do not backprop to f(x).\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A list of `Tensor` objects.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` objects. Has the same type as `input`.\n",
      "    \n",
      "    ifft(input: Annotated[Any, ~TV_IFFT_Tcomplex], name=None) -> Annotated[Any, ~TV_IFFT_Tcomplex]\n",
      "        Inverse fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 1-dimensional discrete Fourier transform over the\n",
      "        inner-most dimension of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    ifft2d(input: Annotated[Any, ~TV_IFFT2D_Tcomplex], name=None) -> Annotated[Any, ~TV_IFFT2D_Tcomplex]\n",
      "        Inverse 2D fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 2-dimensional discrete Fourier transform over the\n",
      "        inner-most 2 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    ifft3d(input: Annotated[Any, ~TV_IFFT3D_Tcomplex], name=None) -> Annotated[Any, ~TV_IFFT3D_Tcomplex]\n",
      "        Inverse 3D fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 3-dimensional discrete Fourier transform over the\n",
      "        inner-most 3 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    ifftnd(input: Annotated[Any, ~TV_IFFTND_Tcomplex], fft_length: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], axes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], name=None) -> Annotated[Any, ~TV_IFFTND_Tcomplex]\n",
      "        ND inverse fast Fourier transform.\n",
      "        \n",
      "        Computes the n-dimensional inverse discrete Fourier transform over designated\n",
      "        dimensions of `input`. The designated dimensions of `input` are assumed to be\n",
      "        the result of `IFFTND`.\n",
      "        \n",
      "        If fft_length[i]<shape(input)[i], the input is cropped. If\n",
      "        fft_length[i]>shape(input)[i], the input is padded with zeros. If fft_length\n",
      "        is not given, the default shape(input) is used.\n",
      "        \n",
      "        Axes mean the dimensions to perform the transform on. Default is to perform on\n",
      "        all axes.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          fft_length: A `Tensor` of type `int32`.\n",
      "            An int32 tensor. The FFT length for each dimension.\n",
      "          axes: A `Tensor` of type `int32`.\n",
      "            An int32 tensor with a same shape as fft_length. Axes to perform the transform.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    igamma(a: typing.Annotated[_any, ~TV_Igamma_T], x: typing.Annotated[_any, ~TV_Igamma_T], name=None) -> typing.Annotated[_any, ~TV_Igamma_T]\n",
      "        Compute the lower regularized incomplete Gamma function `P(a, x)`.\n",
      "        \n",
      "        The lower regularized incomplete Gamma function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \\\\(gamma(a, x) = \\\\int_{0}^{x} t^{a-1} exp(-t) dt\\\\)\n",
      "        \n",
      "        is the lower incomplete Gamma function.\n",
      "        \n",
      "        Note, above `Q(a, x)` (`Igammac`) is the upper regularized complete\n",
      "        Gamma function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    igammac(a: typing.Annotated[_any, ~TV_Igammac_T], x: typing.Annotated[_any, ~TV_Igammac_T], name=None) -> typing.Annotated[_any, ~TV_Igammac_T]\n",
      "        Compute the upper regularized incomplete Gamma function `Q(a, x)`.\n",
      "        \n",
      "        The upper regularized incomplete Gamma function is defined as:\n",
      "        \n",
      "        \\\\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \\\\(Gamma(a, x) = \\int_{x}^{\\infty} t^{a-1} exp(-t) dt\\\\)\n",
      "        \n",
      "        is the upper incomplete Gamma function.\n",
      "        \n",
      "        Note, above `P(a, x)` (`Igamma`) is the lower regularized complete\n",
      "        Gamma function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    imag(input, name=None)\n",
      "        Returns the imaginary part of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the imaginary part of each element in `input` considered as a complex\n",
      "        number. If `input` is real, a tensor of all zeros is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n",
      "        tf.math.imag(x)  # [4.75, 5.75]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float`, `double`,\n",
      "            `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None, producer_op_list=None)\n",
      "        Imports the graph from `graph_def` into the current default `Graph`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(op_dict)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please file an issue at https://github.com/tensorflow/tensorflow/issues if you depend on this feature.\n",
      "        \n",
      "        This function provides a way to import a serialized TensorFlow\n",
      "        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      "        protocol buffer, and extract individual objects in the `GraphDef` as\n",
      "        `tf.Tensor` and `tf.Operation` objects. Once extracted,\n",
      "        these objects are placed into the current default `Graph`. See\n",
      "        `tf.Graph.as_graph_def` for a way to create a `GraphDef`\n",
      "        proto.\n",
      "        \n",
      "        Args:\n",
      "          graph_def: A `GraphDef` proto containing operations to be imported into\n",
      "            the default graph.\n",
      "          input_map: A dictionary mapping input names (as strings) in `graph_def`\n",
      "            to `Tensor` objects. The values of the named input tensors in the\n",
      "            imported graph will be re-mapped to the respective `Tensor` values.\n",
      "          return_elements: A list of strings containing operation names in\n",
      "            `graph_def` that will be returned as `Operation` objects; and/or\n",
      "            tensor names in `graph_def` that will be returned as `Tensor` objects.\n",
      "          name: (Optional.) A prefix that will be prepended to the names in\n",
      "            `graph_def`. Note that this does not apply to imported function names.\n",
      "            Defaults to `\"import\"`.\n",
      "          op_dict: (Optional.) Deprecated, do not use.\n",
      "          producer_op_list: (Optional.) An `OpList` proto with the (possibly stripped)\n",
      "            list of `OpDef`s used by the producer of the graph. If provided,\n",
      "            unrecognized attrs for ops in `graph_def` that have their default value\n",
      "            according to `producer_op_list` will be removed. This will allow some more\n",
      "            `GraphDef`s produced by later binaries to be accepted by earlier binaries.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Operation` and/or `Tensor` objects from the imported graph,\n",
      "          corresponding to the names in `return_elements`,\n",
      "          and None if `returns_elements` is None.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `graph_def` is not a `GraphDef` proto,\n",
      "            `input_map` is not a dictionary mapping strings to `Tensor` objects,\n",
      "            or `return_elements` is not a list of strings.\n",
      "          ValueError: If `input_map`, or `return_elements` contains names that\n",
      "            do not appear in `graph_def`, or `graph_def` is not well-formed (e.g.\n",
      "            it refers to an unknown tensor).\n",
      "    \n",
      "    init_scope() -> collections.abc.Iterator[None]\n",
      "        A context manager that lifts ops out of control-flow scopes and function-building graphs.\n",
      "        \n",
      "        There is often a need to lift variable initialization ops out of control-flow\n",
      "        scopes, function-building graphs, and gradient tapes. Entering an\n",
      "        `init_scope` is a mechanism for satisfying these desiderata. In particular,\n",
      "        entering an `init_scope` has three effects:\n",
      "        \n",
      "          (1) All control dependencies are cleared the moment the scope is entered;\n",
      "              this is equivalent to entering the context manager returned from\n",
      "              `control_dependencies(None)`, which has the side-effect of exiting\n",
      "              control-flow scopes like `tf.cond` and `tf.while_loop`.\n",
      "        \n",
      "          (2) All operations that are created while the scope is active are lifted\n",
      "              into the lowest context on the `context_stack` that is not building a\n",
      "              graph function. Here, a context is defined as either a graph or an eager\n",
      "              context. Every context switch, i.e., every installation of a graph as\n",
      "              the default graph and every switch into eager mode, is logged in a\n",
      "              thread-local stack called `context_switches`; the log entry for a\n",
      "              context switch is popped from the stack when the context is exited.\n",
      "              Entering an `init_scope` is equivalent to crawling up\n",
      "              `context_switches`, finding the first context that is not building a\n",
      "              graph function, and entering it. A caveat is that if graph mode is\n",
      "              enabled but the default graph stack is empty, then entering an\n",
      "              `init_scope` will simply install a fresh graph as the default one.\n",
      "        \n",
      "          (3) The gradient tape is paused while the scope is active.\n",
      "        \n",
      "        When eager execution is enabled, code inside an init_scope block runs with\n",
      "        eager execution enabled even when tracing a `tf.function`. For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        @tf.function\n",
      "        def func():\n",
      "          # A function constructs TensorFlow graphs,\n",
      "          # it does not execute eagerly.\n",
      "          assert not tf.executing_eagerly()\n",
      "          with tf.init_scope():\n",
      "            # Initialization runs with eager execution enabled\n",
      "            assert tf.executing_eagerly()\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if graph state is incompatible with this initialization.\n",
      "    \n",
      "    initialize_all_tables(name='init_all_tables')\n",
      "        Returns an Op that initializes all tables of the default graph. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.tables_initializer` instead.\n",
      "        \n",
      "        Args:\n",
      "          name: Optional name for the initialization op.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all tables.  Note that if there are\n",
      "          not tables the returned Op is a NoOp.\n",
      "    \n",
      "    initialize_all_variables()\n",
      "        See `tf.compat.v1.global_variables_initializer`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.global_variables_initializer` instead.\n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    initialize_local_variables()\n",
      "        See `tf.compat.v1.local_variables_initializer`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.local_variables_initializer` instead.\n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    initialize_variables(var_list, name='init')\n",
      "        See `tf.compat.v1.variables_initializer`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.variables_initializer` instead.\n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    invert_permutation(x: Annotated[Any, ~TV_InvertPermutation_T], name=None) -> Annotated[Any, ~TV_InvertPermutation_T]\n",
      "        Computes the inverse permutation of a tensor.\n",
      "        \n",
      "        This operation computes the inverse of an index permutation. It takes a 1-D\n",
      "        integer tensor `x`, which represents the indices of a zero-based array, and\n",
      "        swaps each value with its index position. In other words, for an output tensor\n",
      "        `y` and an input tensor `x`, this operation computes the following:\n",
      "        \n",
      "        `y[x[i]] = i for i in [0, 1, ..., len(x) - 1]`\n",
      "        \n",
      "        The values must include 0. There can be no duplicate values or negative values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor `x` is [3, 4, 0, 2, 1]\n",
      "        invert_permutation(x) ==> [2, 4, 3, 0, 1]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    irfftnd(input: Annotated[Any, ~TV_IRFFTND_Tcomplex], fft_length: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], axes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], Treal: ~TV_IRFFTND_Treal = tf.float32, name=None) -> Annotated[Any, ~TV_IRFFTND_Treal]\n",
      "        ND inverse real fast Fourier transform.\n",
      "        \n",
      "        Computes the n-dimensional inverse real discrete Fourier transform over\n",
      "        designated dimensions of `input`. The designated dimensions of `input` are\n",
      "        assumed to be the result of `IRFFTND`. The inner-most dimension contains the\n",
      "        `fft_length / 2 + 1` unique components of the DFT of a real-valued signal. \n",
      "        \n",
      "        If fft_length[i]<shape(input)[i], the input is cropped. If\n",
      "        fft_length[i]>shape(input)[i], the input is padded with zeros. If fft_length\n",
      "        is not given, the default shape(input) is used.\n",
      "        \n",
      "        Axes mean the dimensions to perform the transform on. Default is to perform on\n",
      "        all axes.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          fft_length: A `Tensor` of type `int32`.\n",
      "            An int32 tensor. The FFT length for each dimension.\n",
      "          axes: A `Tensor` of type `int32`.\n",
      "            An int32 tensor with a same shape as fft_length. Axes to perform the transform.\n",
      "          Treal: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `Treal`.\n",
      "    \n",
      "    is_finite(x: typing.Annotated[_any, ~TV_IsFinite_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns which elements of x are finite.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isfinite\n",
      "        @end_compatibility\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5.0, 4.8, 6.8, np.inf, np.nan])\n",
      "        tf.math.is_finite(x) ==> [True, True, True, False, False]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_inf(x: typing.Annotated[_any, ~TV_IsInf_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns which elements of x are Inf.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isinf\n",
      "        @end_compatibility\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5.0, np.inf, 6.8, np.inf])\n",
      "        tf.math.is_inf(x) ==> [False, True, False, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_nan(x: typing.Annotated[_any, ~TV_IsNan_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns which elements of x are NaN.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isnan\n",
      "        @end_compatibility\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5.0, np.nan, 6.8, np.nan, np.inf])\n",
      "        tf.math.is_nan(x) ==> [False, True, False, True, False]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_non_decreasing(x, name=None)\n",
      "        Returns `True` if `x` is non-decreasing.\n",
      "        \n",
      "        Elements of `x` are compared in row-major order.  The tensor `[x[0],...]`\n",
      "        is non-decreasing if for every adjacent pair we have `x[i] <= x[i+1]`.\n",
      "        If `x` has less than two elements, it is trivially non-decreasing.\n",
      "        \n",
      "        See also:  `is_strictly_increasing`\n",
      "        \n",
      "        >>> x1 = tf.constant([1.0, 1.0, 3.0])\n",
      "        >>> tf.math.is_non_decreasing(x1)\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "        >>> x2 = tf.constant([3.0, 1.0, 2.0])\n",
      "        >>> tf.math.is_non_decreasing(x2)\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "        \n",
      "        Args:\n",
      "          x: Numeric `Tensor`.\n",
      "          name: A name for this operation (optional).  Defaults to \"is_non_decreasing\"\n",
      "        \n",
      "        Returns:\n",
      "          Boolean `Tensor`, equal to `True` iff `x` is non-decreasing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `x` is not a numeric tensor.\n",
      "    \n",
      "    is_numeric_tensor(tensor)\n",
      "        Returns `True` if the elements of `tensor` are numbers.\n",
      "        \n",
      "        Specifically, returns `True` if the dtype of `tensor` is one of the following:\n",
      "        \n",
      "        * `tf.float16`\n",
      "        * `tf.float32`\n",
      "        * `tf.float64`\n",
      "        * `tf.int8`\n",
      "        * `tf.int16`\n",
      "        * `tf.int32`\n",
      "        * `tf.int64`\n",
      "        * `tf.uint8`\n",
      "        * `tf.uint16`\n",
      "        * `tf.uint32`\n",
      "        * `tf.uint64`\n",
      "        * `tf.qint8`\n",
      "        * `tf.qint16`\n",
      "        * `tf.qint32`\n",
      "        * `tf.quint8`\n",
      "        * `tf.quint16`\n",
      "        * `tf.complex64`\n",
      "        * `tf.complex128`\n",
      "        * `tf.bfloat16`\n",
      "        \n",
      "        Returns `False` if `tensor` is of a non-numeric type or if `tensor` is not\n",
      "        a `tf.Tensor` object.\n",
      "    \n",
      "    is_strictly_increasing(x, name=None)\n",
      "        Returns `True` if `x` is strictly increasing.\n",
      "        \n",
      "        Elements of `x` are compared in row-major order.  The tensor `[x[0],...]`\n",
      "        is strictly increasing if for every adjacent pair we have `x[i] < x[i+1]`.\n",
      "        If `x` has less than two elements, it is trivially strictly increasing.\n",
      "        \n",
      "        See also:  `is_non_decreasing`\n",
      "        \n",
      "        >>> x1 = tf.constant([1.0, 2.0, 3.0])\n",
      "        >>> tf.math.is_strictly_increasing(x1)\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "        >>> x2 = tf.constant([3.0, 1.0, 2.0])\n",
      "        >>> tf.math.is_strictly_increasing(x2)\n",
      "        <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "        \n",
      "        Args:\n",
      "          x: Numeric `Tensor`.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"is_strictly_increasing\"\n",
      "        \n",
      "        Returns:\n",
      "          Boolean `Tensor`, equal to `True` iff `x` is strictly increasing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `x` is not a numeric tensor.\n",
      "    \n",
      "    is_symbolic_tensor(tensor) -> bool\n",
      "        Test if `tensor` is a symbolic Tensor.\n",
      "        \n",
      "        Args:\n",
      "          tensor: a tensor-like object\n",
      "        \n",
      "        Returns:\n",
      "          True if `tensor` is a symbolic tensor (not an eager tensor).\n",
      "    \n",
      "    is_tensor = is_tf_type(x)\n",
      "        Checks whether `x` is a TF-native type that can be passed to many TF ops.\n",
      "        \n",
      "        Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\n",
      "        without any conversion (e.g., `tf.Tensor`, `tf.SparseTensor`, and\n",
      "        `tf.RaggedTensor`) from types that need to be converted into tensors before\n",
      "        they are ingested (e.g., numpy `ndarray` and Python scalars).\n",
      "        \n",
      "        For example, in the following code block:\n",
      "        \n",
      "        ```python\n",
      "        if not tf.is_tensor(t):\n",
      "          t = tf.convert_to_tensor(t)\n",
      "        return t.shape, t.dtype\n",
      "        ```\n",
      "        \n",
      "        we check to make sure that `t` is a tensor (and convert it if not) before\n",
      "        accessing its `shape` and `dtype`.  (But note that not all TensorFlow native\n",
      "        types have shapes or dtypes; `tf.data.Dataset` is an example of a TensorFlow\n",
      "        native type that has neither shape nor dtype.)\n",
      "        \n",
      "        Args:\n",
      "          x: A python object to check.\n",
      "        \n",
      "        Returns:\n",
      "          `True` if `x` is a TensorFlow-native type.\n",
      "    \n",
      "    is_variable_initialized(variable)\n",
      "        Tests if a variable has been initialized.\n",
      "        \n",
      "        Args:\n",
      "          variable: A `Variable`.\n",
      "        \n",
      "        Returns:\n",
      "          Returns a scalar boolean Tensor, `True` if the variable has been\n",
      "          initialized, `False` otherwise.\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    lbeta(x, name=None)\n",
      "        Computes \\\\(ln(|Beta(x)|)\\\\), reducing along the last dimension.\n",
      "        \n",
      "        Given one-dimensional $z = [z_1,...,z_K]$, we define\n",
      "        \n",
      "        $$Beta(z) = \\frac{\\prod_j \\Gamma(z_j)}{\\Gamma(\\sum_j z_j)},$$\n",
      "        \n",
      "        where $\\Gamma$ is the gamma function.\n",
      "        \n",
      "        And for $n + 1$ dimensional $x$ with shape $[N_1, ..., N_n, K]$, we define\n",
      "        \n",
      "        $$lbeta(x)[i_1, ..., i_n] = \\log{|Beta(x[i_1, ..., i_n, :])|}.$$\n",
      "        \n",
      "        In other words, the last dimension is treated as the $z$ vector.\n",
      "        \n",
      "        Note that if $z = [u, v]$, then\n",
      "        \n",
      "        $$Beta(z) = \\frac{\\Gamma(u)\\Gamma(v)}{\\Gamma(u + v)}\n",
      "          = \\int_0^1 t^{u-1} (1 - t)^{v-1} \\mathrm{d}t,$$\n",
      "        \n",
      "        which defines the traditional bivariate beta function.\n",
      "        \n",
      "        If the last dimension is empty, we follow the convention that the sum over\n",
      "        the empty set is zero, and the product is one.\n",
      "        \n",
      "        Args:\n",
      "          x: A rank `n + 1` `Tensor`, `n >= 0` with type `float`, or `double`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The logarithm of \\\\(|Beta(x)|\\\\) reducing along the last dimension.\n",
      "    \n",
      "    less(x: typing.Annotated[_any, ~TV_Less_T], y: typing.Annotated[_any, ~TV_Less_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of (x < y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5])\n",
      "        tf.math.less(x, y) ==> [False, True, False]\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5, 6, 7])\n",
      "        tf.math.less(x, y) ==> [False, True, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    less_equal(x: typing.Annotated[_any, ~TV_LessEqual_T], y: typing.Annotated[_any, ~TV_LessEqual_T], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of (x <= y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5])\n",
      "        tf.math.less_equal(x, y) ==> [True, True, False]\n",
      "        \n",
      "        x = tf.constant([5, 4, 6])\n",
      "        y = tf.constant([5, 6, 6])\n",
      "        tf.math.less_equal(x, y) ==> [True, True, True]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    lgamma(x: typing.Annotated[_any, ~TV_Lgamma_T], name=None) -> typing.Annotated[_any, ~TV_Lgamma_T]\n",
      "        Computes the log of the absolute value of `Gamma(x)` element-wise.\n",
      "        \n",
      "          For positive numbers, this function computes log((input - 1)!) for every element in the tensor.\n",
      "          `lgamma(5) = log((5-1)!) = log(4!) = log(24) = 3.1780539`\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0, 0.5, 1, 4.5, -4, -5.6])\n",
      "        tf.math.lgamma(x) ==> [inf, 0.5723649, 0., 2.4537368, inf, -4.6477685]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    lin_space = linspace_nd(start, stop, num, name=None, axis=0)\n",
      "        Generates evenly-spaced values in an interval along a given axis.\n",
      "        \n",
      "        A sequence of `num` evenly-spaced values are generated beginning at `start`\n",
      "        along a given `axis`.\n",
      "        If `num > 1`, the values in the sequence increase by\n",
      "        `(stop - start) / (num - 1)`, so that the last one is exactly `stop`.\n",
      "        If `num <= 0`, `ValueError` is raised.\n",
      "        \n",
      "        Matches\n",
      "        [np.linspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)'s\n",
      "        behaviour\n",
      "        except when `num == 0`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        tf.linspace(10.0, 12.0, 3, name=\"linspace\") => [ 10.0  11.0  12.0]\n",
      "        ```\n",
      "        \n",
      "        `Start` and `stop` can be tensors of arbitrary size:\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=0)\n",
      "        <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  5.  ],\n",
      "               [ 2.5 , 13.75],\n",
      "               [ 5.  , 22.5 ],\n",
      "               [ 7.5 , 31.25],\n",
      "               [10.  , 40.  ]], dtype=float32)>\n",
      "        \n",
      "        `Axis` is where the values will be generated (the dimension in the\n",
      "        returned tensor which corresponds to the axis will be equal to `num`)\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=-1)\n",
      "        <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  2.5 ,  5.  ,  7.5 , 10.  ],\n",
      "               [ 5.  , 13.75, 22.5 , 31.25, 40.  ]], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          start: A `Tensor`. Must be one of the following types: `bfloat16`,\n",
      "            `float32`, `float64`. N-D tensor. First entry in the range.\n",
      "          stop: A `Tensor`. Must have the same type and shape as `start`. N-D tensor.\n",
      "            Last entry in the range.\n",
      "          num: A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D\n",
      "            tensor. Number of values to generate.\n",
      "          name: A name for the operation (optional).\n",
      "          axis: Axis along which the operation is performed (used only when N-D\n",
      "            tensors are provided).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `start`.\n",
      "    \n",
      "    linspace = linspace_nd(start, stop, num, name=None, axis=0)\n",
      "        Generates evenly-spaced values in an interval along a given axis.\n",
      "        \n",
      "        A sequence of `num` evenly-spaced values are generated beginning at `start`\n",
      "        along a given `axis`.\n",
      "        If `num > 1`, the values in the sequence increase by\n",
      "        `(stop - start) / (num - 1)`, so that the last one is exactly `stop`.\n",
      "        If `num <= 0`, `ValueError` is raised.\n",
      "        \n",
      "        Matches\n",
      "        [np.linspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)'s\n",
      "        behaviour\n",
      "        except when `num == 0`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        tf.linspace(10.0, 12.0, 3, name=\"linspace\") => [ 10.0  11.0  12.0]\n",
      "        ```\n",
      "        \n",
      "        `Start` and `stop` can be tensors of arbitrary size:\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=0)\n",
      "        <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  5.  ],\n",
      "               [ 2.5 , 13.75],\n",
      "               [ 5.  , 22.5 ],\n",
      "               [ 7.5 , 31.25],\n",
      "               [10.  , 40.  ]], dtype=float32)>\n",
      "        \n",
      "        `Axis` is where the values will be generated (the dimension in the\n",
      "        returned tensor which corresponds to the axis will be equal to `num`)\n",
      "        \n",
      "        >>> tf.linspace([0., 5.], [10., 40.], 5, axis=-1)\n",
      "        <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "        array([[ 0.  ,  2.5 ,  5.  ,  7.5 , 10.  ],\n",
      "               [ 5.  , 13.75, 22.5 , 31.25, 40.  ]], dtype=float32)>\n",
      "        \n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          start: A `Tensor`. Must be one of the following types: `bfloat16`,\n",
      "            `float32`, `float64`. N-D tensor. First entry in the range.\n",
      "          stop: A `Tensor`. Must have the same type and shape as `start`. N-D tensor.\n",
      "            Last entry in the range.\n",
      "          num: A `Tensor`. Must be one of the following types: `int32`, `int64`. 0-D\n",
      "            tensor. Number of values to generate.\n",
      "          name: A name for the operation (optional).\n",
      "          axis: Axis along which the operation is performed (used only when N-D\n",
      "            tensors are provided).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `start`.\n",
      "    \n",
      "    load_file_system_library(library_filename)\n",
      "        Loads a TensorFlow plugin, containing file system implementation. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.load_library` instead.\n",
      "        \n",
      "        Pass `library_filename` to a platform-specific mechanism for dynamically\n",
      "        loading a library. The rules for determining the exact location of the\n",
      "        library are platform-specific and are not documented here.\n",
      "        \n",
      "        Args:\n",
      "          library_filename: Path to the plugin.\n",
      "            Relative or absolute filesystem path to a dynamic library file.\n",
      "        \n",
      "        Returns:\n",
      "          None.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: when unable to load the library.\n",
      "    \n",
      "    load_library(library_location)\n",
      "        Loads a TensorFlow plugin.\n",
      "        \n",
      "        \"library_location\" can be a path to a specific shared object, or a folder.\n",
      "        If it is a folder, all shared objects that are named \"libtfkernel*\" will be\n",
      "        loaded. When the library is loaded, kernels registered in the library via the\n",
      "        `REGISTER_*` macros are made available in the TensorFlow process.\n",
      "        \n",
      "        Args:\n",
      "          library_location: Path to the plugin or the folder of plugins.\n",
      "            Relative or absolute filesystem path to a dynamic library file or folder.\n",
      "        \n",
      "        Returns:\n",
      "          None\n",
      "        \n",
      "        Raises:\n",
      "          OSError: When the file to be loaded is not found.\n",
      "          RuntimeError: when unable to load the library.\n",
      "    \n",
      "    load_op_library(library_filename)\n",
      "        Loads a TensorFlow plugin, containing custom ops and kernels.\n",
      "        \n",
      "        Pass \"library_filename\" to a platform-specific mechanism for dynamically\n",
      "        loading a library. The rules for determining the exact location of the\n",
      "        library are platform-specific and are not documented here. When the\n",
      "        library is loaded, ops and kernels registered in the library via the\n",
      "        `REGISTER_*` macros are made available in the TensorFlow process. Note\n",
      "        that ops with the same name as an existing op are rejected and not\n",
      "        registered with the process.\n",
      "        \n",
      "        Args:\n",
      "          library_filename: Path to the plugin.\n",
      "            Relative or absolute filesystem path to a dynamic library file.\n",
      "        \n",
      "        Returns:\n",
      "          A python module containing the Python wrappers for Ops defined in\n",
      "          the plugin.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: when unable to load the library or get the python wrappers.\n",
      "    \n",
      "    local_variables(scope=None)\n",
      "        Returns local variables.\n",
      "        \n",
      "        Local variables - per process variables, usually not saved/restored to\n",
      "        checkpoint and used for temporary or intermediate values.\n",
      "        For example, they can be used as counters for metrics computation or\n",
      "        number of epochs this machine has read data.\n",
      "        The `tf.contrib.framework.local_variable()` function automatically adds the\n",
      "        new variable to `GraphKeys.LOCAL_VARIABLES`.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        An alternative to local variables are global variables. See\n",
      "        `tf.compat.v1.global_variables`\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of local `Variable` objects.\n",
      "    \n",
      "    local_variables_initializer()\n",
      "        Returns an Op that initializes all local variables.\n",
      "        \n",
      "        This is just a shortcut for `variables_initializer(local_variables())`\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        In TF2, variables are initialized immediately when they are created. There is\n",
      "        no longer a need to run variable initializers before using them.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all local variables in the graph.\n",
      "    \n",
      "    log(x: typing.Annotated[_any, ~TV_Log_T], name=None) -> typing.Annotated[_any, ~TV_Log_T]\n",
      "        Computes natural logarithm of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = \\log_e x\\\\).\n",
      "        \n",
      "        Example:\n",
      "        >>> x = tf.constant([0, 0.5, 1, 5])\n",
      "        >>> tf.math.log(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([      -inf, -0.6931472,  0.       ,  1.609438 ], dtype=float32)>\n",
      "        \n",
      "        See: https://en.wikipedia.org/wiki/Logarithm\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    log1p(x: typing.Annotated[_any, ~TV_Log1p_T], name=None) -> typing.Annotated[_any, ~TV_Log1p_T]\n",
      "        Computes natural logarithm of (1 + x) element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = \\log_e (1 + x)\\\\).\n",
      "        \n",
      "        Example:\n",
      "        >>> x = tf.constant([0, 0.5, 1, 5])\n",
      "        >>> tf.math.log1p(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.       , 0.4054651, 0.6931472, 1.7917595], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    log_sigmoid(x, name=None)\n",
      "        Computes log sigmoid of `x` element-wise.\n",
      "        \n",
      "        Specifically, `y = log(1 / (1 + exp(-x)))`.  For numerical stability,\n",
      "        we use `y = -tf.nn.softplus(-x)`.\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor with type `float32` or `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor with the same type as `x`.\n",
      "        \n",
      "        Usage Example:\n",
      "        \n",
      "        If a positive number is large, then its log_sigmoid will approach to 0 since\n",
      "        the formula will be `y = log( <large_num> / (1 + <large_num>) )` which\n",
      "        approximates to `log (1)` which is 0.\n",
      "        \n",
      "        >>> x = tf.constant([0.0, 1.0, 50.0, 100.0])\n",
      "        >>> tf.math.log_sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
      "        array([-6.9314718e-01, -3.1326169e-01, -1.9287499e-22, -0.0000000e+00],\n",
      "              dtype=float32)>\n",
      "        \n",
      "        If a negative number is large, its log_sigmoid will approach to the number\n",
      "        itself since the formula will be `y = log( 1 / (1 + <large_num>) )` which is\n",
      "        `log (1) - log ( (1 + <large_num>) )` which approximates to `- <large_num>`\n",
      "        that is the number itself.\n",
      "        \n",
      "        >>> x = tf.constant([-100.0, -50.0, -1.0, 0.0])\n",
      "        >>> tf.math.log_sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
      "        array([-100.       ,  -50.       ,   -1.3132616,   -0.6931472],\n",
      "              dtype=float32)>\n",
      "    \n",
      "    logical_and(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], y: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of x AND y element-wise.\n",
      "        \n",
      "        Logical AND function.\n",
      "        \n",
      "        Requires that `x` and `y` have the same shape or have\n",
      "        [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        shapes. For example, `x` and `y` can be:\n",
      "        \n",
      "          - Two single elements of type `bool`.\n",
      "          - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "            be calculated by applying logical AND with the single element to each\n",
      "            element in the larger Tensor.\n",
      "          - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "            the result will be the element-wise logical AND of the two input tensors.\n",
      "        \n",
      "        You can also use the `&` operator instead.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "          >>> a = tf.constant([True])\n",
      "          >>> b = tf.constant([False])\n",
      "          >>> tf.math.logical_and(a, b)\n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>\n",
      "          >>> a & b\n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>\n",
      "        \n",
      "          >>> c = tf.constant([True])\n",
      "          >>> x = tf.constant([False, True, True, False])\n",
      "          >>> tf.math.logical_and(c, x)\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "          >>> c & x\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "        \n",
      "          >>> y = tf.constant([False, False, True, True])\n",
      "          >>> z = tf.constant([False, True, False, True])\n",
      "          >>> tf.math.logical_and(y, z)\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])>\n",
      "          >>> y & z\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])>\n",
      "        \n",
      "          This op also supports broadcasting\n",
      "        \n",
      "          >>> tf.logical_and([[True, False]], [[True], [False]])\n",
      "          <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "            array([[ True, False],\n",
      "                   [False, False]])>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_all`.\n",
      "        \n",
      "        Args:\n",
      "            x: A `tf.Tensor` of type bool.\n",
      "            y: A `tf.Tensor` of type bool.\n",
      "            name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          y: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_not(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of `NOT x` element-wise.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> tf.math.logical_not(tf.constant([True, False]))\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`. A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_or(x: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], y: typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>], name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Bool'>]\n",
      "        Returns the truth value of x OR y element-wise.\n",
      "        \n",
      "        Logical OR function.\n",
      "        \n",
      "        Requires that `x` and `y` have the same shape or have\n",
      "        [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        shapes. For example, `x` and `y` can be:\n",
      "        \n",
      "        - Two single elements of type `bool`.\n",
      "        - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "          be calculated by applying logical OR with the single element to each\n",
      "          element in the larger Tensor.\n",
      "        - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "          the result will be the element-wise logical OR of the two input tensors.\n",
      "        \n",
      "        You can also use the `|` operator instead.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "          >>> a = tf.constant([True])\n",
      "          >>> b = tf.constant([False])\n",
      "          >>> tf.math.logical_or(a, b)\n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "          >>> a | b\n",
      "          <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "        \n",
      "          >>> c = tf.constant([False])\n",
      "          >>> x = tf.constant([False, True, True, False])\n",
      "          >>> tf.math.logical_or(c, x)\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "          >>> c | x\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>\n",
      "        \n",
      "          >>> y = tf.constant([False, False, True, True])\n",
      "          >>> z = tf.constant([False, True, False, True])\n",
      "          >>> tf.math.logical_or(y, z)\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "          >>> y | z\n",
      "          <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>\n",
      "        \n",
      "          This op also supports broadcasting\n",
      "        \n",
      "          >>> tf.logical_or([[True, False]], [[True], [False]])\n",
      "          <tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
      "          array([[ True,  True],\n",
      "               [ True, False]])>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_any`.\n",
      "        \n",
      "        Args:\n",
      "            x: A `tf.Tensor` of type bool.\n",
      "            y: A `tf.Tensor` of type bool.\n",
      "            name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          y: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_xor(x, y, name='LogicalXor')\n",
      "        Logical XOR function.\n",
      "        \n",
      "        x ^ y = (x | y) & ~(x & y)\n",
      "        \n",
      "        Requires that `x` and `y` have the same shape or have\n",
      "        [broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        shapes. For example, `x` and `y` can be:\n",
      "        \n",
      "        - Two single elements of type `bool`\n",
      "        - One `tf.Tensor` of type `bool` and one single `bool`, where the result will\n",
      "          be calculated by applying logical XOR with the single element to each\n",
      "          element in the larger Tensor.\n",
      "        - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,\n",
      "          the result will be the element-wise logical XOR of the two input tensors.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        >>> a = tf.constant([True])\n",
      "        >>> b = tf.constant([False])\n",
      "        >>> tf.math.logical_xor(a, b)\n",
      "        <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>\n",
      "        \n",
      "        >>> c = tf.constant([True])\n",
      "        >>> x = tf.constant([False, True, True, False])\n",
      "        >>> tf.math.logical_xor(c, x)\n",
      "        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>\n",
      "        \n",
      "        >>> y = tf.constant([False, False, True, True])\n",
      "        >>> z = tf.constant([False, True, False, True])\n",
      "        >>> tf.math.logical_xor(y, z)\n",
      "        <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>\n",
      "        \n",
      "        Args:\n",
      "            x: A `tf.Tensor` type bool.\n",
      "            y: A `tf.Tensor` of type bool.\n",
      "            name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "    \n",
      "    make_ndarray = MakeNdarray(tensor)\n",
      "        Create a numpy ndarray from a tensor.\n",
      "        \n",
      "        Create a numpy ndarray with the same shape and data as the tensor.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Tensor a has shape (2,3)\n",
      "        a = tf.constant([[1,2,3],[4,5,6]])\n",
      "        proto_tensor = tf.make_tensor_proto(a)  # convert `tensor a` to a proto tensor\n",
      "        tf.make_ndarray(proto_tensor) # output: array([[1, 2, 3],\n",
      "        #                                              [4, 5, 6]], dtype=int32)\n",
      "        # output has shape (2,3)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A TensorProto.\n",
      "        \n",
      "        Returns:\n",
      "          A numpy array with the tensor contents.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if tensor has unsupported type.\n",
      "    \n",
      "    make_template(name_, func_, create_scope_now_=False, unique_name_=None, custom_getter_=None, **kwargs)\n",
      "        Given an arbitrary function, wrap it so that it does variable sharing.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.make_template` is a legacy API that is only compatible\n",
      "        with eager execution enabled and `tf.function` if you combine it with\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables`. See the model mapping\n",
      "        migration guide section on `make_template` for more info:\n",
      "        \n",
      "        https://www.tensorflow.org/guide/migrate/model_mapping#using_tfcompatv1make_template_in_the_decorated_method\n",
      "        \n",
      "        Even if you use legacy apis for `variable_scope`-based variable reuse,\n",
      "        we recommend using\n",
      "        `tf.compat.v1.keras.utils.track_tf1_style_variables` directly and not using\n",
      "        `tf.compat.v1.make_template`, as it interoperates with eager execution in a\n",
      "        simpler and more predictable fashion than `make_template`.\n",
      "        \n",
      "        The TF2 API approach would be tracking your variables using\n",
      "        `tf.Module`s or Keras layers and models rather than relying on\n",
      "        `make_template`.\n",
      "        @end_compatibility\n",
      "        \n",
      "        This wraps `func_` in a Template and partially evaluates it. Templates are\n",
      "        functions that create variables the first time they are called and reuse them\n",
      "        thereafter. In order for `func_` to be compatible with a `Template` it must\n",
      "        have the following properties:\n",
      "        \n",
      "        * The function should create all trainable variables and any variables that\n",
      "           should be reused by calling `tf.compat.v1.get_variable`. If a trainable\n",
      "           variable is\n",
      "           created using `tf.Variable`, then a ValueError will be thrown. Variables\n",
      "           that are intended to be locals can be created by specifying\n",
      "           `tf.Variable(..., trainable=false)`.\n",
      "        * The function may use variable scopes and other templates internally to\n",
      "            create and reuse variables, but it shouldn't use\n",
      "            `tf.compat.v1.global_variables` to\n",
      "            capture variables that are defined outside of the scope of the function.\n",
      "        * Internal scopes and variable names should not depend on any arguments that\n",
      "            are not supplied to `make_template`. In general you will get a ValueError\n",
      "            telling you that you are trying to reuse a variable that doesn't exist\n",
      "            if you make a mistake.\n",
      "        \n",
      "        In the following example, both `z` and `w` will be scaled by the same `y`. It\n",
      "        is important to note that if we didn't assign `scalar_name` and used a\n",
      "        different name for z and w that a `ValueError` would be thrown because it\n",
      "        couldn't reuse the variable.\n",
      "        \n",
      "        ```python\n",
      "        def my_op(x, scalar_name):\n",
      "          var1 = tf.compat.v1.get_variable(scalar_name,\n",
      "                                 shape=[],\n",
      "                                 initializer=tf.compat.v1.constant_initializer(1))\n",
      "          return x * var1\n",
      "        \n",
      "        scale_by_y = tf.compat.v1.make_template('scale_by_y', my_op, scalar_name='y')\n",
      "        \n",
      "        z = scale_by_y(input1)\n",
      "        w = scale_by_y(input2)\n",
      "        ```\n",
      "        \n",
      "        As a safe-guard, the returned function will raise a `ValueError` after the\n",
      "        first call if trainable variables are created by calling `tf.Variable`.\n",
      "        \n",
      "        If all of these are true, then 2 properties are enforced by the template:\n",
      "        \n",
      "        1. Calling the same template multiple times will share all non-local\n",
      "            variables.\n",
      "        2. Two different templates are guaranteed to be unique, unless you reenter the\n",
      "            same variable scope as the initial definition of a template and redefine\n",
      "            it. An examples of this exception:\n",
      "        \n",
      "        ```python\n",
      "        def my_op(x, scalar_name):\n",
      "          var1 = tf.compat.v1.get_variable(scalar_name,\n",
      "                                 shape=[],\n",
      "                                 initializer=tf.compat.v1.constant_initializer(1))\n",
      "          return x * var1\n",
      "        \n",
      "        with tf.compat.v1.variable_scope('scope') as vs:\n",
      "          scale_by_y = tf.compat.v1.make_template('scale_by_y', my_op,\n",
      "          scalar_name='y')\n",
      "          z = scale_by_y(input1)\n",
      "          w = scale_by_y(input2)\n",
      "        \n",
      "        # Creates a template that reuses the variables above.\n",
      "        with tf.compat.v1.variable_scope(vs, reuse=True):\n",
      "          scale_by_y2 = tf.compat.v1.make_template('scale_by_y', my_op,\n",
      "          scalar_name='y')\n",
      "          z2 = scale_by_y2(input1)\n",
      "          w2 = scale_by_y2(input2)\n",
      "        ```\n",
      "        \n",
      "        Depending on the value of `create_scope_now_`, the full variable scope may be\n",
      "        captured either at the time of first call or at the time of construction. If\n",
      "        this option is set to True, then all Tensors created by repeated calls to the\n",
      "        template will have an extra trailing _N+1 to their name, as the first time the\n",
      "        scope is entered in the Template constructor no Tensors are created.\n",
      "        \n",
      "        Note: `name_`, `func_` and `create_scope_now_` have a trailing underscore to\n",
      "        reduce the likelihood of collisions with kwargs.\n",
      "        \n",
      "        Args:\n",
      "          name_: A name for the scope created by this template. If necessary, the name\n",
      "            will be made unique by appending `_N` to the name.\n",
      "          func_: The function to wrap.\n",
      "          create_scope_now_: Boolean controlling whether the scope should be created\n",
      "            when the template is constructed or when the template is called. Default\n",
      "            is False, meaning the scope is created when the template is called.\n",
      "          unique_name_: When used, it overrides name_ and is not made unique. If a\n",
      "            template of the same scope/unique_name already exists and reuse is false,\n",
      "            an error is raised. Defaults to None.\n",
      "          custom_getter_: Optional custom getter for variables used in `func_`. See\n",
      "            the `tf.compat.v1.get_variable` `custom_getter` documentation for more\n",
      "            information.\n",
      "          **kwargs: Keyword arguments to apply to `func_`.\n",
      "        \n",
      "        Returns:\n",
      "          A function to encapsulate a set of variables which should be created once\n",
      "          and reused. An enclosing scope will be created either when `make_template`\n",
      "          is called or when the result is called, depending on the value of\n",
      "          `create_scope_now_`. Regardless of the value, the first time the template\n",
      "          is called it will enter the scope with no reuse, and call `func_` to create\n",
      "          variables, which are guaranteed to be unique. All subsequent calls will\n",
      "          re-enter the scope and reuse those variables.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if `name_` is None.\n",
      "    \n",
      "    make_tensor_proto(values, dtype=None, shape=None, verify_shape=False, allow_broadcast=False)\n",
      "        Create a TensorProto.\n",
      "        \n",
      "        In TensorFlow 2.0, representing tensors as protos should no longer be a\n",
      "        common workflow. That said, this utility function is still useful for\n",
      "        generating TF Serving request protos:\n",
      "        \n",
      "        ```python\n",
      "          request = tensorflow_serving.apis.predict_pb2.PredictRequest()\n",
      "          request.model_spec.name = \"my_model\"\n",
      "          request.model_spec.signature_name = \"serving_default\"\n",
      "          request.inputs[\"images\"].CopyFrom(tf.make_tensor_proto(X_new))\n",
      "        ```\n",
      "        \n",
      "        `make_tensor_proto` accepts \"values\" of a python scalar, a python list, a\n",
      "        numpy ndarray, or a numpy scalar.\n",
      "        \n",
      "        If \"values\" is a python scalar or a python list, make_tensor_proto\n",
      "        first convert it to numpy ndarray. If dtype is None, the\n",
      "        conversion tries its best to infer the right numpy data\n",
      "        type. Otherwise, the resulting numpy array has a compatible data\n",
      "        type with the given dtype.\n",
      "        \n",
      "        In either case above, the numpy ndarray (either the caller provided\n",
      "        or the auto-converted) must have the compatible type with dtype.\n",
      "        \n",
      "        `make_tensor_proto` then converts the numpy array to a tensor proto.\n",
      "        \n",
      "        If \"shape\" is None, the resulting tensor proto represents the numpy\n",
      "        array precisely.\n",
      "        \n",
      "        Otherwise, \"shape\" specifies the tensor's shape and the numpy array\n",
      "        can not have more elements than what \"shape\" specifies.\n",
      "        \n",
      "        Args:\n",
      "          values:         Values to put in the TensorProto.\n",
      "          dtype:          Optional tensor_pb2 DataType value.\n",
      "          shape:          List of integers representing the dimensions of tensor.\n",
      "          verify_shape:   Boolean that enables verification of a shape of values.\n",
      "          allow_broadcast:  Boolean that enables allowing scalars and 1 length vector\n",
      "              broadcasting. Cannot be true when verify_shape is true.\n",
      "        \n",
      "        Returns:\n",
      "          A `TensorProto`. Depending on the type, it may contain data in the\n",
      "          \"tensor_content\" attribute, which is not directly useful to Python programs.\n",
      "          To access the values you should convert the proto back to a numpy ndarray\n",
      "          with `tf.make_ndarray(proto)`.\n",
      "        \n",
      "          If `values` is a `TensorProto`, it is immediately returned; `dtype` and\n",
      "          `shape` are ignored.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  if unsupported types are provided.\n",
      "          ValueError: if arguments have inappropriate values or if verify_shape is\n",
      "           True and shape of values is not equals to a shape from the argument.\n",
      "    \n",
      "    map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None, fn_output_signature=None)\n",
      "        Transforms `elems` by applying `fn` to each element unstacked on axis 0. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use fn_output_signature instead\n",
      "        \n",
      "        See also `tf.scan`.\n",
      "        \n",
      "        `map_fn` unstacks `elems` on axis 0 to obtain a sequence of elements;\n",
      "        calls `fn` to transform each element; and then stacks the transformed\n",
      "        values back together.\n",
      "        \n",
      "        #### Mapping functions with single-Tensor inputs and outputs\n",
      "        \n",
      "        If `elems` is a single tensor and `fn`'s signature is `tf.Tensor->tf.Tensor`,\n",
      "        then `map_fn(fn, elems)` is equivalent to\n",
      "        `tf.stack([fn(elem) for elem in tf.unstack(elems)])`.  E.g.:\n",
      "        \n",
      "        >>> tf.map_fn(fn=lambda t: tf.range(t, t + 3), elems=tf.constant([3, 5, 2]))\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        `map_fn(fn, elems).shape = [elems.shape[0]] + fn(elems[0]).shape`.\n",
      "        \n",
      "        #### Mapping functions with multi-arity inputs and outputs\n",
      "        \n",
      "        `map_fn` also supports functions with multi-arity inputs and outputs:\n",
      "        \n",
      "        * If `elems` is a tuple (or nested structure) of tensors, then those tensors\n",
      "          must all have the same outer-dimension size (`num_elems`); and `fn` is\n",
      "          used to transform each tuple (or structure) of corresponding slices from\n",
      "          `elems`.  E.g., if `elems` is a tuple `(t1, t2, t3)`, then `fn` is used to\n",
      "          transform each tuple of slices `(t1[i], t2[i], t3[i])`\n",
      "          (where `0 <= i < num_elems`).\n",
      "        \n",
      "        * If `fn` returns a tuple (or nested structure) of tensors, then the\n",
      "          result is formed by stacking corresponding elements from those structures.\n",
      "        \n",
      "        #### Specifying `fn`'s output signature\n",
      "        \n",
      "        If `fn`'s input and output signatures are different, then the output\n",
      "        signature must be specified using `fn_output_signature`.  (The input and\n",
      "        output signatures are differ if their structures, dtypes, or tensor types do\n",
      "        not match).  E.g.:\n",
      "        \n",
      "        >>> tf.map_fn(fn=tf.strings.length,  # input & output have different dtypes\n",
      "        ...           elems=tf.constant([\"hello\", \"moon\"]),\n",
      "        ...           fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 4], dtype=int32)>\n",
      "        >>> tf.map_fn(fn=tf.strings.join,  # input & output have different structures\n",
      "        ...           elems=[tf.constant(['The', 'A']), tf.constant(['Dog', 'Cat'])],\n",
      "        ...           fn_output_signature=tf.string)\n",
      "        <tf.Tensor: shape=(2,), dtype=string,\n",
      "         numpy=array([b'TheDog', b'ACat'], dtype=object)>\n",
      "        \n",
      "        `fn_output_signature` can be specified using any of the following:\n",
      "        \n",
      "        * A `tf.DType` or `tf.TensorSpec` (to describe a `tf.Tensor`)\n",
      "        * A `tf.RaggedTensorSpec` (to describe a `tf.RaggedTensor`)\n",
      "        * A `tf.SparseTensorSpec` (to describe a `tf.sparse.SparseTensor`)\n",
      "        * A (possibly nested) tuple, list, or dict containing the above types.\n",
      "        \n",
      "        #### RaggedTensors\n",
      "        \n",
      "        `map_fn` supports `tf.RaggedTensor` inputs and outputs.  In particular:\n",
      "        \n",
      "        * If `elems` is a `RaggedTensor`, then `fn` will be called with each\n",
      "          row of that ragged tensor.\n",
      "          * If `elems` has only one ragged dimension, then the values passed to\n",
      "            `fn` will be `tf.Tensor`s.\n",
      "          * If `elems` has multiple ragged dimensions, then the values passed to\n",
      "            `fn` will be `tf.RaggedTensor`s with one fewer ragged dimension.\n",
      "        \n",
      "        * If the result of `map_fn` should be a `RaggedTensor`, then use a\n",
      "          `tf.RaggedTensorSpec` to specify `fn_output_signature`.\n",
      "          * If `fn` returns `tf.Tensor`s with varying sizes, then use a\n",
      "            `tf.RaggedTensorSpec` with `ragged_rank=0` to combine them into a\n",
      "            single ragged tensor (which will have ragged_rank=1).\n",
      "          * If `fn` returns `tf.RaggedTensor`s, then use a `tf.RaggedTensorSpec`\n",
      "            with the same `ragged_rank`.\n",
      "        \n",
      "        >>> # Example: RaggedTensor input\n",
      "        >>> rt = tf.ragged.constant([[1, 2, 3], [], [4, 5], [6]])\n",
      "        >>> tf.map_fn(tf.reduce_sum, rt, fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([6, 0, 9, 6], dtype=int32)>\n",
      "        \n",
      "        >>> # Example: RaggedTensor output\n",
      "        >>> elems = tf.constant([3, 5, 0, 2])\n",
      "        >>> tf.map_fn(tf.range, elems,\n",
      "        ...           fn_output_signature=tf.RaggedTensorSpec(shape=[None],\n",
      "        ...                                                   dtype=tf.int32))\n",
      "        <tf.RaggedTensor [[0, 1, 2], [0, 1, 2, 3, 4], [], [0, 1]]>\n",
      "        \n",
      "        Note: `map_fn` should only be used if you need to map a function over the\n",
      "        *rows* of a `RaggedTensor`.  If you wish to map a function over the\n",
      "        individual values, then you should use:\n",
      "        \n",
      "        * `tf.ragged.map_flat_values(fn, rt)`\n",
      "          (if fn is expressible as TensorFlow ops)\n",
      "        * `rt.with_flat_values(map_fn(fn, rt.flat_values))`\n",
      "          (otherwise)\n",
      "        \n",
      "        E.g.:\n",
      "        \n",
      "        >>> rt = tf.ragged.constant([[1, 2, 3], [], [4, 5], [6]])\n",
      "        >>> tf.ragged.map_flat_values(lambda x: x + 2, rt)\n",
      "        <tf.RaggedTensor [[3, 4, 5], [], [6, 7], [8]]>\n",
      "        \n",
      "        #### SparseTensors\n",
      "        \n",
      "        `map_fn` supports `tf.sparse.SparseTensor` inputs and outputs.  In particular:\n",
      "        \n",
      "        * If `elems` is a `SparseTensor`, then `fn` will be called with each row\n",
      "          of that sparse tensor. In particular, the value passed to `fn` will be a\n",
      "          `tf.sparse.SparseTensor` with one fewer dimension than `elems`.\n",
      "        \n",
      "        * If the result of `map_fn` should be a `SparseTensor`, then use a\n",
      "          `tf.SparseTensorSpec` to specify `fn_output_signature`.  The individual\n",
      "          `SparseTensor`s returned by `fn` will be stacked into a single\n",
      "          `SparseTensor` with one more dimension.\n",
      "        \n",
      "        >>> # Example: SparseTensor input\n",
      "        >>> st = tf.sparse.SparseTensor([[0, 0], [2, 0], [2, 1]], [2, 3, 4], [4, 4])\n",
      "        >>> tf.map_fn(tf.sparse.reduce_sum, st, fn_output_signature=tf.int32)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([2, 0, 7, 0], dtype=int32)>\n",
      "        \n",
      "        >>> # Example: SparseTensor output\n",
      "        >>> tf.sparse.to_dense(\n",
      "        ...     tf.map_fn(tf.sparse.eye, tf.constant([2, 3]),\n",
      "        ...               fn_output_signature=tf.SparseTensorSpec(None, tf.float32)))\n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
      "          array([[[1., 0., 0.],\n",
      "                  [0., 1., 0.],\n",
      "                  [0., 0., 0.]],\n",
      "                 [[1., 0., 0.],\n",
      "                  [0., 1., 0.],\n",
      "                  [0., 0., 1.]]], dtype=float32)>\n",
      "        \n",
      "        Note: `map_fn` should only be used if you need to map a function over the\n",
      "        *rows* of a `SparseTensor`.  If you wish to map a function over the nonzero\n",
      "        values, then you should use:\n",
      "        \n",
      "        * If the function is expressible as TensorFlow ops, use:\n",
      "          ```python\n",
      "          tf.sparse.SparseTensor(st.indices, fn(st.values), st.dense_shape)\n",
      "          ```\n",
      "        * Otherwise, use:\n",
      "          ```python\n",
      "          tf.sparse.SparseTensor(st.indices, tf.map_fn(fn, st.values),\n",
      "                                 st.dense_shape)\n",
      "          ```\n",
      "        \n",
      "        #### `map_fn` vs. vectorized operations\n",
      "        \n",
      "        `map_fn` will apply the operations used by `fn` to each element of `elems`,\n",
      "        resulting in `O(elems.shape[0])` total operations.  This is somewhat\n",
      "        mitigated by the fact that `map_fn` can process elements in parallel.\n",
      "        However, a transform expressed using `map_fn` is still typically less\n",
      "        efficient than an equivalent transform expressed using vectorized operations.\n",
      "        \n",
      "        `map_fn` should typically only be used if one of the following is true:\n",
      "        \n",
      "        * It is difficult or expensive to express the desired transform with\n",
      "          vectorized operations.\n",
      "        * `fn` creates large intermediate values, so an equivalent vectorized\n",
      "          transform would take too much memory.\n",
      "        * Processing elements in parallel is more efficient than an equivalent\n",
      "          vectorized transform.\n",
      "        * Efficiency of the transform is not critical, and using `map_fn` is\n",
      "          more readable.\n",
      "        \n",
      "        E.g., the example given above that maps `fn=lambda t: tf.range(t, t + 3)`\n",
      "        across `elems` could be rewritten more efficiently using vectorized ops:\n",
      "        \n",
      "        >>> elems = tf.constant([3, 5, 2])\n",
      "        >>> tf.range(3) + tf.expand_dims(elems, 1)\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        In some cases, `tf.vectorized_map` can be used to automatically convert a\n",
      "        function to a vectorized equivalent.\n",
      "        \n",
      "        #### Eager execution\n",
      "        \n",
      "        When executing eagerly, `map_fn` does not execute in parallel even if\n",
      "        `parallel_iterations` is set to a value > 1. You can still get the\n",
      "        performance benefits of running a function in parallel by using the\n",
      "        `tf.function` decorator:\n",
      "        \n",
      "        >>> fn=lambda t: tf.range(t, t + 3)\n",
      "        >>> @tf.function\n",
      "        ... def func(elems):\n",
      "        ...   return tf.map_fn(fn, elems, parallel_iterations=3)\n",
      "        >>> func(tf.constant([3, 5, 2]))\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[3, 4, 5],\n",
      "                 [5, 6, 7],\n",
      "                 [2, 3, 4]], dtype=int32)>\n",
      "        \n",
      "        \n",
      "        Note: if you use the `tf.function` decorator, any non-TensorFlow Python\n",
      "        code that you may have written in your function won't get executed. See\n",
      "        `tf.function` for more  details. The recommendation would be to debug without\n",
      "        `tf.function` but switch to it to get performance benefits of running `map_fn`\n",
      "        in parallel.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.  It accepts one argument, which will have\n",
      "            the same (possibly nested) structure as `elems`.  Its output must have the\n",
      "            same structure as `fn_output_signature` if one is provided; otherwise it\n",
      "            must have the same structure as `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unstacked along their first dimension.  `fn` will be applied to the\n",
      "            nested sequence of the resulting slices.  `elems` may include ragged and\n",
      "            sparse tensors. `elems` must consist of at least one tensor.\n",
      "          dtype: Deprecated: Equivalent to `fn_output_signature`.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel. When graph building, the default value is 10. While executing\n",
      "            eagerly, the default value is set to 1.\n",
      "          back_prop: (optional) False disables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "          fn_output_signature: The output signature of `fn`. Must be specified if\n",
      "            `fn`'s input and output signatures are different (i.e., if their\n",
      "            structures, dtypes, or tensor types do not match).\n",
      "            `fn_output_signature` can be specified using any of the following:\n",
      "        \n",
      "            * A `tf.DType` or `tf.TensorSpec` (to describe a `tf.Tensor`)\n",
      "            * A `tf.RaggedTensorSpec` (to describe a `tf.RaggedTensor`)\n",
      "            * A `tf.SparseTensorSpec` (to describe a `tf.sparse.SparseTensor`)\n",
      "            * A (possibly nested) tuple, list, or dict containing the above types.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors.  Each tensor stacks the\n",
      "          results of applying `fn` to tensors unstacked from `elems` along the first\n",
      "          dimension, from first to last.  The result may include ragged and sparse\n",
      "          tensors.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable or the structure of the output of\n",
      "            `fn` and `fn_output_signature` do not match.\n",
      "          ValueError: if the lengths of the output of `fn` and `fn_output_signature`\n",
      "            do not match, or if the `elems` does not contain any tensor.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          >>> tf.map_fn(lambda x: x * x, elems)\n",
      "          <tf.Tensor: shape=(6,), dtype=int64, numpy=array([ 1,  4,  9, 16, 25, 36])>\n",
      "        \n",
      "          >>> elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\n",
      "          >>> tf.map_fn(lambda x: x[0] * x[1], elems, fn_output_signature=tf.int64)\n",
      "          <tf.Tensor: shape=(3,), dtype=int64, numpy=array([-1,  2, -3])>\n",
      "        \n",
      "          >>> elems = np.array([1, 2, 3])\n",
      "          >>> tf.map_fn(lambda x: (x, -x), elems,\n",
      "          ...          fn_output_signature=(tf.int64, tf.int64))\n",
      "          (<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])>,\n",
      "           <tf.Tensor: shape=(3,), dtype=int64, numpy=array([-1, -2, -3])>)\n",
      "    \n",
      "    matching_files(pattern: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Returns the set of files matching one or more glob patterns.\n",
      "        \n",
      "        Note that this routine only supports wildcard characters in the\n",
      "        basename portion of the pattern, not in the directory portion.\n",
      "        Note also that the order of filenames returned is deterministic.\n",
      "        \n",
      "        Args:\n",
      "          pattern: A `Tensor` of type `string`.\n",
      "            Shell wildcard pattern(s). Scalar or vector of type string.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    matmul(a, b, transpose_a=False, transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False, output_type=None, grad_a=False, grad_b=False, name=None)\n",
      "        Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "        \n",
      "        The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "        where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
      "        and any further outer dimensions specify matching batch size.\n",
      "        \n",
      "        Both matrices must be of the same type. The supported types are:\n",
      "        `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "        `complex64`, `complex128`.\n",
      "        \n",
      "        Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "        the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "        by default.\n",
      "        \n",
      "        If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "        multiplication algorithm can be used by setting the corresponding\n",
      "        `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "        This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "        datatypes `bfloat16` or `float32`.\n",
      "        \n",
      "        A simple 2-D tensor matrix multiplication:\n",
      "        \n",
      "        >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "        >>> a  # 2-D tensor\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[1, 2, 3],\n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "        >>> b  # 2-D tensor\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "        array([[ 7,  8],\n",
      "               [ 9, 10],\n",
      "               [11, 12]], dtype=int32)>\n",
      "        >>> c = tf.matmul(a, b)\n",
      "        >>> c  # `a` * `b`\n",
      "        <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "        array([[ 58,  64],\n",
      "               [139, 154]], dtype=int32)>\n",
      "        \n",
      "        A batch matrix multiplication with batch shape [2]:\n",
      "        \n",
      "        >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
      "        >>> a  # 3-D tensor\n",
      "        <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
      "        array([[[ 1,  2,  3],\n",
      "                [ 4,  5,  6]],\n",
      "               [[ 7,  8,  9],\n",
      "                [10, 11, 12]]], dtype=int32)>\n",
      "        >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
      "        >>> b  # 3-D tensor\n",
      "        <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "        array([[[13, 14],\n",
      "                [15, 16],\n",
      "                [17, 18]],\n",
      "               [[19, 20],\n",
      "                [21, 22],\n",
      "                [23, 24]]], dtype=int32)>\n",
      "        >>> c = tf.matmul(a, b)\n",
      "        >>> c  # `a` * `b`\n",
      "        <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "        array([[[ 94, 100],\n",
      "                [229, 244]],\n",
      "               [[508, 532],\n",
      "                [697, 730]]], dtype=int32)>\n",
      "        \n",
      "        Since python >= 3.5 the @ operator is supported\n",
      "        (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
      "        it simply calls the `tf.matmul()` function, so the following lines are\n",
      "        equivalent:\n",
      "        \n",
      "        >>> d = a @ b @ [[10], [11]]\n",
      "        >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
      "        \n",
      "        Args:\n",
      "          a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
      "            `complex64`, `complex128` and rank > 1.\n",
      "          b: `tf.Tensor` with same type and rank as `a`.\n",
      "          transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "          transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "          adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "            multiplication.\n",
      "          adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "            multiplication.\n",
      "          a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
      "            **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "            that assume most values in `a` are zero. See\n",
      "            `tf.sparse.sparse_dense_matmul` for some support for\n",
      "            `tf.sparse.SparseTensor` multiplication.\n",
      "          b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
      "            **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "            that assume most values in `b` are zero. See\n",
      "            `tf.sparse.sparse_dense_matmul` for some support for\n",
      "            `tf.sparse.SparseTensor` multiplication.\n",
      "          output_type: The output datatype if needed. Defaults to None in which case\n",
      "            the output_type is the same as input type. Currently only works when input\n",
      "            tensors are type (u)int8 and output_type can be int32.\n",
      "          grad_a: Set it to `True` to hint that Tensor `a` is for the backward pass.\n",
      "          grad_b: Set it to `True` to hint that Tensor `b` is for the backward pass.\n",
      "          name: Name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
      "          is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "          transpose or adjoint attributes are `False`:\n",
      "        \n",
      "          `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
      "          for all indices `i`, `j`.\n",
      "        \n",
      "          Note: This is matrix product, not element-wise product.\n",
      "        \n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
      "            `adjoint_b` are both set to `True`.\n",
      "          TypeError: If output_type is specified but the types of `a`, `b` and\n",
      "            `output_type` is not (u)int8, (u)int8 and int32.\n",
      "    \n",
      "    matrix_band_part(input: Annotated[Any, ~TV_MatrixBandPart_T], num_lower: Annotated[Any, ~TV_MatrixBandPart_Tindex], num_upper: Annotated[Any, ~TV_MatrixBandPart_Tindex], name=None) -> Annotated[Any, ~TV_MatrixBandPart_T]\n",
      "        Copy a tensor setting everything outside a central band in each innermost matrix to zero.\n",
      "        \n",
      "        The `band` part is computed as follows:\n",
      "        Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a\n",
      "        tensor with the same shape where\n",
      "        \n",
      "        `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.\n",
      "        \n",
      "        The indicator function\n",
      "        \n",
      "        `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)) &&\n",
      "                         (num_upper < 0 || (n-m) <= num_upper)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # if 'input' is [[ 0,  1,  2, 3]\n",
      "        #                [-1,  0,  1, 2]\n",
      "        #                [-2, -1,  0, 1]\n",
      "        #                [-3, -2, -1, 0]],\n",
      "        \n",
      "        tf.linalg.band_part(input, 1, -1) ==> [[ 0,  1,  2, 3]\n",
      "                                               [-1,  0,  1, 2]\n",
      "                                               [ 0, -1,  0, 1]\n",
      "                                               [ 0,  0, -1, 0]],\n",
      "        \n",
      "        tf.linalg.band_part(input, 2, 1) ==> [[ 0,  1,  0, 0]\n",
      "                                              [-1,  0,  1, 0]\n",
      "                                              [-2, -1,  0, 1]\n",
      "                                              [ 0, -2, -1, 0]]\n",
      "        ```\n",
      "        \n",
      "        Useful special cases:\n",
      "        \n",
      "        ```\n",
      "         tf.linalg.band_part(input, 0, -1) ==> Upper triangular part.\n",
      "         tf.linalg.band_part(input, -1, 0) ==> Lower triangular part.\n",
      "         tf.linalg.band_part(input, 0, 0) ==> Diagonal.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Rank `k` tensor.\n",
      "          num_lower: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            0-D tensor. Number of subdiagonals to keep. If negative, keep entire\n",
      "            lower triangle.\n",
      "          num_upper: A `Tensor`. Must have the same type as `num_lower`.\n",
      "            0-D tensor. Number of superdiagonals to keep. If negative, keep\n",
      "            entire upper triangle.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_determinant(input: Annotated[Any, ~TV_MatrixDeterminant_T], name=None) -> Annotated[Any, ~TV_MatrixDeterminant_T]\n",
      "        Computes the determinant of one or more square matrices.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor containing the determinants\n",
      "        for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_diag(diagonal, name='diag', k=0, num_rows=-1, num_cols=-1, padding_value=0, align='RIGHT_LEFT')\n",
      "        Returns a batched diagonal tensor with given batched diagonal values.\n",
      "        \n",
      "        Returns a tensor with the contents in `diagonal` as `k[0]`-th to `k[1]`-th\n",
      "        diagonals of a matrix, with everything else padded with `padding`. `num_rows`\n",
      "        and `num_cols` specify the dimension of the innermost matrix of the output. If\n",
      "        both are not specified, the op assumes the innermost matrix is square and\n",
      "        infers its size from `k` and the innermost dimension of `diagonal`. If only\n",
      "        one of them is specified, the op assumes the unspecified value is the smallest\n",
      "        possible based on other criteria.\n",
      "        \n",
      "        Let `diagonal` have `r` dimensions `[I, J, ..., L, M, N]`. The output tensor\n",
      "        has rank `r+1` with shape `[I, J, ..., L, M, num_rows, num_cols]` when only\n",
      "        one diagonal is given (`k` is an integer or `k[0] == k[1]`). Otherwise, it has\n",
      "        rank `r` with shape `[I, J, ..., L, num_rows, num_cols]`.\n",
      "        \n",
      "        The second innermost dimension of `diagonal` has double meaning. When `k` is\n",
      "        scalar or `k[0] == k[1]`, `M` is part of the batch size [I, J, ..., M], and\n",
      "        the output tensor is:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, n-max(d_upper, 0)] ; if n - m == d_upper\n",
      "            padding_value                             ; otherwise\n",
      "        ```\n",
      "        \n",
      "        Otherwise, `M` is treated as the number of diagonals for the matrix in the\n",
      "        same batch (`M = k[1]-k[0]+1`), and the output tensor is:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] <= d <= k[1]\n",
      "            padding_value                                     ; otherwise\n",
      "        ```\n",
      "        where `d = n - m`, `diag_index = k[1] - d`, and\n",
      "        `index_in_diag = n - max(d, 0) + offset`.\n",
      "        \n",
      "        `offset` is zero except when the alignment of the diagonal is to the right.\n",
      "        ```\n",
      "        offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}\n",
      "                                                   and `d >= 0`) or\n",
      "                                                 (`align` in {LEFT_RIGHT, RIGHT_RIGHT}\n",
      "                                                   and `d <= 0`)\n",
      "                 0                          ; otherwise\n",
      "        ```\n",
      "        where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # The main diagonal.\n",
      "        diagonal = np.array([[1, 2, 3, 4],            # Input shape: (2, 4)\n",
      "                             [5, 6, 7, 8]])\n",
      "        tf.matrix_diag(diagonal) ==> [[[1, 0, 0, 0],  # Output shape: (2, 4, 4)\n",
      "                                       [0, 2, 0, 0],\n",
      "                                       [0, 0, 3, 0],\n",
      "                                       [0, 0, 0, 4]],\n",
      "                                      [[5, 0, 0, 0],\n",
      "                                       [0, 6, 0, 0],\n",
      "                                       [0, 0, 7, 0],\n",
      "                                       [0, 0, 0, 8]]]\n",
      "        \n",
      "        # A superdiagonal (per batch).\n",
      "        diagonal = np.array([[1, 2, 3],  # Input shape: (2, 3)\n",
      "                             [4, 5, 6]])\n",
      "        tf.matrix_diag(diagonal, k = 1)\n",
      "          ==> [[[0, 1, 0, 0],  # Output shape: (2, 4, 4)\n",
      "                [0, 0, 2, 0],\n",
      "                [0, 0, 0, 3],\n",
      "                [0, 0, 0, 0]],\n",
      "               [[0, 4, 0, 0],\n",
      "                [0, 0, 5, 0],\n",
      "                [0, 0, 0, 6],\n",
      "                [0, 0, 0, 0]]]\n",
      "        \n",
      "        # A tridiagonal band (per batch).\n",
      "        diagonals = np.array([[[8, 9, 0],  # Input shape: (2, 2, 3)\n",
      "                               [1, 2, 3],\n",
      "                               [0, 4, 5]],\n",
      "                              [[2, 3, 0],\n",
      "                               [6, 7, 9],\n",
      "                               [0, 9, 1]]])\n",
      "        tf.matrix_diag(diagonals, k = (-1, 1))\n",
      "          ==> [[[1, 8, 0],  # Output shape: (2, 3, 3)\n",
      "                [4, 2, 9],\n",
      "                [0, 5, 3]],\n",
      "               [[6, 2, 0],\n",
      "                [9, 7, 3],\n",
      "                [0, 1, 9]]]\n",
      "        \n",
      "        # RIGHT_LEFT alignment.\n",
      "        diagonals = np.array([[[0, 8, 9],  # Input shape: (2, 2, 3)\n",
      "                               [1, 2, 3],\n",
      "                               [4, 5, 0]],\n",
      "                              [[0, 2, 3],\n",
      "                               [6, 7, 9],\n",
      "                               [9, 1, 0]]])\n",
      "        tf.matrix_diag(diagonals, k = (-1, 1), align=\"RIGHT_LEFT\")\n",
      "          ==> [[[1, 8, 0],  # Output shape: (2, 3, 3)\n",
      "                [4, 2, 9],\n",
      "                [0, 5, 3]],\n",
      "               [[6, 2, 0],\n",
      "                [9, 7, 3],\n",
      "                [0, 1, 9]]]\n",
      "        \n",
      "        # Rectangular matrix.\n",
      "        diagonal = np.array([1, 2])  # Input shape: (2)\n",
      "        tf.matrix_diag(diagonal, k = -1, num_rows = 3, num_cols = 4)\n",
      "          ==> [[0, 0, 0, 0],  # Output shape: (3, 4)\n",
      "               [1, 0, 0, 0],\n",
      "               [0, 2, 0, 0]]\n",
      "        \n",
      "        # Rectangular matrix with inferred num_cols and padding_value = 9.\n",
      "        tf.matrix_diag(diagonal, k = -1, num_rows = 3, padding_value = 9)\n",
      "          ==> [[9, 9],  # Output shape: (3, 2)\n",
      "               [1, 9],\n",
      "               [9, 2]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          diagonal: A `Tensor` with `rank k >= 1`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "          num_rows: The number of rows of the output matrix. If it is not provided,\n",
      "            the op assumes the output matrix is a square matrix and infers the matrix\n",
      "            size from `d_lower`, `d_upper`, and the innermost dimension of `diagonal`.\n",
      "          num_cols: The number of columns of the output matrix. If it is not provided,\n",
      "            the op assumes the output matrix is a square matrix and infers the matrix\n",
      "            size from `d_lower`, `d_upper`, and the innermost dimension of `diagonal`.\n",
      "          padding_value: The value to fill the area outside the specified diagonal\n",
      "            band with. Default is 0.\n",
      "          align: Some diagonals are shorter than `max_diag_len` and need to be padded.\n",
      "            `align` is a string specifying how superdiagonals and subdiagonals should\n",
      "            be aligned, respectively. There are four possible alignments: \"RIGHT_LEFT\"\n",
      "            (default), \"LEFT_RIGHT\", \"LEFT_LEFT\", and \"RIGHT_RIGHT\". \"RIGHT_LEFT\"\n",
      "            aligns superdiagonals to the right (left-pads the row) and subdiagonals to\n",
      "            the left (right-pads the row). It is the packing format LAPACK uses.\n",
      "            cuSPARSE uses \"LEFT_RIGHT\", which is the opposite alignment.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor. Has the same type as `diagonal`.\n",
      "    \n",
      "    matrix_diag_part(input, name='diag_part', k=0, padding_value=0, align='RIGHT_LEFT')\n",
      "        Returns the batched diagonal part of a batched tensor.\n",
      "        \n",
      "        Returns a tensor with the `k[0]`-th to `k[1]`-th diagonals of the batched\n",
      "        `input`.\n",
      "        \n",
      "        Assume `input` has `r` dimensions `[I, J, ..., L, M, N]`.\n",
      "        Let `max_diag_len` be the maximum length among all diagonals to be extracted,\n",
      "        `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`\n",
      "        Let `num_diags` be the number of diagonals to extract,\n",
      "        `num_diags = k[1] - k[0] + 1`.\n",
      "        \n",
      "        If `num_diags == 1`, the output tensor is of rank `r - 1` with shape\n",
      "        `[I, J, ..., L, max_diag_len]` and values:\n",
      "        \n",
      "        ```\n",
      "        diagonal[i, j, ..., l, n]\n",
      "          = input[i, j, ..., l, n+y, n+x] ; if 0 <= n+y < M and 0 <= n+x < N,\n",
      "            padding_value                 ; otherwise.\n",
      "        ```\n",
      "        where `y = max(-k[1], 0)`, `x = max(k[1], 0)`.\n",
      "        \n",
      "        Otherwise, the output tensor has rank `r` with dimensions\n",
      "        `[I, J, ..., L, num_diags, max_diag_len]` with values:\n",
      "        \n",
      "        ```\n",
      "        diagonal[i, j, ..., l, m, n]\n",
      "          = input[i, j, ..., l, n+y, n+x] ; if 0 <= n+y < M and 0 <= n+x < N,\n",
      "            padding_value                 ; otherwise.\n",
      "        ```\n",
      "        where `d = k[1] - m`, `y = max(-d, 0) - offset`, and `x = max(d, 0) - offset`.\n",
      "        \n",
      "        `offset` is zero except when the alignment of the diagonal is to the right.\n",
      "        ```\n",
      "        offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}\n",
      "                                                   and `d >= 0`) or\n",
      "                                                 (`align` in {LEFT_RIGHT, RIGHT_RIGHT}\n",
      "                                                   and `d <= 0`)\n",
      "                 0                          ; otherwise\n",
      "        ```\n",
      "        where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.\n",
      "        \n",
      "        The input must be at least a matrix.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        input = np.array([[[1, 2, 3, 4],  # Input shape: (2, 3, 4)\n",
      "                           [5, 6, 7, 8],\n",
      "                           [9, 8, 7, 6]],\n",
      "                          [[5, 4, 3, 2],\n",
      "                           [1, 2, 3, 4],\n",
      "                           [5, 6, 7, 8]]])\n",
      "        \n",
      "        # A main diagonal from each batch.\n",
      "        tf.linalg.diag_part(input) ==> [[1, 6, 7],  # Output shape: (2, 3)\n",
      "                                        [5, 2, 7]]\n",
      "        \n",
      "        # A superdiagonal from each batch.\n",
      "        tf.linalg.diag_part(input, k = 1)\n",
      "          ==> [[2, 7, 6],  # Output shape: (2, 3)\n",
      "               [4, 3, 8]]\n",
      "        \n",
      "        # A band from each batch.\n",
      "        tf.linalg.diag_part(input, k = (-1, 2))\n",
      "          ==> [[[3, 8, 0],  # Output shape: (2, 4, 3)\n",
      "                [2, 7, 6],\n",
      "                [1, 6, 7],\n",
      "                [0, 5, 8]],\n",
      "               [[3, 4, 0],\n",
      "                [4, 3, 8],\n",
      "                [5, 2, 7],\n",
      "                [0, 1, 6]]]\n",
      "        \n",
      "        # RIGHT_LEFT alignment.\n",
      "        tf.linalg.diag_part(input, k = (-1, 2), align=\"RIGHT_LEFT\")\n",
      "          ==> [[[0, 3, 8],  # Output shape: (2, 4, 3)\n",
      "                [2, 7, 6],\n",
      "                [1, 6, 7],\n",
      "                [5, 8, 0]],\n",
      "               [[0, 3, 4],\n",
      "                [4, 3, 8],\n",
      "                [5, 2, 7],\n",
      "                [1, 6, 0]]]\n",
      "        \n",
      "        # max_diag_len can be shorter than the main diagonal.\n",
      "        tf.linalg.diag_part(input, k = (-2, -1))\n",
      "          ==> [[[5, 8],\n",
      "                [0, 9]],\n",
      "               [[1, 6],\n",
      "                [0, 5]]]\n",
      "        \n",
      "        # padding_value = 9\n",
      "        tf.linalg.diag_part(input, k = (1, 3), padding_value = 9)\n",
      "          ==> [[[4, 9, 9],  # Output shape: (2, 3, 3)\n",
      "                [3, 8, 9],\n",
      "                [2, 7, 6]],\n",
      "               [[2, 9, 9],\n",
      "                [3, 4, 9],\n",
      "                [4, 3, 8]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` with `rank k >= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "          padding_value: The value to fill the area outside the specified diagonal\n",
      "            band with. Default is 0.\n",
      "          align: Some diagonals are shorter than `max_diag_len` and need to be padded.\n",
      "            `align` is a string specifying how superdiagonals and subdiagonals should\n",
      "            be aligned, respectively. There are four possible alignments: \"RIGHT_LEFT\"\n",
      "            (default), \"LEFT_RIGHT\", \"LEFT_LEFT\", and \"RIGHT_RIGHT\". \"RIGHT_LEFT\"\n",
      "            aligns superdiagonals to the right (left-pads the row) and subdiagonals to\n",
      "            the left (right-pads the row). It is the packing format LAPACK uses.\n",
      "            cuSPARSE uses \"LEFT_RIGHT\", which is the opposite alignment.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor containing diagonals of `input`. Has the same type as `input`.\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: When `k` is out of bound or when `k[0]>k[1:]`.\n",
      "    \n",
      "    matrix_inverse(input: Annotated[Any, ~TV_MatrixInverse_T], adjoint: bool = False, name=None) -> Annotated[Any, ~TV_MatrixInverse_T]\n",
      "        Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).\n",
      "        \n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor of the same shape as the input\n",
      "        containing the inverse for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        The op uses LU decomposition with partial pivoting to compute the inverses.\n",
      "        \n",
      "        If a matrix is not invertible there is no guarantee what the op does. It\n",
      "        may detect the condition and raise an exception or it may simply return a\n",
      "        garbage result.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          adjoint: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_set_diag(input, diagonal, name='set_diag', k=0, align='RIGHT_LEFT')\n",
      "        Returns a batched matrix tensor with new batched diagonal values.\n",
      "        \n",
      "        Given `input` and `diagonal`, this operation returns a tensor with the\n",
      "        same shape and values as `input`, except for the specified diagonals of the\n",
      "        innermost matrices. These will be overwritten by the values in `diagonal`.\n",
      "        \n",
      "        `input` has `r+1` dimensions `[I, J, ..., L, M, N]`. When `k` is scalar or\n",
      "        `k[0] == k[1]`, `diagonal` has `r` dimensions `[I, J, ..., L, max_diag_len]`.\n",
      "        Otherwise, it has `r+1` dimensions `[I, J, ..., L, num_diags, max_diag_len]`.\n",
      "        `num_diags` is the number of diagonals, `num_diags = k[1] - k[0] + 1`.\n",
      "        `max_diag_len` is the longest diagonal in the range `[k[0], k[1]]`,\n",
      "        `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`\n",
      "        \n",
      "        The output is a tensor of rank `k+1` with dimensions `[I, J, ..., L, M, N]`.\n",
      "        If `k` is scalar or `k[0] == k[1]`:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, n-max(k[1], 0)] ; if n - m == k[1]\n",
      "            input[i, j, ..., l, m, n]              ; otherwise\n",
      "        ```\n",
      "        \n",
      "        Otherwise,\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] <= d <= k[1]\n",
      "            input[i, j, ..., l, m, n]                         ; otherwise\n",
      "        ```\n",
      "        where `d = n - m`, `diag_index = k[1] - d`, and\n",
      "        `index_in_diag = n - max(d, 0) + offset`.\n",
      "        \n",
      "        `offset` is zero except when the alignment of the diagonal is to the right.\n",
      "        ```\n",
      "        offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}\n",
      "                                                   and `d >= 0`) or\n",
      "                                                 (`align` in {LEFT_RIGHT, RIGHT_RIGHT}\n",
      "                                                   and `d <= 0`)\n",
      "                 0                          ; otherwise\n",
      "        ```\n",
      "        where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # The main diagonal.\n",
      "        input = np.array([[[7, 7, 7, 7],              # Input shape: (2, 3, 4)\n",
      "                           [7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7]],\n",
      "                          [[7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7]]])\n",
      "        diagonal = np.array([[1, 2, 3],               # Diagonal shape: (2, 3)\n",
      "                             [4, 5, 6]])\n",
      "        tf.matrix_set_diag(input, diagonal)\n",
      "          ==> [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)\n",
      "                [7, 2, 7, 7],\n",
      "                [7, 7, 3, 7]],\n",
      "               [[4, 7, 7, 7],\n",
      "                [7, 5, 7, 7],\n",
      "                [7, 7, 6, 7]]]\n",
      "        \n",
      "        # A superdiagonal (per batch).\n",
      "        tf.matrix_set_diag(input, diagonal, k = 1)\n",
      "          ==> [[[7, 1, 7, 7],  # Output shape: (2, 3, 4)\n",
      "                [7, 7, 2, 7],\n",
      "                [7, 7, 7, 3]],\n",
      "               [[7, 4, 7, 7],\n",
      "                [7, 7, 5, 7],\n",
      "                [7, 7, 7, 6]]]\n",
      "        \n",
      "        # A band of diagonals.\n",
      "        diagonals = np.array([[[9, 1, 0],  # Diagonal shape: (2, 4, 3)\n",
      "                               [6, 5, 8],\n",
      "                               [1, 2, 3],\n",
      "                               [0, 4, 5]],\n",
      "                              [[1, 2, 0],\n",
      "                               [5, 6, 4],\n",
      "                               [6, 1, 2],\n",
      "                               [0, 3, 4]]])\n",
      "        tf.matrix_set_diag(input, diagonals, k = (-1, 2))\n",
      "          ==> [[[1, 6, 9, 7],  # Output shape: (2, 3, 4)\n",
      "                [4, 2, 5, 1],\n",
      "                [7, 5, 3, 8]],\n",
      "               [[6, 5, 1, 7],\n",
      "                [3, 1, 6, 2],\n",
      "                [7, 4, 2, 4]]]\n",
      "        \n",
      "        # RIGHT_LEFT alignment.\n",
      "        diagonals = np.array([[[0, 9, 1],  # Diagonal shape: (2, 4, 3)\n",
      "                               [6, 5, 8],\n",
      "                               [1, 2, 3],\n",
      "                               [4, 5, 0]],\n",
      "                              [[0, 1, 2],\n",
      "                               [5, 6, 4],\n",
      "                               [6, 1, 2],\n",
      "                               [3, 4, 0]]])\n",
      "        tf.matrix_set_diag(input, diagonals, k = (-1, 2), align=\"RIGHT_LEFT\")\n",
      "          ==> [[[1, 6, 9, 7],  # Output shape: (2, 3, 4)\n",
      "                [4, 2, 5, 1],\n",
      "                [7, 5, 3, 8]],\n",
      "               [[6, 5, 1, 7],\n",
      "                [3, 1, 6, 2],\n",
      "                [7, 4, 2, 4]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` with rank `k + 1`, where `k >= 1`.\n",
      "          diagonal:  A `Tensor` with rank `k`, when `d_lower == d_upper`, or `k + 1`,\n",
      "            otherwise. `k >= 1`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "          align: Some diagonals are shorter than `max_diag_len` and need to be padded.\n",
      "            `align` is a string specifying how superdiagonals and subdiagonals should\n",
      "            be aligned, respectively. There are four possible alignments: \"RIGHT_LEFT\"\n",
      "            (default), \"LEFT_RIGHT\", \"LEFT_LEFT\", and \"RIGHT_RIGHT\". \"RIGHT_LEFT\"\n",
      "            aligns superdiagonals to the right (left-pads the row) and subdiagonals to\n",
      "            the left (right-pads the row). It is the packing format LAPACK uses.\n",
      "            cuSPARSE uses \"LEFT_RIGHT\", which is the opposite alignment.\n",
      "    \n",
      "    matrix_solve(matrix: Annotated[Any, ~TV_MatrixSolve_T], rhs: Annotated[Any, ~TV_MatrixSolve_T], adjoint: bool = False, name=None) -> Annotated[Any, ~TV_MatrixSolve_T]\n",
      "        Solves systems of linear equations.\n",
      "        \n",
      "        `Matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. `Rhs` is a tensor of shape `[..., M, K]`. The `output` is\n",
      "        a tensor shape `[..., M, K]`.  If `adjoint` is `False` then each output matrix\n",
      "        satisfies `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.\n",
      "        If `adjoint` is `True` then each output matrix satisfies\n",
      "        `adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          rhs: A `Tensor`. Must have the same type as `matrix`.\n",
      "            Shape is `[..., M, K]`.\n",
      "          adjoint: An optional `bool`. Defaults to `False`.\n",
      "            Boolean indicating whether to solve with `matrix` or its (block-wise)\n",
      "            adjoint.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `matrix`.\n",
      "    \n",
      "    matrix_solve_ls(matrix, rhs, l2_regularizer=0.0, fast=True, name=None)\n",
      "        Solves one or more linear least-squares problems.\n",
      "        \n",
      "        `matrix` is a tensor of shape `[..., M, N]` whose inner-most 2 dimensions\n",
      "        form `M`-by-`N` matrices. Rhs is a tensor of shape `[..., M, K]` whose\n",
      "        inner-most 2 dimensions form `M`-by-`K` matrices.  The computed output is a\n",
      "        `Tensor` of shape `[..., N, K]` whose inner-most 2 dimensions form `M`-by-`K`\n",
      "        matrices that solve the equations\n",
      "        `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]` in the least squares\n",
      "        sense.\n",
      "        \n",
      "        Below we will use the following notation for each pair of matrix and\n",
      "        right-hand sides in the batch:\n",
      "        \n",
      "        `matrix`=\\\\(A \\in \\Re^{m \\times n}\\\\),\n",
      "        `rhs`=\\\\(B  \\in \\Re^{m \\times k}\\\\),\n",
      "        `output`=\\\\(X  \\in \\Re^{n \\times k}\\\\),\n",
      "        `l2_regularizer`=\\\\(\\lambda\\\\).\n",
      "        \n",
      "        If `fast` is `True`, then the solution is computed by solving the normal\n",
      "        equations using Cholesky decomposition. Specifically, if \\\\(m \\ge n\\\\) then\n",
      "        \\\\(X = (A^T A + \\lambda I)^{-1} A^T B\\\\), which solves the least-squares\n",
      "        problem \\\\(X = \\mathrm{argmin}_{Z \\in \\Re^{n \\times k}} ||A Z - B||_F^2 +\n",
      "        \\lambda ||Z||_F^2\\\\). If \\\\(m \\lt n\\\\) then `output` is computed as\n",
      "        \\\\(X = A^T (A A^T + \\lambda I)^{-1} B\\\\), which (for \\\\(\\lambda = 0\\\\)) is\n",
      "        the minimum-norm solution to the under-determined linear system, i.e.\n",
      "        \\\\(X = \\mathrm{argmin}_{Z \\in \\Re^{n \\times k}} ||Z||_F^2 \\\\), subject to\n",
      "        \\\\(A Z = B\\\\). Notice that the fast path is only numerically stable when\n",
      "        \\\\(A\\\\) is numerically full rank and has a condition number\n",
      "        \\\\(\\mathrm{cond}(A) \\lt \\frac{1}{\\sqrt{\\epsilon_{mach}}}\\\\) or\\\\(\\lambda\\\\)\n",
      "        is sufficiently large.\n",
      "        \n",
      "        If `fast` is `False` an algorithm based on the numerically robust complete\n",
      "        orthogonal decomposition is used. This computes the minimum-norm\n",
      "        least-squares solution, even when \\\\(A\\\\) is rank deficient. This path is\n",
      "        typically 6-7 times slower than the fast path. If `fast` is `False` then\n",
      "        `l2_regularizer` is ignored.\n",
      "        \n",
      "        Args:\n",
      "          matrix: `Tensor` of shape `[..., M, N]`.\n",
      "          rhs: `Tensor` of shape `[..., M, K]`.\n",
      "          l2_regularizer: 0-D `double` `Tensor`. Ignored if `fast=False`.\n",
      "          fast: bool. Defaults to `True`.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          output: `Tensor` of shape `[..., N, K]` whose inner-most 2 dimensions form\n",
      "            `M`-by-`K` matrices that solve the equations\n",
      "            `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]` in the least\n",
      "            squares sense.\n",
      "        \n",
      "        Raises:\n",
      "          NotImplementedError: linalg.lstsq is currently disabled for complex128\n",
      "          and l2_regularizer != 0 due to poor accuracy.\n",
      "    \n",
      "    matrix_square_root(input: Annotated[Any, ~TV_MatrixSquareRoot_T], name=None) -> Annotated[Any, ~TV_MatrixSquareRoot_T]\n",
      "        Computes the matrix square root of one or more square matrices:\n",
      "        \n",
      "        matmul(sqrtm(A), sqrtm(A)) = A\n",
      "        \n",
      "        The input matrix should be invertible. If the input matrix is real, it should\n",
      "        have no eigenvalues which are real and negative (pairs of complex conjugate\n",
      "        eigenvalues are allowed).\n",
      "        \n",
      "        The matrix square root is computed by first reducing the matrix to\n",
      "        quasi-triangular form with the real Schur decomposition. The square root\n",
      "        of the quasi-triangular matrix is then computed directly. Details of\n",
      "        the algorithm can be found in: Nicholas J. Higham, \"Computing real\n",
      "        square roots of a real matrix\", Linear Algebra Appl., 1987.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor of the same shape as the input\n",
      "        containing the matrix square root for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_transpose(a, name='matrix_transpose', conjugate=False)\n",
      "        Transposes last two dimensions of tensor `a`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.linalg.matrix_transpose(x)  # [[1, 4],\n",
      "                                       #  [2, 5],\n",
      "                                       #  [3, 6]]\n",
      "        \n",
      "        x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "                         [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "        tf.linalg.matrix_transpose(x, conjugate=True)  # [[1 - 1j, 4 - 4j],\n",
      "                                                       #  [2 - 2j, 5 - 5j],\n",
      "                                                       #  [3 - 3j, 6 - 6j]]\n",
      "        \n",
      "        # Matrix with two batch dimensions.\n",
      "        # x.shape is [1, 2, 3, 4]\n",
      "        # tf.linalg.matrix_transpose(x) is shape [1, 2, 4, 3]\n",
      "        ```\n",
      "        \n",
      "        Note that `tf.matmul` provides kwargs allowing for transpose of arguments.\n",
      "        This is done with minimal cost, and is preferable to using this function. E.g.\n",
      "        \n",
      "        ```python\n",
      "        # Good!  Transpose is taken at minimal additional cost.\n",
      "        tf.matmul(matrix, b, transpose_b=True)\n",
      "        \n",
      "        # Inefficient!\n",
      "        tf.matmul(matrix, tf.linalg.matrix_transpose(b))\n",
      "        ```\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        In `numpy` transposes are memory-efficient constant time operations as they\n",
      "        simply return a new view of the same data with adjusted `strides`.\n",
      "        \n",
      "        TensorFlow does not support strides, `linalg.matrix_transpose` returns a new\n",
      "        tensor with the items permuted.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor` with `rank >= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "          conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "            to tf.math.conj(tf.linalg.matrix_transpose(input)).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed batch matrix `Tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If `a` is determined statically to have `rank < 2`.\n",
      "    \n",
      "    matrix_triangular_solve(matrix, rhs, lower=True, adjoint=False, name=None)\n",
      "        Solve systems of linear equations with upper or lower triangular matrices.\n",
      "        \n",
      "        `matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions form\n",
      "        square matrices. If `lower` is `True` then the strictly upper triangular part\n",
      "        of each inner-most matrix is assumed to be zero and not accessed. If `lower`\n",
      "        is `False` then the strictly lower triangular part of each inner-most matrix\n",
      "        is assumed to be zero and not accessed. `rhs` is a tensor of shape\n",
      "        `[..., M, N]`.\n",
      "        \n",
      "        The output is a tensor of shape `[..., M, N]`. If `adjoint` is `True` then the\n",
      "        innermost matrices in output satisfy matrix equations `\n",
      "        sum_k matrix[..., i, k] * output[..., k, j] = rhs[..., i, j]`.\n",
      "        If `adjoint` is `False` then the\n",
      "        innermost matrices in output satisfy matrix equations\n",
      "        `sum_k adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]`.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> a = tf.constant([[3,  0,  0,  0],\n",
      "        ...   [2,  1,  0,  0],\n",
      "        ...   [1,  0,  1,  0],\n",
      "        ...   [1,  1,  1,  1]], dtype=tf.float32)\n",
      "        \n",
      "        >>> b = tf.constant([[4], [2], [4], [2]], dtype=tf.float32)\n",
      "        >>> x = tf.linalg.triangular_solve(a, b, lower=True)\n",
      "        >>> x\n",
      "        <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
      "        array([[ 1.3333334 ],\n",
      "               [-0.66666675],\n",
      "               [ 2.6666665 ],\n",
      "               [-1.3333331 ]], dtype=float32)>\n",
      "        >>> tf.matmul(a, x)\n",
      "        <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
      "        array([[4.],\n",
      "               [2.],\n",
      "               [4.],\n",
      "               [2.]], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          matrix: A `Tensor`. Must be one of the following types: `float64`,\n",
      "            `float32`, `half`, `complex64`, `complex128`. Shape is `[..., M, M]`.\n",
      "          rhs: A `Tensor`. Must have the same type as `matrix`. Shape is `[..., M,\n",
      "            N]`.\n",
      "          lower: An optional `bool`. Defaults to `True`. Boolean indicating whether\n",
      "            the innermost matrices in matrix are lower or upper triangular.\n",
      "          adjoint: An optional `bool`. Defaults to `False`. Boolean indicating whether\n",
      "            to solve with matrix or its (block-wise) adjoint.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as matrix, and shape is `[..., M, N]`.\n",
      "    \n",
      "    maximum(x: typing.Annotated[_any, ~TV_Maximum_T], y: typing.Annotated[_any, ~TV_Maximum_T], name=None) -> typing.Annotated[_any, ~TV_Maximum_T]\n",
      "        Returns the max of x and y (i.e. x > y ? x : y) element-wise.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> x = tf.constant([0., 0., 0., 0.])\n",
      "        >>> y = tf.constant([-2., 0., 2., 5.])\n",
      "        >>> tf.math.maximum(x, y)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 2., 5.], dtype=float32)>\n",
      "        \n",
      "        Note that `maximum` supports [broadcast semantics](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for `x` and `y`.\n",
      "        \n",
      "        >>> x = tf.constant([-5., 0., 0., 0.])\n",
      "        >>> y = tf.constant([-3.])\n",
      "        >>> tf.math.maximum(x, y)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-3., 0., 0., 0.], dtype=float32)>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_max`\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    meshgrid(*args, **kwargs)\n",
      "        Broadcasts parameters for evaluation on an N-D grid.\n",
      "        \n",
      "        Given N one-dimensional coordinate arrays `*args`, returns a list `outputs`\n",
      "        of N-D coordinate arrays for evaluating expressions on an N-D grid.\n",
      "        \n",
      "        Notes:\n",
      "        \n",
      "        `meshgrid` supports cartesian ('xy') and matrix ('ij') indexing conventions.\n",
      "        When the `indexing` argument is set to 'xy' (the default), the broadcasting\n",
      "        instructions for the first two dimensions are swapped.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        Calling `X, Y = meshgrid(x, y)` with the tensors\n",
      "        \n",
      "        ```python\n",
      "        x = [1, 2, 3]\n",
      "        y = [4, 5, 6]\n",
      "        X, Y = tf.meshgrid(x, y)\n",
      "        # X = [[1, 2, 3],\n",
      "        #      [1, 2, 3],\n",
      "        #      [1, 2, 3]]\n",
      "        # Y = [[4, 4, 4],\n",
      "        #      [5, 5, 5],\n",
      "        #      [6, 6, 6]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          *args: `Tensor`s with rank 1.\n",
      "          **kwargs:\n",
      "            - indexing: Either 'xy' or 'ij' (optional, default: 'xy').\n",
      "            - name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          outputs: A list of N `Tensor`s with rank N.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: When no keyword arguments (kwargs) are passed.\n",
      "          ValueError: When indexing keyword argument is not one of `xy` or `ij`.\n",
      "    \n",
      "    min_max_variable_partitioner(max_partitions=1, axis=0, min_slice_size=262144, bytes_per_string_element=16)\n",
      "        Partitioner to allocate minimum size per slice.\n",
      "        \n",
      "        Returns a partitioner that partitions the variable of given shape and dtype\n",
      "        such that each partition has a minimum of `min_slice_size` slice of the\n",
      "        variable. The maximum number of such partitions (upper bound) is given by\n",
      "        `max_partitions`.\n",
      "        \n",
      "        Args:\n",
      "          max_partitions: Upper bound on the number of partitions. Defaults to 1.\n",
      "          axis: Axis along which to partition the variable. Defaults to 0.\n",
      "          min_slice_size: Minimum size of the variable slice per partition. Defaults\n",
      "            to 256K.\n",
      "          bytes_per_string_element: If the `Variable` is of type string, this provides\n",
      "            an estimate of how large each scalar in the `Variable` is.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "    \n",
      "    minimum(x: typing.Annotated[_any, ~TV_Minimum_T], y: typing.Annotated[_any, ~TV_Minimum_T], name=None) -> typing.Annotated[_any, ~TV_Minimum_T]\n",
      "        Returns the min of x and y (i.e. x < y ? x : y) element-wise.\n",
      "        \n",
      "        Both inputs are number-type tensors (except complex).  `minimum` expects that\n",
      "        both tensors have the same `dtype`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> x = tf.constant([0., 0., 0., 0.])\n",
      "        >>> y = tf.constant([-5., -2., 0., 3.])\n",
      "        >>> tf.math.minimum(x, y)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -2., 0., 0.], dtype=float32)>\n",
      "        \n",
      "        Note that `minimum` supports [broadcast semantics](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for `x` and `y`.\n",
      "        \n",
      "        >>> x = tf.constant([-5., 0., 0., 0.])\n",
      "        >>> y = tf.constant([-3.])\n",
      "        >>> tf.math.minimum(x, y)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -3., -3., -3.], dtype=float32)>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_min`\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    mod = floor_mod(x: typing.Annotated[_any, ~TV_FloorMod_T], y: typing.Annotated[_any, ~TV_FloorMod_T], name=None) -> typing.Annotated[_any, ~TV_FloorMod_T]\n",
      "        Returns element-wise remainder of division.\n",
      "        \n",
      "        This follows Python semantics in that the\n",
      "        result here is consistent with a flooring divide. E.g.\n",
      "        `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
      "        \n",
      "        *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    model_variables(scope=None)\n",
      "        Returns all variables in the MODEL_VARIABLES collection.\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of local Variable objects.\n",
      "    \n",
      "    moving_average_variables(scope=None)\n",
      "        Returns all variables that maintain their moving averages.\n",
      "        \n",
      "        If an `ExponentialMovingAverage` object is created and the `apply()`\n",
      "        method is called on a list of variables, these variables will\n",
      "        be added to the `GraphKeys.MOVING_AVERAGE_VARIABLES` collection.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variable objects.\n",
      "    \n",
      "    multinomial(logits, num_samples, seed=None, name=None, output_dtype=None)\n",
      "        Draws samples from a multinomial distribution. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.random.categorical` instead.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        # samples has shape [1, 5], where each value is either 0 or 1 with equal\n",
      "        # probability.\n",
      "        samples = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 5)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          logits: 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice\n",
      "            `[i, :]` represents the unnormalized log-probabilities for all classes.\n",
      "          num_samples: 0-D.  Number of independent samples to draw for each row slice.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See `tf.random.set_seed` for behavior.\n",
      "          name: Optional name for the operation.\n",
      "          output_dtype: The integer type of the output: `int32` or `int64`. Defaults\n",
      "            to `int64`.\n",
      "        \n",
      "        Returns:\n",
      "          The drawn samples of shape `[batch_size, num_samples]`.\n",
      "    \n",
      "    multiply(x, y, name=None)\n",
      "        Returns an element-wise x * y.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant(([1, 2, 3, 4]))\n",
      "        >>> tf.math.multiply(x, x)\n",
      "        <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
      "        \n",
      "        Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
      "        pass in non-`Tensor` arguments:\n",
      "        \n",
      "        >>> tf.math.multiply(7,6)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
      "        \n",
      "        If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
      "        compatible shape. (More about broadcasting\n",
      "        [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.ones([1, 2]);\n",
      "        >>> y = tf.ones([2, 1]);\n",
      "        >>> x * y  # Taking advantage of operator overriding\n",
      "        <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "        array([[1., 1.],\n",
      "             [1., 1.]], dtype=float32)>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor. Must be one of the following types: `bfloat16`,\n",
      "            `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
      "            `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "        \n",
      "        A `Tensor`.  Has the same type as `x`.\n",
      "        \n",
      "        Raises:\n",
      "        \n",
      "         * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
      "    \n",
      "    negative = neg(x: typing.Annotated[_any, ~TV_Neg_T], name=None) -> typing.Annotated[_any, ~TV_Neg_T]\n",
      "        Computes numerical negative value element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = -x\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    no_gradient(op_type: str) -> None\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    no_op(name=None)\n",
      "        Does nothing. Only useful as a placeholder for control edges.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The created Operation.\n",
      "    \n",
      "    no_regularizer(_)\n",
      "        Use this function to prevent regularization of variables.\n",
      "    \n",
      "    nondifferentiable_batch_function = batch_function(num_batch_threads, max_batch_size, batch_timeout_micros, allowed_batch_sizes=None, max_enqueued_batches=10, autograph=True, enable_large_batch_splitting=True)\n",
      "        Batches the computation done by the decorated function.\n",
      "        \n",
      "        So, for example, in the following code\n",
      "        \n",
      "        ```python\n",
      "        @batch_function(1, 2, 3)\n",
      "        def layer(a):\n",
      "          return tf.matmul(a, a)\n",
      "        \n",
      "        b = layer(w)\n",
      "        ```\n",
      "        \n",
      "        if more than one session.run call is simultaneously trying to compute `b`\n",
      "        the values of `w` will be gathered, non-deterministically concatenated\n",
      "        along the first axis, and only one thread will run the computation. See the\n",
      "        documentation of the `Batch` op for more details.\n",
      "        \n",
      "        Assumes that all arguments of the decorated function are Tensors which will\n",
      "        be batched along their first dimension.\n",
      "        \n",
      "        SparseTensor is not supported. The return value of the decorated function\n",
      "        must be a Tensor or a list/tuple of Tensors.\n",
      "        \n",
      "        Args:\n",
      "          num_batch_threads: Number of scheduling threads for processing batches\n",
      "           of work. Determines the number of batches processed in parallel.\n",
      "          max_batch_size: Batch sizes will never be bigger than this.\n",
      "          batch_timeout_micros: Maximum number of microseconds to wait before\n",
      "           outputting an incomplete batch.\n",
      "          allowed_batch_sizes: Optional list of allowed batch sizes. If left empty,\n",
      "           does nothing. Otherwise, supplies a list of batch sizes, causing the op\n",
      "           to pad batches up to one of those sizes. The entries must increase\n",
      "           monotonically, and the final entry must equal max_batch_size.\n",
      "          max_enqueued_batches: The maximum depth of the batch queue. Defaults to 10.\n",
      "          autograph: Whether to use autograph to compile python and eager style code\n",
      "           for efficient graph-mode execution.\n",
      "          enable_large_batch_splitting: The value of this option doesn't affect\n",
      "           processing output given the same input; it affects implementation details\n",
      "           as stated below: 1. Improve batching efficiency by eliminating unnecessary\n",
      "           adding. 2.`max_batch_size` specifies the limit of input and\n",
      "           `allowed_batch_sizes` specifies the limit of a task to be processed. API\n",
      "           user can give an input of size 128 when 'max_execution_batch_size'\n",
      "           is 32 -> implementation can split input of 128 into 4 x 32, schedule\n",
      "           concurrent processing, and then return concatenated results corresponding\n",
      "           to 128.\n",
      "        \n",
      "        Returns:\n",
      "          The decorated function will return the unbatched computation output Tensors.\n",
      "    \n",
      "    norm(tensor, ord='euclidean', axis=None, keepdims=None, name=None, keep_dims=None)\n",
      "        Computes the norm of vectors, matrices, and tensors. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This function can compute several different vector norms (the 1-norm, the\n",
      "        Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0) and\n",
      "        matrix norms (Frobenius, 1-norm, 2-norm and inf-norm).\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of types `float32`, `float64`, `complex64`, `complex128`\n",
      "          ord: Order of the norm. Supported values are 'fro', 'euclidean',\n",
      "            `1`, `2`, `np.inf` and any positive real number yielding the corresponding\n",
      "            p-norm. Default is 'euclidean' which is equivalent to Frobenius norm if\n",
      "            `tensor` is a matrix and equivalent to 2-norm for vectors.\n",
      "            Some restrictions apply:\n",
      "              a) The Frobenius norm `fro` is not defined for vectors,\n",
      "              b) If axis is a 2-tuple (matrix norm), only 'euclidean', 'fro', `1`,\n",
      "                 `2`, `np.inf` are supported.\n",
      "            See the description of `axis` on how to compute norms for a batch of\n",
      "            vectors or matrices stored in a tensor.\n",
      "          axis: If `axis` is `None` (the default), the input is considered a vector\n",
      "            and a single vector norm is computed over the entire set of values in the\n",
      "            tensor, i.e. `norm(tensor, ord=ord)` is equivalent to\n",
      "            `norm(reshape(tensor, [-1]), ord=ord)`.\n",
      "            If `axis` is a Python integer, the input is considered a batch of vectors,\n",
      "            and `axis` determines the axis in `tensor` over which to compute vector\n",
      "            norms.\n",
      "            If `axis` is a 2-tuple of Python integers it is considered a batch of\n",
      "            matrices and `axis` determines the axes in `tensor` over which to compute\n",
      "            a matrix norm.\n",
      "            Negative indices are supported. Example: If you are passing a tensor that\n",
      "            can be either a matrix or a batch of matrices at runtime, pass\n",
      "            `axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are\n",
      "            computed.\n",
      "          keepdims: If True, the axis indicated in `axis` are kept with size 1.\n",
      "            Otherwise, the dimensions in `axis` are removed from the output shape.\n",
      "          name: The name of the op.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          output: A `Tensor` of the same type as tensor, containing the vector or\n",
      "            matrix norms. If `keepdims` is True then the rank of output is equal to\n",
      "            the rank of `tensor`. Otherwise, if `axis` is none the output is a scalar,\n",
      "            if `axis` is an integer, the rank of `output` is one less than the rank\n",
      "            of `tensor`, if `axis` is a 2-tuple the rank of `output` is two less\n",
      "            than the rank of `tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `ord` or `axis` is invalid.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Mostly equivalent to numpy.linalg.norm.\n",
      "        Not supported: ord <= 0, 2-norm for matrices, nuclear norm.\n",
      "        Other differences:\n",
      "          a) If axis is `None`, treats the flattened `tensor` as a vector\n",
      "           regardless of rank.\n",
      "          b) Explicitly supports 'euclidean' norm as the default, including for\n",
      "           higher order tensors.\n",
      "        @end_compatibility\n",
      "    \n",
      "    not_equal(x, y, name=None)\n",
      "        Returns the truth value of (x != y) element-wise.\n",
      "        \n",
      "        Performs a [broadcast](\n",
      "        https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) with the\n",
      "        arguments and then an element-wise inequality comparison, returning a Tensor\n",
      "        of boolean values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant(2)\n",
      "        >>> tf.math.not_equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>\n",
      "        \n",
      "        >>> x = tf.constant([2, 4])\n",
      "        >>> y = tf.constant([2, 4])\n",
      "        >>> tf.math.not_equal(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  False])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`.\n",
      "          y: A `tf.Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of type bool with the same size as that of x or y.\n",
      "        \n",
      "        Raises:\n",
      "          `tf.errors.InvalidArgumentError`: If shapes of arguments are incompatible\n",
      "    \n",
      "    numpy_function(func=None, inp=None, Tout=None, stateful=True, name=None)\n",
      "        Wraps a python function and uses it as a TensorFlow op.\n",
      "        \n",
      "        Given a python function `func` wrap this function as an operation in a\n",
      "        `tf.function`. `func` must take numpy arrays as its arguments and\n",
      "        return numpy arrays as its outputs.\n",
      "        \n",
      "        There are two ways to use `tf.numpy_function`.\n",
      "        \n",
      "        ### As a decorator\n",
      "        \n",
      "        When using `tf.numpy_function` as a decorator:\n",
      "        \n",
      "        * you must set `Tout`\n",
      "        * you may set `name`\n",
      "        * you must not set `func` or `inp`\n",
      "        \n",
      "        >>> @tf.numpy_function(Tout=tf.float32)\n",
      "        ... def my_numpy_func(x):\n",
      "        ...   # x will be a numpy array with the contents of the input to the\n",
      "        ...   # tf.function\n",
      "        ...   print(f'executing eagerly, {x=}')\n",
      "        ...   return np.sinh(x)\n",
      "        \n",
      "        The function runs eagerly:\n",
      "        \n",
      "        >>> my_numpy_func(1.0).numpy()\n",
      "        executing eagerly, x=1.0\n",
      "        1.17520\n",
      "        \n",
      "        The behavior doesn't change inside a `tf.function`:\n",
      "        \n",
      "        >>> @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)])\n",
      "        ... def tf_function(input):\n",
      "        ...   y = tf.numpy_function(my_numpy_func, [input], tf.float32)\n",
      "        ...   return y\n",
      "        >>> tf_function(tf.constant(1.)).numpy()\n",
      "        executing eagerly, x=array(1.)\n",
      "        1.17520\n",
      "        \n",
      "        ### Inplace\n",
      "        \n",
      "        This form can be useful if you don't control the function's source,\n",
      "        but it is harder to read.\n",
      "        \n",
      "        Here is the same function with no decorator:\n",
      "        \n",
      "        >>> def my_func(x):\n",
      "        ...   # x will be a numpy array with the contents of the input to the\n",
      "        ...   # tf.function\n",
      "        ...   print(f'executing eagerly, {x=}')\n",
      "        ...   return np.sinh(x)\n",
      "        \n",
      "        To run `tf.numpy_function` in-place, pass the function, its inputs, and the\n",
      "        output type in a single call to `tf.numpy_function`:\n",
      "        \n",
      "        >>> tf.numpy_function(my_func, [tf.constant(1.0)], tf.float32)\n",
      "        executing eagerly, x=array(1.)\n",
      "        1.17520\n",
      "        \n",
      "        ### More info\n",
      "        \n",
      "        Comparison to `tf.py_function`:\n",
      "        `tf.py_function` and `tf.numpy_function` are very similar, except that\n",
      "        `tf.numpy_function` takes numpy arrays, and not `tf.Tensor`s. If you want the\n",
      "        function to contain `tf.Tensors`, and have any TensorFlow operations executed\n",
      "        in the function be differentiable, please use `tf.py_function`.\n",
      "        \n",
      "        Note: We recommend to avoid using `tf.numpy_function` outside of\n",
      "        prototyping and experimentation due to the following known limitations:\n",
      "        \n",
      "        * Calling `tf.numpy_function` will acquire the Python Global Interpreter Lock\n",
      "          (GIL) that allows only one thread to run at any point in time. This will\n",
      "          preclude efficient parallelization and distribution of the execution of the\n",
      "          program. Therefore, you are discouraged to use `tf.numpy_function` outside\n",
      "          of prototyping and experimentation.\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `tf.SavedModel`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.numpy_function()`. If you are using distributed\n",
      "          TensorFlow, you must run a `tf.distribute.Server` in the same process as the\n",
      "          program that calls `tf.numpy_function`  you must pin the created\n",
      "          operation to a device in that server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        * Currently `tf.numpy_function` is not compatible with XLA. Calling\n",
      "          `tf.numpy_function` inside `tf.function(jit_compile=True)` will raise an\n",
      "          error.\n",
      "        \n",
      "        * Since the function takes numpy arrays, you cannot take gradients\n",
      "          through a numpy_function. If you require something that is differentiable,\n",
      "          please consider using tf.py_function.\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function, which accepts `numpy.ndarray` objects as arguments\n",
      "            and returns a list of `numpy.ndarray` objects (or a single\n",
      "            `numpy.ndarray`). This function must accept as many arguments as there are\n",
      "            tensors in `inp`, and these argument types will match the corresponding\n",
      "            `tf.Tensor` objects in `inp`. The returns `numpy.ndarray`s must match the\n",
      "            number and types defined `Tout`. Important Note: Input and output\n",
      "            `numpy.ndarray`s of `func` are not guaranteed to be copies. In some cases\n",
      "            their underlying memory will be shared with the corresponding TensorFlow\n",
      "            tensors. In-place modification or storing `func` input or return values in\n",
      "            python datastructures without explicit (np.)copy can have\n",
      "            non-deterministic consequences.\n",
      "          inp: A list of `tf.Tensor` objects.\n",
      "          Tout: A list or tuple of tensorflow data types or a single tensorflow data\n",
      "            type if there is only one, indicating what `func` returns.\n",
      "          stateful: (Boolean.) Setting this argument to False tells the runtime to\n",
      "            treat the function as stateless, which enables certain optimizations. A\n",
      "            function is stateless when given the same input it will return the same\n",
      "            output and have no side effects; its only purpose is to have a return\n",
      "            value. The behavior for a stateful function with the `stateful` argument\n",
      "            False is undefined. In particular, caution should be taken when mutating\n",
      "            the input arguments as this is a stateful operation.\n",
      "          name: (Optional) A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          * If `func` is `None` this returns a decorator that will ensure the\n",
      "            decorated function will always run with eager execution even if called\n",
      "            from a `tf.function`/`tf.Graph`.\n",
      "          * If used `func` is not `None` this executes `func` with eager execution\n",
      "            and returns the result: A single or list of `tf.Tensor` which `func`\n",
      "            computes.\n",
      "    \n",
      "    one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)\n",
      "        Returns a one-hot tensor.\n",
      "        \n",
      "        See also `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        The locations represented by indices in `indices` take value `on_value`,\n",
      "        while all other locations take value `off_value`.\n",
      "        \n",
      "        `on_value` and `off_value` must have matching data types. If `dtype` is also\n",
      "        provided, they must be the same data type as specified by `dtype`.\n",
      "        \n",
      "        If `on_value` is not provided, it will default to the value `1` with type\n",
      "        `dtype`\n",
      "        \n",
      "        If `off_value` is not provided, it will default to the value `0` with type\n",
      "        `dtype`\n",
      "        \n",
      "        If the input `indices` is rank `N`, the output will have rank `N+1`. The\n",
      "        new axis is created at dimension `axis` (default: the new axis is appended\n",
      "        at the end).\n",
      "        \n",
      "        If `indices` is a scalar the output shape will be a vector of length `depth`\n",
      "        \n",
      "        If `indices` is a vector of length `features`, the output shape will be:\n",
      "        \n",
      "        ```\n",
      "          features x depth if axis == -1\n",
      "          depth x features if axis == 0\n",
      "        ```\n",
      "        \n",
      "        If `indices` is a matrix (batch) with shape `[batch, features]`, the output\n",
      "        shape will be:\n",
      "        \n",
      "        ```\n",
      "          batch x features x depth if axis == -1\n",
      "          batch x depth x features if axis == 1\n",
      "          depth x batch x features if axis == 0\n",
      "        ```\n",
      "        \n",
      "        If `indices` is a RaggedTensor, the 'axis' argument must be positive and refer\n",
      "        to a non-ragged axis. The output will be equivalent to applying 'one_hot' on\n",
      "        the values of the RaggedTensor, and creating a new RaggedTensor from the\n",
      "        result.\n",
      "        \n",
      "        If `dtype` is not provided, it will attempt to assume the data type of\n",
      "        `on_value` or `off_value`, if one or both are passed in. If none of\n",
      "        `on_value`, `off_value`, or `dtype` are provided, `dtype` will default to the\n",
      "        value `tf.float32`.\n",
      "        \n",
      "        Note: If a non-numeric data type output is desired (`tf.string`, `tf.bool`,\n",
      "        etc.), both `on_value` and `off_value` _must_ be provided to `one_hot`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        indices = [0, 1, 2]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth)  # output: [3 x 3]\n",
      "        # [[1., 0., 0.],\n",
      "        #  [0., 1., 0.],\n",
      "        #  [0., 0., 1.]]\n",
      "        \n",
      "        indices = [0, 2, -1, 1]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth,\n",
      "                   on_value=5.0, off_value=0.0,\n",
      "                   axis=-1)  # output: [4 x 3]\n",
      "        # [[5.0, 0.0, 0.0],  # one_hot(0)\n",
      "        #  [0.0, 0.0, 5.0],  # one_hot(2)\n",
      "        #  [0.0, 0.0, 0.0],  # one_hot(-1)\n",
      "        #  [0.0, 5.0, 0.0]]  # one_hot(1)\n",
      "        \n",
      "        indices = [[0, 2], [1, -1]]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth,\n",
      "                   on_value=1.0, off_value=0.0,\n",
      "                   axis=-1)  # output: [2 x 2 x 3]\n",
      "        # [[[1.0, 0.0, 0.0],   # one_hot(0)\n",
      "        #   [0.0, 0.0, 1.0]],  # one_hot(2)\n",
      "        #  [[0.0, 1.0, 0.0],   # one_hot(1)\n",
      "        #   [0.0, 0.0, 0.0]]]  # one_hot(-1)\n",
      "        \n",
      "        indices = tf.ragged.constant([[0, 1], [2]])\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth)  # output: [2 x None x 3]\n",
      "        # [[[1., 0., 0.],\n",
      "        #   [0., 1., 0.]],\n",
      "        #  [[0., 0., 1.]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor` of indices.\n",
      "          depth: A scalar defining the depth of the one hot dimension.\n",
      "          on_value: A scalar defining the value to fill in output when `indices[j]\n",
      "            = i`. (default: 1)\n",
      "          off_value: A scalar defining the value to fill in output when `indices[j]\n",
      "            != i`. (default: 0)\n",
      "          axis: The axis to fill (default: -1, a new inner-most axis).\n",
      "          dtype: The data type of the output tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: The one-hot tensor.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If dtype of either `on_value` or `off_value` don't match `dtype`\n",
      "          TypeError: If dtype of `on_value` and `off_value` don't match one another\n",
      "    \n",
      "    ones(shape, dtype=tf.float32, name=None, layout=None)\n",
      "        Creates a tensor with all elements set to one (1).\n",
      "        \n",
      "        See also `tf.ones_like`, `tf.zeros`, `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        This operation returns a tensor of type `dtype` with shape `shape` and\n",
      "        all elements set to one.\n",
      "        \n",
      "        >>> tf.ones([3, 4], tf.int32)\n",
      "        <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
      "        array([[1, 1, 1, 1],\n",
      "               [1, 1, 1, 1],\n",
      "               [1, 1, 1, 1]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          shape: A `list` of integers, a `tuple` of integers, or a 1-D `Tensor` of\n",
      "            type `int32`.\n",
      "          dtype: Optional DType of an element in the resulting `Tensor`. Default is\n",
      "            `tf.float32`.\n",
      "          name: Optional string. A name for the operation.\n",
      "          layout: Optional, `tf.experimental.dtensor.Layout`. If provided, the result\n",
      "            is a [DTensor](https://www.tensorflow.org/guide/dtensor_overview) with the\n",
      "            provided layout.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to one (1).\n",
      "    \n",
      "    ones_like(tensor, dtype=None, name=None, optimize=True)\n",
      "        Creates a tensor with all elements set to 1.\n",
      "        \n",
      "        See also `tf.ones`.\n",
      "        \n",
      "        Given a single tensor (`tensor`), this operation returns a tensor of the same\n",
      "        type and shape as `tensor` with all elements set to 1. Optionally, you can\n",
      "        specify a new type (`dtype`) for the returned tensor.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.ones_like(tensor)  # [[1, 1, 1], [1, 1, 1]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          dtype: A type for the returned `Tensor`. Must be `float32`, `float64`,\n",
      "            `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `complex64`,\n",
      "            `complex128` or `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "          optimize: if true, attempt to statically determine the shape of 'tensor' and\n",
      "            encode it as a constant.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to 1.\n",
      "    \n",
      "    op_scope(values, name, default_name=None) -> collections.abc.Iterator[typing.Optional[str]]\n",
      "        DEPRECATED. Same as name_scope above, just different argument order.\n",
      "    \n",
      "    pad(tensor, paddings, mode='CONSTANT', name=None, constant_values=0)\n",
      "        Pads a tensor.\n",
      "        \n",
      "        This operation pads a `tensor` according to the `paddings` you specify.\n",
      "        `paddings` is an integer tensor with shape `[n, 2]`, where n is the rank of\n",
      "        `tensor`. For each dimension D of `input`, `paddings[D, 0]` indicates how\n",
      "        many values to add before the contents of `tensor` in that dimension, and\n",
      "        `paddings[D, 1]` indicates how many values to add after the contents of\n",
      "        `tensor` in that dimension. If `mode` is \"REFLECT\" then both `paddings[D, 0]`\n",
      "        and `paddings[D, 1]` must be no greater than `tensor.dim_size(D) - 1`. If\n",
      "        `mode` is \"SYMMETRIC\" then both `paddings[D, 0]` and `paddings[D, 1]` must be\n",
      "        no greater than `tensor.dim_size(D)`.\n",
      "        \n",
      "        The padded size of each dimension D of the output is:\n",
      "        \n",
      "        `paddings[D, 0] + tensor.dim_size(D) + paddings[D, 1]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        paddings = tf.constant([[1, 1,], [2, 2]])\n",
      "        # 'constant_values' is 0.\n",
      "        # rank of 't' is 2.\n",
      "        tf.pad(t, paddings, \"CONSTANT\")  # [[0, 0, 0, 0, 0, 0, 0],\n",
      "                                         #  [0, 0, 1, 2, 3, 0, 0],\n",
      "                                         #  [0, 0, 4, 5, 6, 0, 0],\n",
      "                                         #  [0, 0, 0, 0, 0, 0, 0]]\n",
      "        \n",
      "        tf.pad(t, paddings, \"REFLECT\")  # [[6, 5, 4, 5, 6, 5, 4],\n",
      "                                        #  [3, 2, 1, 2, 3, 2, 1],\n",
      "                                        #  [6, 5, 4, 5, 6, 5, 4],\n",
      "                                        #  [3, 2, 1, 2, 3, 2, 1]]\n",
      "        \n",
      "        tf.pad(t, paddings, \"SYMMETRIC\")  # [[2, 1, 1, 2, 3, 3, 2],\n",
      "                                          #  [2, 1, 1, 2, 3, 3, 2],\n",
      "                                          #  [5, 4, 4, 5, 6, 6, 5],\n",
      "                                          #  [5, 4, 4, 5, 6, 6, 5]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          paddings: A `Tensor` of type `int32`.\n",
      "          mode: One of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\" (case-insensitive)\n",
      "          name: A name for the operation (optional).\n",
      "          constant_values: In \"CONSTANT\" mode, the scalar pad value to use. Must be\n",
      "            same type as `tensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When mode is not one of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\".\n",
      "    \n",
      "    parallel_stack(values, name='parallel_stack')\n",
      "        Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor in parallel.\n",
      "        \n",
      "        Requires that the shape of inputs be known at graph construction time.\n",
      "        \n",
      "        Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "        each tensor in `values`, by packing them along the first dimension.\n",
      "        Given a list of length `N` of tensors of shape `(A, B, C)`; the `output`\n",
      "        tensor will have the shape `(N, A, B, C)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([1, 4])\n",
      "        y = tf.constant([2, 5])\n",
      "        z = tf.constant([3, 6])\n",
      "        tf.parallel_stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]]\n",
      "        ```\n",
      "        \n",
      "        The difference between `stack` and `parallel_stack` is that `stack` requires\n",
      "        all the inputs be computed before the operation will begin but doesn't require\n",
      "        that the input shapes be known during graph construction.\n",
      "        \n",
      "        `parallel_stack` will copy pieces of the input into the output as they become\n",
      "        available, in some situations this can provide a performance benefit.\n",
      "        \n",
      "        Unlike `stack`, `parallel_stack` does NOT support backpropagation.\n",
      "        \n",
      "        This is the opposite of unstack.  The numpy equivalent is\n",
      "        \n",
      "            tf.parallel_stack([x, y, z]) = np.asarray([x, y, z])\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        parallel_stack is not compatible with eager execution.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects with the same shape and type.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: A stacked `Tensor` with the same type as `values`.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if executed in eager mode.\n",
      "    \n",
      "    parse_example(serialized, features, name=None, example_names=None)\n",
      "        Parses `Example` protos into a `dict` of tensors.\n",
      "        \n",
      "        Parses a number of serialized [`Example`](https://www.tensorflow.org/code/tensorflow/core/example/example.proto)\n",
      "        protos given in `serialized`. We refer to `serialized` as a batch with\n",
      "        `batch_size` many entries of individual `Example` protos.\n",
      "        \n",
      "        `example_names` may contain descriptive names for the corresponding serialized\n",
      "        protos. These may be useful for debugging purposes, but they have no effect on\n",
      "        the output. If not `None`, `example_names` must be the same length as\n",
      "        `serialized`.\n",
      "        \n",
      "        This op parses serialized examples into a dictionary mapping keys to `Tensor`\n",
      "        `SparseTensor`, and `RaggedTensor` objects. `features` is a Mapping from keys\n",
      "        to `VarLenFeature`, `SparseFeature`, `RaggedFeature`, and `FixedLenFeature`\n",
      "        objects. Each `VarLenFeature` and `SparseFeature` is mapped to a\n",
      "        `SparseTensor`; each `FixedLenFeature` is mapped to a `Tensor`; and each\n",
      "        `RaggedFeature` is mapped to a `RaggedTensor`.\n",
      "        \n",
      "        Each `VarLenFeature` maps to a `SparseTensor` of the specified type\n",
      "        representing a ragged matrix. Its indices are `[batch, index]` where `batch`\n",
      "        identifies the example in `serialized`, and `index` is the value's index in\n",
      "        the list of values associated with that feature and example.\n",
      "        \n",
      "        Each `SparseFeature` maps to a `SparseTensor` of the specified type\n",
      "        representing a Tensor of `dense_shape` `[batch_size] + SparseFeature.size`.\n",
      "        Its `values` come from the feature in the examples with key `value_key`.\n",
      "        A `values[i]` comes from a position `k` in the feature of an example at batch\n",
      "        entry `batch`. This positional information is recorded in `indices[i]` as\n",
      "        `[batch, index_0, index_1, ...]` where `index_j` is the `k-th` value of\n",
      "        the feature in the example at with key `SparseFeature.index_key[j]`.\n",
      "        In other words, we split the indices (except the first index indicating the\n",
      "        batch entry) of a `SparseTensor` by dimension into different features of the\n",
      "        `Example`. Due to its complexity a `VarLenFeature` should be preferred over a\n",
      "        `SparseFeature` whenever possible.\n",
      "        \n",
      "        Each `FixedLenFeature` `df` maps to a `Tensor` of the specified type (or\n",
      "        `tf.float32` if not specified) and shape `(serialized.size(),) + df.shape`.\n",
      "        \n",
      "        `FixedLenFeature` entries with a `default_value` are optional. With no default\n",
      "        value, we will fail if that `Feature` is missing from any example in\n",
      "        `serialized`.\n",
      "        \n",
      "        Each `FixedLenSequenceFeature` `df` maps to a `Tensor` of the specified type\n",
      "        (or `tf.float32` if not specified) and shape\n",
      "        `(serialized.size(), None) + df.shape`.\n",
      "        All examples in `serialized` will be padded with `default_value` along the\n",
      "        second dimension.\n",
      "        \n",
      "        Each `RaggedFeature` maps to a `RaggedTensor` of the specified type.  It\n",
      "        is formed by stacking the `RaggedTensor` for each example, where the\n",
      "        `RaggedTensor` for each individual example is constructed using the tensors\n",
      "        specified by `RaggedTensor.values_key` and `RaggedTensor.partition`.  See\n",
      "        the `tf.io.RaggedFeature` documentation for details and examples.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        For example, if one expects a `tf.float32` `VarLenFeature` `ft` and three\n",
      "        serialized `Example`s are provided:\n",
      "        \n",
      "        ```\n",
      "        serialized = [\n",
      "          features\n",
      "            { feature { key: \"ft\" value { float_list { value: [1.0, 2.0] } } } },\n",
      "          features\n",
      "            { feature []},\n",
      "          features\n",
      "            { feature { key: \"ft\" value { float_list { value: [3.0] } } }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        then the output will look like:\n",
      "        \n",
      "        ```python\n",
      "        {\"ft\": SparseTensor(indices=[[0, 0], [0, 1], [2, 0]],\n",
      "                            values=[1.0, 2.0, 3.0],\n",
      "                            dense_shape=(3, 2)) }\n",
      "        ```\n",
      "        \n",
      "        If instead a `FixedLenSequenceFeature` with `default_value = -1.0` and\n",
      "        `shape=[]` is used then the output will look like:\n",
      "        \n",
      "        ```python\n",
      "        {\"ft\": [[1.0, 2.0], [3.0, -1.0]]}\n",
      "        ```\n",
      "        \n",
      "        Given two `Example` input protos in `serialized`:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"kw\" value { bytes_list { value: [ \"knit\", \"big\" ] } } }\n",
      "            feature { key: \"gps\" value { float_list { value: [] } } }\n",
      "          },\n",
      "          features {\n",
      "            feature { key: \"kw\" value { bytes_list { value: [ \"emmy\" ] } } }\n",
      "            feature { key: \"dank\" value { int64_list { value: [ 42 ] } } }\n",
      "            feature { key: \"gps\" value { } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        And arguments\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"kw\": VarLenFeature(tf.string),\n",
      "            \"dank\": VarLenFeature(tf.int64),\n",
      "            \"gps\": VarLenFeature(tf.float32),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        Then the output is a dictionary:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"kw\": SparseTensor(\n",
      "              indices=[[0, 0], [0, 1], [1, 0]],\n",
      "              values=[\"knit\", \"big\", \"emmy\"]\n",
      "              dense_shape=[2, 2]),\n",
      "          \"dank\": SparseTensor(\n",
      "              indices=[[1, 0]],\n",
      "              values=[42],\n",
      "              dense_shape=[2, 1]),\n",
      "          \"gps\": SparseTensor(\n",
      "              indices=[],\n",
      "              values=[],\n",
      "              dense_shape=[2, 0]),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        For dense results in two serialized `Example`s:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"age\" value { int64_list { value: [ 0 ] } } }\n",
      "            feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\n",
      "           },\n",
      "           features {\n",
      "            feature { key: \"age\" value { int64_list { value: [] } } }\n",
      "            feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        We can use arguments:\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"age\": FixedLenFeature([], dtype=tf.int64, default_value=-1),\n",
      "            \"gender\": FixedLenFeature([], dtype=tf.string),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        And the expected output is:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"age\": [[0], [-1]],\n",
      "          \"gender\": [[\"f\"], [\"f\"]],\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        An alternative to `VarLenFeature` to obtain a `SparseTensor` is\n",
      "        `SparseFeature`. For example, given two `Example` input protos in\n",
      "        `serialized`:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"val\" value { float_list { value: [ 0.5, -1.0 ] } } }\n",
      "            feature { key: \"ix\" value { int64_list { value: [ 3, 20 ] } } }\n",
      "          },\n",
      "          features {\n",
      "            feature { key: \"val\" value { float_list { value: [ 0.0 ] } } }\n",
      "            feature { key: \"ix\" value { int64_list { value: [ 42 ] } } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        And arguments\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"sparse\": SparseFeature(\n",
      "                index_key=\"ix\", value_key=\"val\", dtype=tf.float32, size=100),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        Then the output is a dictionary:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"sparse\": SparseTensor(\n",
      "              indices=[[0, 3], [0, 20], [1, 42]],\n",
      "              values=[0.5, -1.0, 0.0]\n",
      "              dense_shape=[2, 100]),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        See the `tf.io.RaggedFeature` documentation for examples showing how\n",
      "        `RaggedFeature` can be used to obtain `RaggedTensor`s.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A vector (1-D Tensor) of strings, a batch of binary\n",
      "            serialized `Example` protos.\n",
      "          features: A mapping of feature keys to `FixedLenFeature`,\n",
      "            `VarLenFeature`, `SparseFeature`, and `RaggedFeature` values.\n",
      "          example_names: A vector (1-D Tensor) of strings (optional), the names of\n",
      "            the serialized protos in the batch.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `dict` mapping feature keys to `Tensor`, `SparseTensor`, and\n",
      "          `RaggedTensor` values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_single_example(serialized, features, name=None, example_names=None)\n",
      "        Parses a single `Example` proto.\n",
      "        \n",
      "        Similar to `parse_example`, except:\n",
      "        \n",
      "        For dense tensors, the returned `Tensor` is identical to the output of\n",
      "        `parse_example`, except there is no batch dimension, the output shape is the\n",
      "        same as the shape given in `dense_shape`.\n",
      "        \n",
      "        For `SparseTensor`s, the first (batch) column of the indices matrix is removed\n",
      "        (the indices matrix is a column vector), the values vector is unchanged, and\n",
      "        the first (`batch_size`) entry of the shape vector is removed (it is now a\n",
      "        single element vector).\n",
      "        \n",
      "        One might see performance advantages by batching `Example` protos with\n",
      "        `parse_example` instead of using this function directly.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A scalar string Tensor, a single serialized Example.\n",
      "          features: A mapping of feature keys to `FixedLenFeature` or\n",
      "            `VarLenFeature` values.\n",
      "          name: A name for this operation (optional).\n",
      "          example_names: (Optional) A scalar string Tensor, the associated name.\n",
      "        \n",
      "        Returns:\n",
      "          A `dict` mapping feature keys to `Tensor` and `SparseTensor` values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_single_sequence_example(serialized, context_features=None, sequence_features=None, example_name=None, name=None)\n",
      "        Parses a single `SequenceExample` proto.\n",
      "        \n",
      "        Parses a single serialized [`SequenceExample`](https://www.tensorflow.org/code/tensorflow/core/example/example.proto)\n",
      "        proto given in `serialized`.\n",
      "        \n",
      "        This op parses a serialized sequence example into a tuple of dictionaries,\n",
      "        each mapping keys to `Tensor` and `SparseTensor` objects.\n",
      "        The first dictionary contains mappings for keys appearing in\n",
      "        `context_features`, and the second dictionary contains mappings for keys\n",
      "        appearing in `sequence_features`.\n",
      "        \n",
      "        At least one of `context_features` and `sequence_features` must be provided\n",
      "        and non-empty.\n",
      "        \n",
      "        The `context_features` keys are associated with a `SequenceExample` as a\n",
      "        whole, independent of time / frame.  In contrast, the `sequence_features` keys\n",
      "        provide a way to access variable-length data within the `FeatureList` section\n",
      "        of the `SequenceExample` proto.  While the shapes of `context_features` values\n",
      "        are fixed with respect to frame, the frame dimension (the first dimension)\n",
      "        of `sequence_features` values may vary between `SequenceExample` protos,\n",
      "        and even between `feature_list` keys within the same `SequenceExample`.\n",
      "        \n",
      "        `context_features` contains `VarLenFeature`, `RaggedFeature`, and\n",
      "        `FixedLenFeature` objects. Each `VarLenFeature` is mapped to a `SparseTensor`;\n",
      "        each `RaggedFeature` is mapped to a `RaggedTensor`; and each `FixedLenFeature`\n",
      "        is mapped to a `Tensor`, of the specified type, shape, and default value.\n",
      "        \n",
      "        `sequence_features` contains `VarLenFeature`, `RaggedFeature`, and\n",
      "        `FixedLenSequenceFeature` objects. Each `VarLenFeature` is mapped to a\n",
      "        `SparseTensor`; each `RaggedFeature` is mapped to a `RaggedTensor`; and each\n",
      "        `FixedLenSequenceFeature` is mapped to a `Tensor`, each of the specified type.\n",
      "        The shape will be `(T,) + df.dense_shape` for `FixedLenSequenceFeature` `df`,\n",
      "        where `T` is the length of the associated `FeatureList` in the\n",
      "        `SequenceExample`. For instance, `FixedLenSequenceFeature([])` yields a scalar\n",
      "        1-D `Tensor` of static shape `[None]` and dynamic shape `[T]`, while\n",
      "        `FixedLenSequenceFeature([k])` (for `int k >= 1`) yields a 2-D matrix `Tensor`\n",
      "        of static shape `[None, k]` and dynamic shape `[T, k]`.\n",
      "        \n",
      "        Each `SparseTensor` corresponding to `sequence_features` represents a ragged\n",
      "        vector.  Its indices are `[time, index]`, where `time` is the `FeatureList`\n",
      "        entry and `index` is the value's index in the list of values associated with\n",
      "        that time.\n",
      "        \n",
      "        `FixedLenFeature` entries with a `default_value` and `FixedLenSequenceFeature`\n",
      "        entries with `allow_missing=True` are optional; otherwise, we will fail if\n",
      "        that `Feature` or `FeatureList` is missing from any example in `serialized`.\n",
      "        \n",
      "        `example_name` may contain a descriptive name for the corresponding serialized\n",
      "        proto. This may be useful for debugging purposes, but it has no effect on the\n",
      "        output. If not `None`, `example_name` must be a scalar.\n",
      "        \n",
      "        Note that the batch version of this function, `tf.parse_sequence_example`,\n",
      "        is written for better memory efficiency and will be faster on large\n",
      "        `SequenceExample`s.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A scalar (0-D Tensor) of type string, a single binary\n",
      "            serialized `SequenceExample` proto.\n",
      "          context_features: A mapping of feature keys to `FixedLenFeature` or\n",
      "            `VarLenFeature` or `RaggedFeature` values. These features are associated\n",
      "            with a `SequenceExample` as a whole.\n",
      "          sequence_features: A mapping of feature keys to\n",
      "            `FixedLenSequenceFeature` or `VarLenFeature` or `RaggedFeature` values.\n",
      "            These features are associated with data within the `FeatureList` section\n",
      "            of the `SequenceExample` proto.\n",
      "          example_name: A scalar (0-D Tensor) of strings (optional), the name of\n",
      "            the serialized proto.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of two `dict`s, each mapping keys to `Tensor`s and `SparseTensor`s\n",
      "          and `RaggedTensor`s.\n",
      "        \n",
      "          * The first dict contains the context key/values.\n",
      "          * The second dict contains the feature_list key/values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_tensor(serialized: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], out_type: ~TV_ParseTensor_out_type, name=None) -> Annotated[Any, ~TV_ParseTensor_out_type]\n",
      "        Transforms a serialized tensorflow.TensorProto proto into a Tensor.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A `Tensor` of type `string`.\n",
      "            A scalar string containing a serialized TensorProto proto.\n",
      "          out_type: A `tf.DType`.\n",
      "            The type of the serialized tensor.  The provided type must match the\n",
      "            type of the serialized tensor and no implicit conversion will take place.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    placeholder(dtype, shape=None, name=None)\n",
      "        Inserts a placeholder for a tensor that will be always fed.\n",
      "        \n",
      "        **Important**: This tensor will produce an error if evaluated. Its value must\n",
      "        be fed using the `feed_dict` optional argument to `Session.run()`,\n",
      "        `Tensor.eval()`, or `Operation.run()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.compat.v1.placeholder(tf.float32, shape=(1024, 1024))\n",
      "        y = tf.matmul(x, x)\n",
      "        \n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "        \n",
      "          rand_array = np.random.rand(1024, 1024)\n",
      "          print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          dtype: The type of elements in the tensor to be fed.\n",
      "          shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "            specified, you can feed a tensor of any shape.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that may be used as a handle for feeding a value, but not\n",
      "          evaluated directly.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if eager execution is enabled\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is not compatible with eager execution and `tf.function`. To migrate\n",
      "        to TF2, rewrite the code to be compatible with eager execution. Check the\n",
      "        [migration\n",
      "        guide](https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls)\n",
      "        on replacing `Session.run` calls. In TF2, you can just pass tensors directly\n",
      "        into ops and layers. If you want to explicitly set up your inputs, also see\n",
      "        [Keras functional API](https://www.tensorflow.org/guide/keras/functional) on\n",
      "        how to use `tf.keras.Input` to replace `tf.compat.v1.placeholder`.\n",
      "        `tf.function` arguments also do the job of `tf.compat.v1.placeholder`.\n",
      "        For more details please read [Better\n",
      "        performance with tf.function](https://www.tensorflow.org/guide/function).\n",
      "        @end_compatibility\n",
      "    \n",
      "    placeholder_with_default(input, shape, name=None)\n",
      "        A placeholder op that passes through `input` when its output is not fed.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is strongly discouraged for use with eager execution and\n",
      "        `tf.function`. The primary use of this API is for testing computation wrapped\n",
      "        within a `tf.function` where the input tensors might not have statically known\n",
      "        fully-defined shapes. The same can be achieved by creating a\n",
      "        [concrete function](\n",
      "        https://www.tensorflow.org/guide/function#obtaining_concrete_functions)\n",
      "        from the `tf.function` with a `tf.TensorSpec` input which has partially\n",
      "        defined shapes. For example, the code\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f():\n",
      "        ...   x = tf.compat.v1.placeholder_with_default(\n",
      "        ...       tf.constant([[1., 2., 3.], [4., 5., 6.]]), [None, 3])\n",
      "        ...   y = tf.constant([[1.],[2.], [3.]])\n",
      "        ...   z = tf.matmul(x, y)\n",
      "        ...   assert z.shape[0] == None\n",
      "        ...   assert z.shape[1] == 1\n",
      "        \n",
      "        >>> f()\n",
      "        \n",
      "        can easily be replaced by\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def f(x):\n",
      "        ...   y = tf.constant([[1.],[2.], [3.]])\n",
      "        ...   z = tf.matmul(x, y)\n",
      "        ...   assert z.shape[0] == None\n",
      "        ...   assert z.shape[1] == 1\n",
      "        \n",
      "        >>> g = f.get_concrete_function(tf.TensorSpec([None, 3]))\n",
      "        \n",
      "        You can learn more about `tf.function` at [Better\n",
      "        performance with tf.function](https://www.tensorflow.org/guide/function).\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The default value to produce when output is not fed.\n",
      "          shape: A `tf.TensorShape` or list of `int`s. The (possibly partial) shape of\n",
      "            the tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    polygamma(a: typing.Annotated[_any, ~TV_Polygamma_T], x: typing.Annotated[_any, ~TV_Polygamma_T], name=None) -> typing.Annotated[_any, ~TV_Polygamma_T]\n",
      "        Compute the polygamma function \\\\(\\psi^{(n)}(x)\\\\).\n",
      "        \n",
      "        The polygamma function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(\\psi^{(a)}(x) = \\frac{d^a}{dx^a} \\psi(x)\\\\)\n",
      "        \n",
      "        where \\\\(\\psi(x)\\\\) is the digamma function.\n",
      "        The polygamma function is defined only for non-negative integer orders \\\\a\\\\.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    pow(x, y, name=None)\n",
      "        Computes the power of one value to another.\n",
      "        \n",
      "        Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "        corresponding elements in `x` and `y`. For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[2, 2], [3, 3]])\n",
      "        y = tf.constant([[8, 16], [2, 3]])\n",
      "        tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "            `complex64`, or `complex128`.\n",
      "          y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "            `complex64`, or `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.\n",
      "    \n",
      "    print = print_v2(*inputs, **kwargs)\n",
      "        Print the specified inputs.\n",
      "        \n",
      "        A TensorFlow operator that prints the specified inputs to a desired\n",
      "        output stream or logging level. The inputs may be dense or sparse Tensors,\n",
      "        primitive python objects, data structures that contain tensors, and printable\n",
      "        Python objects. Printed tensors will recursively show the first and last\n",
      "        elements of each dimension to summarize.\n",
      "        \n",
      "        Example:\n",
      "          Single-input usage:\n",
      "        \n",
      "          ```python\n",
      "          tensor = tf.range(10)\n",
      "          tf.print(tensor, output_stream=sys.stderr)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1 2 ... 7 8 9]\" to sys.stderr)\n",
      "        \n",
      "          Multi-input usage:\n",
      "        \n",
      "          ```python\n",
      "          tensor = tf.range(10)\n",
      "          tf.print(\"tensors:\", tensor, {2: tensor * 2}, output_stream=sys.stdout)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"tensors: [0 1 2 ... 7 8 9] {2: [0 2 4 ... 14 16 18]}\" to\n",
      "          sys.stdout)\n",
      "        \n",
      "          Changing the input separator:\n",
      "          ```python\n",
      "          tensor_a = tf.range(2)\n",
      "          tensor_b = tensor_a * 2\n",
      "          tf.print(tensor_a, tensor_b, output_stream=sys.stderr, sep=',')\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1],[0 2]\" to sys.stderr)\n",
      "        \n",
      "          Usage in a `tf.function`:\n",
      "        \n",
      "          ```python\n",
      "          @tf.function\n",
      "          def f():\n",
      "              tensor = tf.range(10)\n",
      "              tf.print(tensor, output_stream=sys.stderr)\n",
      "              return tensor\n",
      "        \n",
      "          range_tensor = f()\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1 2 ... 7 8 9]\" to sys.stderr)\n",
      "        \n",
      "        *Compatibility usage in TF 1.x graphs*:\n",
      "        \n",
      "          In graphs manually created outside of `tf.function`, this method returns\n",
      "          the created TF operator that prints the data. To make sure the\n",
      "          operator runs, users need to pass the produced op to\n",
      "          `tf.compat.v1.Session`'s run method, or to use the op as a control\n",
      "          dependency for executed ops by specifying\n",
      "          `with tf.compat.v1.control_dependencies([print_op])`.\n",
      "        \n",
      "          ```python\n",
      "          tf.compat.v1.disable_v2_behavior()  # for TF1 compatibility only\n",
      "        \n",
      "          sess = tf.compat.v1.Session()\n",
      "          with sess.as_default():\n",
      "            tensor = tf.range(10)\n",
      "            print_op = tf.print(\"tensors:\", tensor, {2: tensor * 2},\n",
      "                                output_stream=sys.stdout)\n",
      "            with tf.control_dependencies([print_op]):\n",
      "              tripled_tensor = tensor * 3\n",
      "        \n",
      "            sess.run(tripled_tensor)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"tensors: [0 1 2 ... 7 8 9] {2: [0 2 4 ... 14 16 18]}\" to\n",
      "          sys.stdout)\n",
      "        \n",
      "        Note: In Jupyter notebooks and colabs, `tf.print` prints to the notebook\n",
      "          cell outputs. It will not write to the notebook kernel's console logs.\n",
      "        \n",
      "        Args:\n",
      "          *inputs: Positional arguments that are the inputs to print. Inputs in the\n",
      "            printed output will be separated by spaces. Inputs may be python\n",
      "            primitives, tensors, data structures such as dicts and lists that may\n",
      "            contain tensors (with the data structures possibly nested in arbitrary\n",
      "            ways), and printable python objects.\n",
      "          output_stream: The output stream, logging level, or file to print to.\n",
      "            Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info,\n",
      "            tf.compat.v1.logging.warning, tf.compat.v1.logging.error,\n",
      "            absl.logging.info, absl.logging.warning and absl.logging.error are also\n",
      "            supported. To print to a file, pass a string started with \"file://\"\n",
      "            followed by the file path, e.g., \"file:///tmp/foo.out\".\n",
      "          summarize: The first and last `summarize` elements within each dimension are\n",
      "            recursively printed per Tensor. If None, then the first 3 and last 3\n",
      "            elements of each dimension are printed for each tensor. If set to -1, it\n",
      "            will print all elements of every tensor.\n",
      "          sep: The string to use to separate the inputs. Defaults to \" \".\n",
      "          end: End character that is appended at the end the printed string. Defaults\n",
      "            to the newline character.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          None when executing eagerly. During graph tracing this returns\n",
      "          a TF operator that prints the specified inputs in the specified output\n",
      "          stream or logging level. This operator will be automatically executed\n",
      "          except inside of `tf.compat.v1` graphs and sessions.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If an unsupported output stream is specified.\n",
      "    \n",
      "    py_func(func, inp, Tout, stateful=True, name=None)\n",
      "        Wraps a python function and uses it as a TensorFlow op.\n",
      "        \n",
      "        Given a python function `func`, which takes numpy arrays as its\n",
      "        arguments and returns numpy arrays as its outputs, wrap this function as an\n",
      "        operation in a TensorFlow graph. The following snippet constructs a simple\n",
      "        TensorFlow graph that invokes the `np.sinh()` NumPy function as a operation\n",
      "        in the graph:\n",
      "        \n",
      "        ```python\n",
      "        def my_func(x):\n",
      "          # x will be a numpy array with the contents of the placeholder below\n",
      "          return np.sinh(x)\n",
      "        input = tf.compat.v1.placeholder(tf.float32)\n",
      "        y = tf.compat.v1.py_func(my_func, [input], tf.float32)\n",
      "        ```\n",
      "        \n",
      "        **N.B.** The `tf.compat.v1.py_func()` operation has the following known\n",
      "        limitations:\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `GraphDef`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.compat.v1.py_func()`. If you are using distributed\n",
      "          TensorFlow, you\n",
      "          must run a `tf.distribute.Server` in the same process as the program that\n",
      "          calls\n",
      "          `tf.compat.v1.py_func()` and you must pin the created operation to a device\n",
      "          in that\n",
      "          server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        Note: It produces tensors of unknown shape and rank as shape inference\n",
      "          does not work on arbitrary Python code.\n",
      "          If you need the shape, you need to set it based on statically\n",
      "          available information.\n",
      "        \n",
      "          E.g.\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          import numpy as np\n",
      "        \n",
      "          def make_synthetic_data(i):\n",
      "              return np.cast[np.uint8](i) * np.ones([20,256,256,3],\n",
      "                      dtype=np.float32) / 10.\n",
      "        \n",
      "          def preprocess_fn(i):\n",
      "              ones = tf.py_function(make_synthetic_data,[i],tf.float32)\n",
      "              ones.set_shape(tf.TensorShape([None, None, None, None]))\n",
      "              ones = tf.image.resize(ones, [224,224])\n",
      "              return ones\n",
      "        \n",
      "          ds = tf.data.Dataset.range(10)\n",
      "          ds = ds.map(preprocess_fn)\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function, which accepts `ndarray` objects as arguments and\n",
      "            returns a list of `ndarray` objects (or a single `ndarray`). This function\n",
      "            must accept as many arguments as there are tensors in `inp`, and these\n",
      "            argument types will match the corresponding `tf.Tensor` objects in `inp`.\n",
      "            The returns `ndarray`s must match the number and types defined `Tout`.\n",
      "            Important Note: Input and output numpy `ndarray`s of `func` are not\n",
      "            guaranteed to be copies. In some cases their underlying memory will be\n",
      "            shared with the corresponding TensorFlow tensors. In-place modification or\n",
      "            storing `func` input or return values in python datastructures without\n",
      "            explicit (np.)copy can have non-deterministic consequences.\n",
      "          inp: A list of `Tensor` objects.\n",
      "          Tout: A list or tuple of tensorflow data types or a single tensorflow data\n",
      "            type if there is only one, indicating what `func` returns.\n",
      "          stateful: (Boolean.) If True, the function should be considered stateful. If\n",
      "            a function is stateless, when given the same input it will return the same\n",
      "            output and have no observable side effects. Optimizations such as common\n",
      "            sub-expression elimination are only performed on stateless operations.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` or a single `Tensor` which `func` computes.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but `tf.numpy_function` is a\n",
      "        near-exact replacement, just drop the `stateful` argument (all\n",
      "        `tf.numpy_function` calls are considered stateful). It is compatible with\n",
      "        eager execution and `tf.function`.\n",
      "        \n",
      "        `tf.py_function` is a close but not an exact replacement, passing TensorFlow\n",
      "        tensors to the wrapped function instead of NumPy arrays, which provides\n",
      "        gradients and can take advantage of accelerators.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> def fn_using_numpy(x):\n",
      "        ...   x[0] = 0.\n",
      "        ...   return x\n",
      "        >>> tf.compat.v1.py_func(fn_using_numpy, inp=[tf.constant([1., 2.])],\n",
      "        ...     Tout=tf.float32, stateful=False)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 2.], dtype=float32)>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.numpy_function(fn_using_numpy, inp=[tf.constant([1., 2.])],\n",
      "        ...     Tout=tf.float32)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 2.], dtype=float32)>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    py_function = eager_py_func(func=None, inp=None, Tout=None, name=None)\n",
      "        Wraps a python function into a TensorFlow op that executes it eagerly.\n",
      "        \n",
      "        Using `tf.py_function` inside a `tf.function` allows you to run a python\n",
      "        function using eager execution, inside the `tf.function`'s graph.\n",
      "        This has two main effects:\n",
      "        \n",
      "        1. This allows you to use nofunc=None, inp=None, Tout=None tensorflow code\n",
      "        inside your `tf.function`.\n",
      "        2. It allows you to run python control logic in a `tf.function` without\n",
      "        relying on `tf.autograph` to convert the code to use tensorflow control logic\n",
      "        (tf.cond, tf.while_loop).\n",
      "        \n",
      "        Both of these features can be useful for debugging.\n",
      "        \n",
      "        Since `tf.py_function` operates on `Tensor`s it is still\n",
      "        differentiable (once).\n",
      "        \n",
      "        There are two ways to use this function:\n",
      "        \n",
      "        ### As a decorator\n",
      "        \n",
      "        Use `tf.py_function` as a decorator to ensure the function always runs\n",
      "        eagerly.\n",
      "        \n",
      "        When using `tf.py_function` as a decorator:\n",
      "        \n",
      "        * you must set `Tout`\n",
      "        * you may set `name`\n",
      "        * you must not set `func` or `inp`\n",
      "        \n",
      "        For example, you might use `tf.py_function` to\n",
      "        implement the log huber function.\n",
      "        \n",
      "        >>> @tf.py_function(Tout=tf.float32)\n",
      "        ... def py_log_huber(x, m):\n",
      "        ...   print('Running with eager execution.')\n",
      "        ...   if tf.abs(x) <= m:\n",
      "        ...     return x**2\n",
      "        ...   else:\n",
      "        ...     return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))\n",
      "        \n",
      "        Under eager execution the function operates normally:\n",
      "        \n",
      "        >>> x = tf.constant(1.0)\n",
      "        >>> m = tf.constant(2.0)\n",
      "        >>>\n",
      "        >>> print(py_log_huber(x,m).numpy())\n",
      "        Running with eager execution.\n",
      "        1.0\n",
      "        \n",
      "        Inside a `tf.function` the `tf.py_function` is not converted to a `tf.Graph`.:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def tf_wrapper(x):\n",
      "        ...   print('Tracing.')\n",
      "        ...   m = tf.constant(2.0)\n",
      "        ...   return py_log_huber(x,m)\n",
      "        \n",
      "        The `tf.py_function` only executes eagerly, and only when the `tf.function`\n",
      "        is called:\n",
      "        \n",
      "        >>> print(tf_wrapper(x).numpy())\n",
      "        Tracing.\n",
      "        Running with eager execution.\n",
      "        1.0\n",
      "        >>> print(tf_wrapper(x).numpy())\n",
      "        Running with eager execution.\n",
      "        1.0\n",
      "        \n",
      "        \n",
      "        Gradients work as expected:\n",
      "        \n",
      "        >>> with tf.GradientTape() as t:\n",
      "        ...   t.watch(x)\n",
      "        ...   y = tf_wrapper(x)\n",
      "        Running with eager execution.\n",
      "        >>>\n",
      "        >>> t.gradient(y, x).numpy()\n",
      "        2.0\n",
      "        \n",
      "        ### Inplace\n",
      "        \n",
      "        You can also skip the decorator and use `tf.py_function` in-place.\n",
      "        This form is a useful shortcut if you don't control the function's source,\n",
      "        but it is harder to read.\n",
      "        \n",
      "        >>> # No decorator\n",
      "        >>> def log_huber(x, m):\n",
      "        ...   if tf.abs(x) <= m:\n",
      "        ...     return x**2\n",
      "        ...   else:\n",
      "        ...     return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))\n",
      "        >>>\n",
      "        >>> x = tf.constant(1.0)\n",
      "        >>> m = tf.constant(2.0)\n",
      "        >>>\n",
      "        >>> tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32).numpy()\n",
      "        1.0\n",
      "        \n",
      "        ### More info\n",
      "        \n",
      "        You can also use `tf.py_function` to debug your models at runtime\n",
      "        using Python tools, i.e., you can isolate portions of your code that\n",
      "        you want to debug, wrap them in Python functions and insert `pdb` tracepoints\n",
      "        or print statements as desired, and wrap those functions in\n",
      "        `tf.py_function`.\n",
      "        \n",
      "        For more information on eager execution, see the\n",
      "        [Eager guide](https://tensorflow.org/guide/eager).\n",
      "        \n",
      "        `tf.py_function` is similar in spirit to `tf.numpy_function`, but unlike\n",
      "        the latter, the former lets you use TensorFlow operations in the wrapped\n",
      "        Python function. In particular, while `tf.compat.v1.py_func` only runs on CPUs\n",
      "        and wraps functions that take NumPy arrays as inputs and return NumPy arrays\n",
      "        as outputs, `tf.py_function` can be placed on GPUs and wraps functions\n",
      "        that take Tensors as inputs, execute TensorFlow operations in their bodies,\n",
      "        and return Tensors as outputs.\n",
      "        \n",
      "        Note: We recommend to avoid using `tf.py_function` outside of prototyping\n",
      "        and experimentation due to the following known limitations:\n",
      "        \n",
      "        * Calling `tf.py_function` will acquire the Python Global Interpreter Lock\n",
      "          (GIL) that allows only one thread to run at any point in time. This will\n",
      "          preclude efficient parallelization and distribution of the execution of the\n",
      "          program.\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `GraphDef`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.py_function()`. If you are using distributed\n",
      "          TensorFlow, you must run a `tf.distribute.Server` in the same process as the\n",
      "          program that calls `tf.py_function()` and you must pin the created\n",
      "          operation to a device in that server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        * Currently `tf.py_function` is not compatible with XLA. Calling\n",
      "          `tf.py_function` inside `tf.function(jit_compile=True)` will raise an\n",
      "          error.\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function that accepts `inp` as arguments, and returns a value\n",
      "            (or list of values) whose type is described by `Tout`. Do not set `func`\n",
      "            when using `tf.py_function` as a decorator.\n",
      "          inp: Input arguments for `func`.  A list whose elements are `Tensor`s or\n",
      "            `CompositeTensors` (such as `tf.RaggedTensor`); or a single `Tensor` or\n",
      "            `CompositeTensor`. Do not set `inp` when using `tf.py_function` as a\n",
      "            decorator.\n",
      "          Tout: The type(s) of the value(s) returned by `func`.  One of the following.\n",
      "            * If `func` returns a `Tensor` (or a value that can be converted to a\n",
      "            Tensor): the `tf.DType` for that value. * If `func` returns a\n",
      "            `CompositeTensor`: The `tf.TypeSpec` for that value. * If `func` returns\n",
      "            `None`: the empty list (`[]`). * If `func` returns a list of `Tensor` and\n",
      "            `CompositeTensor` values: a corresponding list of `tf.DType`s and\n",
      "            `tf.TypeSpec`s for each value.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          * If `func` is `None` this returns a decorator that will ensure the\n",
      "          decorated function will always run with eager execution even if called\n",
      "          from a `tf.function`/`tf.Graph`.\n",
      "          * If used `func` is not `None` this executes `func` with eager execution\n",
      "          and returns the result: a `Tensor`, `CompositeTensor`, or list of\n",
      "          `Tensor` and `CompositeTensor`; or an empty list if `func` returns `None`.\n",
      "    \n",
      "    qr(input: Annotated[Any, ~TV_Qr_T], full_matrices: bool = False, name=None)\n",
      "        Computes the QR decompositions of one or more matrices.\n",
      "        \n",
      "        Computes the QR decomposition of each inner matrix in `tensor` such that\n",
      "        `tensor[..., :, :] = q[..., :, :] * r[..., :,:])`\n",
      "        \n",
      "        Currently, the gradient for the QR decomposition is well-defined only when\n",
      "        the first `P` columns of the inner matrix are linearly independent, where\n",
      "        `P` is the minimum of `M` and `N`, the 2 inner-most dimmensions of `tensor`.\n",
      "        \n",
      "        ```python\n",
      "        # a is a tensor.\n",
      "        # q is a tensor of orthonormal matrices.\n",
      "        # r is a tensor of upper triangular matrices.\n",
      "        q, r = qr(a)\n",
      "        q_full, r_full = qr(a, full_matrices=True)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            A tensor of shape `[..., M, N]` whose inner-most 2 dimensions\n",
      "            form matrices of size `[M, N]`. Let `P` be the minimum of `M` and `N`.\n",
      "          full_matrices: An optional `bool`. Defaults to `False`.\n",
      "            If true, compute full-sized `q` and `r`. If false\n",
      "            (the default), compute only the leading `P` columns of `q`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (q, r).\n",
      "        \n",
      "          q: A `Tensor`. Has the same type as `input`.\n",
      "          r: A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    quantize(input, min_range, max_range, T, mode='MIN_COMBINED', round_mode='HALF_AWAY_FROM_ZERO', name=None, narrow_range=False, axis=None, ensure_minimum_range=0.01)\n",
      "        Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.\n",
      "        \n",
      "        [min_range, max_range] are scalar floats that specify the range for\n",
      "        the 'input' data. The 'mode' attribute controls exactly which calculations are\n",
      "        used to convert the float values to their quantized equivalents.  The\n",
      "        'round_mode' attribute controls which rounding tie-breaking algorithm is used\n",
      "        when rounding float values to their quantized equivalents.\n",
      "        \n",
      "        In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:\n",
      "        \n",
      "        ```\n",
      "        out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)\n",
      "        if T == qint8: out[i] -= (range(T) + 1) / 2.0\n",
      "        ```\n",
      "        \n",
      "        here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`\n",
      "        \n",
      "        *MIN_COMBINED Mode Example*\n",
      "        \n",
      "        Assume the input is type float and has a possible range of [0.0, 6.0] and the\n",
      "        output type is quint8 ([0, 255]). The min_range and max_range values should be\n",
      "        specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each\n",
      "        value of the input by 255/6 and cast to quint8.\n",
      "        \n",
      "        If the output type was qint8 ([-128, 127]), the operation will additionally\n",
      "        subtract each value by 128 prior to casting, so that the range of values aligns\n",
      "        with the range of qint8.\n",
      "        \n",
      "        If the mode is 'MIN_FIRST', then this approach is used:\n",
      "        \n",
      "        ```\n",
      "        num_discrete_values = 1 << (# of bits in T)\n",
      "        range_adjust = num_discrete_values / (num_discrete_values - 1)\n",
      "        range = (range_max - range_min) * range_adjust\n",
      "        range_scale = num_discrete_values / range\n",
      "        quantized = round(input * range_scale) - round(range_min * range_scale) +\n",
      "          numeric_limits<T>::min()\n",
      "        quantized = max(quantized, numeric_limits<T>::min())\n",
      "        quantized = min(quantized, numeric_limits<T>::max())\n",
      "        ```\n",
      "        \n",
      "        The biggest difference between this and MIN_COMBINED is that the minimum range\n",
      "        is rounded first, before it's subtracted from the rounded value. With\n",
      "        MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing\n",
      "        and dequantizing will introduce a larger and larger error.\n",
      "        \n",
      "        *SCALED mode Example*\n",
      "        \n",
      "        `SCALED` mode matches the quantization approach used in\n",
      "        `QuantizeAndDequantize{V2|V3}`.\n",
      "        \n",
      "        If the mode is `SCALED`, the quantization is performed by multiplying each\n",
      "        input value by a scaling_factor.\n",
      "        The scaling_factor is determined from `min_range` and `max_range` to be as large\n",
      "        as possible such that the range from `min_range` to `max_range` is representable\n",
      "        within values of type T.\n",
      "        \n",
      "        ```c++\n",
      "        \n",
      "          const int min_T = std::numeric_limits<T>::min();\n",
      "          const int max_T = std::numeric_limits<T>::max();\n",
      "          const float max_float = std::numeric_limits<float>::max();\n",
      "        \n",
      "          const float scale_factor_from_min_side =\n",
      "              (min_T * min_range > 0) ? min_T / min_range : max_float;\n",
      "          const float scale_factor_from_max_side =\n",
      "              (max_T * max_range > 0) ? max_T / max_range : max_float;\n",
      "        \n",
      "          const float scale_factor = std::min(scale_factor_from_min_side,\n",
      "                                              scale_factor_from_max_side);\n",
      "        ```\n",
      "        \n",
      "        We next use the scale_factor to adjust min_range and max_range as follows:\n",
      "        \n",
      "        ```c++\n",
      "              min_range = min_T / scale_factor;\n",
      "              max_range = max_T / scale_factor;\n",
      "        ```\n",
      "        \n",
      "        \n",
      "        e.g. if T = qint8, and initially min_range = -10, and max_range = 9, we would\n",
      "        compare -128/-10.0 = 12.8 to 127/9.0 = 14.11, and set scaling_factor = 12.8\n",
      "        In this case, min_range would remain -10, but max_range would be adjusted to\n",
      "        127 / 12.8 = 9.921875\n",
      "        \n",
      "        So we will quantize input values in the range (-10, 9.921875) to (-128, 127).\n",
      "        \n",
      "        The input tensor can now be quantized by clipping values to the range\n",
      "        `min_range` to `max_range`, then multiplying by scale_factor as follows:\n",
      "        \n",
      "        ```c++\n",
      "        result = round(min(max_range, max(min_range, input)) * scale_factor)\n",
      "        ```\n",
      "        \n",
      "        The adjusted `min_range` and `max_range` are returned as outputs 2 and 3 of\n",
      "        this operation. These outputs should be used as the range for any further\n",
      "        calculations.\n",
      "        \n",
      "        \n",
      "        *narrow_range (bool) attribute*\n",
      "        \n",
      "        If true, we do not use the minimum quantized value.\n",
      "        i.e. for int8 the quantized output, it would be restricted to the range\n",
      "        -127..127 instead of the full -128..127 range.\n",
      "        This is provided for compatibility with certain inference backends.\n",
      "        (Only applies to SCALED mode)\n",
      "        \n",
      "        \n",
      "        *axis (int) attribute*\n",
      "        \n",
      "        An optional `axis` attribute can specify a dimension index of the input tensor,\n",
      "        such that quantization ranges will be calculated and applied separately for each\n",
      "        slice of the tensor along that dimension. This is useful for per-channel\n",
      "        quantization.\n",
      "        \n",
      "        If axis is specified, min_range and max_range\n",
      "        \n",
      "        if `axis`=None, per-tensor quantization is performed as normal.\n",
      "        \n",
      "        \n",
      "        *ensure_minimum_range (float) attribute*\n",
      "        \n",
      "        Ensures the minimum quantization range is at least this value.\n",
      "        The legacy default value for this is 0.01, but it is strongly suggested to\n",
      "        set it to 0 for new uses.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `float32`.\n",
      "          min_range: A `Tensor` of type `float32`.\n",
      "            The minimum value of the quantization range. This value may be adjusted by the\n",
      "            op depending on other parameters. The adjusted value is written to `output_min`.\n",
      "            If the `axis` attribute is specified, this must be a 1-D tensor whose size\n",
      "            matches the `axis` dimension of the input and output tensors.\n",
      "          max_range: A `Tensor` of type `float32`.\n",
      "            The maximum value of the quantization range. This value may be adjusted by the\n",
      "            op depending on other parameters. The adjusted value is written to `output_max`.\n",
      "            If the `axis` attribute is specified, this must be a 1-D tensor whose size\n",
      "            matches the `axis` dimension of the input and output tensors.\n",
      "          T: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.\n",
      "          mode: An optional `string` from: `\"MIN_COMBINED\", \"MIN_FIRST\", \"SCALED\"`. Defaults to `\"MIN_COMBINED\"`.\n",
      "          round_mode: An optional `string` from: `\"HALF_AWAY_FROM_ZERO\", \"HALF_TO_EVEN\"`. Defaults to `\"HALF_AWAY_FROM_ZERO\"`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          axis: An optional `int`. Defaults to `-1`.\n",
      "          ensure_minimum_range: An optional `float`. Defaults to `0.01`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output, output_min, output_max).\n",
      "        \n",
      "          output: A `Tensor` of type `T`.\n",
      "          output_min: A `Tensor` of type `float32`.\n",
      "          output_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    quantize_v2(input, min_range, max_range, T, mode='MIN_COMBINED', name=None, round_mode='HALF_AWAY_FROM_ZERO', narrow_range=False, axis=None, ensure_minimum_range=0.01)\n",
      "        Please use `tf.quantization.quantize` instead.\n",
      "    \n",
      "    quantized_concat(concat_dim: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], values: Annotated[List[Any], ~TV_QuantizedConcat_T], input_mins: Annotated[List[Any], <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], input_maxes: Annotated[List[Any], <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>], name=None)\n",
      "        Concatenates quantized tensors along one dimension.\n",
      "        \n",
      "        Args:\n",
      "          concat_dim: A `Tensor` of type `int32`.\n",
      "            0-D.  The dimension along which to concatenate.  Must be in the\n",
      "            range [0, rank(values)).\n",
      "          values: A list of at least 2 `Tensor` objects with the same type.\n",
      "            The `N` Tensors to concatenate. Their ranks and types must match,\n",
      "            and their sizes must match in all dimensions except `concat_dim`.\n",
      "          input_mins: A list with the same length as `values` of `Tensor` objects with type `float32`.\n",
      "            The minimum scalar values for each of the input tensors.\n",
      "          input_maxes: A list with the same length as `values` of `Tensor` objects with type `float32`.\n",
      "            The maximum scalar values for each of the input tensors.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output, output_min, output_max).\n",
      "        \n",
      "          output: A `Tensor`. Has the same type as `values`.\n",
      "          output_min: A `Tensor` of type `float32`.\n",
      "          output_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    ragged_fill_empty_rows(value_rowids: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>], values: Annotated[Any, ~TV_RaggedFillEmptyRows_T], nrows: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>], default_value: Annotated[Any, ~TV_RaggedFillEmptyRows_T], name=None)\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          value_rowids: A `Tensor` of type `int64`.\n",
      "          values: A `Tensor`.\n",
      "          nrows: A `Tensor` of type `int64`.\n",
      "          default_value: A `Tensor`. Must have the same type as `values`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output_value_rowids, output_values, empty_row_indicator, reverse_index_map).\n",
      "        \n",
      "          output_value_rowids: A `Tensor` of type `int64`.\n",
      "          output_values: A `Tensor`. Has the same type as `values`.\n",
      "          empty_row_indicator: A `Tensor` of type `bool`.\n",
      "          reverse_index_map: A `Tensor` of type `int64`.\n",
      "    \n",
      "    ragged_fill_empty_rows_grad(reverse_index_map: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>], grad_values: Annotated[Any, ~TV_RaggedFillEmptyRowsGrad_T], name=None)\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          reverse_index_map: A `Tensor` of type `int64`.\n",
      "          grad_values: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (d_values, d_default_value).\n",
      "        \n",
      "          d_values: A `Tensor`. Has the same type as `grad_values`.\n",
      "          d_default_value: A `Tensor`. Has the same type as `grad_values`.\n",
      "    \n",
      "    random_crop(value, size, seed=None, name=None)\n",
      "        Randomly crops a tensor to a given size.\n",
      "        \n",
      "        Slices a shape `size` portion out of `value` at a uniformly chosen offset.\n",
      "        Requires `value.shape >= size`.\n",
      "        \n",
      "        If a dimension should not be cropped, pass the full size of that dimension.\n",
      "        For example, RGB images can be cropped with\n",
      "        `size = [crop_height, crop_width, 3]`.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> image = [[1, 2, 3], [4, 5, 6]]\n",
      "        >>> result = tf.image.random_crop(value=image, size=(1, 3))\n",
      "        >>> result.shape.as_list()\n",
      "        [1, 3]\n",
      "        \n",
      "        For producing deterministic results given a `seed` value, use\n",
      "        `tf.image.stateless_random_crop`. Unlike using the `seed` param with\n",
      "        `tf.image.random_*` ops, `tf.image.stateless_random_*` ops guarantee the same\n",
      "        results given the same seed independent of how many times the function is\n",
      "        called, and independent of global seed settings (e.g. tf.random.set_seed).\n",
      "        \n",
      "        Args:\n",
      "          value: Input tensor to crop.\n",
      "          size: 1-D tensor with size the rank of `value`.\n",
      "          seed: Python integer. Used to create a random seed. See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A cropped tensor of the same rank as `value` and shape `size`.\n",
      "    \n",
      "    random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)\n",
      "        Draws `shape` samples from each of the given Gamma distribution(s).\n",
      "        \n",
      "        `alpha` is the shape parameter describing the distribution(s), and `beta` is\n",
      "        the inverse scale parameter(s).\n",
      "        \n",
      "        Note: Because internal calculations are done using `float64` and casting has\n",
      "        `floor` semantics, we must manually map zero outcomes to the smallest\n",
      "        possible positive floating-point value, i.e., `np.finfo(dtype).tiny`.  This\n",
      "        means that `np.finfo(dtype).tiny` occurs more frequently than it otherwise\n",
      "        should.  This bias can only happen for small values of `alpha`, i.e.,\n",
      "        `alpha << 1` or large values of `beta`, i.e., `beta >> 1`.\n",
      "        \n",
      "        The samples are differentiable w.r.t. alpha and beta.\n",
      "        The derivatives are computed using the approach described in\n",
      "        (Figurnov et al., 2018).\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        samples = tf.random.gamma([10], [0.5, 1.5])\n",
      "        # samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents\n",
      "        # the samples drawn from each distribution\n",
      "        \n",
      "        samples = tf.random.gamma([7, 5], [0.5, 1.5])\n",
      "        # samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1]\n",
      "        # represents the 7x5 samples drawn from each of the two distributions\n",
      "        \n",
      "        alpha = tf.constant([[1.],[3.],[5.]])\n",
      "        beta = tf.constant([[3., 4.]])\n",
      "        samples = tf.random.gamma([30], alpha=alpha, beta=beta)\n",
      "        # samples has shape [30, 3, 2], with 30 samples each of 3x2 distributions.\n",
      "        \n",
      "        loss = tf.reduce_mean(tf.square(samples))\n",
      "        dloss_dalpha, dloss_dbeta = tf.gradients(loss, [alpha, beta])\n",
      "        # unbiased stochastic derivatives of the loss function\n",
      "        alpha.shape == dloss_dalpha.shape  # True\n",
      "        beta.shape == dloss_dbeta.shape  # True\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output samples\n",
      "            to be drawn per alpha/beta-parameterized distribution.\n",
      "          alpha: A Tensor or Python value or N-D array of type `dtype`. `alpha`\n",
      "            provides the shape parameter(s) describing the gamma distribution(s) to\n",
      "            sample. Must be broadcastable with `beta`.\n",
      "          beta: A Tensor or Python value or N-D array of type `dtype`. Defaults to 1.\n",
      "            `beta` provides the inverse scale parameter(s) of the gamma\n",
      "            distribution(s) to sample. Must be broadcastable with `alpha`.\n",
      "          dtype: The type of alpha, beta, and the output: `float16`, `float32`, or\n",
      "            `float64`.\n",
      "          seed: A Python integer. Used to create a random seed for the distributions.\n",
      "            See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          samples: a `Tensor` of shape\n",
      "            `tf.concat([shape, tf.shape(alpha + beta)], axis=0)` with values of type\n",
      "            `dtype`.\n",
      "        \n",
      "        References:\n",
      "          Implicit Reparameterization Gradients:\n",
      "            [Figurnov et al., 2018]\n",
      "            (http://papers.nips.cc/paper/7326-implicit-reparameterization-gradients)\n",
      "            ([pdf]\n",
      "            (http://papers.nips.cc/paper/7326-implicit-reparameterization-gradients.pdf))\n",
      "    \n",
      "    random_index_shuffle(index: Annotated[Any, ~TV_RandomIndexShuffle_dtype], seed: Annotated[Any, ~TV_RandomIndexShuffle_Tseed], max_index: Annotated[Any, ~TV_RandomIndexShuffle_dtype], rounds: int = 4, name=None) -> Annotated[Any, ~TV_RandomIndexShuffle_dtype]\n",
      "        Outputs the position of `value` in a permutation of [0, ..., max_index].\n",
      "        \n",
      "        Output values are a bijection of the `index` for any combination and `seed` and `max_index`.\n",
      "        \n",
      "        If multiple inputs are vectors (matrix in case of seed) then the size of the\n",
      "        first dimension must match.\n",
      "        \n",
      "        The outputs are deterministic.\n",
      "        \n",
      "        Args:\n",
      "          index: A `Tensor`. Must be one of the following types: `int32`, `uint32`, `int64`, `uint64`.\n",
      "            A scalar tensor or a vector of dtype `dtype`. The index (or indices) to be shuffled. Must be within [0, max_index].\n",
      "          seed: A `Tensor`. Must be one of the following types: `int32`, `uint32`, `int64`, `uint64`.\n",
      "            A tensor of dtype `Tseed` and shape [3] or [n, 3]. The random seed.\n",
      "          max_index: A `Tensor`. Must have the same type as `index`.\n",
      "            A scalar tensor or vector of dtype `dtype`. The upper bound(s) of the interval (inclusive).\n",
      "          rounds: An optional `int`. Defaults to `4`.\n",
      "            The number of rounds to use the in block cipher.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `index`.\n",
      "    \n",
      "    random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a normal distribution.\n",
      "        \n",
      "        Example that generates a new set of random values every time:\n",
      "        \n",
      "        >>> tf.random.set_seed(5);\n",
      "        >>> tf.random.normal([4], 0, 1, tf.float32)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=..., dtype=float32)>\n",
      "        \n",
      "        Example that outputs a reproducible result:\n",
      "        \n",
      "        >>> tf.random.set_seed(5);\n",
      "        >>> tf.random.normal([2,2], 0, 1, tf.float32, seed=1)\n",
      "        <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "        array([[-1.3768897 , -0.01258316],\n",
      "              [-0.169515   ,  1.0824056 ]], dtype=float32)>\n",
      "        \n",
      "        In this case, we are setting both the global and operation-level seed to\n",
      "        ensure this result is reproducible.  See `tf.random.set_seed` for more\n",
      "        information.\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          mean: A Tensor or Python value of type `dtype`, broadcastable with `stddev`.\n",
      "            The mean of the normal distribution.\n",
      "          stddev: A Tensor or Python value of type `dtype`, broadcastable with `mean`.\n",
      "            The standard deviation of the normal distribution.\n",
      "          dtype: The float type of the output: `float16`, `bfloat16`, `float32`,\n",
      "            `float64`. Defaults to `float32`.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random normal values.\n",
      "    \n",
      "    random_poisson(lam, shape, dtype=tf.float32, seed=None, name=None)\n",
      "        Draws `shape` samples from each of the given Poisson distribution(s).\n",
      "        \n",
      "        `lam` is the rate parameter describing the distribution(s).\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        samples = tf.random.poisson([0.5, 1.5], [10])\n",
      "        # samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents\n",
      "        # the samples drawn from each distribution\n",
      "        \n",
      "        samples = tf.random.poisson([12.2, 3.3], [7, 5])\n",
      "        # samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1]\n",
      "        # represents the 7x5 samples drawn from each of the two distributions\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          lam: A Tensor or Python value or N-D array of type `dtype`.\n",
      "            `lam` provides the rate parameter(s) describing the poisson\n",
      "            distribution(s) to sample.\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output samples\n",
      "            to be drawn per \"rate\"-parameterized distribution.\n",
      "          dtype: The type of the output: `float16`, `float32`, `float64`, `int32` or\n",
      "            `int64`.\n",
      "          seed: A Python integer. Used to create a random seed for the distributions.\n",
      "            See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          samples: a `Tensor` of shape `tf.concat([shape, tf.shape(lam)], axis=0)`\n",
      "            with values of type `dtype`.\n",
      "    \n",
      "    random_shuffle(value, seed=None, name=None)\n",
      "        Randomly shuffles a tensor along its first dimension.\n",
      "        \n",
      "        The tensor is shuffled along dimension 0, such that each `value[j]` is mapped\n",
      "        to one and only one `output[i]`. For example, a mapping that might occur for a\n",
      "        3x2 tensor is:\n",
      "        \n",
      "        ```python\n",
      "        [[1, 2],       [[5, 6],\n",
      "         [3, 4],  ==>   [1, 2],\n",
      "         [5, 6]]        [3, 4]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          value: A Tensor to be shuffled.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See\n",
      "            `tf.random.set_seed`\n",
      "            for behavior.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of same shape and type as `value`, shuffled along its first\n",
      "          dimension.\n",
      "    \n",
      "    random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a uniform distribution.\n",
      "        \n",
      "        The generated values follow a uniform distribution in the range\n",
      "        `[minval, maxval)`. The lower bound `minval` is included in the range, while\n",
      "        the upper bound `maxval` is excluded.\n",
      "        \n",
      "        For floats, the default range is `[0, 1)`.  For ints, at least `maxval` must\n",
      "        be specified explicitly.\n",
      "        \n",
      "        In the integer case, the random integers are slightly biased unless\n",
      "        `maxval - minval` is an exact power of two.  The bias is small for values of\n",
      "        `maxval - minval` significantly smaller than the range of the output (either\n",
      "        `2**32` or `2**64`).\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.random.uniform(shape=[2])\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([..., ...], dtype=float32)>\n",
      "        >>> tf.random.uniform(shape=[], minval=-1., maxval=0.)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=-...>\n",
      "        >>> tf.random.uniform(shape=[], minval=5, maxval=10, dtype=tf.int64)\n",
      "        <tf.Tensor: shape=(), dtype=int64, numpy=...>\n",
      "        \n",
      "        The `seed` argument produces a deterministic sequence of tensors across\n",
      "        multiple calls. To repeat that sequence, use `tf.random.set_seed`:\n",
      "        \n",
      "        >>> tf.random.set_seed(5)\n",
      "        >>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        >>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
      "        >>> tf.random.set_seed(5)\n",
      "        >>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "        >>> tf.random.uniform(shape=[], maxval=3, dtype=tf.int32, seed=10)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
      "        \n",
      "        Without `tf.random.set_seed` but with a `seed` argument is specified, small\n",
      "        changes to function graphs or previously executed operations will change the\n",
      "        returned value. See `tf.random.set_seed` for details.\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          minval: A Tensor or Python value of type `dtype`, broadcastable with\n",
      "            `shape` (for integer types, broadcasting is not supported, so it needs to\n",
      "            be a scalar). The lower bound on the range of random values to generate\n",
      "            (inclusive).  Defaults to 0.\n",
      "          maxval: A Tensor or Python value of type `dtype`, broadcastable with\n",
      "            `shape` (for integer types, broadcasting is not supported, so it needs to\n",
      "            be a scalar). The upper bound on the range of random values to generate\n",
      "            (exclusive). Defaults to 1 if `dtype` is floating point.\n",
      "          dtype: The type of the output: `float16`, `bfloat16`, `float32`, `float64`,\n",
      "            `int32`, or `int64`. Defaults to `float32`.\n",
      "          seed: A Python integer. Used in combination with `tf.random.set_seed` to\n",
      "            create a reproducible sequence of tensors across multiple calls.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random uniform values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `dtype` is integral and `maxval` is not specified.\n",
      "    \n",
      "    range(start, limit=None, delta=1, dtype=None, name='range')\n",
      "        Creates a sequence of numbers.\n",
      "        \n",
      "        Creates a sequence of numbers that begins at `start` and extends by\n",
      "        increments of `delta` up to but not including `limit`.\n",
      "        \n",
      "        The dtype of the resulting tensor is inferred from the inputs unless\n",
      "        it is provided explicitly.\n",
      "        \n",
      "        Like the Python builtin `range`, `start` defaults to 0, so that\n",
      "        `range(n) = range(0, n)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> start = 3\n",
      "        >>> limit = 18\n",
      "        >>> delta = 3\n",
      "        >>> tf.range(start, limit, delta)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 3,  6,  9, 12, 15], dtype=int32)>\n",
      "        \n",
      "        >>> start = 3\n",
      "        >>> limit = 1\n",
      "        >>> delta = -0.5\n",
      "        >>> tf.range(start, limit, delta)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32,\n",
      "        numpy=array([3. , 2.5, 2. , 1.5], dtype=float32)>\n",
      "        \n",
      "        >>> limit = 5\n",
      "        >>> tf.range(limit)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          start: A 0-D `Tensor` (scalar). Acts as first entry in the range if `limit`\n",
      "            is not None; otherwise, acts as range limit and first entry defaults to 0.\n",
      "          limit: A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None,\n",
      "            defaults to the value of `start` while the first entry of the range\n",
      "            defaults to 0.\n",
      "          delta: A 0-D `Tensor` (scalar). Number that increments `start`. Defaults to\n",
      "            1.\n",
      "          dtype: The type of the elements of the resulting tensor.\n",
      "          name: A name for the operation. Defaults to \"range\".\n",
      "        \n",
      "        Returns:\n",
      "          An 1-D `Tensor` of type `dtype`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.arange\n",
      "        @end_compatibility\n",
      "    \n",
      "    rank(input, name=None)\n",
      "        Returns the rank of a tensor.\n",
      "        \n",
      "        See also `tf.shape`.\n",
      "        \n",
      "        Returns a 0-D `int32` `Tensor` representing the rank of `input`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # shape of tensor 't' is [2, 2, 3]\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.rank(t)  # 3\n",
      "        ```\n",
      "        \n",
      "        **Note**: The rank of a tensor is not the same as the rank of a matrix. The\n",
      "        rank of a tensor is the number of indices required to uniquely select each\n",
      "        element of the tensor. Rank is also known as \"order\", \"degree\", or \"ndims.\"\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int32`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.ndim\n",
      "        @end_compatibility\n",
      "    \n",
      "    read_file(filename, name=None)\n",
      "        Reads the contents of file.\n",
      "        \n",
      "        This operation returns a tensor with the entire contents of the input\n",
      "        filename. It does not do any parsing, it just returns the contents as\n",
      "        they are. Usually, this is the first step in the input pipeline.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> with open(\"/tmp/file.txt\", \"w\") as f:\n",
      "        ...   f.write(\"asdf\")\n",
      "        ...\n",
      "        4\n",
      "        >>> tf.io.read_file(\"/tmp/file.txt\")\n",
      "        <tf.Tensor: shape=(), dtype=string, numpy=b'asdf'>\n",
      "        \n",
      "        Example of using the op in a function to read an image, decode it and reshape\n",
      "        the tensor containing the pixel data:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def load_image(filename):\n",
      "        ...   raw = tf.io.read_file(filename)\n",
      "        ...   image = tf.image.decode_png(raw, channels=3)\n",
      "        ...   # the `print` executes during tracing.\n",
      "        ...   print(\"Initial shape: \", image.shape)\n",
      "        ...   image.set_shape([28, 28, 3])\n",
      "        ...   print(\"Final shape: \", image.shape)\n",
      "        ...   return image\n",
      "        \n",
      "        Args:\n",
      "          filename: string. filename to read from.\n",
      "          name: string.  Optional name for the op.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of dtype \"string\", with the file contents.\n",
      "    \n",
      "    real(input, name=None)\n",
      "        Returns the real part of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the real part of each element in `input` considered as a complex number.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n",
      "        tf.math.real(x)  # [-2.25, 3.25]\n",
      "        ```\n",
      "        \n",
      "        If `input` is already real, it is returned unchanged.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must have numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    realdiv = real_div(x: typing.Annotated[_any, ~TV_RealDiv_T], y: typing.Annotated[_any, ~TV_RealDiv_T], name=None) -> typing.Annotated[_any, ~TV_RealDiv_T]\n",
      "        Returns x / y element-wise for real types.\n",
      "        \n",
      "        If `x` and `y` are reals, this will return the floating-point division.\n",
      "        \n",
      "        *NOTE*: `Div` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    reciprocal(x: typing.Annotated[_any, ~TV_Reciprocal_T], name=None) -> typing.Annotated[_any, ~TV_Reciprocal_T]\n",
      "        Computes the reciprocal of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = 1 / x\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    recompute_grad(f)\n",
      "        Defines a function as a recompute-checkpoint for the tape auto-diff.\n",
      "        \n",
      "        Tape checkpointing is a technique to reduce the memory consumption of the\n",
      "        auto-diff tape:\n",
      "        \n",
      "        - Without tape checkpointing operations and intermediate values are\n",
      "        recorded to the tape for use in the backward pass.\n",
      "        \n",
      "        - With tape checkpointing, only the function call and its inputs are\n",
      "        recorded. During back-propagation the `recompute_grad` custom gradient\n",
      "        (`tf.custom_gradient`) recomputes the function under a localized Tape object.\n",
      "        This recomputation of the function during backpropagation performs redundant\n",
      "        calculation, but reduces the overall memory usage of the Tape.\n",
      "        \n",
      "        >>> y = tf.Variable(1.0)\n",
      "        \n",
      "        >>> def my_function(x):\n",
      "        ...   tf.print('running')\n",
      "        ...   z = x*y\n",
      "        ...   return z\n",
      "        \n",
      "        >>> my_function_recompute = tf.recompute_grad(my_function)\n",
      "        \n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   r = tf.constant(1.0)\n",
      "        ...   for i in range(4):\n",
      "        ...     r = my_function_recompute(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, [y])\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        Without `recompute_grad`, the tape contains all intermitate steps, and no\n",
      "        recomputation is performed.\n",
      "        \n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   r = tf.constant(1.0)\n",
      "        ...   for i in range(4):\n",
      "        ...     r = my_function(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, [y])\n",
      "        \n",
      "        \n",
      "        If `f` was a `tf.keras` `Model` or `Layer` object, methods and attributes\n",
      "        such as `f.variables` are not available on the returned function `g`.\n",
      "        Either keep a reference of `f` , or use `g.__wrapped__` for accessing\n",
      "        these variables and methods.\n",
      "        \n",
      "        \n",
      "        >>> def print_running_and_return(x):\n",
      "        ...   tf.print(\"running\")\n",
      "        ...   return x\n",
      "        \n",
      "        >>> model = tf.keras.Sequential([\n",
      "        ...   tf.keras.layers.Lambda(print_running_and_return),\n",
      "        ...   tf.keras.layers.Dense(2)\n",
      "        ... ])\n",
      "        \n",
      "        >>> model_recompute = tf.recompute_grad(model)\n",
      "        \n",
      "        >>> with tf.GradientTape(persistent=True) as tape:\n",
      "        ...   r = tf.constant([[1,2]])\n",
      "        ...   for i in range(4):\n",
      "        ...     r = model_recompute(r)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        >>> grad = tape.gradient(r, model.variables)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        Alternatively, use the `__wrapped__` attribute to access the original\n",
      "        model object.\n",
      "        \n",
      "        >>> grad = tape.gradient(r, model_recompute.__wrapped__.variables)\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        running\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a `Tensor` or sequence of `Tensor` outputs.\n",
      "        \n",
      "        Returns:\n",
      "          A function `g` wrapping `f` that defines a custom gradient, which recomputes\n",
      "          `f` on the backwards pass of a gradient call.\n",
      "    \n",
      "    reduce_all = reduce_all_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes `tf.math.logical_and` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.logical_and` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[True,  True], [False, False]])\n",
      "          >>> tf.math.reduce_all(x)\n",
      "          <tf.Tensor: shape=(), dtype=bool, numpy=False>\n",
      "          >>> tf.math.reduce_all(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([False, False])>\n",
      "          >>> tf.math.reduce_all(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The boolean tensor to reduce.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.all\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_any = reduce_any_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes `tf.math.logical_or` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.logical_or` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[True,  True], [False, False]])\n",
      "          >>> tf.reduce_any(x)\n",
      "          <tf.Tensor: shape=(), dtype=bool, numpy=True>\n",
      "          >>> tf.reduce_any(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>\n",
      "          >>> tf.reduce_any(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The boolean tensor to reduce.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.any\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_join(inputs, axis=None, keep_dims=None, separator='', name=None, reduction_indices=None, keepdims=None)\n",
      "        Joins all strings into a single string, or joins along an axis.\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.strings.join` op.\n",
      "        \n",
      "        >>> tf.strings.reduce_join([['abc','123'],\n",
      "        ...                         ['def','456']]).numpy()\n",
      "        b'abc123def456'\n",
      "        >>> tf.strings.reduce_join([['abc','123'],\n",
      "        ...                         ['def','456']], axis=-1).numpy()\n",
      "        array([b'abc123', b'def456'], dtype=object)\n",
      "        >>> tf.strings.reduce_join([['abc','123'],\n",
      "        ...                         ['def','456']],\n",
      "        ...                        axis=-1,\n",
      "        ...                        separator=\" \").numpy()\n",
      "        array([b'abc 123', b'def 456'], dtype=object)\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `tf.string` tensor.\n",
      "          axis: Which axis to join along. The default behavior is to join all\n",
      "            elements, producing a scalar.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          separator: a string added between each string being joined.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.string` tensor.\n",
      "    \n",
      "    reduce_logsumexp = reduce_logsumexp_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes log(sum(exp(elements across dimensions of a tensor))). (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` has no entries, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        This function is more numerically stable than log(sum(exp(input))). It avoids\n",
      "        overflows caused by taking the exp of large inputs and underflows caused by\n",
      "        taking the log of small inputs.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[0., 0., 0.], [0., 0., 0.]])\n",
      "        tf.reduce_logsumexp(x)  # log(6)\n",
      "        tf.reduce_logsumexp(x, 0)  # [log(2), log(2), log(2)]\n",
      "        tf.reduce_logsumexp(x, 1)  # [log(3), log(3)]\n",
      "        tf.reduce_logsumexp(x, 1, keepdims=True)  # [[log(3)], [log(3)]]\n",
      "        tf.reduce_logsumexp(x, [0, 1])  # log(6)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_max = reduce_max_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes `tf.math.maximum` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.maximum` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        Usage example:\n",
      "        \n",
      "          >>> x = tf.constant([5, 1, 2, 4])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=5>\n",
      "          >>> x = tf.constant([-5, -1, -2, -4])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=-1>\n",
      "          >>> x = tf.constant([4, float('nan')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('nan'), float('nan')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('-inf'), float('inf')])\n",
      "          >>> tf.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=inf>\n",
      "        \n",
      "        See the numpy docs for `np.amax` and `np.nanmax` behavior.\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have real numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_mean = reduce_mean_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the mean of elements across dimensions of a tensor.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis` by computing the\n",
      "        mean of elements across the dimensions in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a tensor with a single\n",
      "        element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([[1., 1.], [2., 2.]])\n",
      "        >>> tf.reduce_mean(x)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=1.5>\n",
      "        >>> tf.reduce_mean(x, 0)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.5, 1.5], dtype=float32)>\n",
      "        >>> tf.reduce_mean(x, 1)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.mean\n",
      "        \n",
      "        Please note that `np.mean` has a `dtype` parameter that could be used to\n",
      "        specify the output type. By default this is `dtype=float64`. On the other\n",
      "        hand, `tf.reduce_mean` has an aggressive type inference from `input_tensor`,\n",
      "        for example:\n",
      "        \n",
      "        >>> x = tf.constant([1, 0, 1, 0])\n",
      "        >>> tf.reduce_mean(x)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
      "        >>> y = tf.constant([1., 0., 1., 0.])\n",
      "        >>> tf.reduce_mean(y)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=0.5>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_min = reduce_min_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the `tf.math.minimum` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.minimum` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        Usage example:\n",
      "        \n",
      "          >>> x = tf.constant([5, 1, 2, 4])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "          >>> x = tf.constant([-5, -1, -2, -4])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=-5>\n",
      "          >>> x = tf.constant([4, float('nan')])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('nan'), float('nan')])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
      "          >>> x = tf.constant([float('-inf'), float('inf')])\n",
      "          >>> tf.reduce_min(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=-inf>\n",
      "        \n",
      "        See the numpy docs for `np.amin` and `np.nanmin` behavior.\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have real numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_prod = reduce_prod_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes `tf.math.multiply` of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.multiply` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> x = tf.constant([[1., 2.], [3., 4.]])\n",
      "          >>> tf.math.reduce_prod(x)\n",
      "          <tf.Tensor: shape=(), dtype=float32, numpy=24.>\n",
      "          >>> tf.math.reduce_prod(x, 0)\n",
      "          <tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 8.], dtype=float32)>\n",
      "          >>> tf.math.reduce_prod(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 12.],\n",
      "          dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.prod\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_sum = reduce_sum_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the sum of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.math.add` op.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "        reduced dimensions are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          >>> # x has a shape of (2, 3) (two rows and three columns):\n",
      "          >>> x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
      "          >>> x.numpy()\n",
      "          array([[1, 1, 1],\n",
      "                 [1, 1, 1]], dtype=int32)\n",
      "          >>> # sum all the elements\n",
      "          >>> # 1 + 1 + 1 + 1 + 1+ 1 = 6\n",
      "          >>> tf.reduce_sum(x).numpy()\n",
      "          6\n",
      "          >>> # reduce along the first dimension\n",
      "          >>> # the result is [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "          >>> tf.reduce_sum(x, 0).numpy()\n",
      "          array([2, 2, 2], dtype=int32)\n",
      "          >>> # reduce along the second dimension\n",
      "          >>> # the result is [1, 1] + [1, 1] + [1, 1] = [3, 3]\n",
      "          >>> tf.reduce_sum(x, 1).numpy()\n",
      "          array([3, 3], dtype=int32)\n",
      "          >>> # keep the original dimensions\n",
      "          >>> tf.reduce_sum(x, 1, keepdims=True).numpy()\n",
      "          array([[3],\n",
      "                 [3]], dtype=int32)\n",
      "          >>> # reduce along both dimensions\n",
      "          >>> # the result is 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
      "          >>> # or, equivalently, reduce along rows, then reduce the resultant array\n",
      "          >>> # [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "          >>> # 2 + 2 + 2 = 6\n",
      "          >>> tf.reduce_sum(x, [0, 1]).numpy()\n",
      "          6\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor, of the same dtype as the input_tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
      "        int64 while tensorflow returns the same dtype as the input.\n",
      "        @end_compatibility\n",
      "    \n",
      "    regex_replace(input, pattern, rewrite, replace_global=True, name=None)\n",
      "        Replace elements of `input` matching regex `pattern` with `rewrite`.\n",
      "        \n",
      "        >>> tf.strings.regex_replace(\"Text with tags.<br /><b>contains html</b>\",\n",
      "        ...                          \"<[^>]+>\", \" \")\n",
      "        <tf.Tensor: shape=(), dtype=string, numpy=b'Text with tags.  contains html '>\n",
      "        \n",
      "        Args:\n",
      "          input: string `Tensor`, the source strings to process.\n",
      "          pattern: string or scalar string `Tensor`, regular expression to use,\n",
      "            see more details at https://github.com/google/re2/wiki/Syntax\n",
      "          rewrite: string or scalar string `Tensor`, value to use in match\n",
      "            replacement, supports backslash-escaped digits (\\1 to \\9) can be to insert\n",
      "            text matching corresponding parenthesized group.\n",
      "          replace_global: `bool`, if `True` replace all non-overlapping matches,\n",
      "            else replace only the first match.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          string `Tensor` of the same shape as `input` with specified replacements.\n",
      "    \n",
      "    register_tensor_conversion_function(base_type, conversion_func, priority=100)\n",
      "        Registers a function for converting objects of `base_type` to `Tensor`.\n",
      "        \n",
      "        The conversion function must have the following signature:\n",
      "        \n",
      "        ```python\n",
      "            def conversion_func(value, dtype=None, name=None, as_ref=False):\n",
      "              # ...\n",
      "        ```\n",
      "        \n",
      "        It must return a `Tensor` with the given `dtype` if specified. If the\n",
      "        conversion function creates a new `Tensor`, it should use the given\n",
      "        `name` if specified. All exceptions will be propagated to the caller.\n",
      "        \n",
      "        The conversion function may return `NotImplemented` for some\n",
      "        inputs. In this case, the conversion process will continue to try\n",
      "        subsequent conversion functions.\n",
      "        \n",
      "        If `as_ref` is true, the function must return a `Tensor` reference,\n",
      "        such as a `Variable`.\n",
      "        \n",
      "        NOTE: The conversion functions will execute in order of priority,\n",
      "        followed by order of registration. To ensure that a conversion function\n",
      "        `F` runs before another conversion function `G`, ensure that `F` is\n",
      "        registered with a smaller priority than `G`.\n",
      "        \n",
      "        Args:\n",
      "          base_type: The base type or tuple of base types for all objects that\n",
      "            `conversion_func` accepts.\n",
      "          conversion_func: A function that converts instances of `base_type` to\n",
      "            `Tensor`.\n",
      "          priority: Optional integer that indicates the priority for applying this\n",
      "            conversion function. Conversion functions with smaller priority values run\n",
      "            earlier than conversion functions with larger priority values. Defaults to\n",
      "            100.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the arguments do not have the appropriate type.\n",
      "    \n",
      "    repeat(input, repeats, axis=None, name=None)\n",
      "        Repeat elements of `input`.\n",
      "        \n",
      "        See also `tf.concat`, `tf.stack`, `tf.tile`.\n",
      "        \n",
      "        Args:\n",
      "          input: An `N`-dimensional Tensor.\n",
      "          repeats: An 1-D `int` Tensor. The number of repetitions for each element.\n",
      "            repeats is broadcasted to fit the shape of the given axis. `len(repeats)`\n",
      "            must equal `input.shape[axis]` if axis is not None.\n",
      "          axis: An int. The axis along which to repeat values. By default, (axis=None),\n",
      "            use the flattened input array, and return a flat output array.\n",
      "          name: A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor which has the same shape as `input`, except along the given axis.\n",
      "            If axis is None then the output array is flattened to match the flattened\n",
      "            input array.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> repeat(['a', 'b', 'c'], repeats=[3, 0, 2], axis=0)\n",
      "        <tf.Tensor: shape=(5,), dtype=string,\n",
      "        numpy=array([b'a', b'a', b'a', b'c', b'c'], dtype=object)>\n",
      "        \n",
      "        >>> repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=0)\n",
      "        <tf.Tensor: shape=(5, 2), dtype=int32, numpy=\n",
      "        array([[1, 2],\n",
      "               [1, 2],\n",
      "               [3, 4],\n",
      "               [3, 4],\n",
      "               [3, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=1)\n",
      "        <tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
      "        array([[1, 1, 2, 2, 2],\n",
      "               [3, 3, 4, 4, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> repeat(3, repeats=4)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 3, 3, 3], dtype=int32)>\n",
      "        \n",
      "        >>> repeat([[1,2], [3,4]], repeats=2)\n",
      "        <tf.Tensor: shape=(8,), dtype=int32,\n",
      "        numpy=array([1, 1, 2, 2, 3, 3, 4, 4], dtype=int32)>\n",
      "    \n",
      "    report_uninitialized_variables(var_list=None, name='report_uninitialized_variables')\n",
      "        Adds ops to list the names of uninitialized variables.\n",
      "        \n",
      "        When run, it returns a 1-D tensor containing the names of uninitialized\n",
      "        variables if there are any, or an empty array if there are none.\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to check. Defaults to the value of\n",
      "            `global_variables() + local_variables()`\n",
      "          name: Optional name of the `Operation`.\n",
      "        \n",
      "        Returns:\n",
      "          A 1-D tensor containing names of the uninitialized variables, or an empty\n",
      "          1-D tensor if there are no variables or no uninitialized variables.\n",
      "        \n",
      "        \n",
      "        Note: The output of this function should be used. If it is not, a warning will be logged or an error may be raised. To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    required_space_to_batch_paddings(input_shape, block_shape, base_paddings=None, name=None)\n",
      "        Calculate padding required to make block_shape divide input_shape.\n",
      "        \n",
      "        This function can be used to calculate a suitable paddings argument for use\n",
      "        with space_to_batch_nd and batch_to_space_nd.\n",
      "        \n",
      "        Args:\n",
      "          input_shape: int32 Tensor of shape [N].\n",
      "          block_shape: int32 Tensor of shape [N].\n",
      "          base_paddings: Optional int32 Tensor of shape [N, 2].  Specifies the minimum\n",
      "            amount of padding to use.  All elements must be >= 0.  If not specified,\n",
      "            defaults to 0.\n",
      "          name: string.  Optional name prefix.\n",
      "        \n",
      "        Returns:\n",
      "          (paddings, crops), where:\n",
      "        \n",
      "          `paddings` and `crops` are int32 Tensors of rank 2 and shape [N, 2]\n",
      "          satisfying:\n",
      "        \n",
      "              paddings[i, 0] = base_paddings[i, 0].\n",
      "              0 <= paddings[i, 1] - base_paddings[i, 1] < block_shape[i]\n",
      "              (input_shape[i] + paddings[i, 0] + paddings[i, 1]) % block_shape[i] == 0\n",
      "        \n",
      "              crops[i, 0] = 0\n",
      "              crops[i, 1] = paddings[i, 1] - base_paddings[i, 1]\n",
      "        \n",
      "        Raises: ValueError if called with incompatible shapes.\n",
      "    \n",
      "    reset_default_graph() -> None\n",
      "        Clears the default graph stack and resets the global default graph.\n",
      "        \n",
      "        NOTE: The default graph is a property of the current thread. This\n",
      "        function applies only to the current thread.  Calling this function while\n",
      "        a `tf.compat.v1.Session` or `tf.compat.v1.InteractiveSession` is active will\n",
      "        result in undefined\n",
      "        behavior. Using any previously created `tf.Operation` or `tf.Tensor` objects\n",
      "        after calling this function will result in undefined behavior.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `reset_default_graph` does not work with either eager execution or\n",
      "        `tf.function`, and you should not invoke it directly. To migrate code that\n",
      "        uses Graph-related functions to TF2, rewrite the code without them. See the\n",
      "        [migration guide](https://www.tensorflow.org/guide/migrate) for more\n",
      "        description about the behavior and semantic changes between Tensorflow 1 and\n",
      "        Tensorflow 2.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          AssertionError: If this function is called within a nested graph.\n",
      "    \n",
      "    reshape(tensor, shape, name=None)\n",
      "        Reshapes a tensor.\n",
      "        \n",
      "        Given `tensor`, this operation returns a new `tf.Tensor` that has the same\n",
      "        values as `tensor` in the same order, except with a new shape given by\n",
      "        `shape`.\n",
      "        \n",
      "        >>> t1 = [[1, 2, 3],\n",
      "        ...       [4, 5, 6]]\n",
      "        >>> print(tf.shape(t1).numpy())\n",
      "        [2 3]\n",
      "        >>> t2 = tf.reshape(t1, [6])\n",
      "        >>> t2\n",
      "        <tf.Tensor: shape=(6,), dtype=int32,\n",
      "          numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "        >>> tf.reshape(t2, [3, 2])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        \n",
      "        The `tf.reshape` does not change the order of or the total number of elements\n",
      "        in the tensor, and so it can reuse the underlying data buffer. This makes it\n",
      "        a fast operation independent of how big of a tensor it is operating on.\n",
      "        \n",
      "        >>> tf.reshape([1, 2, 3], [2, 2])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        InvalidArgumentError: Input to reshape is a tensor with 3 values, but the\n",
      "        requested shape has 4\n",
      "        \n",
      "        To instead reorder the data to rearrange the dimensions of a tensor, see\n",
      "        `tf.transpose`.\n",
      "        \n",
      "        >>> t = [[1, 2, 3],\n",
      "        ...      [4, 5, 6]]\n",
      "        >>> tf.reshape(t, [3, 2]).numpy()\n",
      "        array([[1, 2],\n",
      "               [3, 4],\n",
      "               [5, 6]], dtype=int32)\n",
      "        >>> tf.transpose(t, perm=[1, 0]).numpy()\n",
      "        array([[1, 4],\n",
      "               [2, 5],\n",
      "               [3, 6]], dtype=int32)\n",
      "        \n",
      "        If one component of `shape` is the special value -1, the size of that\n",
      "        dimension is computed so that the total size remains constant.  In particular,\n",
      "        a `shape` of `[-1]` flattens into 1-D.  At most one component of `shape` can\n",
      "        be -1.\n",
      "        \n",
      "        >>> t = [[1, 2, 3],\n",
      "        ...      [4, 5, 6]]\n",
      "        >>> tf.reshape(t, [-1])\n",
      "        <tf.Tensor: shape=(6,), dtype=int32,\n",
      "          numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "        >>> tf.reshape(t, [3, -1])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        >>> tf.reshape(t, [-1, 2])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "          array([[1, 2],\n",
      "                 [3, 4],\n",
      "                 [5, 6]], dtype=int32)>\n",
      "        \n",
      "        `tf.reshape(t, [])` reshapes a tensor `t` with one element to a scalar.\n",
      "        \n",
      "        >>> tf.reshape([7], []).numpy()\n",
      "        7\n",
      "        \n",
      "        More examples:\n",
      "        \n",
      "        >>> t = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [9]\n",
      "        >>> tf.reshape(t, [3, 3])\n",
      "        <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "          array([[1, 2, 3],\n",
      "                 [4, 5, 6],\n",
      "                 [7, 8, 9]], dtype=int32)>\n",
      "        \n",
      "        >>> t = [[[1, 1], [2, 2]],\n",
      "        ...      [[3, 3], [4, 4]]]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [2 2 2]\n",
      "        >>> tf.reshape(t, [2, 4])\n",
      "        <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "          array([[1, 1, 2, 2],\n",
      "                 [3, 3, 4, 4]], dtype=int32)>\n",
      "        \n",
      "        >>> t = [[[1, 1, 1],\n",
      "        ...       [2, 2, 2]],\n",
      "        ...      [[3, 3, 3],\n",
      "        ...       [4, 4, 4]],\n",
      "        ...      [[5, 5, 5],\n",
      "        ...       [6, 6, 6]]]\n",
      "        >>> print(tf.shape(t).numpy())\n",
      "        [3 2 3]\n",
      "        >>> # Pass '[-1]' to flatten 't'.\n",
      "        >>> tf.reshape(t, [-1])\n",
      "        <tf.Tensor: shape=(18,), dtype=int32,\n",
      "          numpy=array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n",
      "          dtype=int32)>\n",
      "        >>> # -- Using -1 to infer the shape --\n",
      "        >>> # Here -1 is inferred to be 9:\n",
      "        >>> tf.reshape(t, [2, -1])\n",
      "        <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "          array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                 [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "        >>> # -1 is inferred to be 2:\n",
      "        >>> tf.reshape(t, [-1, 9])\n",
      "        <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "          array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                 [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "        >>> # -1 is inferred to be 3:\n",
      "        >>> tf.reshape(t, [ 2, -1, 3])\n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=\n",
      "          array([[[1, 1, 1],\n",
      "                  [2, 2, 2],\n",
      "                  [3, 3, 3]],\n",
      "                 [[4, 4, 4],\n",
      "                  [5, 5, 5],\n",
      "                  [6, 6, 6]]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Defines the shape of the output tensor.\n",
      "          name: Optional string. A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    resource_variables_enabled() -> bool\n",
      "        Returns `True` if resource variables are enabled.\n",
      "        \n",
      "        Resource variables are improved versions of TensorFlow variables with a\n",
      "        well-defined memory model. Accessing a resource variable reads its value, and\n",
      "        all ops which access a specific read value of the variable are guaranteed to\n",
      "        see the same value for that tensor. Writes which happen after a read (by\n",
      "        having a control or data dependency on the read) are guaranteed not to affect\n",
      "        the value of the read tensor, and similarly writes which happen before a read\n",
      "        are guaranteed to affect the value. No guarantees are made about unordered\n",
      "        read/write pairs.\n",
      "        \n",
      "        Calling tf.enable_resource_variables() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "    \n",
      "    reverse = reverse_v2(tensor: Annotated[Any, ~TV_ReverseV2_T], axis: Annotated[Any, ~TV_ReverseV2_Tidx], name=None) -> Annotated[Any, ~TV_ReverseV2_T]\n",
      "        Reverses specific dimensions of a tensor.\n",
      "        \n",
      "        Given a `tensor`, and a `int32` tensor `axis` representing the set of\n",
      "        dimensions of `tensor` to reverse. This operation reverses each dimension\n",
      "        `i` for which there exists `j` s.t. `axis[j] == i`.\n",
      "        \n",
      "        `tensor` can have up to 8 dimensions. The number of dimensions specified\n",
      "        in `axis` may be 0 or more entries. If an index is specified more than\n",
      "        once, a InvalidArgument error is raised.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 't' is [[[[ 0,  1,  2,  3],\n",
      "        #                  [ 4,  5,  6,  7],\n",
      "        #                  [ 8,  9, 10, 11]],\n",
      "        #                 [[12, 13, 14, 15],\n",
      "        #                  [16, 17, 18, 19],\n",
      "        #                  [20, 21, 22, 23]]]]\n",
      "        # tensor 't' shape is [1, 2, 3, 4]\n",
      "        \n",
      "        # 'dims' is [3] or 'dims' is [-1]\n",
      "        reverse(t, dims) ==> [[[[ 3,  2,  1,  0],\n",
      "                                [ 7,  6,  5,  4],\n",
      "                                [ 11, 10, 9, 8]],\n",
      "                               [[15, 14, 13, 12],\n",
      "                                [19, 18, 17, 16],\n",
      "                                [23, 22, 21, 20]]]]\n",
      "        \n",
      "        # 'dims' is '[1]' (or 'dims' is '[-3]')\n",
      "        reverse(t, dims) ==> [[[[12, 13, 14, 15],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [20, 21, 22, 23]\n",
      "                               [[ 0,  1,  2,  3],\n",
      "                                [ 4,  5,  6,  7],\n",
      "                                [ 8,  9, 10, 11]]]]\n",
      "        \n",
      "        # 'dims' is '[2]' (or 'dims' is '[-2]')\n",
      "        reverse(t, dims) ==> [[[[8, 9, 10, 11],\n",
      "                                [4, 5, 6, 7],\n",
      "                                [0, 1, 2, 3]]\n",
      "                               [[20, 21, 22, 23],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [12, 13, 14, 15]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `int64`, `uint64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.\n",
      "            Up to 8-D.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. The indices of the dimensions to reverse. Must be in the range\n",
      "            `[-rank(tensor), rank(tensor))`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    reverse_sequence(input, seq_lengths, seq_axis=None, batch_axis=None, name=None, seq_dim=None, batch_dim=None)\n",
      "        Reverses variable length slices. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(seq_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        seq_dim is deprecated, use seq_axis instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(batch_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        batch_dim is deprecated, use batch_axis instead\n",
      "        \n",
      "        This op first slices `input` along the dimension `batch_axis`, and for\n",
      "        each slice `i`, reverses the first `seq_lengths[i]` elements along the\n",
      "        dimension `seq_axis`.\n",
      "        \n",
      "        The elements of `seq_lengths` must obey `seq_lengths[i] <=\n",
      "        input.dims[seq_axis]`, and `seq_lengths` must be a vector of length\n",
      "        `input.dims[batch_axis]`.\n",
      "        \n",
      "        The output slice `i` along dimension `batch_axis` is then given by\n",
      "        input slice `i`, with the first `seq_lengths[i]` slices along\n",
      "        dimension `seq_axis` reversed.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> seq_lengths = [7, 2, 3, 5]\n",
      "        >>> input = [[1, 2, 3, 4, 5, 0, 0, 0], [1, 2, 0, 0, 0, 0, 0, 0],\n",
      "        ...          [1, 2, 3, 4, 0, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7, 8]]\n",
      "        >>> output = tf.reverse_sequence(input, seq_lengths, seq_axis=1, batch_axis=0)\n",
      "        >>> output\n",
      "        <tf.Tensor: shape=(4, 8), dtype=int32, numpy=\n",
      "        array([[0, 0, 5, 4, 3, 2, 1, 0],\n",
      "               [2, 1, 0, 0, 0, 0, 0, 0],\n",
      "               [3, 2, 1, 4, 0, 0, 0, 0],\n",
      "               [5, 4, 3, 2, 1, 6, 7, 8]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The input to reverse.\n",
      "          seq_lengths: A `Tensor`. Must be one of the following types: `int32`,\n",
      "            `int64`. 1-D with length `input.dims(batch_axis)` and `max(seq_lengths) <=\n",
      "            input.dims(seq_axis)`\n",
      "          seq_axis: An `int`. The dimension which is partially reversed.\n",
      "          batch_axis: An optional `int`. Defaults to `0`. The dimension along which\n",
      "            reversal is performed.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor. Has the same type as input.\n",
      "    \n",
      "    reverse_v2(tensor: Annotated[Any, ~TV_ReverseV2_T], axis: Annotated[Any, ~TV_ReverseV2_Tidx], name=None) -> Annotated[Any, ~TV_ReverseV2_T]\n",
      "        Reverses specific dimensions of a tensor.\n",
      "        \n",
      "        Given a `tensor`, and a `int32` tensor `axis` representing the set of\n",
      "        dimensions of `tensor` to reverse. This operation reverses each dimension\n",
      "        `i` for which there exists `j` s.t. `axis[j] == i`.\n",
      "        \n",
      "        `tensor` can have up to 8 dimensions. The number of dimensions specified\n",
      "        in `axis` may be 0 or more entries. If an index is specified more than\n",
      "        once, a InvalidArgument error is raised.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 't' is [[[[ 0,  1,  2,  3],\n",
      "        #                  [ 4,  5,  6,  7],\n",
      "        #                  [ 8,  9, 10, 11]],\n",
      "        #                 [[12, 13, 14, 15],\n",
      "        #                  [16, 17, 18, 19],\n",
      "        #                  [20, 21, 22, 23]]]]\n",
      "        # tensor 't' shape is [1, 2, 3, 4]\n",
      "        \n",
      "        # 'dims' is [3] or 'dims' is [-1]\n",
      "        reverse(t, dims) ==> [[[[ 3,  2,  1,  0],\n",
      "                                [ 7,  6,  5,  4],\n",
      "                                [ 11, 10, 9, 8]],\n",
      "                               [[15, 14, 13, 12],\n",
      "                                [19, 18, 17, 16],\n",
      "                                [23, 22, 21, 20]]]]\n",
      "        \n",
      "        # 'dims' is '[1]' (or 'dims' is '[-3]')\n",
      "        reverse(t, dims) ==> [[[[12, 13, 14, 15],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [20, 21, 22, 23]\n",
      "                               [[ 0,  1,  2,  3],\n",
      "                                [ 4,  5,  6,  7],\n",
      "                                [ 8,  9, 10, 11]]]]\n",
      "        \n",
      "        # 'dims' is '[2]' (or 'dims' is '[-2]')\n",
      "        reverse(t, dims) ==> [[[[8, 9, 10, 11],\n",
      "                                [4, 5, 6, 7],\n",
      "                                [0, 1, 2, 3]]\n",
      "                               [[20, 21, 22, 23],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [12, 13, 14, 15]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `int64`, `uint64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.\n",
      "            Up to 8-D.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. The indices of the dimensions to reverse. Must be in the range\n",
      "            `[-rank(tensor), rank(tensor))`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    rfftnd(input: Annotated[Any, ~TV_RFFTND_Treal], fft_length: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], axes: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int32'>], Tcomplex: ~TV_RFFTND_Tcomplex = tf.complex64, name=None) -> Annotated[Any, ~TV_RFFTND_Tcomplex]\n",
      "        ND fast real Fourier transform.\n",
      "        \n",
      "        Computes the n-dimensional real discrete Fourier transform over designated\n",
      "        dimensions of `input`. The designated dimensions of `input` are assumed to be\n",
      "        the result of `RFFTND`. The length of the last axis transformed will be\n",
      "        fft_length[-1]//2+1.\n",
      "        \n",
      "        If fft_length[i]<shape(input)[i], the input is cropped. If\n",
      "        fft_length[i]>shape(input)[i], the input is padded with zeros. If fft_length\n",
      "        is not given, the default shape(input) is used.\n",
      "        \n",
      "        Axes mean the dimensions to perform the transform on. Default is to perform on\n",
      "        all axes.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "            A complex tensor.\n",
      "          fft_length: A `Tensor` of type `int32`.\n",
      "            An int32 tensor. The FFT length for each dimension.\n",
      "          axes: A `Tensor` of type `int32`.\n",
      "            An int32 tensor with a same shape as fft_length. Axes to perform the transform.\n",
      "          Tcomplex: An optional `tf.DType` from: `tf.complex64, tf.complex128`. Defaults to `tf.complex64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `Tcomplex`.\n",
      "    \n",
      "    rint(x: typing.Annotated[_any, ~TV_Rint_T], name=None) -> typing.Annotated[_any, ~TV_Rint_T]\n",
      "        Returns element-wise integer closest to x.\n",
      "        \n",
      "        If the result is midway between two representable values,\n",
      "        the even representable is chosen.\n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        rint(-1.5) ==> -2.0\n",
      "        rint(0.5000001) ==> 1.0\n",
      "        rint([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) ==> [-2., -2., -0., 0., 2., 2., 2.]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    roll(input, shift, axis, name=None)\n",
      "        Rolls the elements of a tensor along an axis.\n",
      "        \n",
      "        The elements are shifted positively (towards larger indices) by the offset of\n",
      "        `shift` along the dimension of `axis`. Negative `shift` values will shift\n",
      "        elements in the opposite direction. Elements that roll passed the last position\n",
      "        will wrap around to the first and vice versa. Multiple shifts along multiple\n",
      "        axes may be specified.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # 't' is [0, 1, 2, 3, 4]\n",
      "        roll(t, shift=2, axis=0) ==> [3, 4, 0, 1, 2]\n",
      "        \n",
      "        # shifting along multiple dimensions\n",
      "        # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
      "        roll(t, shift=[1, -2], axis=[0, 1]) ==> [[7, 8, 9, 5, 6], [2, 3, 4, 0, 1]]\n",
      "        \n",
      "        # shifting along the same axis multiple times\n",
      "        # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
      "        roll(t, shift=[2, -3], axis=[1, 1]) ==> [[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          shift: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Dimension must be 0-D or 1-D. `shift[i]` specifies the number of places by which\n",
      "            elements are shifted positively (towards larger indices) along the dimension\n",
      "            specified by `axis[i]`. Negative shifts will roll the elements in the opposite\n",
      "            direction.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Dimension must be 0-D or 1-D. `axis[i]` specifies the dimension that the shift\n",
      "            `shift[i]` should occur. If the same axis is referenced more than once, the\n",
      "            total shift for that axis will be the sum of all the shifts that belong to that\n",
      "            axis.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    round(x, name=None)\n",
      "        Rounds the values of a tensor to the nearest integer, element-wise.\n",
      "        \n",
      "        Rounds half to even.  Also known as bankers rounding. If you want to round\n",
      "        according to the current system rounding mode use tf::cint.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0.9, 2.5, 2.3, 1.5, -4.5])\n",
      "        tf.round(x)  # [ 1.0, 2.0, 2.0, 2.0, -4.0 ]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, or `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of same shape and type as `x`.\n",
      "    \n",
      "    rsqrt(x, name=None)\n",
      "        Computes reciprocal of square root of x element-wise.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([2., 0., -2.])\n",
      "        >>> tf.math.rsqrt(x)\n",
      "        <tf.Tensor: shape=(3,), dtype=float32,\n",
      "        numpy=array([0.707, inf, nan], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor`. Must be one of the following types: `bfloat16`, `half`,\n",
      "            `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    saturate_cast(value, dtype, name=None)\n",
      "        Performs a safe saturating cast of `value` to `dtype`.\n",
      "        \n",
      "        This function casts the input to `dtype` without overflow.  If\n",
      "        there is a danger that values would over or underflow in the cast, this op\n",
      "        applies the appropriate clamping before the cast.  See `tf.cast` for more\n",
      "        details.\n",
      "        \n",
      "        Args:\n",
      "          value: A `Tensor`.\n",
      "          dtype: The desired output `DType`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `value` safely cast to `dtype`.\n",
      "    \n",
      "    scalar_mul(scalar, x, name=None)\n",
      "        Multiplies a scalar times a `Tensor` or `IndexedSlices` object.\n",
      "        \n",
      "        This is a special case of `tf.math.multiply`, where the first value must be a\n",
      "        `scalar`. Unlike the general form of `tf.math.multiply`, this is operation is\n",
      "        guaranteed to be efficient for `tf.IndexedSlices`.\n",
      "        \n",
      "        >>> x = tf.reshape(tf.range(30, dtype=tf.float32), [10, 3])\n",
      "        >>> with tf.GradientTape() as g:\n",
      "        ...   g.watch(x)\n",
      "        ...   y = tf.gather(x, [1, 2])  # IndexedSlices\n",
      "        ...   z = tf.math.scalar_mul(10.0, y)\n",
      "        \n",
      "        Args:\n",
      "          scalar: A 0-D scalar `Tensor`. Must have known shape.\n",
      "          x: A `Tensor` or `IndexedSlices` to be scaled.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `scalar * x` of the same type (`Tensor` or `IndexedSlices`) as `x`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if scalar is not a 0-D `scalar`.\n",
      "    \n",
      "    scan(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, infer_shape=True, reverse=False, name=None)\n",
      "        scan on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        See also `tf.map_fn`.\n",
      "        \n",
      "        The simplest version of `scan` repeatedly applies the callable `fn` to a\n",
      "        sequence of elements from first to last. The elements are made of the tensors\n",
      "        unpacked from `elems` on dimension 0. The callable fn takes two tensors as\n",
      "        arguments. The first argument is the accumulated value computed from the\n",
      "        preceding invocation of fn, and the second is the value at the current\n",
      "        position of `elems`. If `initializer` is None, `elems` must contain at least\n",
      "        one element, and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `[len(values)] + fn(initializer, values[0]).shape`.\n",
      "        If reverse=True, it's fn(initializer, values[-1]).shape.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and accumulator.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The second argument of\n",
      "        `fn` must match the structure of `elems`.\n",
      "        \n",
      "        If no `initializer` is provided, the output structure and dtypes of `fn`\n",
      "        are assumed to be the same as its input; and in this case, the first\n",
      "        argument of `fn` must match the structure of `elems`.\n",
      "        \n",
      "        If an `initializer` is provided, then the output of `fn` must have the same\n",
      "        structure as `initializer`; and the first argument of `fn` must match\n",
      "        this structure.\n",
      "        \n",
      "        For example, if `elems` is `(t1, [t2, t3])` and `initializer` is\n",
      "        `[i1, i2]` then an appropriate signature for `fn` in `python2` is:\n",
      "        `fn = lambda (acc_p1, acc_p2), (t1, [t2, t3]):` and `fn` must return a list,\n",
      "        `[acc_n1, acc_n2]`.  An alternative correct signature for `fn`, and the\n",
      "         one that works in `python3`, is:\n",
      "        `fn = lambda a, t:`, where `a` and `t` correspond to the input tuples.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.  It accepts two arguments.  The first will\n",
      "            have the same structure as `initializer` if one is provided, otherwise it\n",
      "            will have the same structure as `elems`.  The second will have the same\n",
      "            (possibly nested) structure as `elems`.  Its output must have the same\n",
      "            structure as `initializer` if one is provided, otherwise it must have the\n",
      "            same structure as `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            initial value for the accumulator, and the expected output type of `fn`.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "          reverse: (optional) True scans the tensor last to first (instead of first to\n",
      "            last).\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors.  Each tensor packs the\n",
      "          results of applying `fn` to tensors unpacked from `elems` along the first\n",
      "          dimension, and the previous accumulator value(s), from first to last (or\n",
      "          last to first, if `reverse=True`).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable or the structure of the output of\n",
      "            `fn` and `initializer` do not match.\n",
      "          ValueError: if the lengths of the output of `fn` and `initializer`\n",
      "            do not match.\n",
      "        \n",
      "        Examples:\n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          sum = scan(lambda a, x: a + x, elems)\n",
      "          # sum == [1, 3, 6, 10, 15, 21]\n",
      "          sum = scan(lambda a, x: a + x, elems, reverse=True)\n",
      "          # sum == [21, 20, 18, 15, 11, 6]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          initializer = np.array(0)\n",
      "          sum_one = scan(\n",
      "              lambda a, x: x[0] - x[1] + a, (elems + 1, elems), initializer)\n",
      "          # sum_one == [1, 2, 3, 4, 5, 6]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 0, 0, 0, 0, 0])\n",
      "          initializer = (np.array(0), np.array(1))\n",
      "          fibonaccis = scan(lambda a, _: (a[1], a[0] + a[1]), elems, initializer)\n",
      "          # fibonaccis == ([1, 1, 2, 3, 5, 8], [1, 2, 3, 5, 8, 13])\n",
      "          ```\n",
      "    \n",
      "    scatter_add(ref, indices, updates, use_locking=False, name=None)\n",
      "        Adds sparse updates to the variable referenced by `resource`.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] += updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] += updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the updated value.\n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions add.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A `Variable`.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to store in `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the updated values after the update is done.\n",
      "    \n",
      "    scatter_div(ref, indices, updates, use_locking=False, name=None)\n",
      "        Divides a variable reference by sparse updates.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] /= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] /= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions divide.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of values\n",
      "            that `ref` is divided by.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the operation\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_max(ref, indices, updates, use_locking=False, name=None)\n",
      "        Reduces sparse updates into a variable reference using the `max` operation.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = max(ref[indices, ...], updates[...])\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...],\n",
      "            updates[i, ..., j, ...])\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions combine.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterAdd.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `half`,\n",
      "            `bfloat16`, `float32`, `float64`, `int32`, `int64`. Should be from a\n",
      "            `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to reduce into `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the update\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_min(ref, indices, updates, use_locking=False, name=None)\n",
      "        Reduces sparse updates into a variable reference using the `min` operation.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = min(ref[indices, ...], updates[...])\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...],\n",
      "            updates[i, ..., j, ...])\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions combine.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterAdd.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `half`,\n",
      "            `bfloat16`, `float32`, `float64`, `int32`, `int64`. Should be from a\n",
      "            `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to reduce into `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the update\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_mul(ref, indices, updates, use_locking=False, name=None)\n",
      "        Multiplies sparse updates into a variable reference.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] *= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] *= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions multiply.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to multiply to `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the operation\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd(indices: Annotated[Any, ~TV_ScatterNd_Tindices], updates: Annotated[Any, ~TV_ScatterNd_T], shape: Annotated[Any, ~TV_ScatterNd_Tindices], name=None) -> Annotated[Any, ~TV_ScatterNd_T]\n",
      "        Scatters `updates` into a tensor of shape `shape` according to `indices`.\n",
      "        \n",
      "        Scatter sparse `updates` according to individual values at the specified\n",
      "        `indices`. This op returns an output tensor with the `shape` you specify. This\n",
      "        op is the inverse of the `tf.gather_nd` operator which extracts values or slices\n",
      "        from a given tensor.\n",
      "        \n",
      "        This operation is similar to `tf.tensor_scatter_nd_add`, except that the tensor\n",
      "        is zero-initialized. Calling `tf.scatter_nd(indices, updates, shape)`\n",
      "        is identical to calling\n",
      "        `tf.tensor_scatter_nd_add(tf.zeros(shape, updates.dtype), indices, updates)`\n",
      "        \n",
      "        If `indices` contains duplicates, the associated `updates` are accumulated\n",
      "        (summed) into the output tensor.\n",
      "        \n",
      "        **WARNING**: For floating-point data types, the output may be nondeterministic.\n",
      "        This is because the order in which the updates are applied is nondeterministic\n",
      "        and when floating-point numbers are added in different orders the resulting\n",
      "        numerical approximation error can be slightly different. However, the output\n",
      "        will be deterministic if op determinism is enabled via\n",
      "        `tf.config.experimental.enable_op_determinism`.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into the output tensor. The\n",
      "        last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices of elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.\n",
      "        \n",
      "        `updates` is a tensor with shape:\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of the scatter op is to insert individual elements in\n",
      "        a tensor by index. Consider an example where you want to insert 4 scattered\n",
      "        elements in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd1.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            shape = tf.constant([8])\n",
      "            scatter = tf.scatter_nd(indices, updates, shape)\n",
      "            print(scatter)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [0, 11, 0, 10, 9, 0, 0, 12]\n",
      "        \n",
      "        You can also insert entire slices of a higher rank tensor all at once. For\n",
      "        example, you can insert two slices in the first dimension of a rank-3 tensor\n",
      "        with two matrices of new values.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd2.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[1], [3]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            shape = tf.constant([4, 4, 4])\n",
      "            scatter = tf.scatter_nd(indices, updates, shape)\n",
      "            print(scatter)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "             [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            Tensor of indices.\n",
      "          updates: A `Tensor`. Values to scatter into the output tensor.\n",
      "          shape: A `Tensor`. Must have the same type as `indices`.\n",
      "            1-D. The shape of the output tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `updates`.\n",
      "    \n",
      "    scatter_nd_add(ref, indices, updates, use_locking=False, name=None)\n",
      "        Applies sparse addition to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "        8 elements. In Python, that addition would look like this:\n",
      "        \n",
      "        ```python\n",
      "        ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "        indices = tf.constant([[4], [3], [1], [7]])\n",
      "        updates = tf.constant([9, 10, 11, 12])\n",
      "        add = tf.compat.v1.scatter_nd_add(ref, indices, updates)\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print sess.run(add)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, 13, 3, 14, 14, 6, 7, 20]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. A mutable Tensor. Should be from a Variable node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd_sub(ref, indices, updates, use_locking=False, name=None)\n",
      "        Applies sparse subtraction to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to subtract 4 scattered elements from a rank-1 tensor\n",
      "        with 8 elements. In Python, that update would look like this:\n",
      "        \n",
      "        ```python\n",
      "        ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "        indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "        updates = tf.constant([9, 10, 11, 12])\n",
      "        op = tf.compat.v1.scatter_nd_sub(ref, indices, updates)\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print sess.run(op)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, -9, 3, -6, -6, 6, 7, -4]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. A mutable Tensor. Should be from a Variable node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            An optional bool. Defaults to True. If True, the assignment will\n",
      "            be protected by a lock; otherwise the behavior is undefined,\n",
      "            but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Applies sparse `updates` to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to update 4 scattered elements to a rank-1 tensor to\n",
      "        8 elements. In Python, that update would look like this:\n",
      "        \n",
      "        ```python\n",
      "            ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "            indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            update = tf.compat.v1.scatter_nd_update(ref, indices, updates)\n",
      "            with tf.compat.v1.Session() as sess:\n",
      "              print sess.run(update)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, 11, 3, 10, 9, 6, 7, 12]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A Variable.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A Tensor. Must have the same type as ref. A tensor of updated\n",
      "            values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `True`.\n",
      "            An optional bool. Defaults to True. If True, the assignment will\n",
      "            be protected by a lock; otherwise the behavior is undefined,\n",
      "            but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The value of the variable after the update.\n",
      "    \n",
      "    scatter_sub(ref, indices, updates, use_locking=False, name=None)\n",
      "        Subtracts sparse updates to a variable reference.\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] -= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] -= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their (negated) contributions add.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or\n",
      "        `updates.shape = []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\"\n",
      "             src=\"https://www.tensorflow.org/images/ScatterSub.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to subtract from `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the subtraction will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Applies sparse updates to a variable reference.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        If values in `ref` is to be updated more than once, because there are\n",
      "        duplicate entries in `indices`, the order at which the updates happen\n",
      "        for each value is undefined.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterUpdate.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A `Variable`.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to store in `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `True`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the updated values after the update is done.\n",
      "    \n",
      "    searchsorted(sorted_sequence, values, side='left', out_type=tf.int32, name=None)\n",
      "        Searches for where a value would go in a sorted sequence.\n",
      "        \n",
      "        This is not a method for checking containment (like python `in`).\n",
      "        \n",
      "        The typical use case for this operation is \"binning\", \"bucketing\", or\n",
      "        \"discretizing\". The `values` are assigned to bucket-indices based on the\n",
      "        **edges** listed in `sorted_sequence`. This operation\n",
      "        returns the bucket-index for each value.\n",
      "        \n",
      "        >>> edges = [-1, 3.3, 9.1, 10.0]\n",
      "        >>> values = [0.0, 4.1, 12.0]\n",
      "        >>> tf.searchsorted(edges, values).numpy()\n",
      "        array([1, 2, 4], dtype=int32)\n",
      "        \n",
      "        The `side` argument controls which index is returned if a value lands exactly\n",
      "        on an edge:\n",
      "        \n",
      "        >>> seq = [0, 3, 9, 10, 10]\n",
      "        >>> values = [0, 4, 10]\n",
      "        >>> tf.searchsorted(seq, values).numpy()\n",
      "        array([0, 2, 3], dtype=int32)\n",
      "        >>> tf.searchsorted(seq, values, side=\"right\").numpy()\n",
      "        array([1, 2, 5], dtype=int32)\n",
      "        \n",
      "        The `axis` is not settable for this operation. It always operates on the\n",
      "        innermost dimension (`axis=-1`). The operation will accept any number of\n",
      "        outer dimensions. Here it is applied to the rows of a matrix:\n",
      "        \n",
      "        >>> sorted_sequence = [[0., 3., 8., 9., 10.],\n",
      "        ...                    [1., 2., 3., 4., 5.]]\n",
      "        >>> values = [[9.8, 2.1, 4.3],\n",
      "        ...           [0.1, 6.6, 4.5, ]]\n",
      "        >>> tf.searchsorted(sorted_sequence, values).numpy()\n",
      "        array([[4, 1, 2],\n",
      "               [0, 5, 4]], dtype=int32)\n",
      "        \n",
      "        Note: This operation assumes that `sorted_sequence` **is sorted** along the\n",
      "        innermost axis, maybe using `tf.sort(..., axis=-1)`. **If the sequence is not\n",
      "        sorted, no error is raised** and the content of the returned tensor is not well\n",
      "        defined.\n",
      "        \n",
      "        Args:\n",
      "          sorted_sequence: N-D `Tensor` containing a sorted sequence.\n",
      "          values: N-D `Tensor` containing the search values.\n",
      "          side: 'left' or 'right'; 'left' corresponds to lower_bound and 'right' to\n",
      "            upper_bound.\n",
      "          out_type: The output type (`int32` or `int64`).  Default is `tf.int32`.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          An N-D `Tensor` the size of `values` containing the result of applying\n",
      "          either lower_bound or upper_bound (depending on side) to each value.  The\n",
      "          result is not a global index to the entire `Tensor`, but the index in the\n",
      "          last dimension.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the last dimension of `sorted_sequence >= 2^31-1` elements.\n",
      "                      If the total size of `values` exceeds `2^31 - 1` elements.\n",
      "                      If the first `N-1` dimensions of the two tensors don't match.\n",
      "    \n",
      "    segment_max(data: typing.Annotated[_any, ~TV_SegmentMax_T], segment_ids: typing.Annotated[_any, ~TV_SegmentMax_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentMax_T]\n",
      "        Computes the maximum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\max_j(data_j)\\\\) where `max` is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the max is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as the same as a smaller following index.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMax.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_max(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[4, 3, 3, 4],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_mean(data: typing.Annotated[_any, ~TV_SegmentMean_T], segment_ids: typing.Annotated[_any, ~TV_SegmentMean_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentMean_T]\n",
      "        Computes the mean along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\frac{\\sum_j data_j}{N}\\\\) where `mean` is\n",
      "        over `j` such that `segment_ids[j] == i` and `N` is the total number of\n",
      "        values summed.\n",
      "        \n",
      "        If the mean is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as a smaller following index when computing the numerator\n",
      "        of the mean.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMean.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1.0,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_mean(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[2.5, 2.5, 2.5, 2.5],\n",
      "               [5., 6., 7., 8.]], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_min(data: typing.Annotated[_any, ~TV_SegmentMin_T], segment_ids: typing.Annotated[_any, ~TV_SegmentMin_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentMin_T]\n",
      "        Computes the minimum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\min_j(data_j)\\\\) where `min` is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the min is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as the same as a smaller following index.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMin.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_min(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[1, 2, 2, 1],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_prod(data: typing.Annotated[_any, ~TV_SegmentProd_T], segment_ids: typing.Annotated[_any, ~TV_SegmentProd_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentProd_T]\n",
      "        Computes the product along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\prod_j data_j\\\\) where the product is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the product is empty for a given segment ID `i`, `output[i] = 1`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as the same as a smaller following index.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentProd.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_prod(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[4, 6, 6, 4],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_sum(data: typing.Annotated[_any, ~TV_SegmentSum_T], segment_ids: typing.Annotated[_any, ~TV_SegmentSum_Tindices], name=None) -> typing.Annotated[_any, ~TV_SegmentSum_T]\n",
      "        Computes the sum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\sum_j data_j\\\\) where sum is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the sum is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be sorted,\n",
      "        and an error is thrown for indices that are not increasing. On GPU, this\n",
      "        does not throw an error for unsorted indices. On GPU, out-of-order indices\n",
      "        result in safe but unspecified behavior, which may include treating\n",
      "        out-of-order indices as the same as a smaller following index.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentSum.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        >>> tf.math.segment_sum(c, tf.constant([0, 0, 1])).numpy()\n",
      "        array([[5, 5, 5, 5],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "        \n",
      "            Caution: The values are always validated to be sorted on CPU, never validated\n",
      "            on GPU.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    self_adjoint_eig(tensor, name=None)\n",
      "        Computes the eigen decomposition of a batch of self-adjoint matrices.\n",
      "        \n",
      "        Computes the eigenvalues and eigenvectors of the innermost N-by-N matrices\n",
      "        in `tensor` such that\n",
      "        `tensor[...,:,:] * v[..., :,i] = e[..., i] * v[...,:,i]`, for i=0...N-1.\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., N, N]`. Only the lower triangular part of\n",
      "            each inner inner matrix is referenced.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          e: Eigenvalues. Shape is `[..., N]`. Sorted in non-decreasing order.\n",
      "          v: Eigenvectors. Shape is `[..., N, N]`. The columns of the inner most\n",
      "            matrices contain eigenvectors of the corresponding matrices in `tensor`\n",
      "    \n",
      "    self_adjoint_eigvals(tensor, name=None)\n",
      "        Computes the eigenvalues of one or more self-adjoint matrices.\n",
      "        \n",
      "        Note: If your program backpropagates through this function, you should replace\n",
      "        it with a call to tf.linalg.eigh (possibly ignoring the second output) to\n",
      "        avoid computing the eigen decomposition twice. This is because the\n",
      "        eigenvectors are used to compute the gradient w.r.t. the eigenvalues. See\n",
      "        _SelfAdjointEigV2Grad in linalg_grad.py.\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., N, N]`.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          e: Eigenvalues. Shape is `[..., N]`. The vector `e[..., :]` contains the `N`\n",
      "            eigenvalues of `tensor[..., :, :]`.\n",
      "    \n",
      "    sequence_mask(lengths, maxlen=None, dtype=tf.bool, name=None)\n",
      "        Returns a mask tensor representing the first N positions of each cell.\n",
      "        \n",
      "        If `lengths` has shape `[d_1, d_2, ..., d_n]` the resulting tensor `mask` has\n",
      "        dtype `dtype` and shape `[d_1, d_2, ..., d_n, maxlen]`, with\n",
      "        \n",
      "        ```\n",
      "        mask[i_1, i_2, ..., i_n, j] = (j < lengths[i_1, i_2, ..., i_n])\n",
      "        ```\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        tf.sequence_mask([1, 3, 2], 5)  # [[True, False, False, False, False],\n",
      "                                        #  [True, True, True, False, False],\n",
      "                                        #  [True, True, False, False, False]]\n",
      "        \n",
      "        tf.sequence_mask([[1, 3],[2,0]])  # [[[True, False, False],\n",
      "                                          #   [True, True, True]],\n",
      "                                          #  [[True, True, False],\n",
      "                                          #   [False, False, False]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          lengths: integer tensor, all its values <= maxlen.\n",
      "          maxlen: scalar integer tensor, size of last dimension of returned tensor.\n",
      "            Default is the maximum value in `lengths`.\n",
      "          dtype: output type of the resulting tensor.\n",
      "          name: name of the op.\n",
      "        \n",
      "        Returns:\n",
      "          A mask tensor of shape `lengths.shape + (maxlen,)`, cast to specified dtype.\n",
      "        Raises:\n",
      "          ValueError: if `maxlen` is not a scalar.\n",
      "    \n",
      "    serialize_many_sparse(sp_input, name=None, out_type=tf.string)\n",
      "        Serialize `N`-minibatch `SparseTensor` into an `[N, 3]` `Tensor`.\n",
      "        \n",
      "        The `SparseTensor` must have rank `R` greater than 1, and the first dimension\n",
      "        is treated as the minibatch dimension.  Elements of the `SparseTensor`\n",
      "        must be sorted in increasing order of this first dimension.  The serialized\n",
      "        `SparseTensor` objects going into each row of the output `Tensor` will have\n",
      "        rank `R-1`.\n",
      "        \n",
      "        The minibatch size `N` is extracted from `sparse_shape[0]`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input rank `R` `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          out_type: The `dtype` to use for serialization.\n",
      "        \n",
      "        Returns:\n",
      "          A matrix (2-D `Tensor`) with `N` rows and `3` columns. Each column\n",
      "          represents serialized `SparseTensor`'s indices, values, and shape\n",
      "          (respectively).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    serialize_sparse(sp_input, name=None, out_type=tf.string)\n",
      "        Serialize a `SparseTensor` into a 3-vector (1-D `Tensor`) object.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          out_type: The `dtype` to use for serialization.\n",
      "        \n",
      "        Returns:\n",
      "          A 3-vector (1-D `Tensor`), with each column representing the serialized\n",
      "          `SparseTensor`'s indices, values, and shape (respectively).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    serialize_tensor(tensor, name=None)\n",
      "        Transforms a Tensor into a serialized TensorProto proto.\n",
      "        \n",
      "        This operation transforms data in a `tf.Tensor` into a `tf.Tensor` of type\n",
      "        `tf.string` containing the data in a binary string in little-endian format.\n",
      "        This operation can transform scalar data and linear arrays, but it is most\n",
      "        useful in converting multidimensional arrays into a format accepted by binary\n",
      "        storage formats such as a `TFRecord` or `tf.train.Example`.\n",
      "        \n",
      "        See also:\n",
      "        - `tf.io.parse_tensor`: inverse operation of `tf.io.serialize_tensor` that\n",
      "        transforms a scalar string containing a serialized Tensor in little-endian\n",
      "        format into a Tensor of a specified type.\n",
      "        - `tf.ensure_shape`: `parse_tensor` cannot statically determine the shape of\n",
      "        the parsed tensor. Use `tf.ensure_shape` to set the static shape when running\n",
      "        under a `tf.function`\n",
      "        - `.SerializeToString`, serializes a proto to a binary-string\n",
      "        \n",
      "        Example of serializing scalar data:\n",
      "        \n",
      "        >>> t = tf.constant(1)\n",
      "        >>> tf.io.serialize_tensor(t)\n",
      "        <tf.Tensor: shape=(), dtype=string, numpy=b'\\x08...\\x00'>\n",
      "        \n",
      "        Example of storing non-scalar data into a `tf.train.Example`:\n",
      "        \n",
      "        >>> t1 = [[1, 2]]\n",
      "        >>> t2 = [[7, 8]]\n",
      "        >>> nonscalar = tf.concat([t1, t2], 0)\n",
      "        >>> nonscalar\n",
      "        <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "        array([[1, 2],\n",
      "               [7, 8]], dtype=int32)>\n",
      "        \n",
      "        Serialize the data using `tf.io.serialize_tensor`.\n",
      "        \n",
      "        >>> serialized_nonscalar = tf.io.serialize_tensor(nonscalar)\n",
      "        >>> serialized_nonscalar\n",
      "        <tf.Tensor: shape=(), dtype=string, numpy=b'\\x08...\\x00'>\n",
      "        \n",
      "        Store the data in a `tf.train.Feature`.\n",
      "        \n",
      "        >>> feature_of_bytes = tf.train.Feature(\n",
      "        ...   bytes_list=tf.train.BytesList(value=[serialized_nonscalar.numpy()]))\n",
      "        >>> feature_of_bytes\n",
      "        bytes_list {\n",
      "          value: \"\\010...\\000\"\n",
      "        }\n",
      "        \n",
      "        Put the `tf.train.Feature` message into a `tf.train.Example`.\n",
      "        \n",
      "        >>> features_for_example = {\n",
      "        ...   'feature0': feature_of_bytes\n",
      "        ... }\n",
      "        >>> example_proto = tf.train.Example(\n",
      "        ...   features=tf.train.Features(feature=features_for_example))\n",
      "        >>> example_proto\n",
      "        features {\n",
      "          feature {\n",
      "            key: \"feature0\"\n",
      "            value {\n",
      "              bytes_list {\n",
      "                value: \"\\010...\\000\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `tf.Tensor`.\n",
      "          name: string.  Optional name for the op.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor of dtype string.\n",
      "    \n",
      "    set_random_seed(seed)\n",
      "        Sets the graph-level random seed for the default graph.\n",
      "        \n",
      "        Operations that rely on a random seed actually derive it from two seeds:\n",
      "        the graph-level and operation-level seeds. This sets the graph-level seed.\n",
      "        \n",
      "        Its interactions with operation-level seeds is as follows:\n",
      "        \n",
      "          1. If neither the graph-level nor the operation seed is set:\n",
      "            A random seed is used for this op.\n",
      "          2. If the graph-level seed is set, but the operation seed is not:\n",
      "            The system deterministically picks an operation seed in conjunction with\n",
      "            the graph-level seed so that it gets a unique random sequence. Within the\n",
      "            same version of tensorflow and user code, this sequence is deterministic.\n",
      "            However across different versions, this sequence might change. If the\n",
      "            code depends on particular seeds to work, specify both graph-level\n",
      "            and operation-level seeds explicitly.\n",
      "          3. If the graph-level seed is not set, but the operation seed is set:\n",
      "            A default graph-level seed and the specified operation seed are used to\n",
      "            determine the random sequence.\n",
      "          4. If both the graph-level and the operation seed are set:\n",
      "            Both seeds are used in conjunction to determine the random sequence.\n",
      "        \n",
      "        To illustrate the user-visible effects, consider these examples:\n",
      "        \n",
      "        To generate different sequences across sessions, set neither\n",
      "        graph-level nor op-level seeds:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.random.uniform([1])\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A3'\n",
      "          print(sess2.run(a))  # generates 'A4'\n",
      "          print(sess2.run(b))  # generates 'B3'\n",
      "          print(sess2.run(b))  # generates 'B4'\n",
      "        ```\n",
      "        \n",
      "        To generate the same repeatable sequence for an op across sessions, set the\n",
      "        seed for the op:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.random.uniform([1], seed=1)\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        # Repeatedly running this block with the same graph will generate the same\n",
      "        # sequence of values for 'a', but different sequences of values for 'b'.\n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A1'\n",
      "          print(sess2.run(a))  # generates 'A2'\n",
      "          print(sess2.run(b))  # generates 'B3'\n",
      "          print(sess2.run(b))  # generates 'B4'\n",
      "        ```\n",
      "        \n",
      "        To make the random sequences generated by all ops be repeatable across\n",
      "        sessions, set a graph-level seed:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.random.set_random_seed(1234)\n",
      "        a = tf.random.uniform([1])\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        # Repeatedly running this block with the same graph will generate the same\n",
      "        # sequences of 'a' and 'b'.\n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A1'\n",
      "          print(sess2.run(a))  # generates 'A2'\n",
      "          print(sess2.run(b))  # generates 'B1'\n",
      "          print(sess2.run(b))  # generates 'B2'\n",
      "        ```\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        'tf.compat.v1.set_random_seed' is compatible with eager mode. However,\n",
      "        in eager mode this API will set the global seed instead of the\n",
      "        graph-level seed of the default graph. In TF2 this API is changed to\n",
      "        [tf.random.set_seed]\n",
      "        (https://www.tensorflow.org/api_docs/python/tf/random/set_seed).\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          seed: integer.\n",
      "    \n",
      "    setdiff1d(x, y, index_dtype=tf.int32, name=None)\n",
      "        Computes the difference between two lists of numbers or strings.\n",
      "        \n",
      "        Given a list `x` and a list `y`, this operation returns a list `out` that\n",
      "        represents all values that are in `x` but not in `y`. The returned list `out`\n",
      "        is sorted in the same order that the numbers appear in `x` (duplicates are\n",
      "        preserved). This operation also returns a list `idx` that represents the\n",
      "        position of each `out` element in `x`. In other words:\n",
      "        \n",
      "        `out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]`\n",
      "        \n",
      "        For example, given this input:\n",
      "        \n",
      "        ```\n",
      "        x = [1, 2, 3, 4, 5, 6]\n",
      "        y = [1, 3, 5]\n",
      "        ```\n",
      "        \n",
      "        This operation would return:\n",
      "        \n",
      "        ```\n",
      "        out ==> [2, 4, 6]\n",
      "        idx ==> [1, 3, 5]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D. Values to keep.\n",
      "          y: A `Tensor`. Must have the same type as `x`. 1-D. Values to remove.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (out, idx).\n",
      "        \n",
      "          out: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    shape(input, name=None, out_type=None)\n",
      "        Returns the shape of a tensor.\n",
      "        \n",
      "        This operation returns a 1-D integer tensor representing the shape of `input`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.shape(t)  # [2, 2, 3]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          out_type: (Optional) The specified output type of the operation (`int32`\n",
      "          or `int64`). Defaults to `tf.int32`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    shape_n(input, out_type=tf.int32, name=None)\n",
      "        Returns shape of a list of tensors.\n",
      "        \n",
      "        Given a list of tensors, `tf.shape_n` is much faster than applying `tf.shape`\n",
      "        to each tensor individually.\n",
      "        >>> a = tf.ones([1, 2])\n",
      "        >>> b = tf.ones([2, 3])\n",
      "        >>> c = tf.ones([3, 4])\n",
      "        >>> tf.shape_n([a, b, c])\n",
      "        [<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>,\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>,\n",
      "        <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>]\n",
      "        \n",
      "        Args:\n",
      "          input: A list of at least 1 `Tensor` object with the same dtype.\n",
      "          out_type: The specified output type of the operation (`int32` or `int64`).\n",
      "            Defaults to `tf.int32`(optional).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` specifying the shape of each input tensor with type of\n",
      "          `out_type`.\n",
      "    \n",
      "    sigmoid(x, name=None)\n",
      "        Computes sigmoid of `x` element-wise.\n",
      "        \n",
      "        Formula for calculating $\\mathrm{sigmoid}(x) = y = 1 / (1 + \\exp(-x))$.\n",
      "        \n",
      "        For $x \\in (-\\infty, \\infty)$, $\\mathrm{sigmoid}(x) \\in (0, 1)$.\n",
      "        \n",
      "        Example Usage:\n",
      "        \n",
      "        If a positive number is large, then its sigmoid will approach to 1 since the\n",
      "        formula will be `y = <large_num> / (1 + <large_num>)`\n",
      "        \n",
      "        >>> x = tf.constant([0.0, 1.0, 50.0, 100.0])\n",
      "        >>> tf.math.sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32,\n",
      "        numpy=array([0.5, 0.7310586, 1.0, 1.0], dtype=float32)>\n",
      "        \n",
      "        If a negative number is large, its sigmoid will approach to 0 since the\n",
      "        formula will be `y = 1 / (1 + <large_num>)`\n",
      "        \n",
      "        >>> x = tf.constant([-100.0, -50.0, -1.0, 0.0])\n",
      "        >>> tf.math.sigmoid(x)\n",
      "        <tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
      "        array([0.0000000e+00, 1.9287499e-22, 2.6894143e-01, 0.5],\n",
      "              dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor with type `float16`, `float32`, `float64`, `complex64`, or\n",
      "            `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor with the same type as `x`.\n",
      "        \n",
      "        Usage Example:\n",
      "        \n",
      "        >>> x = tf.constant([-128.0, 0.0, 128.0], dtype=tf.float32)\n",
      "        >>> tf.sigmoid(x)\n",
      "        <tf.Tensor: shape=(3,), dtype=float32,\n",
      "        numpy=array([0. , 0.5, 1. ], dtype=float32)>\n",
      "        \n",
      "        @compatibility(scipy)\n",
      "        Equivalent to scipy.special.expit\n",
      "        @end_compatibility\n",
      "    \n",
      "    sign(x, name=None)\n",
      "        Returns an element-wise indication of the sign of a number.\n",
      "        \n",
      "        `y = sign(x) = -1 if x < 0; 0 if x == 0; 1 if x > 0`.\n",
      "        \n",
      "        For complex numbers, `y = sign(x) = x / |x| if x != 0, otherwise y = 0`.\n",
      "        \n",
      "        Example usage:\n",
      "        \n",
      "        >>> # real number\n",
      "        >>> tf.math.sign([0., 2., -3.])\n",
      "        <tf.Tensor: shape=(3,), dtype=float32,\n",
      "        numpy=array([ 0.,  1., -1.], dtype=float32)>\n",
      "        \n",
      "        >>> # complex number\n",
      "        >>> tf.math.sign([1 + 1j, 0 + 0j])\n",
      "        <tf.Tensor: shape=(2,), dtype=complex128,\n",
      "        numpy=array([0.70710678+0.70710678j, 0.        +0.j        ])>\n",
      "        \n",
      "        Args:\n",
      "         x: A Tensor. Must be one of the following types: bfloat16, half, float32,\n",
      "           float64, int32, int64, complex64, complex128.\n",
      "         name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "         A Tensor. Has the same type as x.\n",
      "        \n",
      "         If x is a SparseTensor, returns SparseTensor(x.indices,\n",
      "           tf.math.sign(x.values, ...), x.dense_shape).\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.sign(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    sin(x: typing.Annotated[_any, ~TV_Sin_T], name=None) -> typing.Annotated[_any, ~TV_Sin_T]\n",
      "        Computes sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes sine of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `[-1,1]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10, float(\"inf\")])\n",
      "          tf.math.sin(x) ==> [nan -0.4121185 -0.47942555 0.84147096 0.9320391 -0.87329733 -0.54402107 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    sinh(x: typing.Annotated[_any, ~TV_Sinh_T], name=None) -> typing.Annotated[_any, ~TV_Sinh_T]\n",
      "        Computes hyperbolic sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic sine of every\n",
      "          element in the tensor. Input range is `[-inf,inf]` and output range\n",
      "          is `[-inf,inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 2, 10, float(\"inf\")])\n",
      "          tf.math.sinh(x) ==> [-inf -4.0515420e+03 -5.2109528e-01 1.1752012e+00 1.5094614e+00 3.6268604e+00 1.1013232e+04 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    size(input, name=None, out_type=None)\n",
      "        Returns the size of a tensor.\n",
      "        \n",
      "        Returns a 0-D `Tensor` representing the number of elements in `input`\n",
      "        of type `out_type`. Defaults to tf.int32.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.size(t)  # 12\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          out_type: (Optional) The specified non-quantized numeric output type of the\n",
      "            operation. Defaults to `tf.int32`. (Note: there is an experimental\n",
      "            flag, `tf_shape_default_int64` that changes the default to `tf.int64`.\n",
      "            This is an unsupported, experimental setting that causes known breakages.)\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`. Defaults to `tf.int32`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.size()\n",
      "        @end_compatibility\n",
      "    \n",
      "    slice(input_, begin, size, name=None)\n",
      "        Extracts a slice from a tensor.\n",
      "        \n",
      "        See also `tf.strided_slice`.\n",
      "        \n",
      "        This operation extracts a slice of size `size` from a tensor `input_` starting\n",
      "        at the location specified by `begin`. The slice `size` is represented as a\n",
      "        tensor shape, where `size[i]` is the number of elements of the 'i'th dimension\n",
      "        of `input_` that you want to slice. The starting location (`begin`) for the\n",
      "        slice is represented as an offset in each dimension of `input_`. In other\n",
      "        words, `begin[i]` is the offset into the i'th dimension of `input_` that you\n",
      "        want to slice from.\n",
      "        \n",
      "        Note that `tf.Tensor.__getitem__` is typically a more pythonic way to\n",
      "        perform slices, as it allows you to write `foo[3:7, :-2]` instead of\n",
      "        `tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2])`.\n",
      "        \n",
      "        `begin` is zero-based; `size` is one-based. If `size[i]` is -1,\n",
      "        all remaining elements in dimension i are included in the\n",
      "        slice. In other words, this is equivalent to setting:\n",
      "        \n",
      "        `size[i] = input_.dim_size(i) - begin[i]`\n",
      "        \n",
      "        This operation requires that:\n",
      "        \n",
      "        `0 <= begin[i] <= begin[i] + size[i] <= Di  for i in [0, n]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
      "                         [[3, 3, 3], [4, 4, 4]],\n",
      "                         [[5, 5, 5], [6, 6, 6]]])\n",
      "        tf.slice(t, [1, 0, 0], [1, 1, 3])  # [[[3, 3, 3]]]\n",
      "        tf.slice(t, [1, 0, 0], [1, 2, 3])  # [[[3, 3, 3],\n",
      "                                           #   [4, 4, 4]]]\n",
      "        tf.slice(t, [1, 0, 0], [2, 1, 3])  # [[[3, 3, 3]],\n",
      "                                           #  [[5, 5, 5]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_: A `Tensor`.\n",
      "          begin: An `int32` or `int64` `Tensor`.\n",
      "          size: An `int32` or `int64` `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` the same type as `input_`.\n",
      "    \n",
      "    sort(values, axis=-1, direction='ASCENDING', name=None)\n",
      "        Sorts a tensor.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        >>> a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        >>> tf.sort(a).numpy()\n",
      "        array([  1.  ,   2.8 ,  10.  ,  26.9 ,  62.3 , 166.32], dtype=float32)\n",
      "        \n",
      "        >>> tf.sort(a, direction='DESCENDING').numpy()\n",
      "        array([166.32,  62.3 ,  26.9 ,  10.  ,   2.8 ,   1.  ], dtype=float32)\n",
      "        \n",
      "        For multidimensional inputs you can control which axis the sort is applied\n",
      "        along. The default `axis=-1` sorts the innermost axis.\n",
      "        \n",
      "        >>> mat = [[3,2,1],\n",
      "        ...        [2,1,3],\n",
      "        ...        [1,3,2]]\n",
      "        >>> tf.sort(mat, axis=-1).numpy()\n",
      "        array([[1, 2, 3],\n",
      "               [1, 2, 3],\n",
      "               [1, 2, 3]], dtype=int32)\n",
      "        >>> tf.sort(mat, axis=0).numpy()\n",
      "        array([[1, 1, 1],\n",
      "               [2, 2, 2],\n",
      "               [3, 3, 3]], dtype=int32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "          * `tf.argsort`: Like sort, but it returns the sort indices.\n",
      "          * `tf.math.top_k`: A partial sort that returns a fixed number of top values\n",
      "            and corresponding indices.\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          values: 1-D or higher **numeric** `Tensor`.\n",
      "          axis: The axis along which to sort. The default is -1, which sorts the last\n",
      "            axis.\n",
      "          direction: The direction in which to sort the values (`'ASCENDING'` or\n",
      "            `'DESCENDING'`).\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same dtype and shape as `values`, with the elements\n",
      "              sorted along the given `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          tf.errors.InvalidArgumentError: If the `values.dtype` is not a `float` or\n",
      "              `int` type.\n",
      "          ValueError: If axis is not a constant scalar, or the direction is invalid.\n",
      "    \n",
      "    space_to_batch(input, paddings, block_size=None, name=None, block_shape=None)\n",
      "        SpaceToBatch for 4-D tensors of type T.\n",
      "        \n",
      "        This is a legacy version of the more general SpaceToBatchND.\n",
      "        \n",
      "        Zero-pads and then rearranges (permutes) blocks of spatial data into batch.\n",
      "        More specifically, this op outputs a copy of the input tensor where values from\n",
      "        the `height` and `width` dimensions are moved to the `batch` dimension. After\n",
      "        the zero-padding, both `height` and `width` of the input must be divisible by the\n",
      "        block size.\n",
      "        \n",
      "        The attr `block_size` must be greater than one. It indicates the block size.\n",
      "        \n",
      "          * Non-overlapping blocks of size `block_size x block size` in the height and\n",
      "            width dimensions are rearranged into the batch dimension at each location.\n",
      "          * The batch of the output tensor is `batch * block_size * block_size`.\n",
      "          * Both height_pad and width_pad must be divisible by block_size.\n",
      "        \n",
      "        The shape of the output will be:\n",
      "        \n",
      "            [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,\n",
      "             depth]\n",
      "        \n",
      "        Some examples:\n",
      "        \n",
      "        (1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [2]], [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "        ```\n",
      "        \n",
      "        (2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 3]` and value:\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "              [[5],   [6],  [7],  [8]],\n",
      "              [[9],  [10], [11],  [12]],\n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 2, 2, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [3]], [[9], [11]]],\n",
      "             [[[2], [4]], [[10], [12]]],\n",
      "             [[[5], [7]], [[13], [15]]],\n",
      "             [[[6], [8]], [[14], [16]]]]\n",
      "        ```\n",
      "        \n",
      "        (4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "              [[5],   [6],  [7],  [8]]],\n",
      "             [[[9],  [10], [11],  [12]],\n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[8, 1, 2, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],\n",
      "             [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]\n",
      "        ```\n",
      "        \n",
      "        Among others, this operation is useful for reducing atrous convolution into\n",
      "        regular convolution.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. 4-D with shape `[batch, height, width, depth]`.\n",
      "          paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D tensor of non-negative integers with shape `[2, 2]`. It specifies\n",
      "              the padding of the input with zeros across the spatial dimensions as follows:\n",
      "        \n",
      "                  paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]\n",
      "        \n",
      "              The effective spatial dimensions of the zero-padded input tensor will be:\n",
      "        \n",
      "                  height_pad = pad_top + height + pad_bottom\n",
      "                  width_pad = pad_left + width + pad_right\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    space_to_batch_nd(input: Annotated[Any, ~TV_SpaceToBatchND_T], block_shape: Annotated[Any, ~TV_SpaceToBatchND_Tblock_shape], paddings: Annotated[Any, ~TV_SpaceToBatchND_Tpaddings], name=None) -> Annotated[Any, ~TV_SpaceToBatchND_T]\n",
      "        SpaceToBatch for N-D tensors of type T.\n",
      "        \n",
      "        This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into a\n",
      "        grid of blocks of shape `block_shape`, and interleaves these blocks with the\n",
      "        \"batch\" dimension (0) such that in the output, the spatial dimensions\n",
      "        `[1, ..., M]` correspond to the position within the grid, and the batch\n",
      "        dimension combines both the position within a spatial block and the original\n",
      "        batch position.  Prior to division into blocks, the spatial dimensions of the\n",
      "        input are optionally zero padded according to `paddings`. See below for a\n",
      "        precise description.\n",
      "        \n",
      "        This operation is equivalent to the following steps:\n",
      "        \n",
      "        1. Zero-pad the start and end of dimensions `[1, ..., M]` of the\n",
      "           input according to `paddings` to produce `padded` of shape `padded_shape`.\n",
      "        \n",
      "        2. Reshape `padded` to `reshaped_padded` of shape:\n",
      "        \n",
      "             [batch] +\n",
      "             [padded_shape[1] / block_shape[0],\n",
      "               block_shape[0],\n",
      "              ...,\n",
      "              padded_shape[M] / block_shape[M-1],\n",
      "              block_shape[M-1]] +\n",
      "             remaining_shape\n",
      "        \n",
      "        3. Permute dimensions of `reshaped_padded` to produce\n",
      "           `permuted_reshaped_padded` of shape:\n",
      "        \n",
      "             block_shape +\n",
      "             [batch] +\n",
      "             [padded_shape[1] / block_shape[0],\n",
      "              ...,\n",
      "              padded_shape[M] / block_shape[M-1]] +\n",
      "             remaining_shape\n",
      "        \n",
      "        4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch\n",
      "           dimension, producing an output tensor of shape:\n",
      "        \n",
      "             [batch * prod(block_shape)] +\n",
      "             [padded_shape[1] / block_shape[0],\n",
      "              ...,\n",
      "              padded_shape[M] / block_shape[M-1]] +\n",
      "             remaining_shape\n",
      "        \n",
      "        Some examples:\n",
      "        \n",
      "        (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and\n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [2]], [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "        ```\n",
      "        \n",
      "        (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and\n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 1, 1, 3]` and value:\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and\n",
      "            `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "              [[5],   [6],  [7],  [8]],\n",
      "              [[9],  [10], [11],  [12]],\n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[4, 2, 2, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [3]], [[9], [11]]],\n",
      "             [[[2], [4]], [[10], [12]]],\n",
      "             [[[5], [7]], [[13], [15]]],\n",
      "             [[[6], [8]], [[14], [16]]]]\n",
      "        ```\n",
      "        \n",
      "        (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and\n",
      "            paddings = `[[0, 0], [2, 0]]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [3],  [4]],\n",
      "              [[5],   [6],  [7],  [8]]],\n",
      "             [[[9],  [10], [11],  [12]],\n",
      "              [[13], [14], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        The output tensor has shape `[8, 1, 3, 1]` and value:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[0], [1], [3]]], [[[0], [9], [11]]],\n",
      "             [[[0], [2], [4]]], [[[0], [10], [12]]],\n",
      "             [[[0], [5], [7]]], [[[0], [13], [15]]],\n",
      "             [[[0], [6], [8]]], [[[0], [14], [16]]]]\n",
      "        ```\n",
      "        \n",
      "        Among others, this operation is useful for reducing atrous convolution into\n",
      "        regular convolution.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "            N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,\n",
      "            where spatial_shape has `M` dimensions.\n",
      "          block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with shape `[M]`, all values must be >= 1.\n",
      "          paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D with shape `[M, 2]`, all values must be >= 0.\n",
      "              `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension\n",
      "              `i + 1`, which corresponds to spatial dimension `i`.  It is required that\n",
      "              `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    space_to_depth(input, block_size, name=None, data_format='NHWC')\n",
      "        SpaceToDepth for tensors of type T.\n",
      "        \n",
      "        Rearranges blocks of spatial data, into depth. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `height`\n",
      "        and `width` dimensions are moved to the `depth` dimension.\n",
      "        The attr `block_size` indicates the input block size.\n",
      "        \n",
      "          * Non-overlapping blocks of size `block_size x block size` are rearranged\n",
      "            into depth at each location.\n",
      "          * The depth of the output tensor is `block_size * block_size * input_depth`.\n",
      "          * The Y, X coordinates within each block of the input become the high order\n",
      "            component of the output channel index.\n",
      "          * The input tensor's height and width must be divisible by block_size.\n",
      "        \n",
      "        The `data_format` attr specifies the layout of the input and output tensors\n",
      "        with the following options:\n",
      "          \"NHWC\": `[ batch, height, width, channels ]`\n",
      "          \"NCHW\": `[ batch, channels, height, width ]`\n",
      "          \"NCHW_VECT_C\":\n",
      "              `qint8 [ batch, channels / 4, height, width, 4 ]`\n",
      "        \n",
      "        It is useful to consider the operation as transforming a 6-D Tensor.\n",
      "        e.g. for data_format = NHWC,\n",
      "             Each element in the input tensor can be specified via 6 coordinates,\n",
      "             ordered by decreasing memory layout significance as:\n",
      "             n,oY,bY,oX,bX,iC  (where n=batch index, oX, oY means X or Y coordinates\n",
      "                                within the output image, bX, bY means coordinates\n",
      "                                within the input block, iC means input channels).\n",
      "             The output would be a transpose to the following layout:\n",
      "             n,oY,oX,bY,bX,iC\n",
      "        \n",
      "        This operation is useful for resizing the activations between convolutions\n",
      "        (but keeping all data), e.g. instead of pooling. It is also useful for training\n",
      "        purely convolutional models.\n",
      "        \n",
      "        For example, given an input of shape `[1, 2, 2, 1]`, data_format = \"NHWC\" and\n",
      "        block_size = 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [2]],\n",
      "              [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation will output a tensor of shape `[1, 1, 1, 4]`:\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3, 4]]]]\n",
      "        ```\n",
      "        \n",
      "        Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,\n",
      "        the corresponding output will have a single element (i.e. width and height are\n",
      "        both 1) and will have a depth of 4 channels (1 * block_size * block_size).\n",
      "        The output element shape is `[1, 1, 4]`.\n",
      "        \n",
      "        For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation, for block_size of 2, will return the following tensor of shape\n",
      "        `[1, 1, 1, 12]`\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [5],  [6]],\n",
      "              [[3],   [4],  [7],  [8]],\n",
      "              [[9],  [10], [13],  [14]],\n",
      "              [[11], [12], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        the operator will return the following tensor of shape `[1 2 2 4]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4],\n",
      "               [5, 6, 7, 8]],\n",
      "              [[9, 10, 11, 12],\n",
      "               [13, 14, 15, 16]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          block_size: An `int` that is `>= 2`. The size of the spatial block.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\", \"NCHW_VECT_C\"`. Defaults to `\"NHWC\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    sparse_add(a, b, threshold=None, thresh=None)\n",
      "        Adds two tensors, at least one of each is a `SparseTensor`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(thresh)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        thresh is deprecated, use threshold instead\n",
      "        \n",
      "        If one `SparseTensor` and one `Tensor` are passed in, returns a `Tensor`.  If\n",
      "        both arguments are `SparseTensor`s, this returns a `SparseTensor`.  The order\n",
      "        of arguments does not matter.  Use vanilla `tf.add()` for adding two dense\n",
      "        `Tensor`s.\n",
      "        \n",
      "        The shapes of the two operands must match: broadcasting is not supported.\n",
      "        \n",
      "        The indices of any input `SparseTensor` are assumed ordered in standard\n",
      "        lexicographic order.  If this is not the case, before this step run\n",
      "        `SparseReorder` to restore index ordering.\n",
      "        \n",
      "        If both arguments are sparse, we perform \"clipping\" as follows.  By default,\n",
      "        if two values sum to zero at some index, the output `SparseTensor` would still\n",
      "        include that particular location in its index, storing a zero in the\n",
      "        corresponding value slot.  To override this, callers can specify `thresh`,\n",
      "        indicating that if the sum has a magnitude strictly smaller than `thresh`, its\n",
      "        corresponding value and index would then not be included.  In particular,\n",
      "        `thresh == 0.0` (default) means everything is kept and actual thresholding\n",
      "        happens only for a positive value.\n",
      "        \n",
      "        For example, suppose the logical sum of two sparse operands is (densified):\n",
      "        \n",
      "            [       2]\n",
      "            [.1     0]\n",
      "            [ 6   -.2]\n",
      "        \n",
      "        Then,\n",
      "        \n",
      "        * `thresh == 0` (the default): all 5 index/value pairs will be returned.\n",
      "        * `thresh == 0.11`: only .1 and 0 will vanish, and the remaining three\n",
      "            index/value pairs will be returned.\n",
      "        * `thresh == 0.21`: .1, 0, and -.2 will vanish.\n",
      "        \n",
      "        Args:\n",
      "          a: The first operand; `SparseTensor` or `Tensor`.\n",
      "          b: The second operand; `SparseTensor` or `Tensor`. At least one operand\n",
      "            must be sparse.\n",
      "          threshold: An optional 0-D `Tensor` (defaults to `0`). The magnitude\n",
      "            threshold that determines if an output value/index pair takes space. Its\n",
      "            dtype should match that of the values if they are real; if the latter are\n",
      "            complex64/complex128, then the dtype should be float32/float64,\n",
      "            correspondingly.\n",
      "          thresh: Deprecated alias for `threshold`.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or a `Tensor`, representing the sum.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If both `a` and `b` are `Tensor`s.  Use `tf.add()` instead.\n",
      "    \n",
      "    sparse_concat(axis, sp_inputs, name=None, expand_nonconcat_dim=False, concat_dim=None, expand_nonconcat_dims=None)\n",
      "        Concatenates a list of `SparseTensor` along the specified dimension. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(concat_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        concat_dim is deprecated, use axis instead\n",
      "        \n",
      "        Concatenation is with respect to the dense versions of each sparse input.\n",
      "        It is assumed that each inputs is a `SparseTensor` whose elements are ordered\n",
      "        along increasing dimension number.\n",
      "        \n",
      "        If expand_nonconcat_dim is False, all inputs' shapes must match, except for\n",
      "        the concat dimension. If expand_nonconcat_dim is True, then inputs' shapes are\n",
      "        allowed to vary among all inputs.\n",
      "        \n",
      "        The `indices`, `values`, and `shapes` lists must have the same length.\n",
      "        \n",
      "        If expand_nonconcat_dim is False, then the output shape is identical to the\n",
      "        inputs', except along the concat dimension, where it is the sum of the inputs'\n",
      "        sizes along that dimension.\n",
      "        \n",
      "        If expand_nonconcat_dim is True, then the output shape along the non-concat\n",
      "        dimensions will be expand to be the largest among all inputs, and it is the\n",
      "        sum of the inputs sizes along the concat dimension.\n",
      "        \n",
      "        The output elements will be resorted to preserve the sort order along\n",
      "        increasing dimension number.\n",
      "        \n",
      "        This op runs in `O(M log M)` time, where `M` is the total number of non-empty\n",
      "        values across all inputs. This is due to the need for an internal sort in\n",
      "        order to concatenate efficiently across an arbitrary dimension.\n",
      "        \n",
      "        For example, if `axis = 1` and the inputs are\n",
      "        \n",
      "            sp_inputs[0]: shape = [2, 3]\n",
      "            [0, 2]: \"a\"\n",
      "            [1, 0]: \"b\"\n",
      "            [1, 1]: \"c\"\n",
      "        \n",
      "            sp_inputs[1]: shape = [2, 4]\n",
      "            [0, 1]: \"d\"\n",
      "            [0, 2]: \"e\"\n",
      "        \n",
      "        then the output will be\n",
      "        \n",
      "            shape = [2, 7]\n",
      "            [0, 2]: \"a\"\n",
      "            [0, 4]: \"d\"\n",
      "            [0, 5]: \"e\"\n",
      "            [1, 0]: \"b\"\n",
      "            [1, 1]: \"c\"\n",
      "        \n",
      "        Graphically this is equivalent to doing\n",
      "        \n",
      "            [    a] concat [  d e  ] = [    a   d e  ]\n",
      "            [b c  ]        [       ]   [b c          ]\n",
      "        \n",
      "        Another example, if 'axis = 1' and the inputs are\n",
      "        \n",
      "            sp_inputs[0]: shape = [3, 3]\n",
      "            [0, 2]: \"a\"\n",
      "            [1, 0]: \"b\"\n",
      "            [2, 1]: \"c\"\n",
      "        \n",
      "            sp_inputs[1]: shape = [2, 4]\n",
      "            [0, 1]: \"d\"\n",
      "            [0, 2]: \"e\"\n",
      "        \n",
      "        if expand_nonconcat_dim = False, this will result in an error. But if\n",
      "        expand_nonconcat_dim = True, this will result in:\n",
      "        \n",
      "            shape = [3, 7]\n",
      "            [0, 2]: \"a\"\n",
      "            [0, 4]: \"d\"\n",
      "            [0, 5]: \"e\"\n",
      "            [1, 0]: \"b\"\n",
      "            [2, 1]: \"c\"\n",
      "        \n",
      "        Graphically this is equivalent to doing\n",
      "        \n",
      "            [    a] concat [  d e  ] = [    a   d e  ]\n",
      "            [b    ]        [       ]   [b            ]\n",
      "            [  c  ]                    [  c          ]\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          axis: Dimension to concatenate along. Must be in range [-rank, rank),\n",
      "            where rank is the number of dimensions in each input `SparseTensor`.\n",
      "          sp_inputs: List of `SparseTensor` to concatenate.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          expand_nonconcat_dim: Whether to allow the expansion in the non-concat\n",
      "            dimensions. Defaulted to False.\n",
      "          concat_dim: The old (deprecated) name for axis.\n",
      "          expand_nonconcat_dims: alias for expand_nonconcat_dim\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the concatenated output.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_inputs` is not a list of `SparseTensor`.\n",
      "    \n",
      "    sparse_fill_empty_rows(sp_input, default_value, name=None)\n",
      "        Fills empty rows in the input 2-D `SparseTensor` with a default value.\n",
      "        \n",
      "        This op adds entries with the specified `default_value` at index\n",
      "        `[row, 0]` for any row in the input that does not already have a value.\n",
      "        \n",
      "        For example, suppose `sp_input` has shape `[5, 6]` and non-empty values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Rows 1 and 4 are empty, so the output will be of shape `[5, 6]` with values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [1, 0]: default_value\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "            [4, 0]: default_value\n",
      "        \n",
      "        Note that the input may have empty columns at the end, with no effect on\n",
      "        this op.\n",
      "        \n",
      "        The output `SparseTensor` will be in row-major order and will have the\n",
      "        same shape as the input.\n",
      "        \n",
      "        This op also returns an indicator vector such that\n",
      "        \n",
      "            empty_row_indicator[i] = True iff row i was an empty row.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: A `SparseTensor` with shape `[N, M]`.\n",
      "          default_value: The value to fill for empty rows, with the same type as\n",
      "            `sp_input.`\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          sp_ordered_output: A `SparseTensor` with shape `[N, M]`, and with all empty\n",
      "            rows filled in with `default_value`.\n",
      "          empty_row_indicator: A bool vector of length `N` indicating whether each\n",
      "            input row was empty.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_mask(a, mask_indices, name=None)\n",
      "        Masks elements of `IndexedSlices`.\n",
      "        \n",
      "        Given an `IndexedSlices` instance `a`, returns another `IndexedSlices` that\n",
      "        contains a subset of the slices of `a`. Only the slices at indices not\n",
      "        specified in `mask_indices` are returned.\n",
      "        \n",
      "        This is useful when you need to extract a subset of slices in an\n",
      "        `IndexedSlices` object.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # `a` contains slices at indices [12, 26, 37, 45] from a large tensor\n",
      "        # with shape [1000, 10]\n",
      "        a.indices  # [12, 26, 37, 45]\n",
      "        tf.shape(a.values)  # [4, 10]\n",
      "        \n",
      "        # `b` will be the subset of `a` slices at its second and third indices, so\n",
      "        # we want to mask its first and last indices (which are at absolute\n",
      "        # indices 12, 45)\n",
      "        b = tf.sparse.mask(a, [12, 45])\n",
      "        \n",
      "        b.indices  # [26, 37]\n",
      "        tf.shape(b.values)  # [2, 10]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          a: An `IndexedSlices` instance.\n",
      "          mask_indices: Indices of elements to mask.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The masked `IndexedSlices` instance.\n",
      "    \n",
      "    sparse_matmul = sparse_mat_mul(a: typing.Annotated[_any, ~TV_SparseMatMul_Ta], b: typing.Annotated[_any, ~TV_SparseMatMul_Tb], transpose_a: bool = False, transpose_b: bool = False, a_is_sparse: bool = False, b_is_sparse: bool = False, name=None) -> typing.Annotated[_any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float32'>]\n",
      "        Multiply matrix \"a\" by matrix \"b\". (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.linalg.matmul` instead\n",
      "        \n",
      "        The inputs must be two-dimensional matrices and the inner dimension of \"a\" must\n",
      "        match the outer dimension of \"b\". Both \"a\" and \"b\" must be `Tensor`s not\n",
      "        `SparseTensor`s.  This op is optimized for the case where at least one of \"a\" or\n",
      "        \"b\" is sparse, in the sense that they have a large proportion of zero values.\n",
      "        The breakeven for using this versus a dense matrix multiply on one platform was\n",
      "        30% zero values in the sparse matrix.\n",
      "        \n",
      "        The gradient computation of this operation will only take advantage of sparsity\n",
      "        in the input gradient when that gradient comes from a Relu.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.\n",
      "          b: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.\n",
      "          transpose_a: An optional `bool`. Defaults to `False`.\n",
      "          transpose_b: An optional `bool`. Defaults to `False`.\n",
      "          a_is_sparse: An optional `bool`. Defaults to `False`.\n",
      "          b_is_sparse: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    sparse_maximum(sp_a, sp_b, name=None)\n",
      "        Returns the element-wise max of two SparseTensors.\n",
      "        \n",
      "        Assumes the two SparseTensors have the same shape, i.e., no broadcasting.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "          >>> sp_zero = tf.sparse.SparseTensor([[0]], [0], [7])\n",
      "          >>> sp_one = tf.sparse.SparseTensor([[1]], [1], [7])\n",
      "          >>> res = tf.sparse.maximum(sp_zero, sp_one)\n",
      "          >>> res.indices\n",
      "          <tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
      "          array([[0],\n",
      "                 [1]])>\n",
      "          >>> res.values\n",
      "          <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>\n",
      "          >>> res.dense_shape\n",
      "          <tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>\n",
      "        \n",
      "        The reduction version of this elementwise operation is `tf.sparse.reduce_max`\n",
      "        \n",
      "        Args:\n",
      "          sp_a: a `SparseTensor` operand whose dtype is real, and indices\n",
      "            lexicographically ordered.\n",
      "          sp_b: the other `SparseTensor` operand with the same requirements (and the\n",
      "            same shape).\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: the output SparseTensor.\n",
      "    \n",
      "    sparse_merge(sp_ids, sp_values, vocab_size, name=None, already_sorted=False)\n",
      "        Combines a batch of feature ids and values into a single `SparseTensor`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        No similar op available at this time.\n",
      "        \n",
      "        The most common use case for this function occurs when feature ids and\n",
      "        their corresponding values are stored in `Example` protos on disk.\n",
      "        `parse_example` will return a batch of ids and a batch of values, and this\n",
      "        function joins them into a single logical `SparseTensor` for use in\n",
      "        functions such as `sparse_tensor_dense_matmul`, `sparse_to_dense`, etc.\n",
      "        \n",
      "        The `SparseTensor` returned by this function has the following properties:\n",
      "        \n",
      "          - `indices` is equivalent to `sp_ids.indices` with the last\n",
      "            dimension discarded and replaced with `sp_ids.values`.\n",
      "          - `values` is simply `sp_values.values`.\n",
      "          - If `sp_ids.dense_shape = [D0, D1, ..., Dn, K]`, then\n",
      "            `output.shape = [D0, D1, ..., Dn, vocab_size]`.\n",
      "        \n",
      "        For example, consider the following feature vectors:\n",
      "        \n",
      "        ```python\n",
      "          vector1 = [-3, 0, 0, 0, 0, 0]\n",
      "          vector2 = [ 0, 1, 0, 4, 1, 0]\n",
      "          vector3 = [ 5, 0, 0, 9, 0, 0]\n",
      "        ```\n",
      "        \n",
      "        These might be stored sparsely in the following Example protos by storing\n",
      "        only the feature ids (column number if the vectors are treated as a matrix)\n",
      "        of the non-zero elements and the corresponding values:\n",
      "        \n",
      "        ```python\n",
      "          examples = [Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[0])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[-3]))}),\n",
      "                      Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[1, 4, 3])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[1, 1, 4]))}),\n",
      "                      Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[0, 3])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[5, 9]))})]\n",
      "        ```\n",
      "        \n",
      "        The result of calling parse_example on these examples will produce a\n",
      "        dictionary with entries for \"ids\" and \"values\". Passing those two objects\n",
      "        to this function along with vocab_size=6, will produce a `SparseTensor` that\n",
      "        sparsely represents all three instances. Namely, the `indices` property will\n",
      "        contain the coordinates of the non-zero entries in the feature matrix (the\n",
      "        first dimension is the row number in the matrix, i.e., the index within the\n",
      "        batch, and the second dimension is the column number, i.e., the feature id);\n",
      "        `values` will contain the actual values. `shape` will be the shape of the\n",
      "        original matrix, i.e., (3, 6). For our example above, the output will be\n",
      "        equal to:\n",
      "        \n",
      "        ```python\n",
      "          SparseTensor(indices=[[0, 0], [1, 1], [1, 3], [1, 4], [2, 0], [2, 3]],\n",
      "                       values=[-3, 1, 4, 1, 5, 9],\n",
      "                       dense_shape=[3, 6])\n",
      "        ```\n",
      "        \n",
      "        This method generalizes to higher-dimensions by simply providing a list for\n",
      "        both the sp_ids as well as the vocab_size.\n",
      "        In this case the resulting `SparseTensor` has the following properties:\n",
      "          - `indices` is equivalent to `sp_ids[0].indices` with the last\n",
      "            dimension discarded and concatenated with\n",
      "            `sp_ids[0].values, sp_ids[1].values, ...`.\n",
      "          - `values` is simply `sp_values.values`.\n",
      "          - If `sp_ids.dense_shape = [D0, D1, ..., Dn, K]`, then\n",
      "            `output.shape = [D0, D1, ..., Dn] + vocab_size`.\n",
      "        \n",
      "        Args:\n",
      "          sp_ids: A single `SparseTensor` with `values` property of type `int32`\n",
      "            or `int64` or a Python list of such `SparseTensor`s or a list thereof.\n",
      "          sp_values: A `SparseTensor` of any type.\n",
      "          vocab_size: A scalar `int64` Tensor (or Python int) containing the new size\n",
      "            of the last dimension, `all(0 <= sp_ids.values < vocab_size)`.\n",
      "            Or a list thereof with `all(0 <= sp_ids[i].values < vocab_size[i])` for\n",
      "            all `i`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "          already_sorted: A boolean to specify whether the per-batch values in\n",
      "           `sp_values` are already sorted. If so skip sorting, False by default\n",
      "           (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` compactly representing a batch of feature ids and values,\n",
      "          useful for passing to functions that expect such a `SparseTensor`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_values` is not a `SparseTensor`. Or if `sp_ids` is neither\n",
      "            a `SparseTensor` nor a list thereof. Or if `vocab_size` is not a\n",
      "            `Tensor` or a Python int and `sp_ids` is a `SparseTensor`. Or if\n",
      "            `vocab_size` is not a or list thereof and `sp_ids` is a list.\n",
      "          ValueError: If `sp_ids` and `vocab_size` are lists of different lengths.\n",
      "    \n",
      "    sparse_minimum(sp_a, sp_b, name=None)\n",
      "        Returns the element-wise min of two SparseTensors.\n",
      "        \n",
      "        Assumes the two SparseTensors have the same shape, i.e., no broadcasting.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "          >>> sp_zero = tf.sparse.SparseTensor([[0]], [0], [7])\n",
      "          >>> sp_one = tf.sparse.SparseTensor([[1]], [1], [7])\n",
      "          >>> res = tf.sparse.minimum(sp_zero, sp_one)\n",
      "          >>> res.indices\n",
      "          <tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
      "          array([[0],\n",
      "                 [1]])>\n",
      "          >>> res.values\n",
      "          <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>\n",
      "          >>> res.dense_shape\n",
      "          <tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>\n",
      "        \n",
      "        Args:\n",
      "          sp_a: a `SparseTensor` operand whose dtype is real, and indices\n",
      "            lexicographically ordered.\n",
      "          sp_b: the other `SparseTensor` operand with the same requirements (and the\n",
      "            same shape).\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: the output SparseTensor.\n",
      "    \n",
      "    sparse_placeholder(dtype, shape=None, name=None)\n",
      "        Inserts a placeholder for a sparse tensor that will be always fed.\n",
      "        \n",
      "        **Important**: This sparse tensor will produce an error if evaluated.\n",
      "        Its value must be fed using the `feed_dict` optional argument to\n",
      "        `Session.run()`, `Tensor.eval()`, or `Operation.run()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.compat.v1.sparse.placeholder(tf.float32)\n",
      "        y = tf.sparse.reduce_sum(x)\n",
      "        \n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "        \n",
      "          indices = np.array([[3, 2, 0], [4, 5, 1]], dtype=np.int64)\n",
      "          values = np.array([1.0, 2.0], dtype=np.float32)\n",
      "          shape = np.array([7, 9, 2], dtype=np.int64)\n",
      "          print(sess.run(y, feed_dict={\n",
      "            x: tf.compat.v1.SparseTensorValue(indices, values, shape)}))  # Will\n",
      "            succeed.\n",
      "          print(sess.run(y, feed_dict={\n",
      "            x: (indices, values, shape)}))  # Will succeed.\n",
      "        \n",
      "          sp = tf.sparse.SparseTensor(indices=indices, values=values,\n",
      "                                      dense_shape=shape)\n",
      "          sp_value = sp.eval(session=sess)\n",
      "          print(sess.run(y, feed_dict={x: sp_value}))  # Will succeed.\n",
      "        ```\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          dtype: The type of `values` elements in the tensor to be fed.\n",
      "          shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "            specified, you can feed a sparse tensor of any shape.\n",
      "          name: A name for prefixing the operations (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` that may be used as a handle for feeding a value, but not\n",
      "          evaluated directly.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if eager execution is enabled\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        This API is not compatible with eager execution and `tf.function`. To migrate\n",
      "        to TF2, rewrite the code to be compatible with eager execution. Check the\n",
      "        [migration\n",
      "        guide](https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls)\n",
      "        on replacing `Session.run` calls. In TF2, you can just pass tensors directly\n",
      "        into ops and layers. If you want to explicitly set up your inputs, also see\n",
      "        [Keras functional API](https://www.tensorflow.org/guide/keras/functional) on\n",
      "        how to use `tf.keras.Input` to replace `tf.compat.v1.sparse_placeholder`.\n",
      "        `tf.function` arguments also do the job of `tf.compat.v1.sparse_placeholder`.\n",
      "        For more details please read [Better\n",
      "        performance with tf.function](https://www.tensorflow.org/guide/function).\n",
      "        @end_compatibility\n",
      "    \n",
      "    sparse_reduce_max(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes `tf.sparse.maximum` of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(reduction_axes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_axes is deprecated, use axis instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.sparse.maximum` op.\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_max()`.  In particular, this Op also returns a dense `Tensor`\n",
      "        instead of a sparse one.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        similar to the indexing rules in Python.\n",
      "        \n",
      "        The values not defined in `sp_input` don't participate in the reduce max,\n",
      "        as opposed to be implicitly assumed 0 -- hence it can return negative values\n",
      "        for sparse `reduction_axes`. But, in case there are no values in\n",
      "        `reduction_axes`, it will reduce to 0. See second example below.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          # 'x' represents [[1, ?, 2]\n",
      "          #                 [?, 3, ?]]\n",
      "          # where ? is implicitly-zero.\n",
      "        \n",
      "          >>> x = tf.sparse.SparseTensor([[0, 0], [0, 2], [1, 1]], [1, 2, 3], [2, 3])\n",
      "          >>> tf.sparse.reduce_max(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=3>\n",
      "          >>> tf.sparse.reduce_max(x, 0)\n",
      "          <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 2], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_max(x, 1)\n",
      "          <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_max(x, 1, keepdims=True)\n",
      "          <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
      "          array([[2],\n",
      "                 [3]], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_max(x, [0, 1])\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=3>\n",
      "        \n",
      "          # 'y' represents [[-7, ?]\n",
      "          #                 [ 4, 3]\n",
      "          #                 [ ?, ?]\n",
      "        \n",
      "          >>> y = tf.sparse.SparseTensor([[0, 0,], [1, 0], [1, 1]], [-7, 4, 3],\n",
      "          ... [3, 2])\n",
      "          >>> tf.sparse.reduce_max(y, 1)\n",
      "          <tf.Tensor: shape=(3,), dtype=int32, numpy=array([-7,  4,  0], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of `axis`.\n",
      "          keep_dims:  Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced Tensor.\n",
      "    \n",
      "    sparse_reduce_max_sparse(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_max()`.  In contrast to SparseReduceSum, this Op returns a\n",
      "        SparseTensor.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        which are interpreted according to the indexing rules in Python.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced SparseTensor.\n",
      "    \n",
      "    sparse_reduce_sum(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes `tf.sparse.add` of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(reduction_axes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_axes is deprecated, use axis instead\n",
      "        \n",
      "        This is the reduction operation for the elementwise `tf.sparse.add` op.\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_sum()`.  In particular, this Op also returns a dense `Tensor`\n",
      "        instead of a sparse one.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        similar to the indexing rules in Python.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          # 'x' represents [[1, ?, 1]\n",
      "          #                 [?, 1, ?]]\n",
      "          # where ? is implicitly-zero.\n",
      "        \n",
      "          >>> x = tf.sparse.SparseTensor([[0, 0], [0, 2], [1, 1]], [1, 1, 1], [2, 3])\n",
      "          >>> tf.sparse.reduce_sum(x)\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=3>\n",
      "          >>> tf.sparse.reduce_sum(x, 0)\n",
      "          <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 1, 1], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_sum(x, 1)  # Can also use -1 as the axis\n",
      "          <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 1], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_sum(x, 1, keepdims=True)\n",
      "          <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
      "          array([[2],\n",
      "                 [1]], dtype=int32)>\n",
      "          >>> tf.sparse.reduce_sum(x, [0, 1])\n",
      "          <tf.Tensor: shape=(), dtype=int32, numpy=3>\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of `axis`.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced Tensor.\n",
      "    \n",
      "    sparse_reduce_sum_sparse(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_sum()`.  In contrast to SparseReduceSum, this Op returns a\n",
      "        SparseTensor.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        which are interpreted according to the indexing rules in Python.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced SparseTensor.\n",
      "    \n",
      "    sparse_reorder(sp_input, name=None)\n",
      "        Reorders a `SparseTensor` into the canonical, row-major ordering.\n",
      "        \n",
      "        Note that by convention, all sparse ops preserve the canonical ordering\n",
      "        along increasing dimension number. The only time ordering can be violated\n",
      "        is during manual manipulation of the indices and values to add entries.\n",
      "        \n",
      "        Reordering does not affect the shape of the `SparseTensor`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[4, 5]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 3]: b\n",
      "            [0, 1]: a\n",
      "            [3, 1]: d\n",
      "            [2, 0]: c\n",
      "        \n",
      "        then the output will be a `SparseTensor` of shape `[4, 5]` and\n",
      "        `indices` / `values`:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same shape and non-empty values, but in\n",
      "          canonical ordering.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_reset_shape(sp_input, new_shape=None)\n",
      "        Resets the shape of a `SparseTensor` with indices and values unchanged.\n",
      "        \n",
      "        If `new_shape` is None, returns a copy of `sp_input` with its shape reset\n",
      "        to the tight bounding box of `sp_input`. This will be a shape consisting of\n",
      "        all zeros if sp_input has no values.\n",
      "        \n",
      "        If `new_shape` is provided, then it must be larger or equal in all dimensions\n",
      "        compared to the shape of `sp_input`. When this condition is met, the returned\n",
      "        SparseTensor will have its shape reset to `new_shape` and its indices and\n",
      "        values unchanged from that of `sp_input.`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          Consider a `sp_input` with shape [2, 3, 5]:\n",
      "        \n",
      "            [0, 0, 1]: a\n",
      "            [0, 1, 0]: b\n",
      "            [0, 2, 2]: c\n",
      "            [1, 0, 3]: d\n",
      "        \n",
      "          - It is an error to set `new_shape` as [3, 7] since this represents a\n",
      "            rank-2 tensor while `sp_input` is rank-3. This is either a ValueError\n",
      "            during graph construction (if both shapes are known) or an OpError during\n",
      "            run time.\n",
      "        \n",
      "          - Setting `new_shape` as [2, 3, 6] will be fine as this shape is larger or\n",
      "            equal in every dimension compared to the original shape [2, 3, 5].\n",
      "        \n",
      "          - On the other hand, setting new_shape as [2, 3, 4] is also an error: The\n",
      "            third dimension is smaller than the original shape [2, 3, 5] (and an\n",
      "            `InvalidArgumentError` will be raised).\n",
      "        \n",
      "          - If `new_shape` is None, the returned SparseTensor will have a shape\n",
      "            [2, 3, 4], which is the tight bounding box of `sp_input`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          new_shape: None or a vector representing the new shape for the returned\n",
      "            `SparseTensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` indices and values unchanged from `sp_input`. Its shape is\n",
      "            `new_shape` if that is set. Otherwise it is the tight bounding box of\n",
      "             `sp_input`\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError: If `new_shape` represents a tensor with a different rank from\n",
      "            that of `sp_input` (if shapes are known when graph is constructed).\n",
      "          ValueError:  If `new_shape` is determined during graph build to have\n",
      "            dimension sizes that are too small.\n",
      "          OpError:\n",
      "            - If `new_shape` has dimension sizes that are too small.\n",
      "            - If shapes are not known during graph construction time, and during run\n",
      "              time it is found out that the ranks do not match.\n",
      "    \n",
      "    sparse_reshape(sp_input, shape, name=None)\n",
      "        Reshapes a `SparseTensor` to represent values in a new dense shape.\n",
      "        \n",
      "        This operation has the same semantics as `reshape` on the represented dense\n",
      "        tensor.  The indices of non-empty values in `sp_input` are recomputed based\n",
      "        on the new dense shape, and a new `SparseTensor` is returned containing the\n",
      "        new indices and new shape.  The order of non-empty values in `sp_input` is\n",
      "        unchanged.\n",
      "        \n",
      "        If one component of `shape` is the special value -1, the size of that\n",
      "        dimension is computed so that the total dense size remains constant.  At\n",
      "        most one component of `shape` can be -1.  The number of dense elements\n",
      "        implied by `shape` must be the same as the number of dense elements\n",
      "        originally represented by `sp_input`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[2, 3, 6]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 0, 0]: a\n",
      "            [0, 0, 1]: b\n",
      "            [0, 1, 0]: c\n",
      "            [1, 0, 0]: d\n",
      "            [1, 2, 3]: e\n",
      "        \n",
      "        and `shape` is `[9, -1]`, then the output will be a `SparseTensor` of\n",
      "        shape `[9, 4]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 0]: a\n",
      "            [0, 1]: b\n",
      "            [1, 2]: c\n",
      "            [4, 2]: d\n",
      "            [8, 1]: e\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          shape: A 1-D (vector) int64 `Tensor` specifying the new dense shape of the\n",
      "            represented `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same non-empty values but with indices calculated\n",
      "          by the new dense shape.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError:  If argument `shape` requests a `SparseTensor` with a different\n",
      "            number of elements than `sp_input`.\n",
      "          ValueError:  If `shape` has more than one inferred (== -1) dimension.\n",
      "    \n",
      "    sparse_retain(sp_input, to_retain)\n",
      "        Retains specified non-empty values within a `SparseTensor`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[4, 5]` and 4 non-empty string values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        and `to_retain = [True, False, False, True]`, then the output will\n",
      "        be a `SparseTensor` of shape `[4, 5]` with 2 non-empty values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor` with `N` non-empty elements.\n",
      "          to_retain: A bool vector of length `N` with `M` true values.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same shape as the input and `M` non-empty\n",
      "          elements corresponding to the true positions in `to_retain`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_segment_mean(data, indices, segment_ids, name=None, num_segments=None, sparse_gradient=False)\n",
      "        Computes the mean along sparse segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Like `tf.math.segment_mean`, but `segment_ids` can have rank less than\n",
      "        `data`'s first dimension, selecting a subset of dimension 0, specified by\n",
      "        `indices`.\n",
      "        `segment_ids` is allowed to have missing ids, in which case the output will\n",
      "        be zeros at those indices. In those cases `num_segments` is used to determine\n",
      "        the size of the output.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "          sparse_gradient: An optional `bool`. Defaults to `False`. If `True`, the\n",
      "            gradient of this function will be sparse (`IndexedSlices`) instead of\n",
      "            dense (`Tensor`). The sparse gradient will contain one non-zero row for\n",
      "            each unique index in `indices`.\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_segment_sqrt_n(data, indices, segment_ids, name=None, num_segments=None, sparse_gradient=False)\n",
      "        Computes the sum along sparse segments of a tensor divided by the sqrt(N).\n",
      "        \n",
      "        `N` is the size of the segment being reduced.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "          sparse_gradient: An optional `bool`. Defaults to `False`. If `True`, the\n",
      "            gradient of this function will be sparse (IndexedSlices) instead of dense\n",
      "            (Tensor).\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_segment_sum(data, indices, segment_ids, name=None, num_segments=None, sparse_gradient=False)\n",
      "        Computes the sum along sparse segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Like `tf.math.segment_sum`, but `segment_ids` can have rank less than `data`'s\n",
      "        first dimension, selecting a subset of dimension 0, specified by `indices`.\n",
      "        `segment_ids` is allowed to have missing ids, in which case the output will\n",
      "        be zeros at those indices. In those cases `num_segments` is used to determine\n",
      "        the size of the output.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])\n",
      "        \n",
      "        # Select two rows, one segment.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))\n",
      "        # => [[0 0 0 0]]\n",
      "        \n",
      "        # Select two rows, two segment.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))\n",
      "        # => [[ 1  2  3  4]\n",
      "        #     [-1 -2 -3 -4]]\n",
      "        \n",
      "        # With missing segment ids.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 2]),\n",
      "                              num_segments=4)\n",
      "        # => [[ 1  2  3  4]\n",
      "        #     [ 0  0  0  0]\n",
      "        #     [-1 -2 -3 -4]\n",
      "        #     [ 0  0  0  0]]\n",
      "        \n",
      "        # Select all rows, two segments.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))\n",
      "        # => [[0 0 0 0]\n",
      "        #     [5 6 7 8]]\n",
      "        \n",
      "        # Which is equivalent to:\n",
      "        tf.math.segment_sum(c, tf.constant([0, 0, 1]))\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "          sparse_gradient: An optional `bool`. Defaults to `False`. If `True`, the\n",
      "            gradient of this function will be sparse (`IndexedSlices`) instead of\n",
      "            dense (`Tensor`). The sparse gradient will contain one non-zero row for\n",
      "            each unique index in `indices`.\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_slice(sp_input, start, size, name=None)\n",
      "        Slice a `SparseTensor` based on the `start` and `size`.\n",
      "        \n",
      "        For example, if the input is\n",
      "        \n",
      "            input_tensor = shape = [2, 7]\n",
      "            [    a   d e  ]\n",
      "            [b c          ]\n",
      "        \n",
      "        Graphically the output tensors are:\n",
      "        \n",
      "            sparse.slice([0, 0], [2, 4]) = shape = [2, 4]\n",
      "            [    a  ]\n",
      "            [b c    ]\n",
      "        \n",
      "            sparse.slice([0, 4], [2, 3]) = shape = [2, 3]\n",
      "            [ d e  ]\n",
      "            [      ]\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The `SparseTensor` to split.\n",
      "          start: 1-D. tensor represents the start of the slice.\n",
      "          size: 1-D. tensor represents the size of the slice.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` objects resulting from splicing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_softmax(sp_input, name=None)\n",
      "        Applies softmax to a batched N-D `SparseTensor`.\n",
      "        \n",
      "        The inputs represent an N-D SparseTensor with logical shape `[..., B, C]`\n",
      "        (where `N >= 2`), and with indices sorted in the canonical lexicographic\n",
      "        order.\n",
      "        \n",
      "        This op is equivalent to applying the normal `tf.nn.softmax()` to each\n",
      "        innermost logical submatrix with shape `[B, C]`, but with the catch that *the\n",
      "        implicitly zero elements do not participate*.  Specifically, the algorithm is\n",
      "        equivalent to:\n",
      "        \n",
      "          (1) Applies `tf.nn.softmax()` to a densified view of each innermost\n",
      "              submatrix with shape `[B, C]`, along the size-C dimension;\n",
      "          (2) Masks out the original implicitly-zero locations;\n",
      "          (3) Renormalizes the remaining elements.\n",
      "        \n",
      "        Hence, the `SparseTensor` result has exactly the same non-zero indices and\n",
      "        shape.\n",
      "        \n",
      "        Example using a 3-D SparseTensor:\n",
      "        \n",
      "          >>> st = tf.sparse.from_dense(\n",
      "          ...   [[[0., np.e],\n",
      "          ...     [1., 0.]],\n",
      "          ...\n",
      "          ...    [[np.e, 0.],\n",
      "          ...     [np.e, np.e]]])\n",
      "          >>> res = tf.sparse.softmax(st)\n",
      "          >>> res.indices\n",
      "          <tf.Tensor: shape=(5, 3), dtype=int64, numpy=\n",
      "          array([[0, 0, 1],\n",
      "                 [0, 1, 0],\n",
      "                 [1, 0, 0],\n",
      "                 [1, 1, 0],\n",
      "                 [1, 1, 1]])>\n",
      "          >>> res.values\n",
      "          <tf.Tensor: ... numpy=array([1. , 1. , 1. , 0.5, 0.5], dtype=float32)>\n",
      "          >>> res.dense_shape\n",
      "          <tf.Tensor: shape=(3,), dtype=int64, numpy=array([2, 2, 2])>\n",
      "          >>> tf.sparse.to_dense(res)\n",
      "          <tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
      "          array([[[0. , 1. ],\n",
      "                  [1. , 0. ]],\n",
      "                 [[1. , 0. ],\n",
      "                  [0.5, 0.5]]], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          sp_input: N-D `SparseTensor`, where `N >= 2`.\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: N-D `SparseTensor` representing the results.\n",
      "    \n",
      "    sparse_split(keyword_required=KeywordRequired(), sp_input=None, num_split=None, axis=None, name=None, split_dim=None)\n",
      "        Split a `SparseTensor` into `num_split` tensors along `axis`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(split_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        split_dim is deprecated, use axis instead\n",
      "        \n",
      "        If the `sp_input.dense_shape[axis]` is not an integer multiple of `num_split`\n",
      "        each slice starting from 0:`shape[axis] % num_split` gets extra one\n",
      "        dimension. For example, if `axis = 1` and `num_split = 2` and the\n",
      "        input is:\n",
      "        \n",
      "            input_tensor = shape = [2, 7]\n",
      "            [    a   d e  ]\n",
      "            [b c          ]\n",
      "        \n",
      "        Graphically the output tensors are:\n",
      "        \n",
      "            output_tensor[0] =\n",
      "            [    a   ]\n",
      "            [b c     ]\n",
      "        \n",
      "            output_tensor[1] =\n",
      "            [ d e  ]\n",
      "            [      ]\n",
      "        \n",
      "        Args:\n",
      "          keyword_required: Python 2 standin for * (temporary for argument reorder)\n",
      "          sp_input: The `SparseTensor` to split.\n",
      "          num_split: A Python integer. The number of ways to split.\n",
      "          axis: A 0-D `int32` `Tensor`. The dimension along which to split. Must be in\n",
      "            range [-rank, rank), where rank is the number of dimensions in the input\n",
      "            `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          split_dim: Deprecated old name for axis.\n",
      "        \n",
      "        Returns:\n",
      "          `num_split` `SparseTensor` objects resulting from splitting `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError: If the deprecated `split_dim` and `axis` are both non None.\n",
      "    \n",
      "    sparse_tensor_dense_matmul(sp_a, b, adjoint_a=False, adjoint_b=False, name=None)\n",
      "        Multiply SparseTensor (or dense Matrix) (of rank 2) \"A\" by dense matrix\n",
      "        \n",
      "        (or SparseTensor) \"B\". Please note that one and only one of the inputs MUST\n",
      "        be a SparseTensor and the other MUST be a dense matrix.\n",
      "        \n",
      "        The following input format is recommended (but not required) for optimal\n",
      "        performance:\n",
      "        \n",
      "        * If `adjoint_a == false`: `A` should be sorted in lexicographically\n",
      "          increasing order.  Use `sparse.reorder` if you're not sure.\n",
      "        * If `adjoint_a == true`: `A` should be sorted in order of increasing\n",
      "          dimension 1 (i.e., \"column major\" order instead of \"row major\" order).\n",
      "        \n",
      "        Args:\n",
      "          sp_a: SparseTensor (or dense Matrix) A, of rank 2.\n",
      "          b: dense Matrix (or SparseTensor) B, with the same dtype as sp_a.\n",
      "          adjoint_a: Use the adjoint of A in the matrix multiply.  If A is complex,\n",
      "            this is transpose(conj(A)).  Otherwise it's transpose(A).\n",
      "          adjoint_b: Use the adjoint of B in the matrix multiply.  If B is complex,\n",
      "            this is transpose(conj(B)).  Otherwise it's transpose(B).\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A dense matrix (pseudo-code in dense np.matrix notation):\n",
      "            `A = A.H if adjoint_a else A`\n",
      "            `B = B.H if adjoint_b else B`\n",
      "            `return A*B`\n",
      "        \n",
      "        Notes:\n",
      "        \n",
      "        Using `tf.nn.embedding_lookup_sparse` for sparse multiplication:\n",
      "        \n",
      "        It's not obvious but you can consider `embedding_lookup_sparse` as another\n",
      "        sparse and dense multiplication. In some situations, you may prefer to use\n",
      "        `embedding_lookup_sparse` even though you're not dealing with embeddings.\n",
      "        \n",
      "        There are two questions to ask in the decision process: Do you need gradients\n",
      "        computed as sparse too? Is your sparse data represented as two\n",
      "        `SparseTensor`s: ids and values? There is more explanation about data format\n",
      "        below. If you answer any of these questions as yes, consider using\n",
      "        `tf.nn.embedding_lookup_sparse`.\n",
      "        \n",
      "        Following explains differences between the expected SparseTensors:\n",
      "        For example if dense form of your sparse data has shape `[3, 5]` and values:\n",
      "        \n",
      "            [[  a      ]\n",
      "             [b       c]\n",
      "             [    d    ]]\n",
      "        \n",
      "        \n",
      "        `SparseTensor` format expected by `sparse_tensor_dense_matmul`:\n",
      "         `sp_a` (indices, values):\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [1, 0]: b\n",
      "            [1, 4]: c\n",
      "            [2, 2]: d\n",
      "        \n",
      "        `SparseTensor` format expected by `embedding_lookup_sparse`:\n",
      "         `sp_ids`                 `sp_weights`\n",
      "        \n",
      "            [0, 0]: 1                [0, 0]: a\n",
      "            [1, 0]: 0                [1, 0]: b\n",
      "            [1, 1]: 4                [1, 1]: c\n",
      "            [2, 0]: 2                [2, 0]: d\n",
      "        \n",
      "        \n",
      "        Deciding when to use `sparse_tensor_dense_matmul` vs.\n",
      "        `matmul`(a_is_sparse=True):\n",
      "        \n",
      "        There are a number of questions to ask in the decision process, including:\n",
      "        \n",
      "        * Will the SparseTensor `A` fit in memory if densified?\n",
      "        * Is the column count of the product large (>> 1)?\n",
      "        * Is the density of `A` larger than approximately 15%?\n",
      "        \n",
      "        If the answer to several of these questions is yes, consider\n",
      "        converting the `SparseTensor` to a dense one and using `tf.matmul` with\n",
      "        `a_is_sparse=True`.\n",
      "        \n",
      "        This operation tends to perform well when `A` is more sparse, if the column\n",
      "        size of the product is small (e.g. matrix-vector multiplication), if\n",
      "        `sp_a.dense_shape` takes on large values.\n",
      "        \n",
      "        Below is a rough speed comparison between `sparse_tensor_dense_matmul`,\n",
      "        labeled 'sparse', and `matmul`(a_is_sparse=True), labeled 'dense'.  For\n",
      "        purposes of the comparison, the time spent converting from a `SparseTensor` to\n",
      "        a dense `Tensor` is not included, so it is overly conservative with respect to\n",
      "        the time ratio.\n",
      "        \n",
      "        Benchmark system:\n",
      "        CPU: Intel Ivybridge with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:12MB\n",
      "        GPU: NVidia Tesla k40c\n",
      "        \n",
      "        Compiled with:\n",
      "        `-c opt --config=cuda --copt=-mavx`\n",
      "        \n",
      "        ```\n",
      "        tensorflow/python/sparse_tensor_dense_matmul_op_test --benchmarks\n",
      "        A sparse [m, k] with % nonzero values between 1% and 80%\n",
      "        B dense [k, n]\n",
      "        \n",
      "        % nnz  n   gpu   m     k     dt(dense)     dt(sparse)   dt(sparse)/dt(dense)\n",
      "        0.01   1   True  100   100   0.000221166   0.00010154   0.459112\n",
      "        0.01   1   True  100   1000  0.00033858    0.000109275  0.322745\n",
      "        0.01   1   True  1000  100   0.000310557   9.85661e-05  0.317385\n",
      "        0.01   1   True  1000  1000  0.0008721     0.000100875  0.115669\n",
      "        0.01   1   False 100   100   0.000208085   0.000107603  0.51711\n",
      "        0.01   1   False 100   1000  0.000327112   9.51118e-05  0.290762\n",
      "        0.01   1   False 1000  100   0.000308222   0.00010345   0.335635\n",
      "        0.01   1   False 1000  1000  0.000865721   0.000101397  0.117124\n",
      "        0.01   10  True  100   100   0.000218522   0.000105537  0.482958\n",
      "        0.01   10  True  100   1000  0.000340882   0.000111641  0.327506\n",
      "        0.01   10  True  1000  100   0.000315472   0.000117376  0.372064\n",
      "        0.01   10  True  1000  1000  0.000905493   0.000123263  0.136128\n",
      "        0.01   10  False 100   100   0.000221529   9.82571e-05  0.44354\n",
      "        0.01   10  False 100   1000  0.000330552   0.000112615  0.340687\n",
      "        0.01   10  False 1000  100   0.000341277   0.000114097  0.334324\n",
      "        0.01   10  False 1000  1000  0.000819944   0.000120982  0.147549\n",
      "        0.01   25  True  100   100   0.000207806   0.000105977  0.509981\n",
      "        0.01   25  True  100   1000  0.000322879   0.00012921   0.400181\n",
      "        0.01   25  True  1000  100   0.00038262    0.00014158   0.370035\n",
      "        0.01   25  True  1000  1000  0.000865438   0.000202083  0.233504\n",
      "        0.01   25  False 100   100   0.000209401   0.000104696  0.499979\n",
      "        0.01   25  False 100   1000  0.000321161   0.000130737  0.407076\n",
      "        0.01   25  False 1000  100   0.000377012   0.000136801  0.362856\n",
      "        0.01   25  False 1000  1000  0.000861125   0.00020272   0.235413\n",
      "        0.2    1   True  100   100   0.000206952   9.69219e-05  0.46833\n",
      "        0.2    1   True  100   1000  0.000348674   0.000147475  0.422959\n",
      "        0.2    1   True  1000  100   0.000336908   0.00010122   0.300439\n",
      "        0.2    1   True  1000  1000  0.001022      0.000203274  0.198898\n",
      "        0.2    1   False 100   100   0.000207532   9.5412e-05   0.459746\n",
      "        0.2    1   False 100   1000  0.000356127   0.000146824  0.41228\n",
      "        0.2    1   False 1000  100   0.000322664   0.000100918  0.312764\n",
      "        0.2    1   False 1000  1000  0.000998987   0.000203442  0.203648\n",
      "        0.2    10  True  100   100   0.000211692   0.000109903  0.519165\n",
      "        0.2    10  True  100   1000  0.000372819   0.000164321  0.440753\n",
      "        0.2    10  True  1000  100   0.000338651   0.000144806  0.427596\n",
      "        0.2    10  True  1000  1000  0.00108312    0.000758876  0.70064\n",
      "        0.2    10  False 100   100   0.000215727   0.000110502  0.512231\n",
      "        0.2    10  False 100   1000  0.000375419   0.0001613    0.429653\n",
      "        0.2    10  False 1000  100   0.000336999   0.000145628  0.432132\n",
      "        0.2    10  False 1000  1000  0.00110502    0.000762043  0.689618\n",
      "        0.2    25  True  100   100   0.000218705   0.000129913  0.594009\n",
      "        0.2    25  True  100   1000  0.000394794   0.00029428   0.745402\n",
      "        0.2    25  True  1000  100   0.000404483   0.0002693    0.665788\n",
      "        0.2    25  True  1000  1000  0.0012002     0.00194494   1.62052\n",
      "        0.2    25  False 100   100   0.000221494   0.0001306    0.589632\n",
      "        0.2    25  False 100   1000  0.000396436   0.000297204  0.74969\n",
      "        0.2    25  False 1000  100   0.000409346   0.000270068  0.659754\n",
      "        0.2    25  False 1000  1000  0.00121051    0.00193737   1.60046\n",
      "        0.5    1   True  100   100   0.000214981   9.82111e-05  0.456836\n",
      "        0.5    1   True  100   1000  0.000415328   0.000223073  0.537101\n",
      "        0.5    1   True  1000  100   0.000358324   0.00011269   0.314492\n",
      "        0.5    1   True  1000  1000  0.00137612    0.000437401  0.317851\n",
      "        0.5    1   False 100   100   0.000224196   0.000101423  0.452386\n",
      "        0.5    1   False 100   1000  0.000400987   0.000223286  0.556841\n",
      "        0.5    1   False 1000  100   0.000368825   0.00011224   0.304318\n",
      "        0.5    1   False 1000  1000  0.00136036    0.000429369  0.31563\n",
      "        0.5    10  True  100   100   0.000222125   0.000112308  0.505608\n",
      "        0.5    10  True  100   1000  0.000461088   0.00032357   0.701753\n",
      "        0.5    10  True  1000  100   0.000394624   0.000225497  0.571422\n",
      "        0.5    10  True  1000  1000  0.00158027    0.00190898   1.20801\n",
      "        0.5    10  False 100   100   0.000232083   0.000114978  0.495418\n",
      "        0.5    10  False 100   1000  0.000454574   0.000324632  0.714146\n",
      "        0.5    10  False 1000  100   0.000379097   0.000227768  0.600817\n",
      "        0.5    10  False 1000  1000  0.00160292    0.00190168   1.18638\n",
      "        0.5    25  True  100   100   0.00023429    0.000151703  0.647501\n",
      "        0.5    25  True  100   1000  0.000497462   0.000598873  1.20386\n",
      "        0.5    25  True  1000  100   0.000460778   0.000557038  1.20891\n",
      "        0.5    25  True  1000  1000  0.00170036    0.00467336   2.74845\n",
      "        0.5    25  False 100   100   0.000228981   0.000155334  0.678371\n",
      "        0.5    25  False 100   1000  0.000496139   0.000620789  1.25124\n",
      "        0.5    25  False 1000  100   0.00045473    0.000551528  1.21287\n",
      "        0.5    25  False 1000  1000  0.00171793    0.00467152   2.71927\n",
      "        0.8    1   True  100   100   0.000222037   0.000105301  0.47425\n",
      "        0.8    1   True  100   1000  0.000410804   0.000329327  0.801664\n",
      "        0.8    1   True  1000  100   0.000349735   0.000131225  0.375212\n",
      "        0.8    1   True  1000  1000  0.00139219    0.000677065  0.48633\n",
      "        0.8    1   False 100   100   0.000214079   0.000107486  0.502085\n",
      "        0.8    1   False 100   1000  0.000413746   0.000323244  0.781261\n",
      "        0.8    1   False 1000  100   0.000348983   0.000131983  0.378193\n",
      "        0.8    1   False 1000  1000  0.00136296    0.000685325  0.50282\n",
      "        0.8    10  True  100   100   0.000229159   0.00011825   0.516017\n",
      "        0.8    10  True  100   1000  0.000498845   0.000532618  1.0677\n",
      "        0.8    10  True  1000  100   0.000383126   0.00029935   0.781336\n",
      "        0.8    10  True  1000  1000  0.00162866    0.00307312   1.88689\n",
      "        0.8    10  False 100   100   0.000230783   0.000124958  0.541452\n",
      "        0.8    10  False 100   1000  0.000493393   0.000550654  1.11606\n",
      "        0.8    10  False 1000  100   0.000377167   0.000298581  0.791642\n",
      "        0.8    10  False 1000  1000  0.00165795    0.00305103   1.84024\n",
      "        0.8    25  True  100   100   0.000233496   0.000175241  0.75051\n",
      "        0.8    25  True  100   1000  0.00055654    0.00102658   1.84458\n",
      "        0.8    25  True  1000  100   0.000463814   0.000783267  1.68875\n",
      "        0.8    25  True  1000  1000  0.00186905    0.00755344   4.04132\n",
      "        0.8    25  False 100   100   0.000240243   0.000175047  0.728625\n",
      "        0.8    25  False 100   1000  0.000578102   0.00104499   1.80763\n",
      "        0.8    25  False 1000  100   0.000485113   0.000776849  1.60138\n",
      "        0.8    25  False 1000  1000  0.00211448    0.00752736   3.55992\n",
      "        ```\n",
      "    \n",
      "    sparse_tensor_to_dense(sp_input, default_value=None, validate_indices=True, name=None)\n",
      "        Converts a `SparseTensor` into a dense tensor.\n",
      "        \n",
      "        For this sparse tensor with three non-empty values:\n",
      "        \n",
      "        >>> sp_input = tf.sparse.SparseTensor(\n",
      "        ...   dense_shape=[3, 5],\n",
      "        ...   values=[7, 8, 9],\n",
      "        ...   indices =[[0, 1],\n",
      "        ...             [0, 3],\n",
      "        ...             [2, 0]])\n",
      "        \n",
      "        The output will be a dense `[3, 5]` tensor with values:\n",
      "        \n",
      "        >>> tf.sparse.to_dense(sp_input).numpy()\n",
      "        array([[0, 7, 0, 8, 0],\n",
      "               [0, 0, 0, 0, 0],\n",
      "               [9, 0, 0, 0, 0]], dtype=int32)\n",
      "        \n",
      "        Note: Indices must be without repeats.  This is only tested if\n",
      "        `validate_indices` is `True`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          default_value: Scalar value to set for indices not specified in\n",
      "            `sp_input`.  Defaults to zero.\n",
      "          validate_indices: A boolean value.  If `True`, indices are checked to make\n",
      "            sure they are sorted in lexicographic order and that there are no repeats.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A dense tensor with shape `sp_input.dense_shape` and values specified by\n",
      "          the non-empty values in `sp_input`. Indices not in `sp_input` are assigned\n",
      "          `default_value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value=0, validate_indices=True, name=None)\n",
      "        Converts a sparse representation into a dense tensor. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "        \n",
      "        Builds an array `dense` with shape `output_shape` such that\n",
      "        \n",
      "        ```python\n",
      "        # If sparse_indices is scalar\n",
      "        dense[i] = (i == sparse_indices ? sparse_values : default_value)\n",
      "        \n",
      "        # If sparse_indices is a vector, then for each i\n",
      "        dense[sparse_indices[i]] = sparse_values[i]\n",
      "        \n",
      "        # If sparse_indices is an n by d matrix, then for each i in [0, n)\n",
      "        dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]\n",
      "        ```\n",
      "        \n",
      "        All other values in `dense` are set to `default_value`.  If `sparse_values`\n",
      "        is a scalar, all sparse indices are set to this single value.\n",
      "        \n",
      "        Indices should be sorted in lexicographic order, and indices must not\n",
      "        contain any repeats. If `validate_indices` is True, these properties\n",
      "        are checked during execution.\n",
      "        \n",
      "        Args:\n",
      "          sparse_indices: A 0-D, 1-D, or 2-D `Tensor` of type `int32` or `int64`.\n",
      "            `sparse_indices[i]` contains the complete index where `sparse_values[i]`\n",
      "            will be placed.\n",
      "          output_shape: A 1-D `Tensor` of the same type as `sparse_indices`.  Shape\n",
      "            of the dense output tensor.\n",
      "          sparse_values: A 0-D or 1-D `Tensor`.  Values corresponding to each row of\n",
      "            `sparse_indices`, or a scalar value to be used for all sparse indices.\n",
      "          default_value: A 0-D `Tensor` of the same type as `sparse_values`.  Value\n",
      "            to set for indices not specified in `sparse_indices`.  Defaults to zero.\n",
      "          validate_indices: A boolean value.  If True, indices are checked to make\n",
      "            sure they are sorted in lexicographic order and that there are no repeats.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Dense `Tensor` of shape `output_shape`.  Has the same type as\n",
      "          `sparse_values`.\n",
      "    \n",
      "    sparse_to_indicator(sp_input, vocab_size, name=None)\n",
      "        Converts a `SparseTensor` of ids into a dense bool indicator tensor.\n",
      "        \n",
      "        The last dimension of `sp_input.indices` is discarded and replaced with\n",
      "        the values of `sp_input`.  If `sp_input.dense_shape = [D0, D1, ..., Dn, K]`,\n",
      "        then `output.shape = [D0, D1, ..., Dn, vocab_size]`, where\n",
      "        \n",
      "            output[d_0, d_1, ..., d_n, sp_input[d_0, d_1, ..., d_n, k]] = True\n",
      "        \n",
      "        and False elsewhere in `output`.\n",
      "        \n",
      "        For example, if `sp_input.dense_shape = [2, 3, 4]` with non-empty values:\n",
      "        \n",
      "            [0, 0, 0]: 0\n",
      "            [0, 1, 0]: 10\n",
      "            [1, 0, 3]: 103\n",
      "            [1, 1, 1]: 150\n",
      "            [1, 1, 2]: 149\n",
      "            [1, 1, 3]: 150\n",
      "            [1, 2, 1]: 121\n",
      "        \n",
      "        and `vocab_size = 200`, then the output will be a `[2, 3, 200]` dense bool\n",
      "        tensor with False everywhere except at positions\n",
      "        \n",
      "            (0, 0, 0), (0, 1, 10), (1, 0, 103), (1, 1, 149), (1, 1, 150),\n",
      "            (1, 2, 121).\n",
      "        \n",
      "        Note that repeats are allowed in the input SparseTensor.\n",
      "        This op is useful for converting `SparseTensor`s into dense formats for\n",
      "        compatibility with ops that expect dense tensors.\n",
      "        \n",
      "        The input `SparseTensor` must be in row-major order.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: A `SparseTensor` with `values` property of type `int32` or\n",
      "            `int64`.\n",
      "          vocab_size: A scalar int64 Tensor (or Python int) containing the new size\n",
      "            of the last dimension, `all(0 <= sp_input.values < vocab_size)`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A dense bool indicator tensor representing the indices with specified value.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_transpose(sp_input, perm=None, name=None)\n",
      "        Transposes a `SparseTensor`.\n",
      "        \n",
      "        Permutes the dimensions according to the value of `perm`.  This is the sparse\n",
      "        version of `tf.transpose`.\n",
      "        \n",
      "        The returned tensor's dimension `i` will correspond to the input dimension\n",
      "        `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is the rank\n",
      "        of the input tensor. Hence, by default, this operation performs a regular\n",
      "        matrix transpose on 2-D input Tensors.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.SparseTensor(indices=[[0, 1], [0, 3], [2, 3], [3, 1]],\n",
      "        ...                     values=[1.1, 2.2, 3.3, 4.4],\n",
      "        ...                     dense_shape=[4, 5])\n",
      "        >>> print('x =', tf.sparse.to_dense(x))\n",
      "        x = tf.Tensor(\n",
      "        [[0.  1.1 0.  2.2 0. ]\n",
      "        [0.  0.  0.  0.  0. ]\n",
      "        [0.  0.  0.  3.3 0. ]\n",
      "        [0.  4.4 0.  0.  0. ]], shape=(4, 5), dtype=float32)\n",
      "        \n",
      "        >>> x_transpose = tf.sparse.transpose(x)\n",
      "        >>> print('x_transpose =', tf.sparse.to_dense(x_transpose))\n",
      "        x_transpose = tf.Tensor(\n",
      "        [[0.  0.  0.  0. ]\n",
      "        [1.1 0.  0.  4.4]\n",
      "        [0.  0.  0.  0. ]\n",
      "        [2.2 0.  3.3 0. ]\n",
      "        [0.  0.  0.  0. ]], shape=(5, 4), dtype=float32)\n",
      "        \n",
      "        Equivalently, you could call `tf.sparse.transpose(x, perm=[1, 0])`.  The\n",
      "        `perm` argument is more useful for n-dimensional tensors where n > 2.\n",
      "        \n",
      "        >>> x = tf.SparseTensor(indices=[[0, 0, 1], [0, 0, 3], [1, 2, 3], [1, 3, 1]],\n",
      "        ...                     values=[1.1, 2.2, 3.3, 4.4],\n",
      "        ...                     dense_shape=[2, 4, 5])\n",
      "        >>> print('x =', tf.sparse.to_dense(x))\n",
      "        x = tf.Tensor(\n",
      "        [[[0.  1.1 0.  2.2 0. ]\n",
      "          [0.  0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  0.  0. ]]\n",
      "        [[0.  0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  3.3 0. ]\n",
      "          [0.  4.4 0.  0.  0. ]]], shape=(2, 4, 5), dtype=float32)\n",
      "        \n",
      "        As above, simply calling `tf.sparse.transpose` will default to `perm=[2,1,0]`.\n",
      "        \n",
      "        To take the transpose of a batch of sparse matrices, where 0 is the batch\n",
      "        dimension, you would set `perm=[0,2,1]`.\n",
      "        \n",
      "        >>> x_transpose = tf.sparse.transpose(x, perm=[0, 2, 1])\n",
      "        >>> print('x_transpose =', tf.sparse.to_dense(x_transpose))\n",
      "        x_transpose = tf.Tensor(\n",
      "        [[[0.  0.  0.  0. ]\n",
      "          [1.1 0.  0.  0. ]\n",
      "          [0.  0.  0.  0. ]\n",
      "          [2.2 0.  0.  0. ]\n",
      "          [0.  0.  0.  0. ]]\n",
      "        [[0.  0.  0.  0. ]\n",
      "          [0.  0.  0.  4.4]\n",
      "          [0.  0.  0.  0. ]\n",
      "          [0.  0.  3.3 0. ]\n",
      "          [0.  0.  0.  0. ]]], shape=(2, 5, 4), dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          perm: A permutation vector of the dimensions of `sp_input`.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed `SparseTensor`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    split(value, num_or_size_splits, axis=0, num=None, name='split')\n",
      "        Splits a tensor `value` into a list of sub tensors.\n",
      "        \n",
      "        See also `tf.unstack`.\n",
      "        \n",
      "        If `num_or_size_splits` is an `int`,  then it splits `value` along the\n",
      "        dimension `axis` into `num_or_size_splits` smaller tensors. This requires that\n",
      "        `value.shape[axis]` is divisible by `num_or_size_splits`.\n",
      "        \n",
      "        If `num_or_size_splits` is a 1-D Tensor (or list), then `value` is split into\n",
      "        `len(num_or_size_splits)` elements. The shape of the `i`-th\n",
      "        element has the same size as the `value` except along dimension `axis` where\n",
      "        the size is `num_or_size_splits[i]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.Variable(tf.random.uniform([5, 30], -1, 1))\n",
      "        >>>\n",
      "        >>> # Split `x` into 3 tensors along dimension 1\n",
      "        >>> s0, s1, s2 = tf.split(x, num_or_size_splits=3, axis=1)\n",
      "        >>> tf.shape(s0).numpy()\n",
      "        array([ 5, 10], dtype=int32)\n",
      "        >>>\n",
      "        >>> # Split `x` into 3 tensors with sizes [4, 15, 11] along dimension 1\n",
      "        >>> split0, split1, split2 = tf.split(x, [4, 15, 11], 1)\n",
      "        >>> tf.shape(split0).numpy()\n",
      "        array([5, 4], dtype=int32)\n",
      "        >>> tf.shape(split1).numpy()\n",
      "        array([ 5, 15], dtype=int32)\n",
      "        >>> tf.shape(split2).numpy()\n",
      "        array([ 5, 11], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          value: The `Tensor` to split.\n",
      "          num_or_size_splits: Either an `int` indicating the number of splits\n",
      "            along `axis` or a 1-D integer `Tensor` or Python list containing the sizes\n",
      "            of each output tensor along `axis`. If an `int`, then it must evenly\n",
      "            divide `value.shape[axis]`; otherwise the sum of sizes along the split\n",
      "            axis must match that of the `value`.\n",
      "          axis: An `int` or scalar `int32` `Tensor`. The dimension along which\n",
      "            to split. Must be in the range `[-rank(value), rank(value))`. Defaults to\n",
      "            0.\n",
      "          num: Optional, an `int`, used to specify the number of outputs when it\n",
      "            cannot be inferred from the shape of `size_splits`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          if `num_or_size_splits` is an `int` returns a list of\n",
      "          `num_or_size_splits` `Tensor` objects; if `num_or_size_splits` is a 1-D\n",
      "          list or 1-D `Tensor` returns `num_or_size_splits.get_shape[0]`\n",
      "          `Tensor` objects resulting from splitting `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `num` is unspecified and cannot be inferred.\n",
      "          ValueError: If `num_or_size_splits` is a scalar `Tensor`.\n",
      "    \n",
      "    sqrt(x, name=None)\n",
      "        Computes element-wise square root of the input tensor.\n",
      "        \n",
      "        Note: This operation does not support integer types.\n",
      "        \n",
      "        >>> x = tf.constant([[4.0], [16.0]])\n",
      "        >>> tf.sqrt(x)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
      "          array([[2.],\n",
      "                 [4.]], dtype=float32)>\n",
      "        >>> y = tf.constant([[-4.0], [16.0]])\n",
      "        >>> tf.sqrt(y)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
      "          array([[nan],\n",
      "                 [ 4.]], dtype=float32)>\n",
      "        >>> z = tf.constant([[-1.0], [16.0]], dtype=tf.complex128)\n",
      "        >>> tf.sqrt(z)\n",
      "        <tf.Tensor: shape=(2, 1), dtype=complex128, numpy=\n",
      "          array([[0.0+1.j],\n",
      "                 [4.0+0.j]])>\n",
      "        \n",
      "        Note: In order to support complex type, please provide an input tensor\n",
      "        of `complex64` or `complex128`.\n",
      "        \n",
      "        Args:\n",
      "          x: A `tf.Tensor` of type `bfloat16`, `half`, `float32`, `float64`,\n",
      "            `complex64`, `complex128`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.Tensor` of same size, type and sparsity as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.sqrt(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    square(x: typing.Annotated[_any, ~TV_Square_T], name=None) -> typing.Annotated[_any, ~TV_Square_T]\n",
      "        Computes square of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = x * x = x^2\\\\).\n",
      "        \n",
      "        >>> tf.math.square([-2., 0., 3.])\n",
      "        <tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 0., 9.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.square(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    squared_difference(x: typing.Annotated[_any, ~TV_SquaredDifference_T], y: typing.Annotated[_any, ~TV_SquaredDifference_T], name=None) -> typing.Annotated[_any, ~TV_SquaredDifference_T]\n",
      "        Returns conj(x - y)(x - y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.squared_difference` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    squeeze(input, axis=None, name=None, squeeze_dims=None)\n",
      "        Removes dimensions of size 1 from the shape of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(squeeze_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of the same type with\n",
      "        all dimensions of size 1 removed. If you don't want to remove all size 1\n",
      "        dimensions, you can remove specific size 1 dimensions by specifying\n",
      "        `axis`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "        >>> t = tf.ones([1, 2, 1, 3, 1, 1])\n",
      "        >>> print(tf.shape(tf.squeeze(t)).numpy())\n",
      "        [2 3]\n",
      "        \n",
      "        Or, to remove specific size 1 dimensions:\n",
      "        \n",
      "        >>> # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "        >>> t = tf.ones([1, 2, 1, 3, 1, 1])\n",
      "        >>> print(tf.shape(tf.squeeze(t, [2, 4])).numpy())\n",
      "        [1 2 3 1]\n",
      "        \n",
      "        Note: if `input` is a `tf.RaggedTensor`, then this operation takes `O(N)`\n",
      "        time, where `N` is the number of elements in the squeezed dimensions.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The `input` to squeeze.\n",
      "          axis: An optional list of `ints`. Defaults to `[]`. If specified, only\n",
      "            squeezes the dimensions listed. The dimension index starts at 0. It is an\n",
      "            error to squeeze a dimension that is not 1. Must be in the range\n",
      "            `[-rank(input), rank(input))`. Must be specified if `input` is a\n",
      "            `RaggedTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          squeeze_dims: Deprecated keyword argument that is now axis.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "          Contains the same data as `input`, but has one or more dimensions of\n",
      "          size 1 removed.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When both `squeeze_dims` and `axis` are specified.\n",
      "    \n",
      "    stack(values, axis=0, name='stack')\n",
      "        Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.\n",
      "        \n",
      "        See also `tf.concat`, `tf.tile`, `tf.repeat`.\n",
      "        \n",
      "        Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "        each tensor in `values`, by packing them along the `axis` dimension.\n",
      "        Given a list of length `N` of tensors of shape `(A, B, C)`;\n",
      "        \n",
      "        if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.\n",
      "        if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.\n",
      "        Etc.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> x = tf.constant([1, 4])\n",
      "        >>> y = tf.constant([2, 5])\n",
      "        >>> z = tf.constant([3, 6])\n",
      "        >>> tf.stack([x, y, z])\n",
      "        <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "        array([[1, 4],\n",
      "               [2, 5],\n",
      "               [3, 6]], dtype=int32)>\n",
      "        >>> tf.stack([x, y, z], axis=1)\n",
      "        <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "        array([[1, 2, 3],\n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        This is the opposite of unstack.  The numpy equivalent is `np.stack`\n",
      "        \n",
      "        >>> np.array_equal(np.stack([x, y, z]), tf.stack([x, y, z]))\n",
      "        True\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects with the same shape and type.\n",
      "          axis: An `int`. The axis to stack along. Defaults to the first dimension.\n",
      "            Negative values wrap around, so the valid range is `[-(R+1), R+1)`.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: A stacked `Tensor` with the same type as `values`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `axis` is out of the range [-(R+1), R+1).\n",
      "    \n",
      "    stop_gradient(input, name=None)\n",
      "        Stops gradient computation.\n",
      "        \n",
      "        When executed in a graph, this op outputs its input tensor as-is.\n",
      "        \n",
      "        When building ops to compute gradients, this op prevents the contribution of\n",
      "        its inputs to be taken into account.  Normally, the gradient generator adds ops\n",
      "        to a graph to compute the derivatives of a specified 'loss' by recursively\n",
      "        finding out inputs that contributed to its computation.  If you insert this op\n",
      "        in the graph it inputs are masked from the gradient generator.  They are not\n",
      "        taken into account for computing gradients.\n",
      "        \n",
      "        This is useful any time you want to compute a value with TensorFlow but need\n",
      "        to pretend that the value was a constant. For example, the softmax function\n",
      "        for a vector x can be written as\n",
      "        \n",
      "        ```python\n",
      "        \n",
      "          def softmax(x):\n",
      "            numerator = tf.exp(x)\n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "            return numerator / denominator\n",
      "        ```\n",
      "        \n",
      "        This however is susceptible to overflow if the values in x are large. An\n",
      "        alternative more stable way is to subtract the maximum of x from each of the\n",
      "        values.\n",
      "        \n",
      "        ```python\n",
      "        \n",
      "          def stable_softmax(x):\n",
      "            z = x - tf.reduce_max(x)\n",
      "            numerator = tf.exp(z)\n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "            return numerator / denominator\n",
      "        ```\n",
      "        \n",
      "        However, when we backprop through the softmax to x, we dont want to backprop\n",
      "        through the `tf.reduce_max(x)` (if the max values are not unique then the\n",
      "        gradient could flow to the wrong input) calculation and treat that as a\n",
      "        constant. Therefore, we should write this out as\n",
      "        \n",
      "        ```python\n",
      "        \n",
      "          def stable_softmax(x):\n",
      "            z = x - tf.stop_gradient(tf.reduce_max(x))\n",
      "            numerator = tf.exp(z)\n",
      "            denominator = tf.reduce_sum(numerator)\n",
      "            return numerator / denominator\n",
      "        ```\n",
      "        \n",
      "        Some other examples include:\n",
      "        \n",
      "        *  The *EM* algorithm where the *M-step* should not involve backpropagation\n",
      "           through the output of the *E-step*.\n",
      "        *  Contrastive divergence training of Boltzmann machines where, when\n",
      "           differentiating the energy function, the training must not backpropagate\n",
      "           through the graph that generated the samples from the model.\n",
      "        *  Adversarial training, where no backprop should happen through the adversarial\n",
      "           example generation process.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    strided_slice(input_, begin, end, strides=None, begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0, var=None, name=None)\n",
      "        Extracts a strided slice of a tensor (generalized Python array indexing).\n",
      "        \n",
      "        See also `tf.slice`.\n",
      "        \n",
      "        **Instead of calling this op directly most users will want to use the\n",
      "        NumPy-style slicing syntax (e.g. `tensor[..., 3:4:-1, tf.newaxis, 3]`), which\n",
      "        is supported via `tf.Tensor.__getitem__` and `tf.Variable.__getitem__`.**\n",
      "        The interface of this op is a low-level encoding of the slicing syntax.\n",
      "        \n",
      "        Roughly speaking, this op extracts a slice of size `(end-begin)/stride`\n",
      "        from the given `input_` tensor. Starting at the location specified by `begin`\n",
      "        the slice continues by adding `stride` to the index until all dimensions are\n",
      "        not less than `end`.\n",
      "        Note that a stride can be negative, which causes a reverse slice.\n",
      "        \n",
      "        Given a Python slice `input[spec0, spec1, ..., specn]`,\n",
      "        this function will be called as follows.\n",
      "        \n",
      "        `begin`, `end`, and `strides` will be vectors of length n.\n",
      "        n in general is not equal to the rank of the `input_` tensor.\n",
      "        \n",
      "        In each mask field (`begin_mask`, `end_mask`, `ellipsis_mask`,\n",
      "        `new_axis_mask`, `shrink_axis_mask`) the ith bit will correspond to\n",
      "        the ith spec.\n",
      "        \n",
      "        If the ith bit of `begin_mask` is set, `begin[i]` is ignored and\n",
      "        the fullest possible range in that dimension is used instead.\n",
      "        `end_mask` works analogously, except with the end range.\n",
      "        \n",
      "        `foo[5:,:,:3]` on a 7x8x9 tensor is equivalent to `foo[5:7,0:8,0:3]`.\n",
      "        `foo[::-1]` reverses a tensor with shape 8.\n",
      "        \n",
      "        If the ith bit of `ellipsis_mask` is set, as many unspecified dimensions\n",
      "        as needed will be inserted between other dimensions. Only one\n",
      "        non-zero bit is allowed in `ellipsis_mask`.\n",
      "        \n",
      "        For example `foo[3:5,...,4:5]` on a shape 10x3x3x10 tensor is\n",
      "        equivalent to `foo[3:5,:,:,4:5]` and\n",
      "        `foo[3:5,...]` is equivalent to `foo[3:5,:,:,:]`.\n",
      "        \n",
      "        If the ith bit of `new_axis_mask` is set, then `begin`,\n",
      "        `end`, and `stride` are ignored and a new length 1 dimension is\n",
      "        added at this point in the output tensor.\n",
      "        \n",
      "        For example,\n",
      "        `foo[:4, tf.newaxis, :2]` would produce a shape `(4, 1, 2)` tensor.\n",
      "        \n",
      "        If the ith bit of `shrink_axis_mask` is set, it implies that the ith\n",
      "        specification shrinks the dimensionality by 1, taking on the value at index\n",
      "        `begin[i]`. `end[i]` and `strides[i]` are ignored in this case. For example in\n",
      "        Python one might do `foo[:, 3, :]` which would result in `shrink_axis_mask`\n",
      "        equal to 2.\n",
      "        \n",
      "        \n",
      "        NOTE: `begin` and `end` are zero-indexed.\n",
      "        `strides` entries must be non-zero.\n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
      "                         [[3, 3, 3], [4, 4, 4]],\n",
      "                         [[5, 5, 5], [6, 6, 6]]])\n",
      "        tf.strided_slice(t, [1, 0, 0], [2, 1, 3], [1, 1, 1])  # [[[3, 3, 3]]]\n",
      "        tf.strided_slice(t, [1, 0, 0], [2, 2, 3], [1, 1, 1])  # [[[3, 3, 3],\n",
      "                                                              #   [4, 4, 4]]]\n",
      "        tf.strided_slice(t, [1, -1, 0], [2, -3, 3], [1, -1, 1])  # [[[4, 4, 4],\n",
      "                                                                 #   [3, 3, 3]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_: A `Tensor`.\n",
      "          begin: An `int32` or `int64` `Tensor`.\n",
      "          end: An `int32` or `int64` `Tensor`.\n",
      "          strides: An `int32` or `int64` `Tensor`.\n",
      "          begin_mask: An `int32` mask.\n",
      "          end_mask: An `int32` mask.\n",
      "          ellipsis_mask: An `int32` mask.\n",
      "          new_axis_mask: An `int32` mask.\n",
      "          shrink_axis_mask: An `int32` mask.\n",
      "          var: The variable corresponding to `input_` or None\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` the same type as `input`.\n",
      "    \n",
      "    string_join(inputs, separator='', name=None)\n",
      "        Perform element-wise concatenation of a list of string tensors.\n",
      "        \n",
      "        Given a list of string tensors of same shape, performs element-wise\n",
      "        concatenation of the strings of the same index in all tensors.\n",
      "        \n",
      "        \n",
      "        >>> tf.strings.join(['abc','def']).numpy()\n",
      "        b'abcdef'\n",
      "        >>> tf.strings.join([['abc','123'],\n",
      "        ...                  ['def','456'],\n",
      "        ...                  ['ghi','789']]).numpy()\n",
      "        array([b'abcdefghi', b'123456789'], dtype=object)\n",
      "        >>> tf.strings.join([['abc','123'],\n",
      "        ...                  ['def','456']],\n",
      "        ...                  separator=\" \").numpy()\n",
      "        array([b'abc def', b'123 456'], dtype=object)\n",
      "        \n",
      "        The reduction version of this elementwise operation is\n",
      "        `tf.strings.reduce_join`\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `tf.Tensor` objects of same size and `tf.string` dtype.\n",
      "          separator: A string added between each string being joined.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `tf.string` tensor.\n",
      "    \n",
      "    string_split(source, sep=None, skip_empty=True, delimiter=None, result_type='SparseTensor', name=None)\n",
      "        Split elements of `source` based on `delimiter`. (deprecated arguments)\n",
      "        \n",
      "        Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(delimiter)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        delimiter is deprecated, please use sep instead.\n",
      "        \n",
      "        Let N be the size of `source` (typically N will be the batch size). Split each\n",
      "        element of `source` based on `delimiter` and return a `SparseTensor`\n",
      "        or `RaggedTensor` containing the split tokens. Empty tokens are ignored.\n",
      "        \n",
      "        If `sep` is an empty string, each element of the `source` is split\n",
      "        into individual strings, each containing one byte. (This includes splitting\n",
      "        multibyte sequences of UTF-8.) If delimiter contains multiple bytes, it is\n",
      "        treated as a set of delimiters with each considered a potential split point.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> print(tf.compat.v1.string_split(['hello world', 'a b c']))\n",
      "        SparseTensor(indices=tf.Tensor( [[0 0] [0 1] [1 0] [1 1] [1 2]], ...),\n",
      "                     values=tf.Tensor([b'hello' b'world' b'a' b'b' b'c'], ...),\n",
      "                     dense_shape=tf.Tensor([2 3], shape=(2,), dtype=int64))\n",
      "        \n",
      "        >>> print(tf.compat.v1.string_split(['hello world', 'a b c'],\n",
      "        ...     result_type=\"RaggedTensor\"))\n",
      "        <tf.RaggedTensor [[b'hello', b'world'], [b'a', b'b', b'c']]>\n",
      "        \n",
      "        Args:\n",
      "          source: `1-D` string `Tensor`, the strings to split.\n",
      "          sep: `0-D` string `Tensor`, the delimiter character, the string should\n",
      "            be length 0 or 1. Default is ' '.\n",
      "          skip_empty: A `bool`. If `True`, skip the empty strings from the result.\n",
      "          delimiter: deprecated alias for `sep`.\n",
      "          result_type: The tensor type for the result: one of `\"RaggedTensor\"` or\n",
      "            `\"SparseTensor\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If delimiter is not a string.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or `RaggedTensor` of rank `2`, the strings split according\n",
      "          to the delimiter.  The first column of the indices corresponds to the row\n",
      "          in `source` and the second column corresponds to the index of the split\n",
      "          component in this row.\n",
      "    \n",
      "    string_strip(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>]\n",
      "        Strip leading and trailing whitespaces from the Tensor.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.strings.strip([\"\\nTensorFlow\", \"     The python library    \"]).numpy()\n",
      "        array([b'TensorFlow', b'The python library'], dtype=object)\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. A string `Tensor` of any shape.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    string_to_hash_bucket = string_to_hash_bucket_v1(string_tensor=None, num_buckets=None, name=None, input=None)\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process.\n",
      "        \n",
      "        Note that the hash function may change from time to time.\n",
      "        This functionality will be deprecated and it's recommended to use\n",
      "        `tf.string_to_hash_bucket_fast()` or `tf.string_to_hash_bucket_strong()`.\n",
      "        \n",
      "        Args:\n",
      "          string_tensor: A `Tensor` of type `string`.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_hash_bucket_fast(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], num_buckets: int, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>]\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process and will never change. However, it is not suitable for cryptography.\n",
      "        This function may be used when CPU time is scarce and inputs are trusted or\n",
      "        unimportant. There is a risk of adversaries constructing inputs that all hash\n",
      "        to the same bucket. To prevent this problem, use a strong hash function with\n",
      "        `tf.string_to_hash_bucket_strong`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.strings.to_hash_bucket_fast([\"Hello\", \"TensorFlow\", \"2.x\"], 3).numpy()\n",
      "        array([0, 2, 2])\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. The strings to assign a hash bucket.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_hash_bucket_strong(input: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], num_buckets: int, key, name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Int64'>]\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process. The hash function is a keyed hash function, where attribute `key`\n",
      "        defines the key of the hash function. `key` is an array of 2 elements.\n",
      "        \n",
      "        A strong hash is important when inputs may be malicious, e.g. URLs with\n",
      "        additional components. Adversaries could try to make their inputs hash to the\n",
      "        same bucket for a denial-of-service attack or to skew the results. A strong\n",
      "        hash can be used to make it difficult to find inputs with a skewed hash value\n",
      "        distribution over buckets. This requires that the hash function is\n",
      "        seeded by a high-entropy (random) \"key\" unknown to the adversary.\n",
      "        \n",
      "        The additional robustness comes at a cost of roughly 4x higher compute\n",
      "        time than `tf.string_to_hash_bucket_fast`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.strings.to_hash_bucket_strong([\"Hello\", \"TF\"], 3, [1, 2]).numpy()\n",
      "        array([2, 0])\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. The strings to assign a hash bucket.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          key: A list of `ints`.\n",
      "            The key used to seed the hash function, passed as a list of two uint64\n",
      "            elements.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_number = string_to_number_v1(string_tensor=None, out_type=tf.float32, name=None, input=None)\n",
      "        Converts each string in the input Tensor to the specified numeric type.\n",
      "        \n",
      "        (Note that int32 overflow results in an error while float overflow\n",
      "        results in a rounded value.)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        >>> strings = [\"5.0\", \"3.0\", \"7.0\"]\n",
      "        >>> tf.strings.to_number(strings)\n",
      "        <tf.Tensor: shape=(3,), dtype=float32, numpy=array([5., 3., 7.], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          string_tensor: A `Tensor` of type `string`.\n",
      "          out_type: An optional `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.int64`. Defaults to `tf.float32`.\n",
      "            The numeric type to interpret each string in `string_tensor` as.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    substr = substr_deprecated(input, pos, len, name=None, unit='BYTE')\n",
      "        Return substrings from `Tensor` of strings.\n",
      "        \n",
      "        For each string in the input `Tensor`, creates a substring starting at index\n",
      "        `pos` with a total length of `len`.\n",
      "        \n",
      "        If `len` defines a substring that would extend beyond the length of the input\n",
      "        string, or if `len` is negative, then as many characters as possible are used.\n",
      "        \n",
      "        A negative `pos` indicates distance within the string backwards from the end.\n",
      "        \n",
      "        If `pos` specifies an index which is out of range for any of the input strings,\n",
      "        then an `InvalidArgumentError` is thrown.\n",
      "        \n",
      "        `pos` and `len` must have the same shape, otherwise a `ValueError` is thrown on\n",
      "        Op creation.\n",
      "        \n",
      "        *NOTE*: `Substr` supports broadcasting up to two dimensions. More about\n",
      "        broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        ---\n",
      "        \n",
      "        Examples\n",
      "        \n",
      "        Using scalar `pos` and `len`:\n",
      "        \n",
      "        ```python\n",
      "        input = [b'Hello', b'World']\n",
      "        position = 1\n",
      "        length = 3\n",
      "        \n",
      "        output = [b'ell', b'orl']\n",
      "        ```\n",
      "        \n",
      "        Using `pos` and `len` with same shape as `input`:\n",
      "        \n",
      "        ```python\n",
      "        input = [[b'ten', b'eleven', b'twelve'],\n",
      "                 [b'thirteen', b'fourteen', b'fifteen'],\n",
      "                 [b'sixteen', b'seventeen', b'eighteen']]\n",
      "        position = [[1, 2, 3],\n",
      "                    [1, 2, 3],\n",
      "                    [1, 2, 3]]\n",
      "        length =   [[2, 3, 4],\n",
      "                    [4, 3, 2],\n",
      "                    [5, 5, 5]]\n",
      "        \n",
      "        output = [[b'en', b'eve', b'lve'],\n",
      "                  [b'hirt', b'urt', b'te'],\n",
      "                  [b'ixtee', b'vente', b'hteen']]\n",
      "        ```\n",
      "        \n",
      "        Broadcasting `pos` and `len` onto `input`:\n",
      "        \n",
      "        ```\n",
      "        input = [[b'ten', b'eleven', b'twelve'],\n",
      "                 [b'thirteen', b'fourteen', b'fifteen'],\n",
      "                 [b'sixteen', b'seventeen', b'eighteen'],\n",
      "                 [b'nineteen', b'twenty', b'twentyone']]\n",
      "        position = [1, 2, 3]\n",
      "        length =   [1, 2, 3]\n",
      "        \n",
      "        output = [[b'e', b'ev', b'lve'],\n",
      "                  [b'h', b'ur', b'tee'],\n",
      "                  [b'i', b've', b'hte'],\n",
      "                  [b'i', b'en', b'nty']]\n",
      "        ```\n",
      "        \n",
      "        Broadcasting `input` onto `pos` and `len`:\n",
      "        \n",
      "        ```\n",
      "        input = b'thirteen'\n",
      "        position = [1, 5, 7]\n",
      "        length =   [3, 2, 1]\n",
      "        \n",
      "        output = [b'hir', b'ee', b'n']\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "        \n",
      "          * `ValueError`: If the first argument cannot be converted to a\n",
      "             Tensor of `dtype string`.\n",
      "          * `InvalidArgumentError`: If indices are out of range.\n",
      "          * `ValueError`: If `pos` and `len` are not the same shape.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Tensor of strings\n",
      "          pos: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Scalar defining the position of first character in each substring\n",
      "          len: A `Tensor`. Must have the same type as `pos`.\n",
      "            Scalar defining the number of characters to include in each substring\n",
      "          unit: An optional `string` from: `\"BYTE\", \"UTF8_CHAR\"`. Defaults to `\"BYTE\"`.\n",
      "            The unit that is used to create the substring.  One of: `\"BYTE\"` (for\n",
      "            defining position and length by bytes) or `\"UTF8_CHAR\"` (for the UTF-8\n",
      "            encoded Unicode code points).  The default is `\"BYTE\"`. Results are undefined if\n",
      "            `unit=UTF8_CHAR` and the `input` strings do not contain structurally valid\n",
      "            UTF-8.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    subtract(x, y, name=None)\n",
      "        Returns x - y element-wise.\n",
      "        \n",
      "        *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Both input and output have a range `(-inf, inf)`.\n",
      "        \n",
      "        Example usages below.\n",
      "        \n",
      "        Subtract operation between an array and a scalar:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = 1\n",
      "        >>> tf.subtract(x, y)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        >>> tf.subtract(y, x)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
      "        \n",
      "        Note that binary `-` operator can be used instead:\n",
      "        \n",
      "        >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
      "        >>> y = tf.convert_to_tensor(1)\n",
      "        >>> x - y\n",
      "        <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
      "        \n",
      "        Subtract operation between an array and a tensor of same shape:\n",
      "        \n",
      "        >>> x = [1, 2, 3, 4, 5]\n",
      "        >>> y = tf.constant([5, 4, 3, 2, 1])\n",
      "        >>> tf.subtract(y, x)\n",
      "        <tf.Tensor: shape=(5,), dtype=int32,\n",
      "        numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
      "        \n",
      "        **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
      "        non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
      "        of the tensor input. This can potentially cause unwanted overflow or underflow\n",
      "        conversion.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
      "        >>> y = [2**8 + 1, 2**8 + 2]\n",
      "        >>> tf.subtract(x, y)\n",
      "        <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
      "        \n",
      "        When subtracting two input values of different shapes, `tf.subtract` follows the\n",
      "        [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
      "        . The two input array shapes are compared element-wise. Starting with the\n",
      "        trailing dimensions, the two dimensions either have to be equal or one of them\n",
      "        needs to be `1`.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "        >>> y = np.ones(6).reshape(2, 1, 3)\n",
      "        >>> tf.subtract(x, y)\n",
      "        <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
      "        array([[[0., 0., 0.],\n",
      "                [0., 0., 0.],\n",
      "                [0., 0., 0.]],\n",
      "               [[0., 0., 0.],\n",
      "                [0., 0., 0.],\n",
      "                [0., 0., 0.]]])>\n",
      "        \n",
      "        Example with inputs of different dimensions:\n",
      "        \n",
      "        >>> x = np.ones(6).reshape(2, 3, 1)\n",
      "        >>> y = np.ones(6).reshape(1, 6)\n",
      "        >>> tf.subtract(x, y)\n",
      "        <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
      "        array([[[0., 0., 0., 0., 0., 0.],\n",
      "                [0., 0., 0., 0., 0., 0.],\n",
      "                [0., 0., 0., 0., 0., 0.]],\n",
      "               [[0., 0., 0., 0., 0., 0.],\n",
      "                [0., 0., 0., 0., 0., 0.],\n",
      "                [0., 0., 0., 0., 0., 0.]]])>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    svd(tensor, full_matrices=False, compute_uv=True, name=None)\n",
      "        Computes the singular value decompositions of one or more matrices.\n",
      "        \n",
      "        Computes the SVD of each inner matrix in `tensor` such that\n",
      "        `tensor[..., :, :] = u[..., :, :] * diag(s[..., :, :]) *\n",
      "         transpose(conj(v[..., :, :]))`\n",
      "        \n",
      "        ```python\n",
      "        # a is a tensor.\n",
      "        # s is a tensor of singular values.\n",
      "        # u is a tensor of left singular vectors.\n",
      "        # v is a tensor of right singular vectors.\n",
      "        s, u, v = svd(a)\n",
      "        s = svd(a, compute_uv=False)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., M, N]`. Let `P` be the minimum of `M` and\n",
      "            `N`.\n",
      "          full_matrices: If true, compute full-sized `u` and `v`. If false\n",
      "            (the default), compute only the leading `P` singular vectors.\n",
      "            Ignored if `compute_uv` is `False`.\n",
      "          compute_uv: If `True` then left and right singular vectors will be\n",
      "            computed and returned in `u` and `v`, respectively. Otherwise, only the\n",
      "            singular values will be computed, which can be significantly faster.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          s: Singular values. Shape is `[..., P]`. The values are sorted in reverse\n",
      "            order of magnitude, so s[..., 0] is the largest value, s[..., 1] is the\n",
      "            second largest, etc.\n",
      "          u: Left singular vectors. If `full_matrices` is `False` (default) then\n",
      "            shape is `[..., M, P]`; if `full_matrices` is `True` then shape is\n",
      "            `[..., M, M]`. Not returned if `compute_uv` is `False`.\n",
      "          v: Right singular vectors. If `full_matrices` is `False` (default) then\n",
      "            shape is `[..., N, P]`. If `full_matrices` is `True` then shape is\n",
      "            `[..., N, N]`. Not returned if `compute_uv` is `False`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Mostly equivalent to numpy.linalg.svd, except that\n",
      "          * The order of output  arguments here is `s`, `u`, `v` when `compute_uv` is\n",
      "            `True`, as opposed to `u`, `s`, `v` for numpy.linalg.svd.\n",
      "          * full_matrices is `False` by default as opposed to `True` for\n",
      "             numpy.linalg.svd.\n",
      "          * tf.linalg.svd uses the standard definition of the SVD\n",
      "            \\\\(A = U \\Sigma V^H\\\\), such that the left singular vectors of `a` are\n",
      "            the columns of `u`, while the right singular vectors of `a` are the\n",
      "            columns of `v`. On the other hand, numpy.linalg.svd returns the adjoint\n",
      "            \\\\(V^H\\\\) as the third output argument.\n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        import numpy as np\n",
      "        s, u, v = tf.linalg.svd(a)\n",
      "        tf_a_approx = tf.matmul(u, tf.matmul(tf.linalg.diag(s), v, adjoint_b=True))\n",
      "        u, s, v_adj = np.linalg.svd(a, full_matrices=False)\n",
      "        np_a_approx = np.dot(u, np.dot(np.diag(s), v_adj))\n",
      "        # tf_a_approx and np_a_approx should be numerically close.\n",
      "        ```\n",
      "        @end_compatibility\n",
      "    \n",
      "    switch_case(branch_index, branch_fns, default=None, name='switch_case')\n",
      "        Create a switch/case operation, i.e.\n",
      "        \n",
      "        an integer-indexed conditional.\n",
      "        \n",
      "        See also `tf.case`.\n",
      "        \n",
      "        This op can be substantially more efficient than `tf.case` when exactly one\n",
      "        branch will be selected. `tf.switch_case` is more like a C++ switch/case\n",
      "        statement than `tf.case`, which is more like an if/elif/elif/else chain.\n",
      "        \n",
      "        The `branch_fns` parameter is either a dict from `int` to callables, or list\n",
      "        of (`int`, callable) pairs, or simply a list of callables (in which case the\n",
      "        index is implicitly the key). The `branch_index` `Tensor` is used to select an\n",
      "        element in `branch_fns` with matching `int` key, falling back to `default`\n",
      "        if none match, or `max(keys)` if no `default` is provided. The keys must form\n",
      "        a contiguous set from `0` to `len(branch_fns) - 1`.\n",
      "        \n",
      "        `tf.switch_case` supports nested structures as implemented in `tf.nest`. All\n",
      "        callables must return the same (possibly nested) value structure of lists,\n",
      "        tuples, and/or named tuples.\n",
      "        \n",
      "        **Example:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```c++\n",
      "        switch (branch_index) {  // c-style switch\n",
      "          case 0: return 17;\n",
      "          case 1: return 31;\n",
      "          default: return -1;\n",
      "        }\n",
      "        ```\n",
      "        or\n",
      "        ```python\n",
      "        branches = {0: lambda: 17, 1: lambda: 31}\n",
      "        branches.get(branch_index, lambda: -1)()\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        def f1(): return tf.constant(17)\n",
      "        def f2(): return tf.constant(31)\n",
      "        def f3(): return tf.constant(-1)\n",
      "        r = tf.switch_case(branch_index, branch_fns={0: f1, 1: f2}, default=f3)\n",
      "        # Equivalent: tf.switch_case(branch_index, branch_fns={0: f1, 1: f2, 2: f3})\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          branch_index: An int Tensor specifying which of `branch_fns` should be\n",
      "            executed.\n",
      "          branch_fns: A `dict` mapping `int`s to callables, or a `list` of (`int`,\n",
      "            callable) pairs, or simply a list of callables (in which case the index\n",
      "            serves as the key). Each callable must return a matching structure of\n",
      "            tensors.\n",
      "          default: Optional callable that returns a structure of tensors.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The tensors returned by the callable identified by `branch_index`, or those\n",
      "          returned by `default` if no key matches and `default` was provided, or those\n",
      "          returned by the max-keyed `branch_fn` if no `default` is provided.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `branch_fns` is not a list/dictionary.\n",
      "          TypeError: If `branch_fns` is a list but does not contain 2-tuples or\n",
      "                     callables.\n",
      "          TypeError: If `fns[i]` is not callable for any i, or `default` is not\n",
      "                     callable.\n",
      "    \n",
      "    tables_initializer(name='init_all_tables')\n",
      "        Returns an Op that initializes all tables of the default graph.\n",
      "        \n",
      "        Args:\n",
      "          name: Optional name for the initialization op.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all tables.  Note that if there are\n",
      "          not tables the returned Op is a NoOp.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.tables_initializer` is no longer needed with eager execution and\n",
      "        `tf.function`. In TF2, when creating an initializable table like a\n",
      "        `tf.lookup.StaticHashTable`, the table will automatically be initialized on\n",
      "        creation.\n",
      "        \n",
      "        #### Before & After Usage Example\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> with tf.compat.v1.Session():\n",
      "        ...   init = tf.compat.v1.lookup.KeyValueTensorInitializer(['a', 'b'], [1, 2])\n",
      "        ...   table = tf.compat.v1.lookup.StaticHashTable(init, default_value=-1)\n",
      "        ...   tf.compat.v1.tables_initializer().run()\n",
      "        ...   result = table.lookup(tf.constant(['a', 'c'])).eval()\n",
      "        >>> result\n",
      "        array([ 1, -1], dtype=int32)\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> init = tf.lookup.KeyValueTensorInitializer(['a', 'b'], [1, 2])\n",
      "        >>> table = tf.lookup.StaticHashTable(init, default_value=-1)\n",
      "        >>> table.lookup(tf.constant(['a', 'c'])).numpy()\n",
      "        array([ 1, -1], dtype=int32)\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    tan(x: typing.Annotated[_any, ~TV_Tan_T], name=None) -> typing.Annotated[_any, ~TV_Tan_T]\n",
      "        Computes tan of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes tangent of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `(-inf, inf)`. If input lies outside the boundary, `nan`\n",
      "          is returned.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.tan(x) ==> [nan 0.45231566 -0.5463025 1.5574077 2.572152 -1.7925274 0.32097113 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    tanh(x: typing.Annotated[_any, ~TV_Tanh_T], name=None) -> typing.Annotated[_any, ~TV_Tanh_T]\n",
      "        Computes hyperbolic tangent of `x` element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic tangent of every\n",
      "          element in the tensor. Input range is `[-inf, inf]` and\n",
      "          output range is `[-1,1]`.\n",
      "        \n",
      "          >>> x = tf.constant([-float(\"inf\"), -5, -0.5, 1, 1.2, 2, 3, float(\"inf\")])\n",
      "          >>> tf.math.tanh(x)\n",
      "          <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
      "          array([-1.0, -0.99990916, -0.46211717,  0.7615942 ,  0.8336547 ,\n",
      "                  0.9640276 ,  0.9950547 ,  1.0], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.tanh(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    tensor_scatter_add(tensor: Annotated[Any, ~TV_TensorScatterAdd_T], indices: Annotated[Any, ~TV_TensorScatterAdd_Tindices], updates: Annotated[Any, ~TV_TensorScatterAdd_T], name=None) -> Annotated[Any, ~TV_TensorScatterAdd_T]\n",
      "        Adds sparse `updates` to an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by adding sparse `updates` to the passed\n",
      "        in `tensor`.\n",
      "        This operation is very similar to `tf.compat.v1.scatter_nd_add`, except that the\n",
      "        updates are added onto an existing tensor (as opposed to a variable). If the\n",
      "        memory for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `tensor.shape`.  The last dimension of `indices` can be at most the rank of\n",
      "        `tensor.shape`:\n",
      "        \n",
      "        ```\n",
      "        indices.shape[-1] <= tensor.shape.rank\n",
      "        ```\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = tensor.shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < tensor.shape.rank`) along dimension\n",
      "        `indices.shape[-1]` of `tensor.shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "        ```\n",
      "        indices.shape[:-1] + tensor.shape[indices.shape[-1]:]\n",
      "        ```\n",
      "        \n",
      "        The simplest form of `tensor_scatter_nd_add` is to add individual elements to a\n",
      "        tensor by index. For example, say we want to add 4 elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        >>> indices = tf.constant([[4], [3], [1], [7]])\n",
      "        >>> updates = tf.constant([9, 10, 11, 12])\n",
      "        >>> tensor = tf.ones([8], dtype=tf.int32)\n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        >>> updated\n",
      "        <tf.Tensor: shape=(8,), dtype=int32,\n",
      "        numpy=array([ 1, 12,  1, 11, 10,  1,  1, 13], dtype=int32)>\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        >>> indices = tf.constant([[0], [2]])\n",
      "        >>> updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "        ...                        [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "        >>> tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        >>> updated\n",
      "        <tf.Tensor: shape=(4, 4, 4), dtype=int32,\n",
      "        numpy=array([[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "                     [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]], dtype=int32)>\n",
      "        \n",
      "        Note: on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_add = tensor_scatter_add(tensor: Annotated[Any, ~TV_TensorScatterAdd_T], indices: Annotated[Any, ~TV_TensorScatterAdd_Tindices], updates: Annotated[Any, ~TV_TensorScatterAdd_T], name=None) -> Annotated[Any, ~TV_TensorScatterAdd_T]\n",
      "        Adds sparse `updates` to an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by adding sparse `updates` to the passed\n",
      "        in `tensor`.\n",
      "        This operation is very similar to `tf.compat.v1.scatter_nd_add`, except that the\n",
      "        updates are added onto an existing tensor (as opposed to a variable). If the\n",
      "        memory for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `tensor.shape`.  The last dimension of `indices` can be at most the rank of\n",
      "        `tensor.shape`:\n",
      "        \n",
      "        ```\n",
      "        indices.shape[-1] <= tensor.shape.rank\n",
      "        ```\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = tensor.shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < tensor.shape.rank`) along dimension\n",
      "        `indices.shape[-1]` of `tensor.shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "        ```\n",
      "        indices.shape[:-1] + tensor.shape[indices.shape[-1]:]\n",
      "        ```\n",
      "        \n",
      "        The simplest form of `tensor_scatter_nd_add` is to add individual elements to a\n",
      "        tensor by index. For example, say we want to add 4 elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        >>> indices = tf.constant([[4], [3], [1], [7]])\n",
      "        >>> updates = tf.constant([9, 10, 11, 12])\n",
      "        >>> tensor = tf.ones([8], dtype=tf.int32)\n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        >>> updated\n",
      "        <tf.Tensor: shape=(8,), dtype=int32,\n",
      "        numpy=array([ 1, 12,  1, 11, 10,  1,  1, 13], dtype=int32)>\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        >>> indices = tf.constant([[0], [2]])\n",
      "        >>> updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "        ...                        [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "        ...                         [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "        >>> tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "        >>> updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
      "        >>> updated\n",
      "        <tf.Tensor: shape=(4, 4, 4), dtype=int32,\n",
      "        numpy=array([[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "                     [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "                     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]], dtype=int32)>\n",
      "        \n",
      "        Note: on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_max = tensor_scatter_max(tensor: Annotated[Any, ~TV_TensorScatterMax_T], indices: Annotated[Any, ~TV_TensorScatterMax_Tindices], updates: Annotated[Any, ~TV_TensorScatterMax_T], name=None) -> Annotated[Any, ~TV_TensorScatterMax_T]\n",
      "        Apply a sparse update to a tensor taking the element-wise maximum.\n",
      "        \n",
      "        Returns a new tensor copied from `tensor` whose values are element-wise maximum between\n",
      "        tensor and updates according to the indices.\n",
      "        \n",
      "        >>> tensor = [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "        >>> indices = [[1], [4], [5]]\n",
      "        >>> updates = [1, -1, 1]\n",
      "        >>> tf.tensor_scatter_nd_max(tensor, indices, updates).numpy()\n",
      "        array([0, 1, 0, 0, 0, 1, 0, 0], dtype=int32)\n",
      "        \n",
      "        Refer to `tf.tensor_scatter_nd_update` for more details.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_min = tensor_scatter_min(tensor: Annotated[Any, ~TV_TensorScatterMin_T], indices: Annotated[Any, ~TV_TensorScatterMin_Tindices], updates: Annotated[Any, ~TV_TensorScatterMin_T], name=None) -> Annotated[Any, ~TV_TensorScatterMin_T]\n",
      "        TODO: add doc.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_sub = tensor_scatter_sub(tensor: Annotated[Any, ~TV_TensorScatterSub_T], indices: Annotated[Any, ~TV_TensorScatterSub_Tindices], updates: Annotated[Any, ~TV_TensorScatterSub_T], name=None) -> Annotated[Any, ~TV_TensorScatterSub_T]\n",
      "        Subtracts sparse `updates` from an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by subtracting sparse `updates` from the\n",
      "        passed in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd_sub`, except that the updates\n",
      "        are subtracted from an existing tensor (as opposed to a variable). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of tensor_scatter_sub is to subtract individual elements\n",
      "        from a tensor by index. For example, say we want to insert 4 scattered elements\n",
      "        in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter subtract operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "            print(updated)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, -10, 1, -9, -8, 1, 1, -11]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "            print(updated)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_update(tensor, indices, updates, name=None)\n",
      "        Scatter `updates` into an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by applying sparse `updates` to the\n",
      "        input `tensor`. This is similar to an index assignment.\n",
      "        \n",
      "        ```\n",
      "        # Not implemented: tensors cannot be updated inplace.\n",
      "        tensor[indices] = updates\n",
      "        ```\n",
      "        \n",
      "        If an out of bound index is found on CPU, an error is returned.\n",
      "        \n",
      "        > **WARNING**: There are some GPU specific semantics for this operation.\n",
      "        >\n",
      "        > - If an out of bound index is found, the index is ignored.\n",
      "        > - The order in which updates are applied is nondeterministic, so the output\n",
      "        >   will be nondeterministic if `indices` contains duplicates.\n",
      "        \n",
      "        This operation is very similar to `tf.scatter_nd`, except that the updates are\n",
      "        scattered onto an existing tensor (as opposed to a zero-tensor). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        In general:\n",
      "        \n",
      "        * `indices` is an integer tensor - the indices to update in `tensor`.\n",
      "        * `indices` has **at least two** axes, the last axis is the depth of the\n",
      "          index vectors.\n",
      "        * For each index vector in `indices` there is a corresponding entry in\n",
      "          `updates`.\n",
      "        * If the length of the index vectors matches the rank of the `tensor`, then\n",
      "          the index vectors each point to scalars in `tensor` and each update is a\n",
      "          scalar.\n",
      "        * If the length of the index vectors is less than the rank of `tensor`, then\n",
      "          the index vectors each point to the slices of `tensor` and shape of the updates\n",
      "          must match that slice.\n",
      "        \n",
      "        Overall this leads to the following shape constraints:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Typical usage is often much simpler than this general form, and it\n",
      "        can be better understood starting with simple examples:\n",
      "        \n",
      "        ### Scalar updates\n",
      "        \n",
      "        The simplest usage inserts scalar elements into a tensor by index.\n",
      "        In this case, the `index_depth` must equal the rank of the\n",
      "        input `tensor`, slice each column of `indices` is an index into an axis of the\n",
      "        input `tensor`.\n",
      "        \n",
      "        In this simplest case the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        assert updates.shape == [num_updates]\n",
      "        assert index_depth == tf.rank(tensor)`\n",
      "        ```\n",
      "        \n",
      "        For example, to insert 4 scattered elements in a rank-1 tensor with\n",
      "        8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\"\n",
      "          src=\"https://www.tensorflow.org/images/ScatterNd1.png\">\n",
      "        </div>\n",
      "        \n",
      "        This scatter operation would look like this:\n",
      "        \n",
      "        >>> tensor = [0, 0, 0, 0, 0, 0, 0, 0]    # tf.rank(tensor) == 1\n",
      "        >>> indices = [[1], [3], [4], [7]]       # num_updates == 4, index_depth == 1\n",
      "        >>> updates = [9, 10, 11, 12]            # num_updates == 4\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor([ 0 9  0 10  11  0  0 12], shape=(8,), dtype=int32)\n",
      "        \n",
      "        The length (first axis) of `updates` must equal the length of the `indices`:\n",
      "        `num_updates`. This is the number of updates being inserted. Each scalar\n",
      "        update is inserted into `tensor` at the indexed location.\n",
      "        \n",
      "        For a higher rank input `tensor` scalar updates can be inserted by using an\n",
      "        `index_depth` that matches `tf.rank(tensor)`:\n",
      "        \n",
      "        >>> tensor = [[1, 1], [1, 1], [1, 1]]    # tf.rank(tensor) == 2\n",
      "        >>> indices = [[0, 1], [2, 0]]           # num_updates == 2, index_depth == 2\n",
      "        >>> updates = [5, 10]                    # num_updates == 2\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor(\n",
      "            [[ 1  5]\n",
      "             [ 1  1]\n",
      "             [10  1]], shape=(3, 2), dtype=int32)\n",
      "        \n",
      "        ### Slice updates\n",
      "        \n",
      "        When the input `tensor` has more than one axis scatter can be used to update\n",
      "        entire slices.\n",
      "        \n",
      "        In this case it's helpful to think of the input `tensor` as being a two level\n",
      "        array-of-arrays. The shape of this two level array is split into the\n",
      "        `outer_shape` and the `inner_shape`.\n",
      "        \n",
      "        `indices` indexes into the outer level of the input tensor (`outer_shape`).\n",
      "        and replaces the sub-array at that location with the corresponding item from\n",
      "        the `updates` list. The shape of each update is `inner_shape`.\n",
      "        \n",
      "        When updating a list of slices the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == [num_updates, inner_shape]\n",
      "        ```\n",
      "        \n",
      "        For example, to update rows of a `(6, 3)` `tensor`:\n",
      "        \n",
      "        >>> tensor = tf.zeros([6, 3], dtype=tf.int32)\n",
      "        \n",
      "        Use an index depth of one.\n",
      "        \n",
      "        >>> indices = tf.constant([[2], [4]])     # num_updates == 2, index_depth == 1\n",
      "        >>> num_updates, index_depth = indices.shape.as_list()\n",
      "        \n",
      "        The `outer_shape` is `6`, the inner shape is `3`:\n",
      "        \n",
      "        >>> outer_shape = tensor.shape[:index_depth]\n",
      "        >>> inner_shape = tensor.shape[index_depth:]\n",
      "        \n",
      "        2 rows are being indexed so 2 `updates` must be supplied.\n",
      "        Each update must be shaped to match the `inner_shape`.\n",
      "        \n",
      "        >>> # num_updates == 2, inner_shape==3\n",
      "        >>> updates = tf.constant([[1, 2, 3],\n",
      "        ...                        [4, 5, 6]])\n",
      "        \n",
      "        Altogether this gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 0, 0],\n",
      "               [1, 2, 3],\n",
      "               [0, 0, 0],\n",
      "               [4, 5, 6],\n",
      "               [0, 0, 0]], dtype=int32)\n",
      "        \n",
      "        #### More slice update examples\n",
      "        \n",
      "        A tensor representing a batch of uniformly sized video clips naturally has 5\n",
      "        axes: `[batch_size, time, width, height, channels]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> batch_size, time, width, height, channels = 13,11,7,5,3\n",
      "        >>> video_batch = tf.zeros([batch_size, time, width, height, channels])\n",
      "        \n",
      "        To replace a selection of video clips:\n",
      "          * Use an `index_depth` of 1 (indexing the `outer_shape`: `[batch_size]`)\n",
      "          * Provide updates each with a shape matching the `inner_shape`:\n",
      "            `[time, width, height, channels]`.\n",
      "        \n",
      "        To replace the first two clips with ones:\n",
      "        \n",
      "        >>> indices = [[0],[1]]\n",
      "        >>> new_clips = tf.ones([2, time, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_clips)\n",
      "        \n",
      "        To replace a selection of frames in the videos:\n",
      "        \n",
      "        * `indices` must have an `index_depth` of 2 for the `outer_shape`:\n",
      "          `[batch_size, time]`.\n",
      "        * `updates` must be shaped like a list of images.  Each update must have a\n",
      "          shape, matching the `inner_shape`: `[width, height, channels]`.\n",
      "        \n",
      "        To replace the first frame of the first three video clips:\n",
      "        \n",
      "        >>> indices = [[0, 0], [1, 0], [2, 0]] # num_updates=3, index_depth=2\n",
      "        >>> new_images = tf.ones([\n",
      "        ...   # num_updates=3, inner_shape=(width, height, channels)\n",
      "        ...   3, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_images)\n",
      "        \n",
      "        ### Folded indices\n",
      "        \n",
      "        In simple cases it's convenient to think of `indices` and `updates` as\n",
      "        lists, but this is not a strict requirement. Instead of a flat `num_updates`,\n",
      "        the `indices` and `updates` can be folded into a `batch_shape`. This\n",
      "        `batch_shape` is all axes of the `indices`, except for the innermost\n",
      "        `index_depth` axis.\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        ```\n",
      "        \n",
      "        Note: The one exception is that the `batch_shape` cannot be `[]`. You can't\n",
      "        update a single index by passing indices with shape `[index_depth]`.\n",
      "        \n",
      "        `updates` must have a matching `batch_shape` (the axes before `inner_shape`).\n",
      "        \n",
      "        ```\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Note: The result is equivalent to flattening the `batch_shape` axes of\n",
      "        `indices` and `updates`. This generalization just avoids the need\n",
      "        for reshapes when it is more natural to construct \"folded\" indices and\n",
      "        updates.\n",
      "        \n",
      "        With this generalization the full shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        For example, to draw an `X` on a `(5,5)` matrix start with these indices:\n",
      "        \n",
      "        >>> tensor = tf.zeros([5,5])\n",
      "        >>> indices = tf.constant([\n",
      "        ...  [[0,0],\n",
      "        ...   [1,1],\n",
      "        ...   [2,2],\n",
      "        ...   [3,3],\n",
      "        ...   [4,4]],\n",
      "        ...  [[0,4],\n",
      "        ...   [1,3],\n",
      "        ...   [2,2],\n",
      "        ...   [3,1],\n",
      "        ...   [4,0]],\n",
      "        ... ])\n",
      "        >>> indices.shape.as_list()  # batch_shape == [2, 5], index_depth == 2\n",
      "        [2, 5, 2]\n",
      "        \n",
      "        Here the `indices` do not have a shape of `[num_updates, index_depth]`, but a\n",
      "        shape of `batch_shape+[index_depth]`.\n",
      "        \n",
      "        Since the `index_depth` is equal to the rank of `tensor`:\n",
      "        \n",
      "        * `outer_shape` is `(5,5)`\n",
      "        * `inner_shape` is `()` - each update is scalar\n",
      "        * `updates.shape` is `batch_shape + inner_shape == (5,2) + ()`\n",
      "        \n",
      "        >>> updates = [\n",
      "        ...   [1,1,1,1,1],\n",
      "        ...   [1,1,1,1,1],\n",
      "        ... ]\n",
      "        \n",
      "        Putting this together gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[1., 0., 0., 0., 1.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [0., 0., 1., 0., 0.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [1., 0., 0., 0., 1.]], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          tensor: Tensor to copy/update.\n",
      "          indices: Indices to update.\n",
      "          updates: Updates to apply at the indices.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A new tensor with the given shape and updates applied according to the\n",
      "          indices.\n",
      "    \n",
      "    tensor_scatter_sub(tensor: Annotated[Any, ~TV_TensorScatterSub_T], indices: Annotated[Any, ~TV_TensorScatterSub_Tindices], updates: Annotated[Any, ~TV_TensorScatterSub_T], name=None) -> Annotated[Any, ~TV_TensorScatterSub_T]\n",
      "        Subtracts sparse `updates` from an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by subtracting sparse `updates` from the\n",
      "        passed in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd_sub`, except that the updates\n",
      "        are subtracted from an existing tensor (as opposed to a variable). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of tensor_scatter_sub is to subtract individual elements\n",
      "        from a tensor by index. For example, say we want to insert 4 scattered elements\n",
      "        in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter subtract operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "            print(updated)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, -10, 1, -9, -8, 1, 1, -11]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)\n",
      "            print(updated)\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_update = tensor_scatter_nd_update(tensor, indices, updates, name=None)\n",
      "        Scatter `updates` into an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by applying sparse `updates` to the\n",
      "        input `tensor`. This is similar to an index assignment.\n",
      "        \n",
      "        ```\n",
      "        # Not implemented: tensors cannot be updated inplace.\n",
      "        tensor[indices] = updates\n",
      "        ```\n",
      "        \n",
      "        If an out of bound index is found on CPU, an error is returned.\n",
      "        \n",
      "        > **WARNING**: There are some GPU specific semantics for this operation.\n",
      "        >\n",
      "        > - If an out of bound index is found, the index is ignored.\n",
      "        > - The order in which updates are applied is nondeterministic, so the output\n",
      "        >   will be nondeterministic if `indices` contains duplicates.\n",
      "        \n",
      "        This operation is very similar to `tf.scatter_nd`, except that the updates are\n",
      "        scattered onto an existing tensor (as opposed to a zero-tensor). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        In general:\n",
      "        \n",
      "        * `indices` is an integer tensor - the indices to update in `tensor`.\n",
      "        * `indices` has **at least two** axes, the last axis is the depth of the\n",
      "          index vectors.\n",
      "        * For each index vector in `indices` there is a corresponding entry in\n",
      "          `updates`.\n",
      "        * If the length of the index vectors matches the rank of the `tensor`, then\n",
      "          the index vectors each point to scalars in `tensor` and each update is a\n",
      "          scalar.\n",
      "        * If the length of the index vectors is less than the rank of `tensor`, then\n",
      "          the index vectors each point to the slices of `tensor` and shape of the updates\n",
      "          must match that slice.\n",
      "        \n",
      "        Overall this leads to the following shape constraints:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Typical usage is often much simpler than this general form, and it\n",
      "        can be better understood starting with simple examples:\n",
      "        \n",
      "        ### Scalar updates\n",
      "        \n",
      "        The simplest usage inserts scalar elements into a tensor by index.\n",
      "        In this case, the `index_depth` must equal the rank of the\n",
      "        input `tensor`, slice each column of `indices` is an index into an axis of the\n",
      "        input `tensor`.\n",
      "        \n",
      "        In this simplest case the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        assert updates.shape == [num_updates]\n",
      "        assert index_depth == tf.rank(tensor)`\n",
      "        ```\n",
      "        \n",
      "        For example, to insert 4 scattered elements in a rank-1 tensor with\n",
      "        8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\"\n",
      "          src=\"https://www.tensorflow.org/images/ScatterNd1.png\">\n",
      "        </div>\n",
      "        \n",
      "        This scatter operation would look like this:\n",
      "        \n",
      "        >>> tensor = [0, 0, 0, 0, 0, 0, 0, 0]    # tf.rank(tensor) == 1\n",
      "        >>> indices = [[1], [3], [4], [7]]       # num_updates == 4, index_depth == 1\n",
      "        >>> updates = [9, 10, 11, 12]            # num_updates == 4\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor([ 0 9  0 10  11  0  0 12], shape=(8,), dtype=int32)\n",
      "        \n",
      "        The length (first axis) of `updates` must equal the length of the `indices`:\n",
      "        `num_updates`. This is the number of updates being inserted. Each scalar\n",
      "        update is inserted into `tensor` at the indexed location.\n",
      "        \n",
      "        For a higher rank input `tensor` scalar updates can be inserted by using an\n",
      "        `index_depth` that matches `tf.rank(tensor)`:\n",
      "        \n",
      "        >>> tensor = [[1, 1], [1, 1], [1, 1]]    # tf.rank(tensor) == 2\n",
      "        >>> indices = [[0, 1], [2, 0]]           # num_updates == 2, index_depth == 2\n",
      "        >>> updates = [5, 10]                    # num_updates == 2\n",
      "        >>> print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
      "        tf.Tensor(\n",
      "            [[ 1  5]\n",
      "             [ 1  1]\n",
      "             [10  1]], shape=(3, 2), dtype=int32)\n",
      "        \n",
      "        ### Slice updates\n",
      "        \n",
      "        When the input `tensor` has more than one axis scatter can be used to update\n",
      "        entire slices.\n",
      "        \n",
      "        In this case it's helpful to think of the input `tensor` as being a two level\n",
      "        array-of-arrays. The shape of this two level array is split into the\n",
      "        `outer_shape` and the `inner_shape`.\n",
      "        \n",
      "        `indices` indexes into the outer level of the input tensor (`outer_shape`).\n",
      "        and replaces the sub-array at that location with the corresponding item from\n",
      "        the `updates` list. The shape of each update is `inner_shape`.\n",
      "        \n",
      "        When updating a list of slices the shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        num_updates, index_depth = indices.shape.as_list()\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == [num_updates, inner_shape]\n",
      "        ```\n",
      "        \n",
      "        For example, to update rows of a `(6, 3)` `tensor`:\n",
      "        \n",
      "        >>> tensor = tf.zeros([6, 3], dtype=tf.int32)\n",
      "        \n",
      "        Use an index depth of one.\n",
      "        \n",
      "        >>> indices = tf.constant([[2], [4]])     # num_updates == 2, index_depth == 1\n",
      "        >>> num_updates, index_depth = indices.shape.as_list()\n",
      "        \n",
      "        The `outer_shape` is `6`, the inner shape is `3`:\n",
      "        \n",
      "        >>> outer_shape = tensor.shape[:index_depth]\n",
      "        >>> inner_shape = tensor.shape[index_depth:]\n",
      "        \n",
      "        2 rows are being indexed so 2 `updates` must be supplied.\n",
      "        Each update must be shaped to match the `inner_shape`.\n",
      "        \n",
      "        >>> # num_updates == 2, inner_shape==3\n",
      "        >>> updates = tf.constant([[1, 2, 3],\n",
      "        ...                        [4, 5, 6]])\n",
      "        \n",
      "        Altogether this gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 0, 0],\n",
      "               [1, 2, 3],\n",
      "               [0, 0, 0],\n",
      "               [4, 5, 6],\n",
      "               [0, 0, 0]], dtype=int32)\n",
      "        \n",
      "        #### More slice update examples\n",
      "        \n",
      "        A tensor representing a batch of uniformly sized video clips naturally has 5\n",
      "        axes: `[batch_size, time, width, height, channels]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> batch_size, time, width, height, channels = 13,11,7,5,3\n",
      "        >>> video_batch = tf.zeros([batch_size, time, width, height, channels])\n",
      "        \n",
      "        To replace a selection of video clips:\n",
      "          * Use an `index_depth` of 1 (indexing the `outer_shape`: `[batch_size]`)\n",
      "          * Provide updates each with a shape matching the `inner_shape`:\n",
      "            `[time, width, height, channels]`.\n",
      "        \n",
      "        To replace the first two clips with ones:\n",
      "        \n",
      "        >>> indices = [[0],[1]]\n",
      "        >>> new_clips = tf.ones([2, time, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_clips)\n",
      "        \n",
      "        To replace a selection of frames in the videos:\n",
      "        \n",
      "        * `indices` must have an `index_depth` of 2 for the `outer_shape`:\n",
      "          `[batch_size, time]`.\n",
      "        * `updates` must be shaped like a list of images.  Each update must have a\n",
      "          shape, matching the `inner_shape`: `[width, height, channels]`.\n",
      "        \n",
      "        To replace the first frame of the first three video clips:\n",
      "        \n",
      "        >>> indices = [[0, 0], [1, 0], [2, 0]] # num_updates=3, index_depth=2\n",
      "        >>> new_images = tf.ones([\n",
      "        ...   # num_updates=3, inner_shape=(width, height, channels)\n",
      "        ...   3, width, height, channels])\n",
      "        >>> tf.tensor_scatter_nd_update(video_batch, indices, new_images)\n",
      "        \n",
      "        ### Folded indices\n",
      "        \n",
      "        In simple cases it's convenient to think of `indices` and `updates` as\n",
      "        lists, but this is not a strict requirement. Instead of a flat `num_updates`,\n",
      "        the `indices` and `updates` can be folded into a `batch_shape`. This\n",
      "        `batch_shape` is all axes of the `indices`, except for the innermost\n",
      "        `index_depth` axis.\n",
      "        \n",
      "        ```\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        ```\n",
      "        \n",
      "        Note: The one exception is that the `batch_shape` cannot be `[]`. You can't\n",
      "        update a single index by passing indices with shape `[index_depth]`.\n",
      "        \n",
      "        `updates` must have a matching `batch_shape` (the axes before `inner_shape`).\n",
      "        \n",
      "        ```\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        Note: The result is equivalent to flattening the `batch_shape` axes of\n",
      "        `indices` and `updates`. This generalization just avoids the need\n",
      "        for reshapes when it is more natural to construct \"folded\" indices and\n",
      "        updates.\n",
      "        \n",
      "        With this generalization the full shape constraints are:\n",
      "        \n",
      "        ```\n",
      "        assert tf.rank(indices) >= 2\n",
      "        index_depth = indices.shape[-1]\n",
      "        batch_shape = indices.shape[:-1]\n",
      "        assert index_depth <= tf.rank(tensor)\n",
      "        outer_shape = tensor.shape[:index_depth]\n",
      "        inner_shape = tensor.shape[index_depth:]\n",
      "        assert updates.shape == batch_shape + inner_shape\n",
      "        ```\n",
      "        \n",
      "        For example, to draw an `X` on a `(5,5)` matrix start with these indices:\n",
      "        \n",
      "        >>> tensor = tf.zeros([5,5])\n",
      "        >>> indices = tf.constant([\n",
      "        ...  [[0,0],\n",
      "        ...   [1,1],\n",
      "        ...   [2,2],\n",
      "        ...   [3,3],\n",
      "        ...   [4,4]],\n",
      "        ...  [[0,4],\n",
      "        ...   [1,3],\n",
      "        ...   [2,2],\n",
      "        ...   [3,1],\n",
      "        ...   [4,0]],\n",
      "        ... ])\n",
      "        >>> indices.shape.as_list()  # batch_shape == [2, 5], index_depth == 2\n",
      "        [2, 5, 2]\n",
      "        \n",
      "        Here the `indices` do not have a shape of `[num_updates, index_depth]`, but a\n",
      "        shape of `batch_shape+[index_depth]`.\n",
      "        \n",
      "        Since the `index_depth` is equal to the rank of `tensor`:\n",
      "        \n",
      "        * `outer_shape` is `(5,5)`\n",
      "        * `inner_shape` is `()` - each update is scalar\n",
      "        * `updates.shape` is `batch_shape + inner_shape == (5,2) + ()`\n",
      "        \n",
      "        >>> updates = [\n",
      "        ...   [1,1,1,1,1],\n",
      "        ...   [1,1,1,1,1],\n",
      "        ... ]\n",
      "        \n",
      "        Putting this together gives:\n",
      "        \n",
      "        >>> tf.tensor_scatter_nd_update(tensor, indices, updates).numpy()\n",
      "        array([[1., 0., 0., 0., 1.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [0., 0., 1., 0., 0.],\n",
      "               [0., 1., 0., 1., 0.],\n",
      "               [1., 0., 0., 0., 1.]], dtype=float32)\n",
      "        \n",
      "        Args:\n",
      "          tensor: Tensor to copy/update.\n",
      "          indices: Indices to update.\n",
      "          updates: Updates to apply at the indices.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A new tensor with the given shape and updates applied according to the\n",
      "          indices.\n",
      "    \n",
      "    tensordot(a, b, axes, name=None)\n",
      "        Tensor contraction of a and b along specified axes and outer product.\n",
      "        \n",
      "        Tensordot (also known as tensor contraction) sums the product of elements\n",
      "        from `a` and `b` over the indices specified by `axes`.\n",
      "        \n",
      "        This operation corresponds to `numpy.tensordot(a, b, axes)`.\n",
      "        \n",
      "        Example 1: When `a` and `b` are matrices (order 2), the case `axes=1`\n",
      "        is equivalent to matrix multiplication.\n",
      "        \n",
      "        Example 2: When `a` and `b` are matrices (order 2), the case\n",
      "        `axes = [[1], [0]]` is equivalent to matrix multiplication.\n",
      "        \n",
      "        Example 3: When `a` and `b` are matrices (order 2), the case `axes=0` gives\n",
      "        the outer product, a tensor of order 4.\n",
      "        \n",
      "        Example 4: Suppose that \\\\(a_{ijk}\\\\) and \\\\(b_{lmn}\\\\) represent two\n",
      "        tensors of order 3. Then, `contract(a, b, [[0], [2]])` is the order 4 tensor\n",
      "        \\\\(c_{jklm}\\\\) whose entry\n",
      "        corresponding to the indices \\\\((j,k,l,m)\\\\) is given by:\n",
      "        \n",
      "        \\\\( c_{jklm} = \\sum_i a_{ijk} b_{lmi} \\\\).\n",
      "        \n",
      "        In general, `order(c) = order(a) + order(b) - 2*len(axes[0])`.\n",
      "        \n",
      "        Args:\n",
      "          a: `Tensor` of type `float32` or `float64`.\n",
      "          b: `Tensor` with the same type as `a`.\n",
      "          axes: Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k].\n",
      "            If axes is a scalar, sum over the last N axes of a and the first N axes of\n",
      "            b in order. If axes is a list or `Tensor` the first and second row contain\n",
      "            the set of unique integers specifying axes along which the contraction is\n",
      "            computed, for `a` and `b`, respectively. The number of axes for `a` and\n",
      "            `b` must be equal. If `axes=0`, computes the outer product between `a` and\n",
      "            `b`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same type as `a`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the shapes of `a`, `b`, and `axes` are incompatible.\n",
      "          IndexError: If the values in axes exceed the rank of the corresponding\n",
      "            tensor.\n",
      "    \n",
      "    tile(input: Annotated[Any, ~TV_Tile_T], multiples: Annotated[Any, ~TV_Tile_Tmultiples], name=None) -> Annotated[Any, ~TV_Tile_T]\n",
      "        Constructs a tensor by tiling a given tensor.\n",
      "        \n",
      "        This operation creates a new tensor by replicating `input` `multiples` times.\n",
      "        The output tensor's i'th dimension has `input.dims(i) * multiples[i]` elements,\n",
      "        and the values of `input` are replicated `multiples[i]` times along the 'i'th\n",
      "        dimension. For example, tiling `[a b c d]` by `[2]` produces\n",
      "        `[a b c d a b c d]`.\n",
      "        \n",
      "        >>> a = tf.constant([[1,2,3],[4,5,6]], tf.int32)\n",
      "        >>> b = tf.constant([1,2], tf.int32)\n",
      "        >>> tf.tile(a, b)\n",
      "        <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
      "        array([[1, 2, 3, 1, 2, 3],\n",
      "               [4, 5, 6, 4, 5, 6]], dtype=int32)>\n",
      "        >>> c = tf.constant([2,1], tf.int32)\n",
      "        >>> tf.tile(a, c)\n",
      "        <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
      "        array([[1, 2, 3],\n",
      "               [4, 5, 6],\n",
      "               [1, 2, 3],\n",
      "               [4, 5, 6]], dtype=int32)>\n",
      "        >>> d = tf.constant([2,2], tf.int32)\n",
      "        >>> tf.tile(a, d)\n",
      "        <tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
      "        array([[1, 2, 3, 1, 2, 3],\n",
      "               [4, 5, 6, 4, 5, 6],\n",
      "               [1, 2, 3, 1, 2, 3],\n",
      "               [4, 5, 6, 4, 5, 6]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Can be of any rank.\n",
      "          multiples: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. Length must be the same as the number of dimensions in `input`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    timestamp(name=None) -> Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.Float64'>]\n",
      "        Provides the time since epoch in seconds.\n",
      "        \n",
      "        Returns the timestamp as a `float64` for seconds since the Unix epoch.\n",
      "        \n",
      "        Common usages include:\n",
      "        * Logging\n",
      "        * Providing a random number seed\n",
      "        * Debugging graph execution\n",
      "        * Generating timing information, mainly through comparison of timestamps\n",
      "        \n",
      "        Note: In graph mode, the timestamp is computed when the op is executed,\n",
      "        not when it is added to the graph.  In eager mode, the timestamp is computed\n",
      "        when the op is eagerly executed.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float64`.\n",
      "    \n",
      "    to_bfloat16(x, name='ToBFloat16')\n",
      "        Casts a tensor to type `bfloat16`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `bfloat16`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `bfloat16`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.bfloat16)`. There are no further issues with eager execution\n",
      "        or tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_bfloat16(tf.constant(3.14, dtype=tf.float32))\n",
      "        <tf.Tensor: shape=(), dtype=bfloat16, numpy=3.14>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(3.14, dtype=tf.float32), tf.bfloat16)\n",
      "        <tf.Tensor: shape=(), dtype=bfloat16, numpy=3.14>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_complex128(x, name='ToComplex128')\n",
      "        Casts a tensor to type `complex128`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `complex128`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `complex128`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.complex128)`. There are no further issues with eager\n",
      "        execution or tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_complex128(tf.constant(1. + 2.j, dtype=tf.complex64))\n",
      "        <tf.Tensor: shape=(), dtype=complex128, numpy=(1+2j)>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(1. + 2.j, dtype=tf.complex64), tf.complex128)\n",
      "        <tf.Tensor: shape=(), dtype=complex128, numpy=(1+2j)>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_complex64(x, name='ToComplex64')\n",
      "        Casts a tensor to type `complex64`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `complex64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `complex64`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.complex64)`. There are no further issues with eager execution\n",
      "        or tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_complex64(tf.constant(1. + 2.j, dtype=tf.complex128))\n",
      "        <tf.Tensor: shape=(), dtype=complex64, numpy=(1+2j)>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(1. + 2.j, dtype=tf.complex128), tf.complex64)\n",
      "        <tf.Tensor: shape=(), dtype=complex64, numpy=(1+2j)>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_double(x, name='ToDouble')\n",
      "        Casts a tensor to type `float64`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `float64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `float64`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.double)`. There are no further issues with eager execution or\n",
      "        tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_double(tf.constant(3.14, dtype=tf.float32))\n",
      "        <tf.Tensor: shape=(), dtype=float64, numpy=3.14>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(3.14, dtype=tf.float32), tf.double)\n",
      "        <tf.Tensor: shape=(), dtype=float64, numpy=3.14>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_float(x, name='ToFloat')\n",
      "        Casts a tensor to type `float32`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `float32`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `float32`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.float32)`. There are no further issues with eager execution\n",
      "        or tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_float(tf.constant(3.14, dtype=tf.double))\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=3.14>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(3.14, dtype=tf.double), tf.float32)\n",
      "        <tf.Tensor: shape=(), dtype=float32, numpy=3.14>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_int32(x, name='ToInt32')\n",
      "        Casts a tensor to type `int32`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `int32`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `int32`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.int32)`. There are no further issues with eager execution or\n",
      "        tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_int32(tf.constant(1, dtype=tf.int64))\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(1, dtype=tf.int64), tf.int32)\n",
      "        <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    to_int64(x, name='ToInt64')\n",
      "        Casts a tensor to type `int64`. (deprecated)\n",
      "        \n",
      "        Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `int64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `int64`.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This name was deprecated and removed in TF2, but has an exact replacement\n",
      "        `tf.cast(..., tf.int64)`. There are no further issues with eager execution or\n",
      "        tf.function.\n",
      "        \n",
      "        Before:\n",
      "        \n",
      "        >>> tf.compat.v1.to_int64(tf.constant(1, dtype=tf.int32))\n",
      "        <tf.Tensor: shape=(), dtype=int64, numpy=1>\n",
      "        \n",
      "        After:\n",
      "        \n",
      "        >>> tf.cast(tf.constant(1, dtype=tf.int32), tf.int64)\n",
      "        <tf.Tensor: shape=(), dtype=int64, numpy=1>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    trace(x, name=None)\n",
      "        Compute the trace of a tensor `x`.\n",
      "        \n",
      "        `trace(x)` returns the sum along the main diagonal of each inner-most matrix\n",
      "        in x. If x is of rank `k` with shape `[I, J, K, ..., L, M, N]`, then output\n",
      "        is a tensor of rank `k-2` with dimensions `[I, J, K, ..., L]` where\n",
      "        \n",
      "        `output[i, j, k, ..., l] = trace(x[i, j, k, ..., l, :, :])`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2], [3, 4]])\n",
      "        tf.linalg.trace(x)  # 5\n",
      "        \n",
      "        x = tf.constant([[1, 2, 3],\n",
      "                         [4, 5, 6],\n",
      "                         [7, 8, 9]])\n",
      "        tf.linalg.trace(x)  # 15\n",
      "        \n",
      "        x = tf.constant([[[1, 2, 3],\n",
      "                          [4, 5, 6],\n",
      "                          [7, 8, 9]],\n",
      "                         [[-1, -2, -3],\n",
      "                          [-4, -5, -6],\n",
      "                          [-7, -8, -9]]])\n",
      "        tf.linalg.trace(x)  # [15, -15]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The trace of input tensor.\n",
      "    \n",
      "    trainable_variables(scope=None)\n",
      "        Returns all variables created with `trainable=True`.\n",
      "        \n",
      "        When passed `trainable=True`, the `Variable()` constructor automatically\n",
      "        adds new variables to the graph collection\n",
      "        `GraphKeys.TRAINABLE_VARIABLES`. This convenience function returns the\n",
      "        contents of that collection.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        Not compatible with eager execution and `tf.function`. In particular, Graph\n",
      "        collections are deprecated in TF2. Instead please create a `tf.Module`\n",
      "        container for all your model state, including variables.\n",
      "        You can then list all the trainable variables in your `tf.Module` through the\n",
      "        `trainable_variables` attribute.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variable objects.\n",
      "    \n",
      "    transpose(a, perm=None, name='transpose', conjugate=False)\n",
      "        Transposes `a`.\n",
      "        \n",
      "        Permutes the dimensions according to `perm`.\n",
      "        \n",
      "        The returned tensor's dimension i will correspond to the input dimension\n",
      "        `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is\n",
      "        the rank of the input tensor. Hence, by default, this operation performs a\n",
      "        regular matrix transpose on 2-D input Tensors. If conjugate is True and\n",
      "        `a.dtype` is either `complex64` or `complex128` then the values of `a`\n",
      "        are conjugated and transposed.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        In `numpy` transposes are memory-efficient constant time operations as they\n",
      "        simply return a new view of the same data with adjusted `strides`.\n",
      "        \n",
      "        TensorFlow does not support strides, so `transpose` returns a new tensor with\n",
      "        the items permuted.\n",
      "        @end_compatibility\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.transpose(x)  # [[1, 4]\n",
      "                         #  [2, 5]\n",
      "                         #  [3, 6]]\n",
      "        \n",
      "        # Equivalently\n",
      "        tf.transpose(x, perm=[1, 0])  # [[1, 4]\n",
      "                                      #  [2, 5]\n",
      "                                      #  [3, 6]]\n",
      "        \n",
      "        # If x is complex, setting conjugate=True gives the conjugate transpose\n",
      "        x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "                         [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "        tf.transpose(x, conjugate=True)  # [[1 - 1j, 4 - 4j],\n",
      "                                         #  [2 - 2j, 5 - 5j],\n",
      "                                         #  [3 - 3j, 6 - 6j]]\n",
      "        \n",
      "        # 'perm' is more useful for n-dimensional tensors, for n > 2\n",
      "        x = tf.constant([[[ 1,  2,  3],\n",
      "                          [ 4,  5,  6]],\n",
      "                         [[ 7,  8,  9],\n",
      "                          [10, 11, 12]]])\n",
      "        \n",
      "        # Take the transpose of the matrices in dimension-0\n",
      "        # (this common operation has a shorthand `linalg.matrix_transpose`)\n",
      "        tf.transpose(x, perm=[0, 2, 1])  # [[[1,  4],\n",
      "                                         #   [2,  5],\n",
      "                                         #   [3,  6]],\n",
      "                                         #  [[7, 10],\n",
      "                                         #   [8, 11],\n",
      "                                         #   [9, 12]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`.\n",
      "          perm: A permutation of the dimensions of `a`.\n",
      "          name: A name for the operation (optional).\n",
      "          conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "            to tf.math.conj(tf.transpose(input)).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed `Tensor`.\n",
      "    \n",
      "    truediv(x, y, name=None)\n",
      "        Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "        \n",
      "        NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "        division operator semantics.\n",
      "        \n",
      "        This function forces Python 3 division operator semantics where all integer\n",
      "        arguments are cast to floating types first.   This op is generated by normal\n",
      "        `x / y` division in Python 3 and in Python 2.7 with\n",
      "        `from __future__ import division`.  If you want integer division that rounds\n",
      "        down, use `x // y` or `tf.math.floordiv`.\n",
      "        \n",
      "        `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "        point, the output will have the same type.  If the inputs are integral, the\n",
      "        inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "        and `int64` (matching the behavior of Numpy).\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of numeric type.\n",
      "          y: `Tensor` denominator of numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` evaluated in floating point.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` and `y` have different dtypes.\n",
      "    \n",
      "    truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a truncated normal distribution.\n",
      "        \n",
      "        The values are drawn from a normal distribution with specified mean and\n",
      "        standard deviation, discarding and re-drawing any samples that are more than\n",
      "        two standard deviations from the mean.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        >>> tf.random.truncated_normal(shape=[2])\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([..., ...], dtype=float32)>\n",
      "        \n",
      "        >>> tf.random.truncated_normal(shape=[2], mean=3, stddev=1, dtype=tf.float32)\n",
      "        <tf.Tensor: shape=(2,), dtype=float32, numpy=array([..., ...], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          mean: A 0-D Tensor or Python value of type `dtype`. The mean of the\n",
      "            truncated normal distribution.\n",
      "          stddev: A 0-D Tensor or Python value of type `dtype`. The standard deviation\n",
      "            of the normal distribution, before truncation.\n",
      "          dtype: The type of the output. Restricted to floating-point types:\n",
      "            `tf.half`, `tf.float`, `tf.double`, etc.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See `tf.random.set_seed` for more information.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random truncated normal values.\n",
      "    \n",
      "    truncatediv = truncate_div(x: typing.Annotated[_any, ~TV_TruncateDiv_T], y: typing.Annotated[_any, ~TV_TruncateDiv_T], name=None) -> typing.Annotated[_any, ~TV_TruncateDiv_T]\n",
      "        Returns x / y element-wise, rounded towards zero.\n",
      "        \n",
      "        Truncation designates that negative numbers will round fractional quantities\n",
      "        toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different\n",
      "        than Python semantics. See `FloorDiv` for a division function that matches\n",
      "        Python Semantics.\n",
      "        \n",
      "        *NOTE*: `truncatediv` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    truncatemod = truncate_mod(x: typing.Annotated[_any, ~TV_TruncateMod_T], y: typing.Annotated[_any, ~TV_TruncateMod_T], name=None) -> typing.Annotated[_any, ~TV_TruncateMod_T]\n",
      "        Returns element-wise remainder of division. This emulates C semantics in that\n",
      "        \n",
      "        the result here is consistent with a truncating divide. E.g. `truncate(x / y) *\n",
      "        y + truncate_mod(x, y) = x`.\n",
      "        \n",
      "        *NOTE*: `truncatemod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    tuple(tensors, name=None, control_inputs=None)\n",
      "        Group tensors together.\n",
      "        \n",
      "        This creates a tuple of tensors with the same values as the `tensors`\n",
      "        argument, except that the value of each tensor is only returned after the\n",
      "        values of all tensors have been computed.\n",
      "        \n",
      "        `control_inputs` contains additional ops that have to finish before this op\n",
      "        finishes, but whose outputs are not returned.\n",
      "        \n",
      "        This can be used as a \"join\" mechanism for parallel computations: all the\n",
      "        argument tensors can be computed in parallel, but the values of any tensor\n",
      "        returned by `tuple` are only available after all the parallel computations\n",
      "        are done.\n",
      "        \n",
      "        See also `tf.group` and\n",
      "        `tf.control_dependencies`.\n",
      "        \n",
      "        Args:\n",
      "          tensors: A list of `Tensor`s or `IndexedSlices`, some entries can be `None`.\n",
      "          name: (optional) A name to use as a `name_scope` for the operation.\n",
      "          control_inputs: List of additional ops to finish before returning.\n",
      "        \n",
      "        Returns:\n",
      "          Same as `tensors`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `tensors` does not contain any `Tensor` or `IndexedSlices`.\n",
      "          TypeError: If `control_inputs` is not a list of `Operation` or `Tensor`\n",
      "            objects.\n",
      "    \n",
      "    type_spec_from_value(value) -> tensorflow.python.framework.type_spec.TypeSpec\n",
      "        Returns a `tf.TypeSpec` that represents the given `value`.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> tf.type_spec_from_value(tf.constant([1, 2, 3]))\n",
      "          TensorSpec(shape=(3,), dtype=tf.int32, name=None)\n",
      "          >>> tf.type_spec_from_value(np.array([4.0, 5.0], np.float64))\n",
      "          TensorSpec(shape=(2,), dtype=tf.float64, name=None)\n",
      "          >>> tf.type_spec_from_value(tf.ragged.constant([[1, 2], [3, 4, 5]]))\n",
      "          RaggedTensorSpec(TensorShape([2, None]), tf.int32, 1, tf.int64)\n",
      "        \n",
      "          >>> example_input = tf.ragged.constant([[1, 2], [3]])\n",
      "          >>> @tf.function(input_signature=[tf.type_spec_from_value(example_input)])\n",
      "          ... def f(x):\n",
      "          ...   return tf.reduce_sum(x, axis=1)\n",
      "        \n",
      "        Args:\n",
      "          value: A value that can be accepted or returned by TensorFlow APIs. Accepted\n",
      "            types for `value` include `tf.Tensor`, any value that can be converted to\n",
      "            `tf.Tensor` using `tf.convert_to_tensor`, and any subclass of\n",
      "            `CompositeTensor` (such as `tf.RaggedTensor`).\n",
      "        \n",
      "        Returns:\n",
      "          A `TypeSpec` that is compatible with `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If a TypeSpec cannot be built for `value`, because its type\n",
      "            is not supported.\n",
      "    \n",
      "    unique(x, out_idx=tf.int32, name=None)\n",
      "        Finds unique elements in a 1-D tensor.\n",
      "        \n",
      "        This operation returns a tensor `y` containing all of the unique elements of `x`\n",
      "        sorted in the same order that they occur in `x`; `x` does not need to be sorted.\n",
      "        This operation also returns a tensor `idx` the same size as `x` that contains\n",
      "        the index of each value of `x` in the unique output `y`. In other words:\n",
      "        \n",
      "        `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```\n",
      "        # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
      "        y, idx = unique(x)\n",
      "        y ==> [1, 2, 4, 7, 8]\n",
      "        idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]\n",
      "        ```\n",
      "        \n",
      "        ```\n",
      "        # tensor 'x' is [4, 5, 1, 2, 3, 3, 4, 5]\n",
      "        y, idx = unique(x)\n",
      "        y ==> [4, 5, 1, 2, 3]\n",
      "        idx ==> [0, 1, 2, 3, 4, 4, 0, 1]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (y, idx).\n",
      "        \n",
      "          y: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    unique_with_counts(x, out_idx=tf.int32, name=None)\n",
      "        Finds unique elements in a 1-D tensor.\n",
      "        \n",
      "        This operation returns a tensor `y` containing all of the unique elements of `x`\n",
      "        sorted in the same order that they occur in `x`. This operation also returns a\n",
      "        tensor `idx` the same size as `x` that contains the index of each value of `x`\n",
      "        in the unique output `y`. Finally, it returns a third tensor `count` that\n",
      "        contains the count of each element of `y` in `x`. In other words:\n",
      "        \n",
      "        `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
      "        y, idx, count = unique_with_counts(x)\n",
      "        y ==> [1, 2, 4, 7, 8]\n",
      "        idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]\n",
      "        count ==> [2, 1, 3, 1, 2]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (y, idx, count).\n",
      "        \n",
      "          y: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "          count: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    unravel_index(indices: Annotated[Any, ~TV_UnravelIndex_Tidx], dims: Annotated[Any, ~TV_UnravelIndex_Tidx], name=None) -> Annotated[Any, ~TV_UnravelIndex_Tidx]\n",
      "        Converts an array of flat indices into a tuple of coordinate arrays.\n",
      "        \n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```\n",
      "        y = tf.unravel_index(indices=[2, 5, 7], dims=[3, 3])\n",
      "        # 'dims' represent a hypothetical (3, 3) tensor of indices:\n",
      "        # [[0, 1, *2*],\n",
      "        #  [3, 4, *5*],\n",
      "        #  [6, *7*, 8]]\n",
      "        # For each entry from 'indices', this operation returns\n",
      "        # its coordinates (marked with '*'), such as\n",
      "        # 2 ==> (0, 2)\n",
      "        # 5 ==> (1, 2)\n",
      "        # 7 ==> (2, 1)\n",
      "        y ==> [[0, 1, 2], [2, 2, 1]]\n",
      "        ```\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.unravel_index\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            An 0-D or 1-D `int` Tensor whose elements are indices into the\n",
      "            flattened version of an array of dimensions dims.\n",
      "          dims: A `Tensor`. Must have the same type as `indices`.\n",
      "            An 1-D `int` Tensor. The shape of the array to use for unraveling\n",
      "            indices.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `indices`.\n",
      "    \n",
      "    unsorted_segment_max(data: typing.Annotated[_any, ~TV_UnsortedSegmentMax_T], segment_ids: typing.Annotated[_any, ~TV_UnsortedSegmentMax_Tindices], num_segments: typing.Annotated[_any, ~TV_UnsortedSegmentMax_Tnumsegments], name=None) -> typing.Annotated[_any, ~TV_UnsortedSegmentMax_T]\n",
      "        Computes the maximum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to `tf.math.unsorted_segment_sum`,\n",
      "        Instead of computing the sum over segments, it computes the maximum such that:\n",
      "        \n",
      "        \\\\(output_i = \\max_{j...} data[j...]\\\\) where max is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.\n",
      "        \n",
      "        If the maximum is empty for a given segment ID `i`, it outputs the smallest\n",
      "        possible value for the specific numeric type,\n",
      "        `output[i] = numeric_limits<T>::lowest()`.\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/UnsortedSegmentMax.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        >>> tf.math.unsorted_segment_max(c, tf.constant([0, 1, 0]), num_segments=2).numpy()\n",
      "        array([[4, 3, 3, 4],\n",
      "               [5,  6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "        \n",
      "            Caution: The values are always validated to be in range on CPU, never validated\n",
      "            on GPU.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_mean(data, segment_ids, num_segments, name=None)\n",
      "        Computes the mean along segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the `tf.math.unsorted_segment_sum` operator.\n",
      "        Instead of computing the sum over segments, it computes the mean of all\n",
      "        entries belonging to a segment such that:\n",
      "        \n",
      "        \\\\(output_i = 1/N_i \\sum_{j...} data[j...]\\\\) where the sum is over tuples\n",
      "        `j...` such that `segment_ids[j...] == i` with \\\\N_i\\\\ being the number of\n",
      "        occurrences of id \\\\i\\\\.\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 0.\n",
      "        \n",
      "        If the given segment ID `i` is negative, the value is dropped and will not\n",
      "        be added to the sum of the segment.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with floating point or complex dtype.\n",
      "          segment_ids: An integer tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "            The values are always validated to be in range on CPU,\n",
      "            never validated on GPU.\n",
      "          num_segments: An integer scalar `Tensor`.  The number of distinct segment\n",
      "            IDs.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.  Has same shape as data, except for the first `segment_ids.rank`\n",
      "          dimensions, which are replaced with a single dimension which has size\n",
      "         `num_segments`.\n",
      "    \n",
      "    unsorted_segment_min(data: typing.Annotated[_any, ~TV_UnsortedSegmentMin_T], segment_ids: typing.Annotated[_any, ~TV_UnsortedSegmentMin_Tindices], num_segments: typing.Annotated[_any, ~TV_UnsortedSegmentMin_Tnumsegments], name=None) -> typing.Annotated[_any, ~TV_UnsortedSegmentMin_T]\n",
      "        Computes the minimum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to `tf.math.unsorted_segment_sum`,\n",
      "        Instead of computing the sum over segments, it computes the minimum such that:\n",
      "        \n",
      "        \\\\(output_i = \\min_{j...} data_[j...]\\\\) where min is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.\n",
      "        \n",
      "        If the minimum is empty for a given segment ID `i`, it outputs the largest\n",
      "        possible value for the specific numeric type,\n",
      "        `output[i] = numeric_limits<T>::max()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        >>> tf.math.unsorted_segment_min(c, tf.constant([0, 1, 0]), num_segments=2).numpy()\n",
      "        array([[1, 2, 2, 1],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "        \n",
      "            Caution: The values are always validated to be in range on CPU, never validated\n",
      "            on GPU.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_prod(data: typing.Annotated[_any, ~TV_UnsortedSegmentProd_T], segment_ids: typing.Annotated[_any, ~TV_UnsortedSegmentProd_Tindices], num_segments: typing.Annotated[_any, ~TV_UnsortedSegmentProd_Tnumsegments], name=None) -> typing.Annotated[_any, ~TV_UnsortedSegmentProd_T]\n",
      "        Computes the product along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to `tf.math.unsorted_segment_sum`,\n",
      "        Instead of computing the sum over segments, it computes the product of all\n",
      "        entries belonging to a segment such that:\n",
      "        \n",
      "        \\\\(output_i = \\prod_{j...} data[j...]\\\\) where the product is over tuples\n",
      "        `j...` such that `segment_ids[j...] == i`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        >>> c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        >>> tf.math.unsorted_segment_prod(c, tf.constant([0, 1, 0]), num_segments=2).numpy()\n",
      "        array([[4, 6, 6, 4],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 1.\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "        \n",
      "            Caution: The values are always validated to be in range on CPU, never validated\n",
      "            on GPU.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_sqrt_n(data, segment_ids, num_segments, name=None)\n",
      "        Computes the sum along segments of a tensor divided by the sqrt(N).\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the `tf.math.unsorted_segment_sum` operator.\n",
      "        Additionally to computing the sum over segments, it divides the results by\n",
      "        sqrt(N).\n",
      "        \n",
      "        \\\\(output_i = 1/sqrt(N_i) \\sum_{j...} data[j...]\\\\) where the sum is over\n",
      "        tuples `j...` such that `segment_ids[j...] == i` with \\\\N_i\\\\ being the\n",
      "        number of occurrences of id \\\\i\\\\.\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 0.\n",
      "        \n",
      "        Note that this op only supports floating point and complex dtypes,\n",
      "        due to tf.sqrt only supporting these types.\n",
      "        \n",
      "        If the given segment ID `i` is negative, the value is dropped and will not\n",
      "        be added to the sum of the segment.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with floating point or complex dtype.\n",
      "          segment_ids: An integer tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be in the range `[0, num_segments)`.\n",
      "            The values are always validated to be in range on CPU,\n",
      "            never validated on GPU.\n",
      "          num_segments: An integer scalar `Tensor`.  The number of distinct segment\n",
      "            IDs.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.  Has same shape as data, except for the first `segment_ids.rank`\n",
      "          dimensions, which are replaced with a single dimension which has size\n",
      "         `num_segments`.\n",
      "    \n",
      "    unsorted_segment_sum(data: typing.Annotated[_any, ~TV_UnsortedSegmentSum_T], segment_ids: typing.Annotated[_any, ~TV_UnsortedSegmentSum_Tindices], num_segments: typing.Annotated[_any, ~TV_UnsortedSegmentSum_Tnumsegments], name=None) -> typing.Annotated[_any, ~TV_UnsortedSegmentSum_T]\n",
      "        Computes the sum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output[i] = \\sum_{j...} data[j...]\\\\) where the sum is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.  Unlike `SegmentSum`, `segment_ids`\n",
      "        need not be sorted and need not cover all values in the full\n",
      "        range of valid values.\n",
      "        \n",
      "        If the sum is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        If the given segment ID `i` is negative, the value is dropped and will not be\n",
      "        added to the sum of the segment.\n",
      "        \n",
      "        `num_segments` should equal the number of distinct segment IDs.\n",
      "        \n",
      "        Caution: On CPU, values in `segment_ids` are always validated to be less than\n",
      "        `num_segments`, and an error is thrown for out-of-bound indices. On GPU, this\n",
      "        does not throw an error for out-of-bound indices. On Gpu, out-of-bound indices\n",
      "        result in safe but unspecified behavior, which may include ignoring\n",
      "        out-of-bound indices or outputting a tensor with a 0 stored in the first\n",
      "        dimension of its shape if `num_segments` is 0.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/UnsortedSegmentSum.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        >>> c = [[1,2,3,4], [5,6,7,8], [4,3,2,1]]\n",
      "        >>> tf.math.unsorted_segment_sum(c, [0, 1, 0], num_segments=2).numpy()\n",
      "        array([[5, 5, 5, 5],\n",
      "               [5, 6, 7, 8]], dtype=int32)\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `qint16`, `quint16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int16`, `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "            The values must be less than `num_segments`.\n",
      "        \n",
      "            Caution: The values are always validated to be in range on CPU, never validated\n",
      "            on GPU.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unstack(value, num=None, axis=0, name='unstack')\n",
      "        Unpacks the given dimension of a rank-`R` tensor into rank-`(R-1)` tensors.\n",
      "        \n",
      "        Unpacks tensors from `value` by chipping it along the `axis` dimension.\n",
      "        \n",
      "        >>> x = tf.reshape(tf.range(12), (3,4))\n",
      "        >>>\n",
      "        >>> p, q, r = tf.unstack(x)\n",
      "        >>> p.shape.as_list()\n",
      "        [4]\n",
      "        \n",
      "        >>> i, j, k, l = tf.unstack(x, axis=1)\n",
      "        >>> i.shape.as_list()\n",
      "        [3]\n",
      "        \n",
      "        This is the opposite of stack.\n",
      "        \n",
      "        >>> x = tf.stack([i, j, k, l], axis=1)\n",
      "        \n",
      "        More generally if you have a tensor of shape `(A, B, C, D)`:\n",
      "        \n",
      "        >>> A, B, C, D = [2, 3, 4, 5]\n",
      "        >>> t = tf.random.normal(shape=[A, B, C, D])\n",
      "        \n",
      "        The number of tensor returned is equal to the length of the target `axis`:\n",
      "        \n",
      "        >>> axis = 2\n",
      "        >>> items = tf.unstack(t, axis=axis)\n",
      "        >>> len(items) == t.shape[axis]\n",
      "        True\n",
      "        \n",
      "        The shape of each result tensor is equal to the shape of the input tensor,\n",
      "        with the target `axis` removed.\n",
      "        \n",
      "        >>> items[0].shape.as_list()  # [A, B, D]\n",
      "        [2, 3, 5]\n",
      "        \n",
      "        The value of each tensor `items[i]` is equal to the slice of `input` across\n",
      "        `axis` at index `i`:\n",
      "        \n",
      "        >>> for i in range(len(items)):\n",
      "        ...   slice = t[:,:,i,:]\n",
      "        ...   assert tf.reduce_all(slice == items[i])\n",
      "        \n",
      "        #### Python iterable unpacking\n",
      "        \n",
      "        With eager execution you _can_ unstack the 0th axis of a tensor using python's\n",
      "        iterable unpacking:\n",
      "        \n",
      "        >>> t = tf.constant([1,2,3])\n",
      "        >>> a,b,c = t\n",
      "        \n",
      "        `unstack` is still necessary because Iterable unpacking doesn't work in\n",
      "        a `@tf.function`: Symbolic tensors are not iterable.\n",
      "        \n",
      "        You need to use `tf.unstack` here:\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def bad(t):\n",
      "        ...   a,b,c = t\n",
      "        ...   return a\n",
      "        >>>\n",
      "        >>> bad(t)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        OperatorNotAllowedInGraphError: ...\n",
      "        \n",
      "        >>> @tf.function\n",
      "        ... def good(t):\n",
      "        ...   a,b,c = tf.unstack(t)\n",
      "        ...   return a\n",
      "        >>>\n",
      "        >>> good(t).numpy()\n",
      "        1\n",
      "        \n",
      "        #### Unknown shapes\n",
      "        \n",
      "        Eager tensors have concrete values, so their shape is always known.\n",
      "        Inside a `tf.function` the symbolic tensors may have unknown shapes.\n",
      "        If the length of `axis` is unknown `tf.unstack` will fail because it cannot\n",
      "        handle an unknown number of tensors:\n",
      "        \n",
      "        >>> @tf.function(input_signature=[tf.TensorSpec([None], tf.float32)])\n",
      "        ... def bad(t):\n",
      "        ...   tensors = tf.unstack(t)\n",
      "        ...   return tensors[0]\n",
      "        >>>\n",
      "        >>> bad(tf.constant([1.0, 2.0, 3.0]))\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        ValueError: Cannot infer argument `num` from shape (None,)\n",
      "        \n",
      "        If you know the `axis` length you can pass it as the `num` argument. But this\n",
      "        must be a constant value.\n",
      "        \n",
      "        If you actually need a variable number of tensors in a single `tf.function`\n",
      "        trace, you will need to use exlicit loops and a `tf.TensorArray` instead.\n",
      "        \n",
      "        Args:\n",
      "          value: A rank `R > 0` `Tensor` to be unstacked.\n",
      "          num: An `int`. The length of the dimension `axis`. Automatically inferred if\n",
      "            `None` (the default).\n",
      "          axis: An `int`. The axis to unstack along. Defaults to the first dimension.\n",
      "            Negative values wrap around, so the valid range is `[-R, R)`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The list of `Tensor` objects unstacked from `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `axis` is out of the range `[-R, R)`.\n",
      "          ValueError: If `num` is unspecified and cannot be inferred.\n",
      "          InvalidArgumentError: If `num` does not match the shape of `value`.\n",
      "    \n",
      "    variable_axis_size_partitioner(max_shard_bytes, axis=0, bytes_per_string_element=16, max_shards=None)\n",
      "        Get a partitioner for VariableScope to keep shards below `max_shard_bytes`.\n",
      "        \n",
      "        This partitioner will shard a Variable along one axis, attempting to keep\n",
      "        the maximum shard size below `max_shard_bytes`.  In practice, this is not\n",
      "        always possible when sharding along only one axis.  When this happens,\n",
      "        this axis is sharded as much as possible (i.e., every dimension becomes\n",
      "        a separate shard).\n",
      "        \n",
      "        If the partitioner hits the `max_shards` limit, then each shard may end up\n",
      "        larger than `max_shard_bytes`. By default `max_shards` equals `None` and no\n",
      "        limit on the number of shards is enforced.\n",
      "        \n",
      "        One reasonable value for `max_shard_bytes` is `(64 << 20) - 1`, or almost\n",
      "        `64MB`, to keep below the protobuf byte limit.\n",
      "        \n",
      "        Args:\n",
      "          max_shard_bytes: The maximum size any given shard is allowed to be.\n",
      "          axis: The axis to partition along.  Default: outermost axis.\n",
      "          bytes_per_string_element: If the `Variable` is of type string, this provides\n",
      "            an estimate of how large each scalar in the `Variable` is.\n",
      "          max_shards: The maximum number of shards in int created taking precedence\n",
      "            over `max_shard_bytes`.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the byte counts are non-positive.\n",
      "    \n",
      "    variable_creator_scope = variable_creator_scope_v1(variable_creator)\n",
      "        Scope which defines a variable creation function to be used by variable().\n",
      "        \n",
      "        variable_creator is expected to be a function with the following signature:\n",
      "        \n",
      "        ```\n",
      "          def variable_creator(next_creator, **kwargs)\n",
      "        ```\n",
      "        \n",
      "        The creator is supposed to eventually call the next_creator to create a\n",
      "        variable if it does want to create a variable and not call Variable or\n",
      "        ResourceVariable directly. This helps make creators composable. A creator may\n",
      "        choose to create multiple variables, return already existing variables, or\n",
      "        simply register that a variable was created and defer to the next creators in\n",
      "        line. Creators can also modify the keyword arguments seen by the next\n",
      "        creators.\n",
      "        \n",
      "        Custom getters in the variable scope will eventually resolve down to these\n",
      "        custom creators when they do create variables.\n",
      "        \n",
      "        The valid keyword arguments in kwds are:\n",
      "        \n",
      "         * initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
      "              which is the initial value for the Variable. The initial value must have\n",
      "              a shape specified unless `validate_shape` is set to False. Can also be a\n",
      "              callable with no argument that returns the initial value when called. In\n",
      "              that case, `dtype` must be specified. (Note that initializer functions\n",
      "              from init_ops.py must first be bound to a shape before being used here.)\n",
      "         * trainable: If `True`, the default, also adds the variable to the graph\n",
      "              collection `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as\n",
      "              the default list of variables to use by the `Optimizer` classes.\n",
      "              `trainable` defaults to `True`, unless `synchronization` is\n",
      "              set to `ON_READ`, in which case it defaults to `False`.\n",
      "         * collections: List of graph collections keys. The new variable is added to\n",
      "              these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "         * validate_shape: If `False`, allows the variable to be initialized with a\n",
      "              value of unknown shape. If `True`, the default, the shape of\n",
      "              `initial_value` must be known.\n",
      "         * caching_device: Optional device string describing where the Variable\n",
      "              should be cached for reading.  Defaults to the Variable's device.\n",
      "              If not `None`, caches on another device.  Typical use is to cache\n",
      "              on the device where the Ops using the Variable reside, to deduplicate\n",
      "              copying through `Switch` and other conditional statements.\n",
      "         * name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
      "              uniquified automatically.\n",
      "         * dtype: If set, initial_value will be converted to the given type.\n",
      "              If `None`, either the datatype will be kept (if `initial_value` is\n",
      "              a Tensor), or `convert_to_tensor` will decide.\n",
      "         * constraint: A constraint function to be applied to the variable after\n",
      "              updates by some algorithms.\n",
      "         * use_resource: if True, a ResourceVariable is always created.\n",
      "         * synchronization: Indicates when a distributed a variable will be\n",
      "              aggregated. Accepted values are constants defined in the class\n",
      "              `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "              `AUTO` and the current `DistributionStrategy` chooses\n",
      "              when to synchronize.\n",
      "         * aggregation: Indicates how a distributed variable will be aggregated.\n",
      "              Accepted values are constants defined in the class\n",
      "              `tf.VariableAggregation`.\n",
      "        \n",
      "        This set may grow over time, so it's important the signature of creators is as\n",
      "        mentioned above.\n",
      "        \n",
      "        Args:\n",
      "          variable_creator: the passed creator\n",
      "        \n",
      "        Yields:\n",
      "          A scope in which the creator is active\n",
      "    \n",
      "    variable_op_scope(values, name_or_scope, default_name=None, initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, reuse=None, dtype=None, use_resource=None, constraint=None)\n",
      "        Deprecated: context manager for defining an op that creates variables.\n",
      "    \n",
      "    variables_initializer(var_list, name='init')\n",
      "        Returns an Op that initializes a list of variables.\n",
      "        \n",
      "        After you launch the graph in a session, you can run the returned Op to\n",
      "        initialize all the variables in `var_list`. This Op runs all the\n",
      "        initializers of the variables in `var_list` in parallel.\n",
      "        \n",
      "        Calling `initialize_variables()` is equivalent to passing the list of\n",
      "        initializers to `Group()`.\n",
      "        \n",
      "        If `var_list` is empty, however, the function still returns an Op that can\n",
      "        be run. That Op just has no effect.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        In TF2, variables are initialized immediately when they are created. There is\n",
      "        no longer a need to run variable initializers before using them.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to initialize.\n",
      "          name: Optional name for the returned operation.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that run the initializers of all the specified variables.\n",
      "    \n",
      "    vectorized_map(fn, elems, fallback_to_while_loop=True, warn=True)\n",
      "        Parallel map on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This method works similar to `tf.map_fn` but is optimized to run much faster,\n",
      "        possibly with a much larger memory footprint. The speedups are obtained by\n",
      "        vectorization (see [Auto-Vectorizing TensorFlow Graphs: Jacobians,\n",
      "        Auto-Batching and Beyond](https://arxiv.org/pdf/1903.04243.pdf)). The idea\n",
      "        behind vectorization is to semantically launch all the invocations of `fn` in\n",
      "        parallel and fuse corresponding operations across all these invocations. This\n",
      "        fusion is done statically at graph generation time and the generated code is\n",
      "        often similar in performance to a manually fused version.\n",
      "        \n",
      "        Because `tf.vectorized_map` fully parallelizes the batch, this method will\n",
      "        generally be significantly faster than using `tf.map_fn`, especially in eager\n",
      "        mode. However this is an experimental feature and currently has a lot of\n",
      "        limitations:\n",
      "          - There should be no data dependency between the different semantic\n",
      "            invocations of `fn`, i.e. it should be safe to map the elements of the\n",
      "            inputs in any order.\n",
      "          - Stateful kernels may mostly not be supported since these often imply a\n",
      "            data dependency. We do support a limited set of such stateful kernels\n",
      "            though (like RandomFoo, Variable operations like reads, etc).\n",
      "          - `fn` has limited support for control flow operations.\n",
      "          - `fn` should return nested structure of Tensors or Operations. However\n",
      "            if an Operation is returned, it should have zero outputs.\n",
      "          - The shape and dtype of any intermediate or output tensors in the\n",
      "            computation of `fn` should not depend on the input to `fn`.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "        def outer_product(a):\n",
      "          return tf.tensordot(a, a, 0)\n",
      "        \n",
      "        batch_size = 100\n",
      "        a = tf.ones((batch_size, 32, 32))\n",
      "        c = tf.vectorized_map(outer_product, a)\n",
      "        assert c.shape == (batch_size, 32, 32, 32, 32)\n",
      "        ```\n",
      "        \n",
      "        ```python\n",
      "        # Computing per-example gradients\n",
      "        \n",
      "        batch_size = 10\n",
      "        num_features = 32\n",
      "        layer = tf.keras.layers.Dense(1)\n",
      "        \n",
      "        def model_fn(arg):\n",
      "          with tf.GradientTape() as g:\n",
      "            inp, label = arg\n",
      "            inp = tf.expand_dims(inp, 0)\n",
      "            label = tf.expand_dims(label, 0)\n",
      "            prediction = layer(inp)\n",
      "            loss = tf.nn.l2_loss(label - prediction)\n",
      "          return g.gradient(loss, (layer.kernel, layer.bias))\n",
      "        \n",
      "        inputs = tf.random.uniform([batch_size, num_features])\n",
      "        labels = tf.random.uniform([batch_size, 1])\n",
      "        per_example_gradients = tf.vectorized_map(model_fn, (inputs, labels))\n",
      "        assert per_example_gradients[0].shape == (batch_size, num_features, 1)\n",
      "        assert per_example_gradients[1].shape == (batch_size, 1)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed. It accepts one argument, which will have\n",
      "            the same (possibly nested) structure as `elems`, and returns a possibly\n",
      "            nested structure of Tensors and Operations, which may be different than\n",
      "            the structure of `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension. The nested sequence of the\n",
      "            resulting slices will be mapped over by `fn`. The first dimensions of all\n",
      "            elements must broadcast to a consistent value; equivalently, each\n",
      "            element tensor must have first dimension of either `B` or `1`, for some\n",
      "            common batch size `B >= 1`.\n",
      "          fallback_to_while_loop: If true, on failing to vectorize an operation,\n",
      "            the unsupported op is wrapped in a tf.while_loop to execute the map\n",
      "            iterations. Note that this fallback only happens for unsupported ops and\n",
      "            other parts of `fn` are still vectorized. If false, on encountering an\n",
      "            unsupported op, a ValueError is thrown. Note that the fallbacks can result\n",
      "            in slowdowns since vectorization often yields speedup of one to two orders\n",
      "            of magnitude.\n",
      "          warn: If set to `false`, this will supress any warnings due to operation\n",
      "          conversions in the provided `fn` falling back to while loops.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors. Each tensor packs the\n",
      "          results of applying fn to tensors unpacked from elems along the first\n",
      "          dimension, from first to last.\n",
      "        \n",
      "          Although they are less common as user-visible inputs and outputs, note that\n",
      "          tensors of type `tf.variant` which represent tensor lists (for example from\n",
      "          `tf.raw_ops.TensorListFromTensor`) are vectorized by stacking the list\n",
      "          contents rather than the variant itself, and so the container tensor will\n",
      "          have a scalar shape when returned rather than the usual stacked shape. This\n",
      "          improves the performance of control flow gradient vectorization.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If vectorization fails and fallback_to_while_loop is False.\n",
      "    \n",
      "    verify_tensor_all_finite(t=None, msg=None, name=None, x=None, message=None)\n",
      "        Assert that the tensor does not contain any NaN's or Inf's.\n",
      "        \n",
      "        Args:\n",
      "          t: Tensor to check.\n",
      "          msg: Message to log on failure.\n",
      "          name: A name for this operation (optional).\n",
      "          x: Alias for t.\n",
      "          message: Alias for msg.\n",
      "        \n",
      "        Returns:\n",
      "          Same tensor as `t`.\n",
      "    \n",
      "    where(condition, x=None, y=None, name=None)\n",
      "        Return the elements, either from `x` or `y`, depending on the `condition`.\n",
      "        \n",
      "        If both `x` and `y` are None, then this operation returns the coordinates of\n",
      "        true elements of `condition`.  The coordinates are returned in a 2-D tensor\n",
      "        where the first dimension (rows) represents the number of true elements, and\n",
      "        the second dimension (columns) represents the coordinates of the true\n",
      "        elements. Keep in mind, the shape of the output tensor can vary depending on\n",
      "        how many true values there are in input. Indices are output in row-major\n",
      "        order.\n",
      "        \n",
      "        If both non-None, `x` and `y` must have the same shape.\n",
      "        The `condition` tensor must be a scalar if `x` and `y` are scalar.\n",
      "        If `x` and `y` are tensors of higher rank, then `condition` must be either a\n",
      "        vector with size matching the first dimension of `x`, or must have the same\n",
      "        shape as `x`.\n",
      "        \n",
      "        The `condition` tensor acts as a mask that chooses, based on the value at each\n",
      "        element, whether the corresponding element / row in the output should be taken\n",
      "        from `x` (if true) or `y` (if false).\n",
      "        \n",
      "        If `condition` is a vector and `x` and `y` are higher rank matrices, then it\n",
      "        chooses which row (outer dimension) to copy from `x` and `y`. If `condition`\n",
      "        has the same shape as `x` and `y`, then it chooses which element to copy from\n",
      "        `x` and `y`.\n",
      "        \n",
      "        Args:\n",
      "          condition: A `Tensor` of type `bool`\n",
      "          x: A Tensor which may have the same shape as `condition`. If `condition` is\n",
      "            rank 1, `x` may have higher rank, but its first dimension must match the\n",
      "            size of `condition`.\n",
      "          y: A `tensor` with the same shape and type as `x`.\n",
      "          name: A name of the operation (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same type and shape as `x`, `y` if they are non-None.\n",
      "          Otherwise, a `Tensor` with shape `(num_true, rank(condition))`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When exactly one of `x` or `y` is non-None.\n",
      "        \n",
      "        @compatibility(TF2)\n",
      "        \n",
      "        This API is compatible with eager execution and `tf.function`. However, this\n",
      "        is still a legacy API endpoint originally designed for TF1. To migrate to\n",
      "        fully-native TF2, please replace its usage with `tf.where` instead, which is\n",
      "        directly backwards compatible with `tf.compat.v1.where`.\n",
      "        \n",
      "        However,`tf.compat.v1.where` is more restrictive than `tf.where`, requiring\n",
      "        `x` and `y` to have the same shape, and returning a `Tensor` with the same\n",
      "        type and shape as `x`, `y` (if they are both non-None).\n",
      "        \n",
      "        `tf.where` will accept `x`, `y` that are not the same shape as long as they\n",
      "        are broadcastable with one another and with `condition`, and will return a\n",
      "        `Tensor` with shape broadcast from `condition`, `x`, and `y`.\n",
      "        \n",
      "        For example, the following works with `tf.where` but not `tf.compat.v1.where`:\n",
      "        \n",
      "        >>> tf.where([True, False, False, True], [1,2,3,4], [100])\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([  1, 100, 100,   4],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        >>> tf.where(True, [1,2,3,4], 100)\n",
      "        <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4],\n",
      "        dtype=int32)>\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    where_v2(condition, x=None, y=None, name=None)\n",
      "        Returns the indices of non-zero elements, or multiplexes `x` and `y`.\n",
      "        \n",
      "        This operation has two modes:\n",
      "        \n",
      "        1. **Return the indices of non-zero elements** - When only\n",
      "           `condition` is provided the result is an `int64` tensor where each row is\n",
      "           the index of a non-zero element of `condition`. The result's shape\n",
      "           is `[tf.math.count_nonzero(condition), tf.rank(condition)]`.\n",
      "        2. **Multiplex `x` and `y`** - When both `x` and `y` are provided the\n",
      "           result has the shape of `x`, `y`, and `condition` broadcast together. The\n",
      "           result is taken from `x` where `condition` is non-zero\n",
      "           or `y` where `condition` is zero.\n",
      "        \n",
      "        #### 1. Return the indices of non-zero elements\n",
      "        \n",
      "        Note: In this mode `condition` can have a dtype of `bool` or any numeric\n",
      "        dtype.\n",
      "        \n",
      "        If `x` and `y` are not provided (both are None):\n",
      "        \n",
      "        `tf.where` will return the indices of `condition` that are non-zero,\n",
      "        in the form of a 2-D tensor with shape `[n, d]`, where `n` is the number of\n",
      "        non-zero elements in `condition` (`tf.count_nonzero(condition)`), and `d` is\n",
      "        the number of axes of `condition` (`tf.rank(condition)`).\n",
      "        \n",
      "        Indices are output in row-major order. The `condition` can have a `dtype` of\n",
      "        `tf.bool`, or any numeric `dtype`.\n",
      "        \n",
      "        Here `condition` is a 1-axis `bool` tensor with 2 `True` values. The result\n",
      "        has a shape of `[2,1]`\n",
      "        \n",
      "        >>> tf.where([True, False, False, True]).numpy()\n",
      "        array([[0],\n",
      "               [3]])\n",
      "        \n",
      "        Here `condition` is a 2-axis integer tensor, with 3 non-zero values. The\n",
      "        result has a shape of `[3, 2]`.\n",
      "        \n",
      "        >>> tf.where([[1, 0, 0], [1, 0, 1]]).numpy()\n",
      "        array([[0, 0],\n",
      "               [1, 0],\n",
      "               [1, 2]])\n",
      "        \n",
      "        Here `condition` is a 3-axis float tensor, with 5 non-zero values. The output\n",
      "        shape is `[5, 3]`.\n",
      "        \n",
      "        >>> float_tensor = [[[0.1, 0], [0, 2.2], [3.5, 1e6]],\n",
      "        ...                 [[0,   0], [0,   0], [99,    0]]]\n",
      "        >>> tf.where(float_tensor).numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 1, 1],\n",
      "               [0, 2, 0],\n",
      "               [0, 2, 1],\n",
      "               [1, 2, 0]])\n",
      "        \n",
      "        These indices are the same that `tf.sparse.SparseTensor` would use to\n",
      "        represent the condition tensor:\n",
      "        \n",
      "        >>> sparse = tf.sparse.from_dense(float_tensor)\n",
      "        >>> sparse.indices.numpy()\n",
      "        array([[0, 0, 0],\n",
      "               [0, 1, 1],\n",
      "               [0, 2, 0],\n",
      "               [0, 2, 1],\n",
      "               [1, 2, 0]])\n",
      "        \n",
      "        A complex number is considered non-zero if either the real or imaginary\n",
      "        component is non-zero:\n",
      "        \n",
      "        >>> tf.where([complex(0.), complex(1.), 0+1j, 1+1j]).numpy()\n",
      "        array([[1],\n",
      "               [2],\n",
      "               [3]])\n",
      "        \n",
      "        #### 2. Multiplex `x` and `y`\n",
      "        \n",
      "        Note: In this mode `condition` must have a dtype of `bool`.\n",
      "        \n",
      "        If `x` and `y` are also provided (both have non-None values) the `condition`\n",
      "        tensor acts as a mask that chooses whether the corresponding\n",
      "        element / row in the output should be taken from `x` (if the element in\n",
      "        `condition` is `True`) or `y` (if it is `False`).\n",
      "        \n",
      "        The shape of the result is formed by\n",
      "        [broadcasting](https://docs.scipy.org/doc/numpy/reference/ufuncs.html)\n",
      "        together the shapes of `condition`, `x`, and `y`.\n",
      "        \n",
      "        When all three inputs have the same size, each is handled element-wise.\n",
      "        \n",
      "        >>> tf.where([True, False, False, True],\n",
      "        ...          [1, 2, 3, 4],\n",
      "        ...          [100, 200, 300, 400]).numpy()\n",
      "        array([  1, 200, 300,   4], dtype=int32)\n",
      "        \n",
      "        There are two main rules for broadcasting:\n",
      "        \n",
      "        1. If a tensor has fewer axes than the others, length-1 axes are added to the\n",
      "           left of the shape.\n",
      "        2. Axes with length-1 are streched to match the coresponding axes of the other\n",
      "           tensors.\n",
      "        \n",
      "        A length-1 vector is streched to match the other vectors:\n",
      "        \n",
      "        >>> tf.where([True, False, False, True], [1, 2, 3, 4], [100]).numpy()\n",
      "        array([  1, 100, 100,   4], dtype=int32)\n",
      "        \n",
      "        A scalar is expanded to match the other arguments:\n",
      "        \n",
      "        >>> tf.where([[True, False], [False, True]], [[1, 2], [3, 4]], 100).numpy()\n",
      "        array([[  1, 100], [100,   4]], dtype=int32)\n",
      "        >>> tf.where([[True, False], [False, True]], 1, 100).numpy()\n",
      "        array([[  1, 100], [100,   1]], dtype=int32)\n",
      "        \n",
      "        A scalar `condition` returns the complete `x` or `y` tensor, with\n",
      "        broadcasting applied.\n",
      "        \n",
      "        >>> tf.where(True, [1, 2, 3, 4], 100).numpy()\n",
      "        array([1, 2, 3, 4], dtype=int32)\n",
      "        >>> tf.where(False, [1, 2, 3, 4], 100).numpy()\n",
      "        array([100, 100, 100, 100], dtype=int32)\n",
      "        \n",
      "        For a non-trivial example of broadcasting, here `condition` has a shape of\n",
      "        `[3]`, `x` has a shape of `[3,3]`, and `y` has a shape of `[3,1]`.\n",
      "        Broadcasting first expands the shape of `condition` to `[1,3]`. The final\n",
      "        broadcast shape is `[3,3]`. `condition` will select columns from `x` and `y`.\n",
      "        Since `y` only has one column, all columns from `y` will be identical.\n",
      "        \n",
      "        >>> tf.where([True, False, True],\n",
      "        ...          x=[[1, 2, 3],\n",
      "        ...             [4, 5, 6],\n",
      "        ...             [7, 8, 9]],\n",
      "        ...          y=[[100],\n",
      "        ...             [200],\n",
      "        ...             [300]]\n",
      "        ... ).numpy()\n",
      "        array([[ 1, 100, 3],\n",
      "               [ 4, 200, 6],\n",
      "               [ 7, 300, 9]], dtype=int32)\n",
      "        \n",
      "        Note that if the gradient of either branch of the `tf.where` generates\n",
      "        a `NaN`, then the gradient of the entire `tf.where` will be `NaN`. This is\n",
      "        because the gradient calculation for `tf.where` combines the two branches, for\n",
      "        performance reasons.\n",
      "        \n",
      "        A workaround is to use an inner `tf.where` to ensure the function has\n",
      "        no asymptote, and to avoid computing a value whose gradient is `NaN` by\n",
      "        replacing dangerous inputs with safe inputs.\n",
      "        \n",
      "        Instead of this,\n",
      "        \n",
      "        >>> x = tf.constant(0., dtype=tf.float32)\n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   y = tf.where(x < 1., 0., 1. / x)\n",
      "        >>> print(tape.gradient(y, x))\n",
      "        tf.Tensor(nan, shape=(), dtype=float32)\n",
      "        \n",
      "        Although, the `1. / x` values are never used, its gradient is a `NaN` when\n",
      "        `x = 0`. Instead, we should guard that with another `tf.where`\n",
      "        \n",
      "        >>> x = tf.constant(0., dtype=tf.float32)\n",
      "        >>> with tf.GradientTape() as tape:\n",
      "        ...   tape.watch(x)\n",
      "        ...   safe_x = tf.where(tf.equal(x, 0.), 1., x)\n",
      "        ...   y = tf.where(x < 1., 0., 1. / safe_x)\n",
      "        >>> print(tape.gradient(y, x))\n",
      "        tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "        \n",
      "        See also:\n",
      "        \n",
      "        * `tf.sparse` - The indices returned by the first form of `tf.where` can be\n",
      "           useful in `tf.sparse.SparseTensor` objects.\n",
      "        * `tf.gather_nd`, `tf.scatter_nd`, and related ops - Given the\n",
      "          list of indices returned from `tf.where` the `scatter` and `gather` family\n",
      "          of ops can be used fetch values or insert values at those indices.\n",
      "        * `tf.strings.length` - `tf.string` is not an allowed dtype for the\n",
      "          `condition`. Use the string length instead.\n",
      "        \n",
      "        Args:\n",
      "          condition: A `tf.Tensor` of dtype bool, or any numeric dtype. `condition`\n",
      "            must have dtype `bool` when `x` and `y` are provided.\n",
      "          x: If provided, a Tensor which is of the same type as `y`, and has a shape\n",
      "            broadcastable with `condition` and `y`.\n",
      "          y: If provided, a Tensor which is of the same type as `x`, and has a shape\n",
      "            broadcastable with `condition` and `x`.\n",
      "          name: A name of the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          If `x` and `y` are provided:\n",
      "            A `Tensor` with the same type as `x` and `y`, and shape that\n",
      "            is broadcast from `condition`, `x`, and `y`.\n",
      "          Otherwise, a `Tensor` with shape `[tf.math.count_nonzero(condition),\n",
      "          tf.rank(condition)]`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When exactly one of `x` or `y` is non-None, or the shapes\n",
      "            are not all broadcastable.\n",
      "    \n",
      "    while_loop(cond, body, loop_vars, shape_invariants=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None, maximum_iterations=None, return_same_structure=False)\n",
      "        Repeat `body` while the condition `cond` is true.\n",
      "        \n",
      "        `cond` is a callable returning a boolean scalar tensor. `body` is a callable\n",
      "        returning a (possibly nested) tuple, namedtuple or list of tensors of the same\n",
      "        arity (length and structure) and types as `loop_vars`. `loop_vars` is a\n",
      "        (possibly nested) tuple, namedtuple or list of tensors that is passed to both\n",
      "        `cond` and `body`. `cond` and `body` both take as many arguments as there are\n",
      "        `loop_vars`.\n",
      "        \n",
      "        In addition to regular Tensors or IndexedSlices, the body may accept and\n",
      "        return TensorArray objects.  The flows of the TensorArray objects will\n",
      "        be appropriately forwarded between loops and during gradient calculations.\n",
      "        \n",
      "        Note that `while_loop` calls `cond` and `body` *exactly once* (inside the\n",
      "        call to `while_loop`, and not at all during `Session.run()`). `while_loop`\n",
      "        stitches together the graph fragments created during the `cond` and `body`\n",
      "        calls with some additional graph nodes to create the graph flow that\n",
      "        repeats `body` until `cond` returns false.\n",
      "        \n",
      "        For correctness, `tf.while_loop()` strictly enforces shape invariants for\n",
      "        the loop variables. A shape invariant is a (possibly partial) shape that\n",
      "        is unchanged across the iterations of the loop. An error will be raised\n",
      "        if the shape of a loop variable after an iteration is determined to be more\n",
      "        general than or incompatible with its shape invariant. For example, a shape\n",
      "        of [11, None] is more general than a shape of [11, 17], and [11, 21] is not\n",
      "        compatible with [11, 17]. By default (if the argument `shape_invariants` is\n",
      "        not specified), it is assumed that the initial shape of each tensor in\n",
      "        `loop_vars` is the same in every iteration. The `shape_invariants` argument\n",
      "        allows the caller to specify a less specific shape invariant for each loop\n",
      "        variable, which is needed if the shape varies between iterations. The\n",
      "        `tf.Tensor.set_shape`\n",
      "        function may also be used in the `body` function to indicate that\n",
      "        the output loop variable has a particular shape. The shape invariant for\n",
      "        SparseTensor and IndexedSlices are treated specially as follows:\n",
      "        \n",
      "        a) If a loop variable is a SparseTensor, the shape invariant must be\n",
      "        TensorShape([r]) where r is the rank of the dense tensor represented\n",
      "        by the sparse tensor. It means the shapes of the three tensors of the\n",
      "        SparseTensor are ([None], [None, r], [r]). NOTE: The shape invariant here\n",
      "        is the shape of the SparseTensor.dense_shape property. It must be the shape of\n",
      "        a vector.\n",
      "        \n",
      "        b) If a loop variable is an IndexedSlices, the shape invariant must be\n",
      "        a shape invariant of the values tensor of the IndexedSlices. It means\n",
      "        the shapes of the three tensors of the IndexedSlices are (shape, [shape[0]],\n",
      "        [shape.ndims]).\n",
      "        \n",
      "        `while_loop` implements non-strict semantics, enabling multiple iterations\n",
      "        to run in parallel. The maximum number of parallel iterations can be\n",
      "        controlled by `parallel_iterations`, which gives users some control over\n",
      "        memory consumption and execution order. For correct programs, `while_loop`\n",
      "        should return the same result for any parallel_iterations > 0.\n",
      "        \n",
      "        For training, TensorFlow stores the tensors that are produced in the\n",
      "        forward inference and are needed in back propagation. These tensors are a\n",
      "        main source of memory consumption and often cause OOM errors when training\n",
      "        on GPUs. When the flag swap_memory is true, we swap out these tensors from\n",
      "        GPU to CPU. This for example allows us to train RNN models with very long\n",
      "        sequences and large batches.\n",
      "        \n",
      "        Args:\n",
      "          cond: A callable that represents the termination condition of the loop.\n",
      "          body: A callable that represents the loop body.\n",
      "          loop_vars: A (possibly nested) tuple, namedtuple or list of numpy array,\n",
      "            `Tensor`, and `TensorArray` objects.\n",
      "          shape_invariants: The shape invariants for the loop variables.\n",
      "          parallel_iterations: The number of iterations allowed to run in parallel. It\n",
      "            must be a positive integer.\n",
      "          back_prop: Whether backprop is enabled for this while loop.\n",
      "          swap_memory: Whether GPU-CPU memory swap is enabled for this loop.\n",
      "          name: Optional name prefix for the returned tensors.\n",
      "          maximum_iterations: Optional maximum number of iterations of the while loop\n",
      "            to run.  If provided, the `cond` output is AND-ed with an additional\n",
      "            condition ensuring the number of iterations executed is no greater than\n",
      "            `maximum_iterations`.\n",
      "          return_same_structure: If True, output has same structure as `loop_vars`. If\n",
      "            eager execution is enabled, this is ignored (and always treated as True).\n",
      "        \n",
      "        Returns:\n",
      "          The output tensors for the loop variables after the loop.\n",
      "           If `return_same_structure` is True, the return value has the same\n",
      "           structure as `loop_vars`.\n",
      "           If `return_same_structure` is False, the return value is a Tensor,\n",
      "           TensorArray or IndexedSlice if the length of `loop_vars` is 1, or a list\n",
      "           otherwise.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `cond` or `body` is not callable.\n",
      "          ValueError: if `loop_vars` is empty.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        i = tf.constant(0)\n",
      "        c = lambda i: tf.less(i, 10)\n",
      "        b = lambda i: tf.add(i, 1)\n",
      "        r = tf.while_loop(c, b, [i])\n",
      "        ```\n",
      "        \n",
      "        Example with nesting and a namedtuple:\n",
      "        \n",
      "        ```python\n",
      "        import collections\n",
      "        Pair = collections.namedtuple('Pair', 'j, k')\n",
      "        ijk_0 = (tf.constant(0), Pair(tf.constant(1), tf.constant(2)))\n",
      "        c = lambda i, p: i < 10\n",
      "        b = lambda i, p: (i + 1, Pair((p.j + p.k), (p.j - p.k)))\n",
      "        ijk_final = tf.while_loop(c, b, ijk_0)\n",
      "        ```\n",
      "        \n",
      "        Example using shape_invariants:\n",
      "        \n",
      "        ```python\n",
      "        i0 = tf.constant(0)\n",
      "        m0 = tf.ones([2, 2])\n",
      "        c = lambda i, m: i < 10\n",
      "        b = lambda i, m: [i+1, tf.concat([m, m], axis=0)]\n",
      "        tf.while_loop(\n",
      "            c, b, loop_vars=[i0, m0],\n",
      "            shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])])\n",
      "        ```\n",
      "        \n",
      "        Example which demonstrates non-strict semantics: In the following\n",
      "        example, the final value of the counter `i` does not depend on `x`. So\n",
      "        the `while_loop` can increment the counter parallel to updates of `x`.\n",
      "        However, because the loop counter at one loop iteration depends\n",
      "        on the value at the previous iteration, the loop counter itself cannot\n",
      "        be incremented in parallel. Hence if we just want the final value of the\n",
      "        counter (which we print on the line `print(sess.run(i))`), then\n",
      "        `x` will never be incremented, but the counter will be updated on a\n",
      "        single thread. Conversely, if we want the value of the output (which we\n",
      "        print on the line `print(sess.run(out).shape)`), then the counter may be\n",
      "        incremented on its own thread, while `x` can be incremented in\n",
      "        parallel on a separate thread. In the extreme case, it is conceivable\n",
      "        that the thread incrementing the counter runs until completion before\n",
      "        `x` is incremented even a single time. The only thing that can never\n",
      "        happen is that the thread updating `x` can never get ahead of the\n",
      "        counter thread because the thread incrementing `x` depends on the value\n",
      "        of the counter.\n",
      "        \n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        \n",
      "        n = 10000\n",
      "        x = tf.constant(list(range(n)))\n",
      "        c = lambda i, x: i < n\n",
      "        b = lambda i, x: (tf.compat.v1.Print(i + 1, [i]), tf.compat.v1.Print(x + 1,\n",
      "        [i], \"x:\"))\n",
      "        i, out = tf.while_loop(c, b, (0, x))\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "            print(sess.run(i))  # prints [0] ... [9999]\n",
      "        \n",
      "            # The following line may increment the counter and x in parallel.\n",
      "            # The counter thread may get ahead of the other thread, but not the\n",
      "            # other way around. So you may see things like\n",
      "            # [9996] x:[9987]\n",
      "            # meaning that the counter thread is on iteration 9996,\n",
      "            # while the other thread is on iteration 9987\n",
      "            print(sess.run(out).shape)\n",
      "        ```\n",
      "    \n",
      "    wrap_function(fn, signature, name=None)\n",
      "        Wraps the TF 1.x function fn into a graph function.\n",
      "        \n",
      "        The python function `fn` will be called once with symbolic arguments specified\n",
      "        in the `signature`, traced, and turned into a graph function. Any variables\n",
      "        created by `fn` will be owned by the object returned by `wrap_function`. The\n",
      "        resulting graph function can be called with tensors which match the\n",
      "        signature.\n",
      "        \n",
      "        ```python\n",
      "        def f(x, do_add):\n",
      "          v = tf.Variable(5.0)\n",
      "          if do_add:\n",
      "            op = v.assign_add(x)\n",
      "          else:\n",
      "            op = v.assign_sub(x)\n",
      "          with tf.control_dependencies([op]):\n",
      "            return v.read_value()\n",
      "        \n",
      "        f_add = tf.compat.v1.wrap_function(f, [tf.TensorSpec((), tf.float32), True])\n",
      "        \n",
      "        assert float(f_add(1.0)) == 6.0\n",
      "        assert float(f_add(1.0)) == 7.0\n",
      "        \n",
      "        # Can call tf.compat.v1.wrap_function again to get a new trace, a new set\n",
      "        # of variables, and possibly different non-template arguments.\n",
      "        f_sub= tf.compat.v1.wrap_function(f, [tf.TensorSpec((), tf.float32), False])\n",
      "        \n",
      "        assert float(f_sub(1.0)) == 4.0\n",
      "        assert float(f_sub(1.0)) == 3.0\n",
      "        ```\n",
      "        \n",
      "        Both `tf.compat.v1.wrap_function` and `tf.function` create a callable\n",
      "        TensorFlow graph. But while `tf.function` runs all stateful operations\n",
      "        (e.g. `tf.print`) and sequences operations to provide the same semantics as\n",
      "        eager execution, `wrap_function` is closer to the behavior of `session.run` in\n",
      "        TensorFlow 1.x. It will not run any operations unless they are required to\n",
      "        compute the function's outputs, either through a data dependency or a control\n",
      "        dependency. Nor will it sequence operations.\n",
      "        \n",
      "        Unlike `tf.function`, `wrap_function` will only trace the Python function\n",
      "        once. As with placeholders in TF 1.x, shapes and dtypes must be provided to\n",
      "        `wrap_function`'s `signature` argument.\n",
      "        \n",
      "        Since it is only traced once, variables and state may be created inside the\n",
      "        function and owned by the function wrapper object.\n",
      "        \n",
      "        Args:\n",
      "          fn: python function to be wrapped\n",
      "          signature: the placeholder and python arguments to be passed to the wrapped\n",
      "            function\n",
      "          name: Optional. The name of the function.\n",
      "        \n",
      "        Returns:\n",
      "          the wrapped graph function.\n",
      "    \n",
      "    write_file(filename: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], contents: Annotated[Any, <class 'tensorflow.security.fuzzing.py.annotation_types.String'>], name=None)\n",
      "        Writes `contents` to the file at input `filename`.\n",
      "        \n",
      "        Creates the file and recursively creates directory if it does not exist.\n",
      "        \n",
      "        Args:\n",
      "          filename: A `Tensor` of type `string`.\n",
      "            scalar. The name of the file to which we write the contents.\n",
      "          contents: A `Tensor` of type `string`.\n",
      "            scalar. The content to be written to the output file.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The created Operation.\n",
      "    \n",
      "    zeros(shape, dtype=tf.float32, name=None, layout=None)\n",
      "        Creates a tensor with all elements set to zero.\n",
      "        \n",
      "        See also `tf.zeros_like`, `tf.ones`, `tf.fill`, `tf.eye`.\n",
      "        \n",
      "        This operation returns a tensor of type `dtype` with shape `shape` and\n",
      "        all elements set to zero.\n",
      "        \n",
      "        >>> tf.zeros([3, 4], tf.int32)\n",
      "        <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
      "        array([[0, 0, 0, 0],\n",
      "               [0, 0, 0, 0],\n",
      "               [0, 0, 0, 0]], dtype=int32)>\n",
      "        \n",
      "        Args:\n",
      "          shape: A `list` of integers, a `tuple` of integers, or a 1-D `Tensor` of\n",
      "            type `int32`.\n",
      "          dtype: The DType of an element in the resulting `Tensor`.\n",
      "          name: Optional string. A name for the operation.\n",
      "          layout: Optional, `tf.experimental.dtensor.Layout`. If provided, the result\n",
      "            is a [DTensor](https://www.tensorflow.org/guide/dtensor_overview) with the\n",
      "            provided layout.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to zero.\n",
      "    \n",
      "    zeros_like(tensor, dtype=None, name=None, optimize=True)\n",
      "        Creates a tensor with all elements set to zero.\n",
      "        \n",
      "        See also `tf.zeros`.\n",
      "        \n",
      "        Given a single tensor (`tensor`), this operation returns a tensor of the\n",
      "        same type and shape as `tensor` with all elements set to zero. Optionally,\n",
      "        you can use `dtype` to specify a new type for the returned tensor.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "          >>> tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "          >>> tf.zeros_like(tensor)\n",
      "          <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "          array([[0, 0, 0],\n",
      "                 [0, 0, 0]], dtype=int32)>\n",
      "        \n",
      "          >>> tf.zeros_like(tensor, dtype=tf.float32)\n",
      "          <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
      "          array([[0., 0., 0.],\n",
      "                 [0., 0., 0.]], dtype=float32)>\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          dtype: A type for the returned `Tensor`. Must be `float16`, `float32`,\n",
      "            `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`,\n",
      "            `complex64`, `complex128`, `bool` or `string`. (optional)\n",
      "          name: A name for the operation (optional).\n",
      "          optimize: if `True`, attempt to statically determine the shape of `tensor`\n",
      "            and encode it as a constant. (optional, defaults to `True`)\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to zero.\n",
      "    \n",
      "    zeta(x: typing.Annotated[_any, ~TV_Zeta_T], q: typing.Annotated[_any, ~TV_Zeta_T], name=None) -> typing.Annotated[_any, ~TV_Zeta_T]\n",
      "        Compute the Hurwitz zeta function \\\\(\\zeta(x, q)\\\\).\n",
      "        \n",
      "        The Hurwitz zeta function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(\\zeta(x, q) = \\sum_{n=0}^{\\infty} (q + n)^{-x}\\\\)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          q: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "\n",
      "DATA\n",
      "    AUTO_REUSE = <_ReuseMode.AUTO_REUSE: 1>\n",
      "        @compatibility(TF2)\n",
      "        `tf.compat.v1.AUTO_REUSE` is a legacy API that is a no-op when TF2 behaviors\n",
      "        are enabled.\n",
      "        \n",
      "        If you rely on `get_variable` and auto-reuse, see the\n",
      "        [model mapping guide](https://www.tensorflow.org/guide/migrate/model_mapping)\n",
      "        for more info on how to migrate your code.\n",
      "        \n",
      "        Note: when you use the `tf.compat.v1.keras.utils.track_tf1_style_variables`\n",
      "        API as described in the above guide, `get_variable` will always behave as if\n",
      "        `v1.AUTO_REUSE` is set. Without the decorator, reuse will be ignored and new\n",
      "        variables will always be created, regardless of if they have already been\n",
      "        created.\n",
      "        @end_compatibility\n",
      "        \n",
      "        When passed in as the value for the `reuse` flag, `AUTO_REUSE` indicates that\n",
      "        get_variable() should create the requested variable if it doesn't exist or, if\n",
      "        it does exist, simply return it.\n",
      "    \n",
      "    COMPILER_VERSION = 'Apple LLVM 14.0.3 (clang-1403.0.22.14.1)'\n",
      "    CXX11_ABI_FLAG = 0\n",
      "    CXX_VERSION = 201703\n",
      "    GIT_VERSION = 'v2.16.1-0-g5bc9d26649c'\n",
      "    GRAPH_DEF_VERSION = 1766\n",
      "    GRAPH_DEF_VERSION_MIN_CONSUMER = 0\n",
      "    GRAPH_DEF_VERSION_MIN_PRODUCER = 0\n",
      "    MONOLITHIC_BUILD = 0\n",
      "    QUANTIZED_DTYPES = frozenset({tf.qint8, tf.quint8, tf.qint32, tf.qint8...\n",
      "    VERSION = '2.16.1'\n",
      "    __all__ = ['AUTO_REUSE', 'AggregationMethod', 'Assert', 'AttrValue', '...\n",
      "    __compiler_version__ = 'Apple LLVM 14.0.3 (clang-1403.0.22.14.1)'\n",
      "    __cxx11_abi_flag__ = 0\n",
      "    __cxx_version__ = 201703\n",
      "    __git_version__ = 'v2.16.1-0-g5bc9d26649c'\n",
      "    __monolithic_build__ = 0\n",
      "    bfloat16 = tf.bfloat16\n",
      "        16-bit bfloat (brain floating point).\n",
      "    \n",
      "    bool = tf.bool\n",
      "        Boolean.\n",
      "    \n",
      "    complex128 = tf.complex128\n",
      "        128-bit complex.\n",
      "    \n",
      "    complex64 = tf.complex64\n",
      "        64-bit complex.\n",
      "    \n",
      "    double = tf.float64\n",
      "        64-bit (double precision) floating-point.\n",
      "    \n",
      "    float16 = tf.float16\n",
      "        16-bit (half precision) floating-point.\n",
      "    \n",
      "    float32 = tf.float32\n",
      "        32-bit (single precision) floating-point.\n",
      "    \n",
      "    float64 = tf.float64\n",
      "        64-bit (double precision) floating-point.\n",
      "    \n",
      "    half = tf.float16\n",
      "        16-bit (half precision) floating-point.\n",
      "    \n",
      "    int16 = tf.int16\n",
      "        Signed 16-bit integer.\n",
      "    \n",
      "    int32 = tf.int32\n",
      "        Signed 32-bit integer.\n",
      "    \n",
      "    int64 = tf.int64\n",
      "        Signed 64-bit integer.\n",
      "    \n",
      "    int8 = tf.int8\n",
      "        Signed 8-bit integer.\n",
      "    \n",
      "    newaxis = None\n",
      "    qint16 = tf.qint16\n",
      "        Signed quantized 16-bit integer.\n",
      "    \n",
      "    qint32 = tf.qint32\n",
      "        signed quantized 32-bit integer.\n",
      "    \n",
      "    qint8 = tf.qint8\n",
      "        Signed quantized 8-bit integer.\n",
      "    \n",
      "    quint16 = tf.quint16\n",
      "        Unsigned quantized 16-bit integer.\n",
      "    \n",
      "    quint8 = tf.quint8\n",
      "        Unsigned quantized 8-bit integer.\n",
      "    \n",
      "    resource = tf.resource\n",
      "        Handle to a mutable, dynamically allocated resource.\n",
      "    \n",
      "    string = tf.string\n",
      "        Variable-length string, represented as byte array.\n",
      "    \n",
      "    uint16 = tf.uint16\n",
      "        Unsigned 16-bit (word) integer.\n",
      "    \n",
      "    uint32 = tf.uint32\n",
      "        Unsigned 32-bit (dword) integer.\n",
      "    \n",
      "    uint64 = tf.uint64\n",
      "        Unsigned 64-bit (qword) integer.\n",
      "    \n",
      "    uint8 = tf.uint8\n",
      "        Unsigned 8-bit (byte) integer.\n",
      "    \n",
      "    variant = tf.variant\n",
      "        Data of arbitrary type (known at runtime).\n",
      "\n",
      "VERSION\n",
      "    2.16.1\n",
      "\n",
      "FILE\n",
      "    /Users/user/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.compat.v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 shape: (1500, 2) Batch 2 shape: (1500, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 13:32:50.303159: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 6.255\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 6.953\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 7.388\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMAGAN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_MAGAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/Python_Files/MAGAN.py:390\u001b[0m, in \u001b[0;36mrun_MAGAN\u001b[0;34m(xb1, xb2, labels1, labels2)\u001b[0m\n\u001b[1;32m    387\u001b[0m xb1_, labels1_ \u001b[38;5;241m=\u001b[39m loadb1\u001b[38;5;241m.\u001b[39mnext_batch(batch_size)\n\u001b[1;32m    388\u001b[0m xb2_, labels2_ \u001b[38;5;241m=\u001b[39m loadb2\u001b[38;5;241m.\u001b[39mnext_batch(batch_size)\n\u001b[0;32m--> 390\u001b[0m \u001b[43mmagan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb2_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Evaluate the loss and plot\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Work/Python_Files/MAGAN.py:271\u001b[0m, in \u001b[0;36mMAGAN.train_model\u001b[0;34m(self, xb1, xb2)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    266\u001b[0m feed \u001b[38;5;241m=\u001b[39m {tbn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxb1:0\u001b[39m\u001b[38;5;124m'\u001b[39m): xb1,\n\u001b[1;32m    267\u001b[0m         tbn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxb2:0\u001b[39m\u001b[38;5;124m'\u001b[39m): xb2,\n\u001b[1;32m    268\u001b[0m         tbn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr:0\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[1;32m    269\u001b[0m         tbn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_training:0\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m--> 271\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_op_G\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mrun([obn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_op_D\u001b[39m\u001b[38;5;124m'\u001b[39m)], feed_dict\u001b[38;5;241m=\u001b[39mfeed)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1215\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1401\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1404\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAGAN.run_MAGAN(xb1, xb2, labels1, labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 shape: (214, 5) Batch 2 shape: (214, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 13:28:43.011838: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 6.155\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 6.835\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 7.259\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 7.657\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: D G 0.000 8.078\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMAGAN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_MAGAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43miris_tma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miris_tma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43miris_tma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/Python_Files/MAGAN.py:390\u001b[0m, in \u001b[0;36mrun_MAGAN\u001b[0;34m(xb1, xb2, labels1)\u001b[0m\n\u001b[1;32m    387\u001b[0m xb1_, labels1_ \u001b[38;5;241m=\u001b[39m loadb1\u001b[38;5;241m.\u001b[39mnext_batch(batch_size)\n\u001b[1;32m    388\u001b[0m xb2_, labels2_ \u001b[38;5;241m=\u001b[39m loadb2\u001b[38;5;241m.\u001b[39mnext_batch(batch_size)\n\u001b[0;32m--> 390\u001b[0m \u001b[43mmagan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb2_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Evaluate the loss and plot\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Work/Python_Files/MAGAN.py:272\u001b[0m, in \u001b[0;36mMAGAN.train_model\u001b[0;34m(self, xb1, xb2)\u001b[0m\n\u001b[1;32m    266\u001b[0m feed \u001b[38;5;241m=\u001b[39m {tbn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxb1:0\u001b[39m\u001b[38;5;124m'\u001b[39m): xb1,\n\u001b[1;32m    267\u001b[0m         tbn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxb2:0\u001b[39m\u001b[38;5;124m'\u001b[39m): xb2,\n\u001b[1;32m    268\u001b[0m         tbn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr:0\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[1;32m    269\u001b[0m         tbn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_training:0\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    271\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mrun([obn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_op_G\u001b[39m\u001b[38;5;124m'\u001b[39m)], feed_dict\u001b[38;5;241m=\u001b[39mfeed)\n\u001b[0;32m--> 272\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_op_D\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1215\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1401\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1404\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/.conda/lib/python3.11/site-packages/tensorflow/python/client/session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAGAN.run_MAGAN(iris_tma.split_A, iris_tma.split_B, labels1 = iris_tma.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/user/Desktop/Work/Python_Files'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
